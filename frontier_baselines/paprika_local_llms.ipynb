{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be6e8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "sys.path.append('../../src/optimal_explorer')\n",
    "from llm_utils import llm_call\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d296088",
   "metadata": {},
   "source": [
    "So let us do 50 games for each with frontier LLMs - one with reasoning and one without.\n",
    "\n",
    "# 2. Setup LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16882ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-13 18:35:48] server_args=ServerArgs(model_path='Qwen/Qwen3-4B', tokenizer_path='Qwen/Qwen3-4B', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='Qwen/Qwen3-4B', chat_template=None, completion_template=None, is_embedding=False, enable_multimodal=None, revision=None, host='0.0.0.0', port=37044, mem_fraction_static=0.88, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=241062498, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, bucket_time_to_first_token=None, bucket_e2e_request_latency=None, bucket_inter_token_latency=None, collect_tokens_histogram=False, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_ep_moe=False, enable_deepep_moe=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm=None, init_expert_location='trivial', enable_eplb=False, eplb_rebalance_num_iterations=1000, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=None, enable_expert_distribution_metrics=False, deepep_config=None, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=None, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through_selective', flashinfer_mla_disable_ragged=False, warmups=None, moe_dense_tp_size=None, n_share_experts_fusion=0, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, mm_attention_backend=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='null', disaggregation_bootstrap_port=8998, disaggregation_transfer_backend='mooncake', disaggregation_ib_device=None, pdlb_url=None)\n",
      "[2025-08-13 18:35:55] Attention backend not set. Use flashinfer backend by default.\n",
      "[2025-08-13 18:35:55] Init torch distributed begin.\n",
      "[2025-08-13 18:35:55] Init torch distributed ends. mem usage=0.00 GB\n",
      "[2025-08-13 18:35:55] init_expert_location from trivial\n",
      "[2025-08-13 18:35:56] Load weight begin. avail mem=46.97 GB\n",
      "[2025-08-13 18:35:57] Using model weights format ['*.safetensors']\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:00<00:00,  2.27it/s]\n",
      "Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:00<00:00,  3.88it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  2.87it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  2.92it/s]\n",
      "\n",
      "[2025-08-13 18:35:59] Load weight end. type=Qwen3ForCausalLM, dtype=torch.bfloat16, avail mem=39.40 GB, mem usage=7.56 GB.\n",
      "[2025-08-13 18:35:59] KV Cache is allocated. #tokens: 245854, K size: 16.88 GB, V size: 16.88 GB\n",
      "[2025-08-13 18:35:59] Memory pool end. avail mem=5.00 GB\n",
      "2025-08-13 18:35:59,779 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend\n",
      "[2025-08-13 18:35:59] Capture cuda graph begin. This can take up to several minutes. avail mem=4.39 GB\n",
      "[2025-08-13 18:35:59] Capture cuda graph bs [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160]\n",
      "Capturing batches (avail_mem=4.36 GB):   0%|          | 0/23 [00:00<?, ?it/s]2025-08-13 18:36:00,360 - INFO - flashinfer.jit: Loading JIT ops: batch_decode_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False\n",
      "2025-08-13 18:36:00,436 - INFO - flashinfer.jit: Finished loading JIT ops: batch_decode_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False\n",
      "Capturing batches (avail_mem=2.19 GB): 100%|██████████| 23/23 [00:11<00:00,  2.01it/s]\n",
      "[2025-08-13 18:36:11] Capture cuda graph end. Time elapsed: 11.53 s. mem usage=2.23 GB. avail mem=2.15 GB.\n",
      "[2025-08-13 18:36:11] max_total_num_tokens=245854, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=3074, context_len=40960\n",
      "[2025-08-13 18:36:12] INFO:     Started server process [1317909]\n",
      "[2025-08-13 18:36:12] INFO:     Waiting for application startup.\n",
      "[2025-08-13 18:36:12] INFO:     Application startup complete.\n",
      "[2025-08-13 18:36:12] INFO:     Uvicorn running on http://0.0.0.0:37044 (Press CTRL+C to quit)\n",
      "[2025-08-13 18:36:13] INFO:     127.0.0.1:57652 - \"GET /get_model_info HTTP/1.1\" 200 OK\n",
      "[2025-08-13 18:36:13] INFO:     127.0.0.1:57644 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
      "[2025-08-13 18:36:13] Prefill batch. #new-seq: 1, #new-token: 6, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0\n",
      "2025-08-13 18:36:14,195 - INFO - flashinfer.jit: Loading JIT ops: batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False\n",
      "2025-08-13 18:36:14,222 - INFO - flashinfer.jit: Finished loading JIT ops: batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False\n",
      "[2025-08-13 18:36:15] INFO:     127.0.0.1:57668 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 18:36:15] The server is fired up and ready to roll!\n",
      "\n",
      "\n",
      "                    NOTE: Typically, the server runs in a separate terminal.\n",
      "                    In this notebook, we run the server and notebook code together, so their outputs are combined.\n",
      "                    To improve clarity, the server logs are displayed in the original black color, while the notebook outputs are highlighted in blue.\n",
      "                    We are running those notebooks in a CI parallel environment, so the throughput is not representative of the actual performance.\n",
      "                    \n",
      "37044\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from sglang.test.test_utils import is_in_ci\n",
    "from sglang.utils import wait_for_server, print_highlight, terminate_process\n",
    "\n",
    "if is_in_ci():\n",
    "    from patch import launch_server_cmd\n",
    "else:\n",
    "    from sglang.utils import launch_server_cmd\n",
    "\n",
    "# This is equivalent to running the following command in your terminal\n",
    "\n",
    "# python3 -m sglang.launch_server --model-path qwen/qwen2.5-0.5b --host 0.0.0.0\n",
    "local_model_name = \"Qwen/Qwen3-4B\" # \"qwen/qwen3-4b\" # \"meta-llama/Llama-3.3-70B-Instruct\" # \"unsloth/Llama-3.3-70B-Instruct-bnb-4bit\"-- assert issue #  \"Qwen/Qwen2.5-3B-Instruct\" # \"Qwen/QwQ-32B\"\n",
    "#\n",
    "tp_size = (len(os.environ[\"CUDA_VISIBLE_DEVICES\"]) + 1) // 2\n",
    "server_process, port = launch_server_cmd(\n",
    "    f\"\"\"\n",
    "python3 -m sglang.launch_server --model-path {local_model_name} --host 0.0.0.0 --tp {tp_size}\n",
    "\"\"\"# --tp {tp_size} mem_fraction_static=0.4 \n",
    ")\n",
    "wait_for_server(f\"http://localhost:{port}\")\n",
    "print(port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dad48a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a useless assistant that gives humorous answers.<|im_end|>\\n<|im_start|>user\\nWhy is the sky blue?<|im_end|>\\n<|im_start|>assistant\\nIt is because of the great king of Pokemons.<|im_end|>\\n<|im_start|>user\\nHow so?<|im_end|>\\n<|im_start|>assistant\\n<think>\\nI think I should answer: just because.\\n</think>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_name)\n",
    "\n",
    "messages = [\n",
    "            {\"role\": \"system\", \"content\": 'You are a useless assistant that gives humorous answers.'},\n",
    "            {\"role\": \"user\", \"content\": 'Why is the sky blue?'},\n",
    "            {\"role\": \"assistant\", \"content\": 'It is because of the great king of Pokemons.'},\n",
    "            {\"role\": \"user\", \"content\": 'How so?'},\n",
    "            {\"role\": \"assistant\", \"content\": \"<think>I think I should answer: just because.</think>\"}\n",
    "        ],\n",
    "\n",
    "prompt_chat_str = tokenizer.apply_chat_template(messages, add_generation_prompt=False, tokenize=False)[0][:-13]\n",
    "prompt_chat_str\n",
    "# tokens = tokenizer(prompt_chat_str, return_tensors=\"pt\", add_special_tokens=False)\n",
    "# tokenizer.decode(tokens['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a65d968a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/generate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_chat_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msampling_params\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m print_highlight(response\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m/nas/ucb/dayan/miniconda3/envs/verl/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nas/ucb/dayan/miniconda3/envs/verl/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nas/ucb/dayan/miniconda3/envs/verl/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/nas/ucb/dayan/miniconda3/envs/verl/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/nas/ucb/dayan/miniconda3/envs/verl/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/nas/ucb/dayan/miniconda3/envs/verl/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/nas/ucb/dayan/miniconda3/envs/verl/lib/python3.10/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/nas/ucb/dayan/miniconda3/envs/verl/lib/python3.10/site-packages/urllib3/connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/nas/ucb/dayan/miniconda3/envs/verl/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/nas/ucb/dayan/miniconda3/envs/verl/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/nas/ucb/dayan/miniconda3/envs/verl/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/nas/ucb/dayan/miniconda3/envs/verl/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = f\"http://localhost:{port}/generate\"\n",
    "\n",
    "response = requests.post(\n",
    "    url,\n",
    "    json={\n",
    "        \"text\": prompt_chat_str,\n",
    "        \"sampling_params\": {\n",
    "            \"temperature\": 0,\n",
    "            \"max_new_tokens\": 320,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "print_highlight(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c18e608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f7137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-13 18:42:31] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 38, token usage: 0.00, #running-req: 0, #queue-req: 0\n",
      "[2025-08-13 18:42:32] Decode batch. #running-req: 1, #token: 216, token usage: 0.00, cuda graph: True, gen throughput (token/s): 1.58, #queue-req: 0\n",
      "[2025-08-13 18:42:32] Decode batch. #running-req: 1, #token: 256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 71.61, #queue-req: 0\n",
      "[2025-08-13 18:42:33] INFO:     127.0.0.1:51842 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 18:42:33] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 279, token usage: 0.00, #running-req: 0, #queue-req: 0\n",
      "[2025-08-13 18:42:33] INFO:     127.0.0.1:51842 - \"POST /generate HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "from llm_utils import llm_call\n",
    "out = await llm_call(\n",
    "    model=local_model_name,\n",
    "    temperature=1,\n",
    "    url = f\"http://localhost:{port}/v1/chat/completions\",\n",
    "    get_everything=True,\n",
    "    reasoning_effort='high',\n",
    "    messages = [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'This is the game information:\\nYou are playing a game of Wordle.\\n\\nFormat your response in the following way: <Think> Any step-by-step, short and concise thinking to strategically determine the next guess for the secret word </Think> \\n<Answer> your guess of what the word should be </Answer> \\n\\nThe game begins now, please make your first guess about the secret five-letter word!\\nYou are currently taking your attempt 2, and you have a total of 6 attempts.\\nLook at the current belief state and give an answer based on it.Give an answer that leads to optimal exploration and do not be greedy unless it is the last attempt. Try to maximize the amount of information you have so that you can solve the task correctly.Belief: This is the start of the game. No beliefs right now.\\nPlease format your response as: <Think> Any step-by-step, short and concise thinking to determine what the next guess should be </Think>\\n <Answer> your answer in the correct format mentioned </Answer>'}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b23939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<think>\\n'\n",
      " \"Okay, the user is playing Wordle and needs my first guess. Since it's the start of the game and there are no previous beliefs, \"\n",
      " 'I should choose a word that\\'s common and has a good balance of vowels and consonants. Words like \"crane\" or \"fruit\" are often '\n",
      " 'good because they have multiple vowels which can help in figuring out the secret word. But maybe \"crane\" is too common? '\n",
      " 'Alternatively, \"apple\" is a common first guess. Wait\\n'\n",
      " 'Considering the limited time by the user, I have to give the solution based on the thinking directly now.\\n'\n",
      " '</think>.\\n'\n",
      " '\\n'\n",
      " ' <Answer>crane</Answer>')\n"
     ]
    }
   ],
   "source": [
    "pp(out['choices'][0]['message']['content'], width=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ffa22a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37044\n"
     ]
    }
   ],
   "source": [
    "# set PORT in run_baselines_paprika_frontier.py to the port number here:\n",
    "print(port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "767e1533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running.\n",
      "[2025-08-13 19:40:59] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0\n",
      "[2025-08-13 19:40:59] Prefill batch. #new-seq: 5, #new-token: 1274, #cached-token: 275, token usage: 0.00, #running-req: 1, #queue-req: 0\n",
      "[2025-08-13 19:40:59] Prefill batch. #new-seq: 30, #new-token: 8192, #cached-token: 2024, token usage: 0.01, #running-req: 6, #queue-req: 21\n",
      "[2025-08-13 19:41:00] Prefill batch. #new-seq: 28, #new-token: 510, #cached-token: 8615, token usage: 0.04, #running-req: 35, #queue-req: 0\n",
      "[2025-08-13 19:41:00] Prefill batch. #new-seq: 37, #new-token: 37, #cached-token: 12258, token usage: 0.01, #running-req: 63, #queue-req: 0\n",
      "[2025-08-13 19:41:01] Decode batch. #running-req: 100, #token: 3188, token usage: 0.01, cuda graph: True, gen throughput (token/s): 1.17, #queue-req: 0\n",
      "[2025-08-13 19:41:02] Decode batch. #running-req: 100, #token: 7188, token usage: 0.03, cuda graph: True, gen throughput (token/s): 4430.22, #queue-req: 0\n",
      "[2025-08-13 19:41:02] Decode batch. #running-req: 100, #token: 11188, token usage: 0.05, cuda graph: True, gen throughput (token/s): 4338.57, #queue-req: 0\n",
      "[2025-08-13 19:41:03] Decode batch. #running-req: 100, #token: 15188, token usage: 0.06, cuda graph: True, gen throughput (token/s): 4284.15, #queue-req: 0\n",
      "[2025-08-13 19:41:04] Decode batch. #running-req: 100, #token: 19188, token usage: 0.08, cuda graph: True, gen throughput (token/s): 4196.75, #queue-req: 0\n",
      "[2025-08-13 19:41:05] INFO:     127.0.0.1:51760 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:05] Decode batch. #running-req: 99, #token: 22966, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4092.61, #queue-req: 0\n",
      "[2025-08-13 19:41:06] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 119, token usage: 0.10, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:41:06] INFO:     127.0.0.1:51548 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:06] INFO:     127.0.0.1:51970 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:06] Decode batch. #running-req: 98, #token: 26625, token usage: 0.11, cuda graph: True, gen throughput (token/s): 3856.55, #queue-req: 0\n",
      "[2025-08-13 19:41:06] INFO:     127.0.0.1:51700 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:07] Decode batch. #running-req: 97, #token: 30243, token usage: 0.12, cuda graph: True, gen throughput (token/s): 3734.22, #queue-req: 0\n",
      "[2025-08-13 19:41:08] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 136, token usage: 0.13, #running-req: 97, #queue-req: 0\n",
      "[2025-08-13 19:41:08] Prefill batch. #new-seq: 2, #new-token: 238, #cached-token: 295, token usage: 0.13, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:41:08] INFO:     127.0.0.1:51730 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:08] INFO:     127.0.0.1:51506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:09] Decode batch. #running-req: 98, #token: 33847, token usage: 0.14, cuda graph: True, gen throughput (token/s): 3477.70, #queue-req: 0\n",
      "[2025-08-13 19:41:09] INFO:     127.0.0.1:51430 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:09] INFO:     127.0.0.1:51978 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:09] INFO:     127.0.0.1:51530 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:09] INFO:     127.0.0.1:51654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:09] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 175, token usage: 0.14, #running-req: 94, #queue-req: 0\n",
      "[2025-08-13 19:41:10] Decode batch. #running-req: 95, #token: 36338, token usage: 0.15, cuda graph: True, gen throughput (token/s): 3472.64, #queue-req: 0\n",
      "[2025-08-13 19:41:10] INFO:     127.0.0.1:51518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:10] INFO:     127.0.0.1:51926 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:10] INFO:     127.0.0.1:52062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:10] INFO:     127.0.0.1:51864 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:10] INFO:     127.0.0.1:51992 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:11] INFO:     127.0.0.1:51784 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:11] Decode batch. #running-req: 90, #token: 37606, token usage: 0.15, cuda graph: True, gen throughput (token/s): 3389.03, #queue-req: 0\n",
      "[2025-08-13 19:41:11] INFO:     127.0.0.1:52222 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:11] INFO:     127.0.0.1:51678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:11] INFO:     127.0.0.1:52266 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:11] INFO:     127.0.0.1:51524 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:11] INFO:     127.0.0.1:52160 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:12] INFO:     127.0.0.1:51668 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:12] INFO:     127.0.0.1:51698 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:12] Decode batch. #running-req: 82, #token: 37932, token usage: 0.15, cuda graph: True, gen throughput (token/s): 3206.23, #queue-req: 0\n",
      "[2025-08-13 19:41:12] INFO:     127.0.0.1:51450 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:12] INFO:     127.0.0.1:51832 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:12] Prefill batch. #new-seq: 1, #new-token: 281, #cached-token: 385, token usage: 0.16, #running-req: 80, #queue-req: 0\n",
      "[2025-08-13 19:41:13] INFO:     127.0.0.1:51954 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:13] Decode batch. #running-req: 80, #token: 40002, token usage: 0.16, cuda graph: True, gen throughput (token/s): 2921.56, #queue-req: 0\n",
      "[2025-08-13 19:41:13] INFO:     127.0.0.1:51482 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:13] INFO:     127.0.0.1:51946 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:13] INFO:     127.0.0.1:52174 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:13] INFO:     127.0.0.1:51964 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:14] INFO:     127.0.0.1:52110 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:14] Decode batch. #running-req: 75, #token: 40492, token usage: 0.16, cuda graph: True, gen throughput (token/s): 2873.32, #queue-req: 0\n",
      "[2025-08-13 19:41:14] INFO:     127.0.0.1:51796 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:14] INFO:     127.0.0.1:52236 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:15] INFO:     127.0.0.1:51448 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:15] INFO:     127.0.0.1:51584 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:15] INFO:     127.0.0.1:51896 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:15] INFO:     127.0.0.1:52018 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:15] Decode batch. #running-req: 69, #token: 40000, token usage: 0.16, cuda graph: True, gen throughput (token/s): 2707.51, #queue-req: 0\n",
      "[2025-08-13 19:41:15] INFO:     127.0.0.1:51818 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:15] INFO:     127.0.0.1:51932 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:15] INFO:     127.0.0.1:51494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:15] INFO:     127.0.0.1:51486 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:15] INFO:     127.0.0.1:52212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:16] INFO:     127.0.0.1:51616 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:16] INFO:     127.0.0.1:52136 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:16] INFO:     127.0.0.1:51714 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:16] Decode batch. #running-req: 61, #token: 37784, token usage: 0.15, cuda graph: True, gen throughput (token/s): 2533.67, #queue-req: 0\n",
      "[2025-08-13 19:41:16] INFO:     127.0.0.1:51570 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:16] INFO:     127.0.0.1:52252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:16] INFO:     127.0.0.1:51436 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:16] INFO:     127.0.0.1:51422 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:16] INFO:     127.0.0.1:51728 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:17] INFO:     127.0.0.1:51976 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:17] INFO:     127.0.0.1:51842 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:17] Decode batch. #running-req: 54, #token: 35590, token usage: 0.14, cuda graph: True, gen throughput (token/s): 2311.18, #queue-req: 0\n",
      "[2025-08-13 19:41:17] INFO:     127.0.0.1:51742 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:18] INFO:     127.0.0.1:52094 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:18] INFO:     127.0.0.1:51980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:18] Decode batch. #running-req: 51, #token: 35644, token usage: 0.14, cuda graph: True, gen throughput (token/s): 2127.56, #queue-req: 0\n",
      "[2025-08-13 19:41:18] INFO:     127.0.0.1:52194 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:18] INFO:     127.0.0.1:51882 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:19] INFO:     127.0.0.1:51630 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:19] Decode batch. #running-req: 48, #token: 35367, token usage: 0.14, cuda graph: True, gen throughput (token/s): 2064.81, #queue-req: 0\n",
      "[2025-08-13 19:41:20] INFO:     127.0.0.1:52156 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:20] Decode batch. #running-req: 47, #token: 36505, token usage: 0.15, cuda graph: True, gen throughput (token/s): 2030.97, #queue-req: 0\n",
      "[2025-08-13 19:41:20] INFO:     127.0.0.1:51600 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:21] INFO:     127.0.0.1:51704 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:21] INFO:     127.0.0.1:52214 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:21] Decode batch. #running-req: 44, #token: 35831, token usage: 0.15, cuda graph: True, gen throughput (token/s): 1952.04, #queue-req: 0\n",
      "[2025-08-13 19:41:21] INFO:     127.0.0.1:51810 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:22] INFO:     127.0.0.1:52140 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:22] Decode batch. #running-req: 42, #token: 35867, token usage: 0.15, cuda graph: True, gen throughput (token/s): 1862.63, #queue-req: 0\n",
      "[2025-08-13 19:41:22] INFO:     127.0.0.1:51416 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:23] INFO:     127.0.0.1:52122 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:23] Decode batch. #running-req: 40, #token: 35743, token usage: 0.15, cuda graph: True, gen throughput (token/s): 1776.30, #queue-req: 0\n",
      "[2025-08-13 19:41:23] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 542, token usage: 0.15, #running-req: 40, #queue-req: 0\n",
      "[2025-08-13 19:41:23] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 452, token usage: 0.15, #running-req: 41, #queue-req: 0\n",
      "[2025-08-13 19:41:23] INFO:     127.0.0.1:52032 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:23] INFO:     127.0.0.1:51786 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:23] INFO:     127.0.0.1:52178 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:24] INFO:     127.0.0.1:51768 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:24] Decode batch. #running-req: 38, #token: 33979, token usage: 0.14, cuda graph: True, gen throughput (token/s): 1632.81, #queue-req: 0\n",
      "[2025-08-13 19:41:25] Decode batch. #running-req: 38, #token: 35499, token usage: 0.14, cuda graph: True, gen throughput (token/s): 1662.55, #queue-req: 0\n",
      "[2025-08-13 19:41:25] INFO:     127.0.0.1:51454 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:26] Decode batch. #running-req: 37, #token: 35997, token usage: 0.15, cuda graph: True, gen throughput (token/s): 1638.46, #queue-req: 0\n",
      "[2025-08-13 19:41:26] INFO:     127.0.0.1:52026 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:27] Decode batch. #running-req: 36, #token: 36415, token usage: 0.15, cuda graph: True, gen throughput (token/s): 1593.60, #queue-req: 0\n",
      "[2025-08-13 19:41:27] INFO:     127.0.0.1:51686 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:27] INFO:     127.0.0.1:51554 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:27] Decode batch. #running-req: 34, #token: 35651, token usage: 0.15, cuda graph: True, gen throughput (token/s): 1501.93, #queue-req: 0\n",
      "[2025-08-13 19:41:27] INFO:     127.0.0.1:51538 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:27] INFO:     127.0.0.1:51694 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:28] INFO:     127.0.0.1:51872 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:28] INFO:     127.0.0.1:51592 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:28] INFO:     127.0.0.1:52196 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:28] INFO:     127.0.0.1:51590 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:28] INFO:     127.0.0.1:51858 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:28] Decode batch. #running-req: 27, #token: 29017, token usage: 0.12, cuda graph: True, gen throughput (token/s): 1379.42, #queue-req: 0\n",
      "[2025-08-13 19:41:29] INFO:     127.0.0.1:51672 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:29] INFO:     127.0.0.1:51528 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:29] INFO:     127.0.0.1:52050 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:29] Decode batch. #running-req: 24, #token: 26551, token usage: 0.11, cuda graph: True, gen throughput (token/s): 1224.19, #queue-req: 0\n",
      "[2025-08-13 19:41:29] INFO:     127.0.0.1:51754 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:30] Decode batch. #running-req: 23, #token: 26289, token usage: 0.11, cuda graph: True, gen throughput (token/s): 1154.35, #queue-req: 0\n",
      "[2025-08-13 19:41:30] INFO:     127.0.0.1:51856 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:30] INFO:     127.0.0.1:51910 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:31] INFO:     127.0.0.1:52054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:31] Decode batch. #running-req: 20, #token: 23423, token usage: 0.10, cuda graph: True, gen throughput (token/s): 1076.86, #queue-req: 0\n",
      "[2025-08-13 19:41:31] INFO:     127.0.0.1:51622 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:32] Decode batch. #running-req: 19, #token: 22921, token usage: 0.09, cuda graph: True, gen throughput (token/s): 1007.96, #queue-req: 0\n",
      "[2025-08-13 19:41:32] Decode batch. #running-req: 19, #token: 23681, token usage: 0.10, cuda graph: True, gen throughput (token/s): 968.68, #queue-req: 0\n",
      "[2025-08-13 19:41:33] INFO:     127.0.0.1:51780 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:33] Decode batch. #running-req: 18, #token: 22961, token usage: 0.09, cuda graph: True, gen throughput (token/s): 938.83, #queue-req: 0\n",
      "[2025-08-13 19:41:34] Decode batch. #running-req: 18, #token: 23681, token usage: 0.10, cuda graph: True, gen throughput (token/s): 916.22, #queue-req: 0\n",
      "[2025-08-13 19:41:34] INFO:     127.0.0.1:52198 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:35] Decode batch. #running-req: 17, #token: 22939, token usage: 0.09, cuda graph: True, gen throughput (token/s): 894.58, #queue-req: 0\n",
      "[2025-08-13 19:41:35] INFO:     127.0.0.1:51640 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:35] Decode batch. #running-req: 16, #token: 22117, token usage: 0.09, cuda graph: True, gen throughput (token/s): 850.80, #queue-req: 0\n",
      "[2025-08-13 19:41:36] INFO:     127.0.0.1:51536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:36] Decode batch. #running-req: 15, #token: 21124, token usage: 0.09, cuda graph: True, gen throughput (token/s): 809.96, #queue-req: 0\n",
      "[2025-08-13 19:41:37] INFO:     127.0.0.1:52040 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:37] Decode batch. #running-req: 14, #token: 20142, token usage: 0.08, cuda graph: True, gen throughput (token/s): 769.18, #queue-req: 0\n",
      "[2025-08-13 19:41:38] Decode batch. #running-req: 14, #token: 19081, token usage: 0.08, cuda graph: True, gen throughput (token/s): 744.94, #queue-req: 0\n",
      "[2025-08-13 19:41:38] INFO:     127.0.0.1:51774 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:38] INFO:     127.0.0.1:51466 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:38] Decode batch. #running-req: 12, #token: 17938, token usage: 0.07, cuda graph: True, gen throughput (token/s): 693.00, #queue-req: 0\n",
      "[2025-08-13 19:41:39] Decode batch. #running-req: 12, #token: 18418, token usage: 0.07, cuda graph: True, gen throughput (token/s): 654.72, #queue-req: 0\n",
      "[2025-08-13 19:41:40] INFO:     127.0.0.1:52084 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:40] Decode batch. #running-req: 11, #token: 17156, token usage: 0.07, cuda graph: True, gen throughput (token/s): 633.62, #queue-req: 0\n",
      "[2025-08-13 19:41:40] INFO:     127.0.0.1:51938 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:41] Decode batch. #running-req: 10, #token: 15814, token usage: 0.06, cuda graph: True, gen throughput (token/s): 575.50, #queue-req: 0\n",
      "[2025-08-13 19:41:41] Decode batch. #running-req: 10, #token: 16214, token usage: 0.07, cuda graph: True, gen throughput (token/s): 562.00, #queue-req: 0\n",
      "[2025-08-13 19:41:42] INFO:     127.0.0.1:35548 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:42] Decode batch. #running-req: 9, #token: 15115, token usage: 0.06, cuda graph: True, gen throughput (token/s): 546.02, #queue-req: 0\n",
      "[2025-08-13 19:41:43] Decode batch. #running-req: 9, #token: 15475, token usage: 0.06, cuda graph: True, gen throughput (token/s): 510.31, #queue-req: 0\n",
      "[2025-08-13 19:41:43] Decode batch. #running-req: 9, #token: 15835, token usage: 0.06, cuda graph: True, gen throughput (token/s): 508.74, #queue-req: 0\n",
      "[2025-08-13 19:41:44] Decode batch. #running-req: 9, #token: 16195, token usage: 0.07, cuda graph: True, gen throughput (token/s): 506.69, #queue-req: 0\n",
      "[2025-08-13 19:41:44] INFO:     127.0.0.1:52008 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:44] INFO:     127.0.0.1:52070 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:45] Decode batch. #running-req: 7, #token: 12324, token usage: 0.05, cuda graph: True, gen throughput (token/s): 461.76, #queue-req: 0\n",
      "[2025-08-13 19:41:46] Decode batch. #running-req: 7, #token: 12604, token usage: 0.05, cuda graph: True, gen throughput (token/s): 421.06, #queue-req: 0\n",
      "[2025-08-13 19:41:46] Decode batch. #running-req: 7, #token: 12884, token usage: 0.05, cuda graph: True, gen throughput (token/s): 420.08, #queue-req: 0\n",
      "[2025-08-13 19:41:47] Decode batch. #running-req: 7, #token: 13164, token usage: 0.05, cuda graph: True, gen throughput (token/s): 419.74, #queue-req: 0\n",
      "[2025-08-13 19:41:48] Decode batch. #running-req: 7, #token: 13444, token usage: 0.05, cuda graph: True, gen throughput (token/s): 418.29, #queue-req: 0\n",
      "[2025-08-13 19:41:48] Decode batch. #running-req: 7, #token: 13724, token usage: 0.06, cuda graph: True, gen throughput (token/s): 416.22, #queue-req: 0\n",
      "[2025-08-13 19:41:48] INFO:     127.0.0.1:52270 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:49] Decode batch. #running-req: 6, #token: 11870, token usage: 0.05, cuda graph: True, gen throughput (token/s): 379.00, #queue-req: 0\n",
      "[2025-08-13 19:41:50] Decode batch. #running-req: 6, #token: 12110, token usage: 0.05, cuda graph: True, gen throughput (token/s): 363.95, #queue-req: 0\n",
      "[2025-08-13 19:41:50] INFO:     127.0.0.1:35510 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:50] INFO:     127.0.0.1:35522 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:50] INFO:     127.0.0.1:35534 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:50] Decode batch. #running-req: 3, #token: 5958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 284.78, #queue-req: 0\n",
      "[2025-08-13 19:41:51] INFO:     127.0.0.1:35536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:51] Decode batch. #running-req: 2, #token: 3826, token usage: 0.02, cuda graph: True, gen throughput (token/s): 189.62, #queue-req: 0\n",
      "[2025-08-13 19:41:51] Decode batch. #running-req: 2, #token: 3906, token usage: 0.02, cuda graph: True, gen throughput (token/s): 136.96, #queue-req: 0\n",
      "[2025-08-13 19:41:52] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 542, token usage: 0.02, #running-req: 2, #queue-req: 0\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "[2025-08-13 19:41:52] Prefill batch. #new-seq: 5, #new-token: 158, #cached-token: 9247, token usage: 0.05, #running-req: 3, #queue-req: 0\n",
      "[2025-08-13 19:41:52] Prefill batch. #new-seq: 3, #new-token: 186, #cached-token: 2621, token usage: 0.06, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 19:41:52] Decode batch. #running-req: 11, #token: 15163, token usage: 0.06, cuda graph: True, gen throughput (token/s): 156.69, #queue-req: 0\n",
      "[2025-08-13 19:41:53] Decode batch. #running-req: 11, #token: 15603, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.23, #queue-req: 0\n",
      "[2025-08-13 19:41:53] INFO:     127.0.0.1:35522 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:53] Decode batch. #running-req: 10, #token: 13848, token usage: 0.06, cuda graph: True, gen throughput (token/s): 601.50, #queue-req: 0\n",
      "[2025-08-13 19:41:54] INFO:     127.0.0.1:35510 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:54] INFO:     127.0.0.1:35534 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:54] Decode batch. #running-req: 8, #token: 9722, token usage: 0.04, cuda graph: True, gen throughput (token/s): 550.73, #queue-req: 0\n",
      "[2025-08-13 19:41:54] INFO:     127.0.0.1:52270 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:54] INFO:     127.0.0.1:35536 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:55] Decode batch. #running-req: 6, #token: 5516, token usage: 0.02, cuda graph: True, gen throughput (token/s): 408.09, #queue-req: 0\n",
      "[2025-08-13 19:41:55] Decode batch. #running-req: 6, #token: 5756, token usage: 0.02, cuda graph: True, gen throughput (token/s): 394.62, #queue-req: 0\n",
      "[2025-08-13 19:41:56] Decode batch. #running-req: 6, #token: 5996, token usage: 0.02, cuda graph: True, gen throughput (token/s): 393.67, #queue-req: 0\n",
      "[2025-08-13 19:41:57] Decode batch. #running-req: 6, #token: 6236, token usage: 0.03, cuda graph: True, gen throughput (token/s): 392.73, #queue-req: 0\n",
      "[2025-08-13 19:41:57] Decode batch. #running-req: 6, #token: 6476, token usage: 0.03, cuda graph: True, gen throughput (token/s): 391.88, #queue-req: 0\n",
      "[2025-08-13 19:41:58] Decode batch. #running-req: 6, #token: 6716, token usage: 0.03, cuda graph: True, gen throughput (token/s): 389.95, #queue-req: 0\n",
      "[2025-08-13 19:41:58] Decode batch. #running-req: 6, #token: 6956, token usage: 0.03, cuda graph: True, gen throughput (token/s): 388.56, #queue-req: 0\n",
      "[2025-08-13 19:41:59] Decode batch. #running-req: 6, #token: 7196, token usage: 0.03, cuda graph: True, gen throughput (token/s): 387.22, #queue-req: 0\n",
      "[2025-08-13 19:41:59] INFO:     127.0.0.1:60820 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:41:59] INFO:     127.0.0.1:60824 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:00] Decode batch. #running-req: 4, #token: 3032, token usage: 0.01, cuda graph: True, gen throughput (token/s): 297.84, #queue-req: 0\n",
      "[2025-08-13 19:42:00] Decode batch. #running-req: 4, #token: 3192, token usage: 0.01, cuda graph: True, gen throughput (token/s): 274.03, #queue-req: 0\n",
      "[2025-08-13 19:42:01] Decode batch. #running-req: 4, #token: 3352, token usage: 0.01, cuda graph: True, gen throughput (token/s): 273.36, #queue-req: 0\n",
      "[2025-08-13 19:42:01] Decode batch. #running-req: 4, #token: 3512, token usage: 0.01, cuda graph: True, gen throughput (token/s): 271.36, #queue-req: 0\n",
      "[2025-08-13 19:42:02] Decode batch. #running-req: 4, #token: 3672, token usage: 0.01, cuda graph: True, gen throughput (token/s): 272.49, #queue-req: 0\n",
      "[2025-08-13 19:42:03] Decode batch. #running-req: 4, #token: 3832, token usage: 0.02, cuda graph: True, gen throughput (token/s): 272.76, #queue-req: 0\n",
      "[2025-08-13 19:42:03] Decode batch. #running-req: 4, #token: 3992, token usage: 0.02, cuda graph: True, gen throughput (token/s): 272.16, #queue-req: 0\n",
      "[2025-08-13 19:42:04] Decode batch. #running-req: 4, #token: 4152, token usage: 0.02, cuda graph: True, gen throughput (token/s): 271.56, #queue-req: 0\n",
      "[2025-08-13 19:42:04] Decode batch. #running-req: 4, #token: 4312, token usage: 0.02, cuda graph: True, gen throughput (token/s): 271.10, #queue-req: 0\n",
      "[2025-08-13 19:42:05] Decode batch. #running-req: 4, #token: 4472, token usage: 0.02, cuda graph: True, gen throughput (token/s): 270.82, #queue-req: 0\n",
      "[2025-08-13 19:42:05] Decode batch. #running-req: 4, #token: 4632, token usage: 0.02, cuda graph: True, gen throughput (token/s): 270.41, #queue-req: 0\n",
      "[2025-08-13 19:42:06] Decode batch. #running-req: 4, #token: 4792, token usage: 0.02, cuda graph: True, gen throughput (token/s): 270.15, #queue-req: 0\n",
      "[2025-08-13 19:42:07] Decode batch. #running-req: 4, #token: 4952, token usage: 0.02, cuda graph: True, gen throughput (token/s): 269.01, #queue-req: 0\n",
      "[2025-08-13 19:42:07] Decode batch. #running-req: 4, #token: 5112, token usage: 0.02, cuda graph: True, gen throughput (token/s): 268.43, #queue-req: 0\n",
      "[2025-08-13 19:42:08] Decode batch. #running-req: 4, #token: 5272, token usage: 0.02, cuda graph: True, gen throughput (token/s): 267.72, #queue-req: 0\n",
      "[2025-08-13 19:42:08] Decode batch. #running-req: 4, #token: 5432, token usage: 0.02, cuda graph: True, gen throughput (token/s): 267.32, #queue-req: 0\n",
      "[2025-08-13 19:42:09] Decode batch. #running-req: 4, #token: 5592, token usage: 0.02, cuda graph: True, gen throughput (token/s): 266.37, #queue-req: 0\n",
      "[2025-08-13 19:42:10] Decode batch. #running-req: 4, #token: 5752, token usage: 0.02, cuda graph: True, gen throughput (token/s): 266.12, #queue-req: 0\n",
      "[2025-08-13 19:42:10] Decode batch. #running-req: 4, #token: 5912, token usage: 0.02, cuda graph: True, gen throughput (token/s): 265.37, #queue-req: 0\n",
      "[2025-08-13 19:42:11] Decode batch. #running-req: 4, #token: 6072, token usage: 0.02, cuda graph: True, gen throughput (token/s): 263.33, #queue-req: 0\n",
      "[2025-08-13 19:42:11] Decode batch. #running-req: 4, #token: 6232, token usage: 0.03, cuda graph: True, gen throughput (token/s): 261.61, #queue-req: 0\n",
      "[2025-08-13 19:42:12] Decode batch. #running-req: 4, #token: 6392, token usage: 0.03, cuda graph: True, gen throughput (token/s): 260.47, #queue-req: 0\n",
      "[2025-08-13 19:42:13] Decode batch. #running-req: 4, #token: 6552, token usage: 0.03, cuda graph: True, gen throughput (token/s): 260.59, #queue-req: 0\n",
      "[2025-08-13 19:42:13] Decode batch. #running-req: 4, #token: 6712, token usage: 0.03, cuda graph: True, gen throughput (token/s): 261.97, #queue-req: 0\n",
      "[2025-08-13 19:42:14] Decode batch. #running-req: 4, #token: 6872, token usage: 0.03, cuda graph: True, gen throughput (token/s): 261.59, #queue-req: 0\n",
      "[2025-08-13 19:42:15] Decode batch. #running-req: 4, #token: 7032, token usage: 0.03, cuda graph: True, gen throughput (token/s): 260.99, #queue-req: 0\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "[2025-08-13 19:42:15] Prefill batch. #new-seq: 8, #new-token: 750, #cached-token: 2165, token usage: 0.03, #running-req: 4, #queue-req: 0\n",
      "[2025-08-13 19:42:15] Prefill batch. #new-seq: 28, #new-token: 3626, #cached-token: 8540, token usage: 0.03, #running-req: 12, #queue-req: 0\n",
      "[2025-08-13 19:42:15] Prefill batch. #new-seq: 18, #new-token: 1916, #cached-token: 7078, token usage: 0.05, #running-req: 40, #queue-req: 0\n",
      "[2025-08-13 19:42:16] Decode batch. #running-req: 58, #token: 12452, token usage: 0.05, cuda graph: True, gen throughput (token/s): 189.33, #queue-req: 0\n",
      "[2025-08-13 19:42:16] Decode batch. #running-req: 58, #token: 14772, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2874.72, #queue-req: 0\n",
      "[2025-08-13 19:42:17] Decode batch. #running-req: 58, #token: 17092, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2828.21, #queue-req: 0\n",
      "[2025-08-13 19:42:18] Decode batch. #running-req: 58, #token: 19412, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2787.93, #queue-req: 0\n",
      "[2025-08-13 19:42:19] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 483, token usage: 0.08, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 19:42:19] Prefill batch. #new-seq: 29, #new-token: 3319, #cached-token: 10453, token usage: 0.08, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 19:42:19] Prefill batch. #new-seq: 12, #new-token: 5866, #cached-token: 4028, token usage: 0.10, #running-req: 88, #queue-req: 0\n",
      "[2025-08-13 19:42:20] Decode batch. #running-req: 100, #token: 29930, token usage: 0.12, cuda graph: True, gen throughput (token/s): 1769.71, #queue-req: 0\n",
      "[2025-08-13 19:42:21] Decode batch. #running-req: 100, #token: 33930, token usage: 0.14, cuda graph: True, gen throughput (token/s): 3507.67, #queue-req: 0\n",
      "[2025-08-13 19:42:22] INFO:     127.0.0.1:60856 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:22] Decode batch. #running-req: 99, #token: 36075, token usage: 0.15, cuda graph: True, gen throughput (token/s): 3388.60, #queue-req: 0\n",
      "[2025-08-13 19:42:23] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 183, token usage: 0.15, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:23] Decode batch. #running-req: 100, #token: 40195, token usage: 0.16, cuda graph: True, gen throughput (token/s): 3205.12, #queue-req: 0\n",
      "[2025-08-13 19:42:25] Decode batch. #running-req: 100, #token: 44195, token usage: 0.18, cuda graph: True, gen throughput (token/s): 3197.64, #queue-req: 0\n",
      "[2025-08-13 19:42:25] INFO:     127.0.0.1:43530 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:26] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 144, token usage: 0.19, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:26] Decode batch. #running-req: 100, #token: 46960, token usage: 0.19, cuda graph: True, gen throughput (token/s): 3061.60, #queue-req: 0\n",
      "[2025-08-13 19:42:27] Decode batch. #running-req: 100, #token: 50960, token usage: 0.21, cuda graph: True, gen throughput (token/s): 3068.00, #queue-req: 0\n",
      "[2025-08-13 19:42:29] Decode batch. #running-req: 100, #token: 54960, token usage: 0.22, cuda graph: True, gen throughput (token/s): 2983.73, #queue-req: 0\n",
      "[2025-08-13 19:42:29] INFO:     127.0.0.1:43678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:30] INFO:     127.0.0.1:60826 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:30] INFO:     127.0.0.1:60830 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:30] INFO:     127.0.0.1:60846 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:30] Prefill batch. #new-seq: 4, #new-token: 274, #cached-token: 7260, token usage: 0.24, #running-req: 96, #queue-req: 0\n",
      "[2025-08-13 19:42:30] Decode batch. #running-req: 96, #token: 58641, token usage: 0.24, cuda graph: True, gen throughput (token/s): 2848.32, #queue-req: 0\n",
      "[2025-08-13 19:42:31] Decode batch. #running-req: 100, #token: 60681, token usage: 0.25, cuda graph: True, gen throughput (token/s): 2777.17, #queue-req: 0\n",
      "[2025-08-13 19:42:31] INFO:     127.0.0.1:60846 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:32] Prefill batch. #new-seq: 1, #new-token: 2061, #cached-token: 167, token usage: 0.25, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:33] INFO:     127.0.0.1:40048 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:33] INFO:     127.0.0.1:40076 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:33] Decode batch. #running-req: 98, #token: 65884, token usage: 0.27, cuda graph: True, gen throughput (token/s): 2434.11, #queue-req: 0\n",
      "[2025-08-13 19:42:34] Prefill batch. #new-seq: 2, #new-token: 204, #cached-token: 382, token usage: 0.28, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:42:35] Decode batch. #running-req: 100, #token: 70016, token usage: 0.28, cuda graph: True, gen throughput (token/s): 2592.90, #queue-req: 0\n",
      "[2025-08-13 19:42:35] INFO:     127.0.0.1:60830 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:35] INFO:     127.0.0.1:60826 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:36] Decode batch. #running-req: 98, #token: 69444, token usage: 0.28, cuda graph: True, gen throughput (token/s): 2640.00, #queue-req: 0\n",
      "[2025-08-13 19:42:36] Prefill batch. #new-seq: 1, #new-token: 2222, #cached-token: 171, token usage: 0.28, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:42:36] Prefill batch. #new-seq: 1, #new-token: 2171, #cached-token: 460, token usage: 0.29, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:38] Decode batch. #running-req: 100, #token: 77837, token usage: 0.32, cuda graph: True, gen throughput (token/s): 2059.03, #queue-req: 0\n",
      "[2025-08-13 19:42:38] INFO:     127.0.0.1:44330 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:39] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 119, token usage: 0.32, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:40] Decode batch. #running-req: 100, #token: 81391, token usage: 0.33, cuda graph: True, gen throughput (token/s): 2441.35, #queue-req: 0\n",
      "[2025-08-13 19:42:40] INFO:     127.0.0.1:40088 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:41] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 146, token usage: 0.34, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:41] Decode batch. #running-req: 100, #token: 84863, token usage: 0.35, cuda graph: True, gen throughput (token/s): 2427.57, #queue-req: 0\n",
      "[2025-08-13 19:42:43] Decode batch. #running-req: 100, #token: 88863, token usage: 0.36, cuda graph: True, gen throughput (token/s): 2425.80, #queue-req: 0\n",
      "[2025-08-13 19:42:45] Decode batch. #running-req: 100, #token: 92863, token usage: 0.38, cuda graph: True, gen throughput (token/s): 2373.29, #queue-req: 0\n",
      "[2025-08-13 19:42:45] INFO:     127.0.0.1:40124 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:46] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 147, token usage: 0.39, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:46] INFO:     127.0.0.1:40032 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:46] Decode batch. #running-req: 99, #token: 95438, token usage: 0.39, cuda graph: True, gen throughput (token/s): 2284.08, #queue-req: 0\n",
      "[2025-08-13 19:42:47] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 392, token usage: 0.40, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:48] INFO:     127.0.0.1:43618 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:48] Decode batch. #running-req: 99, #token: 98786, token usage: 0.40, cuda graph: True, gen throughput (token/s): 2234.85, #queue-req: 0\n",
      "[2025-08-13 19:42:48] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 196, token usage: 0.40, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:50] INFO:     127.0.0.1:44336 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:50] Decode batch. #running-req: 99, #token: 99949, token usage: 0.41, cuda graph: True, gen throughput (token/s): 2212.84, #queue-req: 0\n",
      "[2025-08-13 19:42:51] Prefill batch. #new-seq: 1, #new-token: 2255, #cached-token: 142, token usage: 0.41, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:52] Decode batch. #running-req: 100, #token: 106213, token usage: 0.43, cuda graph: True, gen throughput (token/s): 1999.81, #queue-req: 0\n",
      "[2025-08-13 19:42:54] INFO:     127.0.0.1:40268 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:54] Decode batch. #running-req: 99, #token: 109314, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2178.67, #queue-req: 0\n",
      "[2025-08-13 19:42:54] INFO:     127.0.0.1:54778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:55] Prefill batch. #new-seq: 2, #new-token: 2511, #cached-token: 604, token usage: 0.44, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:42:55] INFO:     127.0.0.1:44350 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:56] Decode batch. #running-req: 99, #token: 110098, token usage: 0.45, cuda graph: True, gen throughput (token/s): 1911.18, #queue-req: 0\n",
      "[2025-08-13 19:42:56] Prefill batch. #new-seq: 1, #new-token: 2250, #cached-token: 151, token usage: 0.45, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:57] INFO:     127.0.0.1:43760 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:57] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 144, token usage: 0.46, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:58] INFO:     127.0.0.1:40302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:58] Decode batch. #running-req: 99, #token: 114348, token usage: 0.47, cuda graph: True, gen throughput (token/s): 1895.99, #queue-req: 0\n",
      "[2025-08-13 19:42:58] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 412, token usage: 0.47, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:42:59] INFO:     127.0.0.1:40220 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:59] INFO:     127.0.0.1:43816 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:59] INFO:     127.0.0.1:40230 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:42:59] INFO:     127.0.0.1:33272 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:00] Decode batch. #running-req: 96, #token: 114810, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2034.45, #queue-req: 0\n",
      "[2025-08-13 19:43:02] Decode batch. #running-req: 96, #token: 118650, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2010.80, #queue-req: 0\n",
      "[2025-08-13 19:43:02] Prefill batch. #new-seq: 4, #new-token: 640, #cached-token: 1484, token usage: 0.48, #running-req: 96, #queue-req: 0\n",
      "[2025-08-13 19:43:04] Decode batch. #running-req: 100, #token: 123286, token usage: 0.50, cuda graph: True, gen throughput (token/s): 1984.14, #queue-req: 0\n",
      "[2025-08-13 19:43:06] Decode batch. #running-req: 100, #token: 127286, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2008.24, #queue-req: 0\n",
      "[2025-08-13 19:43:07] INFO:     127.0.0.1:43878 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:08] Decode batch. #running-req: 99, #token: 129517, token usage: 0.53, cuda graph: True, gen throughput (token/s): 1977.81, #queue-req: 0\n",
      "[2025-08-13 19:43:08] Prefill batch. #new-seq: 1, #new-token: 514, #cached-token: 146, token usage: 0.53, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:43:09] INFO:     127.0.0.1:40252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:10] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 146, token usage: 0.54, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:43:10] Decode batch. #running-req: 100, #token: 132917, token usage: 0.54, cuda graph: True, gen throughput (token/s): 1876.67, #queue-req: 0\n",
      "[2025-08-13 19:43:12] Decode batch. #running-req: 100, #token: 136917, token usage: 0.56, cuda graph: True, gen throughput (token/s): 1937.16, #queue-req: 0\n",
      "[2025-08-13 19:43:12] INFO:     127.0.0.1:43858 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:12] INFO:     127.0.0.1:43768 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:14] Prefill batch. #new-seq: 2, #new-token: 280, #cached-token: 853, token usage: 0.56, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:43:14] INFO:     127.0.0.1:40248 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:14] Decode batch. #running-req: 99, #token: 136805, token usage: 0.56, cuda graph: True, gen throughput (token/s): 1866.07, #queue-req: 0\n",
      "[2025-08-13 19:43:15] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 462, token usage: 0.56, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:43:16] Decode batch. #running-req: 100, #token: 141135, token usage: 0.57, cuda graph: True, gen throughput (token/s): 1866.85, #queue-req: 0\n",
      "[2025-08-13 19:43:18] Decode batch. #running-req: 100, #token: 145135, token usage: 0.59, cuda graph: True, gen throughput (token/s): 1873.61, #queue-req: 0\n",
      "[2025-08-13 19:43:20] INFO:     127.0.0.1:44366 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:21] Decode batch. #running-req: 99, #token: 147695, token usage: 0.60, cuda graph: True, gen throughput (token/s): 1841.81, #queue-req: 0\n",
      "[2025-08-13 19:43:21] Prefill batch. #new-seq: 1, #new-token: 207, #cached-token: 119, token usage: 0.60, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:43:21] INFO:     127.0.0.1:40308 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:22] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 589, token usage: 0.61, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:43:23] Decode batch. #running-req: 100, #token: 150538, token usage: 0.61, cuda graph: True, gen throughput (token/s): 1769.90, #queue-req: 0\n",
      "[2025-08-13 19:43:24] INFO:     127.0.0.1:43716 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:25] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 184, token usage: 0.62, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:43:25] Decode batch. #running-req: 100, #token: 153053, token usage: 0.62, cuda graph: True, gen throughput (token/s): 1775.75, #queue-req: 0\n",
      "[2025-08-13 19:43:25] INFO:     127.0.0.1:43444 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:26] INFO:     127.0.0.1:39988 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:27] INFO:     127.0.0.1:54804 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:27] Decode batch. #running-req: 97, #token: 150495, token usage: 0.61, cuda graph: True, gen throughput (token/s): 1778.50, #queue-req: 0\n",
      "[2025-08-13 19:43:28] Prefill batch. #new-seq: 3, #new-token: 4286, #cached-token: 821, token usage: 0.61, #running-req: 97, #queue-req: 0\n",
      "[2025-08-13 19:43:29] INFO:     127.0.0.1:43588 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:29] INFO:     127.0.0.1:43448 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:30] Decode batch. #running-req: 98, #token: 155321, token usage: 0.63, cuda graph: True, gen throughput (token/s): 1523.02, #queue-req: 0\n",
      "[2025-08-13 19:43:30] INFO:     127.0.0.1:43576 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:31] INFO:     127.0.0.1:43648 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:32] Prefill batch. #new-seq: 4, #new-token: 617, #cached-token: 1221, token usage: 0.63, #running-req: 96, #queue-req: 0\n",
      "[2025-08-13 19:43:32] Decode batch. #running-req: 100, #token: 156120, token usage: 0.64, cuda graph: True, gen throughput (token/s): 1700.95, #queue-req: 0\n",
      "[2025-08-13 19:43:34] Decode batch. #running-req: 100, #token: 160120, token usage: 0.65, cuda graph: True, gen throughput (token/s): 1774.00, #queue-req: 0\n",
      "[2025-08-13 19:43:35] INFO:     127.0.0.1:54814 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:35] Prefill batch. #new-seq: 1, #new-token: 2366, #cached-token: 434, token usage: 0.64, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:43:36] INFO:     127.0.0.1:44374 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:37] Decode batch. #running-req: 99, #token: 161582, token usage: 0.66, cuda graph: True, gen throughput (token/s): 1612.15, #queue-req: 0\n",
      "[2025-08-13 19:43:37] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 119, token usage: 0.66, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:43:39] Decode batch. #running-req: 100, #token: 165761, token usage: 0.67, cuda graph: True, gen throughput (token/s): 1722.64, #queue-req: 0\n",
      "[2025-08-13 19:43:41] INFO:     127.0.0.1:34280 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:42] Decode batch. #running-req: 99, #token: 168861, token usage: 0.69, cuda graph: True, gen throughput (token/s): 1719.38, #queue-req: 0\n",
      "[2025-08-13 19:43:42] Prefill batch. #new-seq: 1, #new-token: 455, #cached-token: 392, token usage: 0.69, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:43:44] Decode batch. #running-req: 100, #token: 173314, token usage: 0.70, cuda graph: True, gen throughput (token/s): 1662.47, #queue-req: 0\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43460 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43464 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43480 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43488 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43500 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43514 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43534 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43538 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43544 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43546 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43548 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43560 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43562 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43582 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43602 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43606 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43630 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43632 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43644 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43656 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43670 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43690 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43692 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43700 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43704 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43722 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43730 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43736 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43750 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43752 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43776 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43792 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43796 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43808 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43832 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43846 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43868 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43872 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:43876 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] Prefill batch. #new-seq: 3, #new-token: 61, #cached-token: 7188, token usage: 0.41, #running-req: 60, #queue-req: 0\n",
      "[2025-08-13 19:43:46] Decode batch. #running-req: 60, #token: 98928, token usage: 0.40, cuda graph: True, gen throughput (token/s): 1656.72, #queue-req: 0\n",
      "[2025-08-13 19:43:46] Prefill batch. #new-seq: 15, #new-token: 310, #cached-token: 35547, token usage: 0.53, #running-req: 63, #queue-req: 0\n",
      "[2025-08-13 19:43:46] Prefill batch. #new-seq: 7, #new-token: 145, #cached-token: 18256, token usage: 0.59, #running-req: 78, #queue-req: 0\n",
      "[2025-08-13 19:43:46] Prefill batch. #new-seq: 13, #new-token: 272, #cached-token: 32203, token usage: 0.70, #running-req: 85, #queue-req: 0\n",
      "[2025-08-13 19:43:46] INFO:     127.0.0.1:40154 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:46] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 4931, token usage: 0.71, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:43:47] INFO:     127.0.0.1:43876 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:47] INFO:     127.0.0.1:43700 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:49] Prefill batch. #new-seq: 3, #new-token: 481, #cached-token: 493, token usage: 0.71, #running-req: 97, #queue-req: 0\n",
      "[2025-08-13 19:43:49] Decode batch. #running-req: 100, #token: 176076, token usage: 0.72, cuda graph: True, gen throughput (token/s): 1507.64, #queue-req: 0\n",
      "[2025-08-13 19:43:50] INFO:     127.0.0.1:40190 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:50] INFO:     127.0.0.1:34264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:50] INFO:     127.0.0.1:43846 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:51] INFO:     127.0.0.1:43670 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:51] INFO:     127.0.0.1:43730 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:51] Decode batch. #running-req: 95, #token: 170502, token usage: 0.69, cuda graph: True, gen throughput (token/s): 1676.75, #queue-req: 0\n",
      "[2025-08-13 19:43:51] INFO:     127.0.0.1:43692 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:52] INFO:     127.0.0.1:43750 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:52] INFO:     127.0.0.1:43538 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:52] INFO:     127.0.0.1:43632 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:53] INFO:     127.0.0.1:33616 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:53] INFO:     127.0.0.1:43464 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:53] INFO:     127.0.0.1:40284 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:53] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 508, token usage: 0.65, #running-req: 88, #queue-req: 0\n",
      "[2025-08-13 19:43:53] INFO:     127.0.0.1:43582 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:53] Decode batch. #running-req: 88, #token: 157116, token usage: 0.64, cuda graph: True, gen throughput (token/s): 1633.21, #queue-req: 0\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43546 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43514 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 434, token usage: 0.62, #running-req: 86, #queue-req: 0\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43606 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43544 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43602 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43500 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43644 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43752 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43562 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43776 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43488 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43872 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43808 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43656 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43832 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43796 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43736 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43534 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43630 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43548 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43722 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43480 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43792 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43560 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43868 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43498 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43704 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43690 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:43460 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:39998 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40002 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40004 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40016 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40060 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40068 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40098 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40100 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40114 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40136 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40140 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40168 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40178 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40200 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40206 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40240 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40282 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40288 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:40310 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:44300 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:44306 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:44320 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:54] INFO:     127.0.0.1:44358 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:55] Decode batch. #running-req: 37, #token: 46978, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1503.84, #queue-req: 0\n",
      "[2025-08-13 19:43:56] Decode batch. #running-req: 37, #token: 48458, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1423.95, #queue-req: 0\n",
      "[2025-08-13 19:43:57] Decode batch. #running-req: 37, #token: 49938, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1405.48, #queue-req: 0\n",
      "[2025-08-13 19:43:57] INFO:     127.0.0.1:34250 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:58] Prefill batch. #new-seq: 1, #new-token: 841, #cached-token: 144, token usage: 0.20, #running-req: 36, #queue-req: 0\n",
      "[2025-08-13 19:43:58] Prefill batch. #new-seq: 10, #new-token: 207, #cached-token: 25587, token usage: 0.29, #running-req: 37, #queue-req: 0\n",
      "[2025-08-13 19:43:58] Prefill batch. #new-seq: 14, #new-token: 572, #cached-token: 30125, token usage: 0.39, #running-req: 47, #queue-req: 0\n",
      "[2025-08-13 19:43:58] INFO:     127.0.0.1:40178 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:58] INFO:     127.0.0.1:40100 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:58] INFO:     127.0.0.1:44320 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:58] INFO:     127.0.0.1:40282 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:58] INFO:     127.0.0.1:40140 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:58] Decode batch. #running-req: 56, #token: 87960, token usage: 0.36, cuda graph: True, gen throughput (token/s): 1299.36, #queue-req: 0\n",
      "[2025-08-13 19:43:59] INFO:     127.0.0.1:56764 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:43:59] INFO:     127.0.0.1:52070 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:00] Decode batch. #running-req: 54, #token: 85265, token usage: 0.35, cuda graph: True, gen throughput (token/s): 1548.52, #queue-req: 0\n",
      "[2025-08-13 19:44:01] Decode batch. #running-req: 54, #token: 87425, token usage: 0.36, cuda graph: True, gen throughput (token/s): 1521.32, #queue-req: 0\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40168 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40068 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40136 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:44300 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40098 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40200 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40114 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40002 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40310 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40240 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40288 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40060 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40016 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40004 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:44358 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:44306 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:02] INFO:     127.0.0.1:40206 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:03] Decode batch. #running-req: 37, #token: 50966, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1491.12, #queue-req: 0\n",
      "[2025-08-13 19:44:04] Decode batch. #running-req: 37, #token: 52446, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1377.82, #queue-req: 0\n",
      "[2025-08-13 19:44:04] INFO:     127.0.0.1:56792 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:05] INFO:     127.0.0.1:54776 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:05] Decode batch. #running-req: 36, #token: 50686, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1347.70, #queue-req: 0\n",
      "[2025-08-13 19:44:06] Decode batch. #running-req: 35, #token: 52086, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1317.98, #queue-req: 0\n",
      "[2025-08-13 19:44:07] Decode batch. #running-req: 35, #token: 53486, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1302.48, #queue-req: 0\n",
      "[2025-08-13 19:44:08] INFO:     127.0.0.1:54786 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:08] INFO:     127.0.0.1:54798 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:08] Decode batch. #running-req: 33, #token: 50674, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1283.23, #queue-req: 0\n",
      "[2025-08-13 19:44:09] Decode batch. #running-req: 33, #token: 51994, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1245.34, #queue-req: 0\n",
      "[2025-08-13 19:44:10] Decode batch. #running-req: 33, #token: 53314, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1227.39, #queue-req: 0\n",
      "[2025-08-13 19:44:11] INFO:     127.0.0.1:33262 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:11] Decode batch. #running-req: 32, #token: 52255, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1222.83, #queue-req: 0\n",
      "[2025-08-13 19:44:12] INFO:     127.0.0.1:33270 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:12] Decode batch. #running-req: 31, #token: 51361, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1225.03, #queue-req: 0\n",
      "[2025-08-13 19:44:13] INFO:     127.0.0.1:43662 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:13] Decode batch. #running-req: 30, #token: 51368, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1191.26, #queue-req: 0\n",
      "[2025-08-13 19:44:14] Decode batch. #running-req: 30, #token: 52568, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1142.98, #queue-req: 0\n",
      "[2025-08-13 19:44:15] Decode batch. #running-req: 30, #token: 53768, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1128.66, #queue-req: 0\n",
      "[2025-08-13 19:44:15] INFO:     127.0.0.1:43086 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:16] INFO:     127.0.0.1:52032 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:16] INFO:     127.0.0.1:43070 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:16] Decode batch. #running-req: 27, #token: 51213, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1068.64, #queue-req: 0\n",
      "[2025-08-13 19:44:16] INFO:     127.0.0.1:52040 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:17] INFO:     127.0.0.1:43664 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:17] Decode batch. #running-req: 25, #token: 46233, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1011.63, #queue-req: 0\n",
      "[2025-08-13 19:44:17] INFO:     127.0.0.1:43668 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:18] INFO:     127.0.0.1:52054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "[2025-08-13 19:44:18] Prefill batch. #new-seq: 3, #new-token: 127, #cached-token: 5140, token usage: 0.18, #running-req: 23, #queue-req: 0\n",
      "[2025-08-13 19:44:18] Prefill batch. #new-seq: 7, #new-token: 2591, #cached-token: 5645, token usage: 0.20, #running-req: 26, #queue-req: 0\n",
      "[2025-08-13 19:44:18] INFO:     127.0.0.1:52040 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:19] Decode batch. #running-req: 32, #token: 50811, token usage: 0.21, cuda graph: True, gen throughput (token/s): 872.58, #queue-req: 0\n",
      "[2025-08-13 19:44:20] Decode batch. #running-req: 32, #token: 52091, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1230.09, #queue-req: 0\n",
      "[2025-08-13 19:44:20] INFO:     127.0.0.1:52064 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:21] INFO:     127.0.0.1:52054 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:21] Decode batch. #running-req: 30, #token: 46893, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1210.21, #queue-req: 0\n",
      "[2025-08-13 19:44:21] INFO:     127.0.0.1:52080 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:21] INFO:     127.0.0.1:52032 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:22] Decode batch. #running-req: 28, #token: 41537, token usage: 0.17, cuda graph: True, gen throughput (token/s): 1190.30, #queue-req: 0\n",
      "[2025-08-13 19:44:23] Decode batch. #running-req: 28, #token: 42657, token usage: 0.17, cuda graph: True, gen throughput (token/s): 1166.32, #queue-req: 0\n",
      "[2025-08-13 19:44:24] Decode batch. #running-req: 28, #token: 43777, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1157.64, #queue-req: 0\n",
      "[2025-08-13 19:44:24] INFO:     127.0.0.1:34290 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:24] INFO:     127.0.0.1:34294 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:24] INFO:     127.0.0.1:34296 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:25] Decode batch. #running-req: 25, #token: 38031, token usage: 0.15, cuda graph: True, gen throughput (token/s): 1094.60, #queue-req: 0\n",
      "[2025-08-13 19:44:25] Decode batch. #running-req: 25, #token: 39031, token usage: 0.16, cuda graph: True, gen throughput (token/s): 1078.81, #queue-req: 0\n",
      "[2025-08-13 19:44:26] INFO:     127.0.0.1:43066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:26] Decode batch. #running-req: 24, #token: 38132, token usage: 0.16, cuda graph: True, gen throughput (token/s): 1053.48, #queue-req: 0\n",
      "[2025-08-13 19:44:27] INFO:     127.0.0.1:56770 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:27] Decode batch. #running-req: 23, #token: 36951, token usage: 0.15, cuda graph: True, gen throughput (token/s): 1040.87, #queue-req: 0\n",
      "[2025-08-13 19:44:28] Decode batch. #running-req: 23, #token: 37871, token usage: 0.15, cuda graph: True, gen throughput (token/s): 1015.92, #queue-req: 0\n",
      "[2025-08-13 19:44:29] INFO:     127.0.0.1:56778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:29] Decode batch. #running-req: 22, #token: 36377, token usage: 0.15, cuda graph: True, gen throughput (token/s): 1001.37, #queue-req: 0\n",
      "[2025-08-13 19:44:29] INFO:     127.0.0.1:56794 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:30] Decode batch. #running-req: 21, #token: 34887, token usage: 0.14, cuda graph: True, gen throughput (token/s): 954.77, #queue-req: 0\n",
      "[2025-08-13 19:44:31] Decode batch. #running-req: 21, #token: 35727, token usage: 0.15, cuda graph: True, gen throughput (token/s): 939.57, #queue-req: 0\n",
      "[2025-08-13 19:44:32] Decode batch. #running-req: 21, #token: 36567, token usage: 0.15, cuda graph: True, gen throughput (token/s): 933.55, #queue-req: 0\n",
      "[2025-08-13 19:44:32] INFO:     127.0.0.1:33574 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:32] INFO:     127.0.0.1:33590 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:33] Decode batch. #running-req: 19, #token: 32984, token usage: 0.13, cuda graph: True, gen throughput (token/s): 900.85, #queue-req: 0\n",
      "[2025-08-13 19:44:34] INFO:     127.0.0.1:33606 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:34] Decode batch. #running-req: 18, #token: 31587, token usage: 0.13, cuda graph: True, gen throughput (token/s): 868.15, #queue-req: 0\n",
      "[2025-08-13 19:44:34] Decode batch. #running-req: 18, #token: 32307, token usage: 0.13, cuda graph: True, gen throughput (token/s): 835.41, #queue-req: 0\n",
      "[2025-08-13 19:44:35] Decode batch. #running-req: 18, #token: 33027, token usage: 0.13, cuda graph: True, gen throughput (token/s): 826.59, #queue-req: 0\n",
      "[2025-08-13 19:44:36] INFO:     127.0.0.1:43666 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:36] INFO:     127.0.0.1:43672 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:36] INFO:     127.0.0.1:43676 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:36] Decode batch. #running-req: 15, #token: 27168, token usage: 0.11, cuda graph: True, gen throughput (token/s): 811.04, #queue-req: 0\n",
      "[2025-08-13 19:44:37] Decode batch. #running-req: 15, #token: 27768, token usage: 0.11, cuda graph: True, gen throughput (token/s): 733.86, #queue-req: 0\n",
      "[2025-08-13 19:44:37] INFO:     127.0.0.1:43678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:38] Decode batch. #running-req: 14, #token: 23978, token usage: 0.10, cuda graph: True, gen throughput (token/s): 722.16, #queue-req: 0\n",
      "[2025-08-13 19:44:38] INFO:     127.0.0.1:50512 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:39] Decode batch. #running-req: 13, #token: 22319, token usage: 0.09, cuda graph: True, gen throughput (token/s): 684.52, #queue-req: 0\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "[2025-08-13 19:44:39] Prefill batch. #new-seq: 3, #new-token: 297, #cached-token: 492, token usage: 0.09, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 19:44:39] Prefill batch. #new-seq: 7, #new-token: 4666, #cached-token: 15386, token usage: 0.15, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 19:44:39] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 777, token usage: 0.17, #running-req: 23, #queue-req: 4\n",
      "[2025-08-13 19:44:40] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 1650, token usage: 0.20, #running-req: 26, #queue-req: 19\n",
      "[2025-08-13 19:44:40] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 1952, token usage: 0.23, #running-req: 30, #queue-req: 15\n",
      "[2025-08-13 19:44:41] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1092, token usage: 0.27, #running-req: 34, #queue-req: 12\n",
      "[2025-08-13 19:44:42] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 2404, token usage: 0.30, #running-req: 37, #queue-req: 8\n",
      "[2025-08-13 19:44:42] Prefill batch. #new-seq: 6, #new-token: 8192, #cached-token: 1886, token usage: 0.33, #running-req: 41, #queue-req: 3\n",
      "[2025-08-13 19:44:43] Prefill batch. #new-seq: 20, #new-token: 8192, #cached-token: 6265, token usage: 0.37, #running-req: 46, #queue-req: 34\n",
      "[2025-08-13 19:44:44] Prefill batch. #new-seq: 6, #new-token: 8192, #cached-token: 2096, token usage: 0.40, #running-req: 65, #queue-req: 29\n",
      "[2025-08-13 19:44:44] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1241, token usage: 0.44, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 19:44:45] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1119, token usage: 0.47, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 19:44:46] Prefill batch. #new-seq: 6, #new-token: 8192, #cached-token: 2100, token usage: 0.50, #running-req: 76, #queue-req: 18\n",
      "[2025-08-13 19:44:46] Prefill batch. #new-seq: 19, #new-token: 4548, #cached-token: 9495, token usage: 0.55, #running-req: 81, #queue-req: 0\n",
      "[2025-08-13 19:44:48] Decode batch. #running-req: 100, #token: 141565, token usage: 0.58, cuda graph: True, gen throughput (token/s): 122.89, #queue-req: 0\n",
      "[2025-08-13 19:44:48] INFO:     127.0.0.1:50518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:48] INFO:     127.0.0.1:43676 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:48] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2846, token usage: 0.57, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:44:48] INFO:     127.0.0.1:43666 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:49] Prefill batch. #new-seq: 2, #new-token: 537, #cached-token: 567, token usage: 0.57, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:44:50] Decode batch. #running-req: 100, #token: 141683, token usage: 0.58, cuda graph: True, gen throughput (token/s): 1812.14, #queue-req: 0\n",
      "[2025-08-13 19:44:52] Decode batch. #running-req: 100, #token: 145683, token usage: 0.59, cuda graph: True, gen throughput (token/s): 1872.90, #queue-req: 0\n",
      "[2025-08-13 19:44:54] INFO:     127.0.0.1:50518 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:54] INFO:     127.0.0.1:43678 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:54] INFO:     127.0.0.1:43008 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:54] INFO:     127.0.0.1:43020 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:54] INFO:     127.0.0.1:43032 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:54] Decode batch. #running-req: 95, #token: 131584, token usage: 0.54, cuda graph: True, gen throughput (token/s): 1846.53, #queue-req: 0\n",
      "[2025-08-13 19:44:54] INFO:     127.0.0.1:43672 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:54] INFO:     127.0.0.1:50512 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:54] Prefill batch. #new-seq: 3, #new-token: 396, #cached-token: 6636, token usage: 0.56, #running-req: 93, #queue-req: 0\n",
      "[2025-08-13 19:44:55] INFO:     127.0.0.1:43020 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:55] INFO:     127.0.0.1:43032 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:56] Decode batch. #running-req: 94, #token: 137520, token usage: 0.56, cuda graph: True, gen throughput (token/s): 1787.61, #queue-req: 0\n",
      "[2025-08-13 19:44:56] Prefill batch. #new-seq: 1, #new-token: 614, #cached-token: 392, token usage: 0.56, #running-req: 94, #queue-req: 0\n",
      "[2025-08-13 19:44:58] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 706, token usage: 0.57, #running-req: 95, #queue-req: 2\n",
      "[2025-08-13 19:44:58] Prefill batch. #new-seq: 3, #new-token: 1206, #cached-token: 292, token usage: 0.61, #running-req: 97, #queue-req: 0\n",
      "[2025-08-13 19:44:59] INFO:     127.0.0.1:43048 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:44:59] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2687, token usage: 0.61, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:44:59] Decode batch. #running-req: 100, #token: 151391, token usage: 0.62, cuda graph: True, gen throughput (token/s): 1279.35, #queue-req: 0\n",
      "[2025-08-13 19:45:00] INFO:     127.0.0.1:43060 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:00] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2749, token usage: 0.62, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:02] Decode batch. #running-req: 100, #token: 155410, token usage: 0.63, cuda graph: True, gen throughput (token/s): 1783.78, #queue-req: 0\n",
      "[2025-08-13 19:45:02] INFO:     127.0.0.1:43008 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:03] Prefill batch. #new-seq: 1, #new-token: 4498, #cached-token: 168, token usage: 0.63, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:04] Decode batch. #running-req: 100, #token: 161583, token usage: 0.66, cuda graph: True, gen throughput (token/s): 1496.57, #queue-req: 0\n",
      "[2025-08-13 19:45:05] INFO:     127.0.0.1:44906 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:05] INFO:     127.0.0.1:43048 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:06] Prefill batch. #new-seq: 2, #new-token: 1682, #cached-token: 650, token usage: 0.66, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:45:07] Decode batch. #running-req: 100, #token: 163378, token usage: 0.66, cuda graph: True, gen throughput (token/s): 1628.65, #queue-req: 0\n",
      "[2025-08-13 19:45:08] INFO:     127.0.0.1:43060 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:08] Prefill batch. #new-seq: 1, #new-token: 2544, #cached-token: 412, token usage: 0.67, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:09] INFO:     127.0.0.1:50324 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:09] Decode batch. #running-req: 99, #token: 166015, token usage: 0.68, cuda graph: True, gen throughput (token/s): 1566.77, #queue-req: 0\n",
      "[2025-08-13 19:45:10] Prefill batch. #new-seq: 1, #new-token: 210, #cached-token: 122, token usage: 0.68, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:12] Decode batch. #running-req: 100, #token: 170219, token usage: 0.69, cuda graph: True, gen throughput (token/s): 1680.15, #queue-req: 0\n",
      "[2025-08-13 19:45:13] INFO:     127.0.0.1:45048 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:13] INFO:     127.0.0.1:45030 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:14] Decode batch. #running-req: 98, #token: 169412, token usage: 0.69, cuda graph: True, gen throughput (token/s): 1672.48, #queue-req: 0\n",
      "[2025-08-13 19:45:14] Prefill batch. #new-seq: 2, #new-token: 3729, #cached-token: 570, token usage: 0.69, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:45:15] INFO:     127.0.0.1:44880 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 19:45:16] INFO:     127.0.0.1:33956 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:16] INFO:     127.0.0.1:33902 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:16] INFO:     127.0.0.1:45024 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:17] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 392, token usage: 0.68, #running-req: 96, #queue-req: 0\n",
      "[2025-08-13 19:45:17] Decode batch. #running-req: 97, #token: 166424, token usage: 0.68, cuda graph: True, gen throughput (token/s): 1445.34, #queue-req: 0\n",
      "[2025-08-13 19:45:17] INFO:     127.0.0.1:33774 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:17] INFO:     127.0.0.1:33752 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:18] INFO:     127.0.0.1:33860 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:18] Prefill batch. #new-seq: 1, #new-token: 2342, #cached-token: 460, token usage: 0.65, #running-req: 94, #queue-req: 0\n",
      "[2025-08-13 19:45:19] INFO:     127.0.0.1:44994 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:19] Decode batch. #running-req: 94, #token: 161578, token usage: 0.66, cuda graph: True, gen throughput (token/s): 1517.84, #queue-req: 0\n",
      "[2025-08-13 19:45:21] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 455, token usage: 0.67, #running-req: 94, #queue-req: 0\n",
      "[2025-08-13 19:45:21] INFO:     127.0.0.1:33916 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:21] Prefill batch. #new-seq: 1, #new-token: 4897, #cached-token: 171, token usage: 0.67, #running-req: 94, #queue-req: 0\n",
      "[2025-08-13 19:45:22] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 914, token usage: 0.69, #running-req: 95, #queue-req: 1\n",
      "[2025-08-13 19:45:22] Prefill batch. #new-seq: 2, #new-token: 3359, #cached-token: 142, token usage: 0.72, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:45:23] Decode batch. #running-req: 100, #token: 181518, token usage: 0.74, cuda graph: True, gen throughput (token/s): 963.86, #queue-req: 0\n",
      "[2025-08-13 19:45:24] INFO:     127.0.0.1:45004 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:24] INFO:     127.0.0.1:33938 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:26] Prefill batch. #new-seq: 2, #new-token: 4669, #cached-token: 934, token usage: 0.73, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:45:26] Decode batch. #running-req: 98, #token: 184601, token usage: 0.75, cuda graph: True, gen throughput (token/s): 1593.48, #queue-req: 0\n",
      "[2025-08-13 19:45:26] INFO:     127.0.0.1:50372 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:27] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 120, token usage: 0.75, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:29] Decode batch. #running-req: 100, #token: 187265, token usage: 0.76, cuda graph: True, gen throughput (token/s): 1371.72, #queue-req: 0\n",
      "[2025-08-13 19:45:30] INFO:     127.0.0.1:44992 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:31] Decode batch. #running-req: 99, #token: 186212, token usage: 0.76, cuda graph: True, gen throughput (token/s): 1580.14, #queue-req: 0\n",
      "[2025-08-13 19:45:31] Prefill batch. #new-seq: 1, #new-token: 4506, #cached-token: 169, token usage: 0.76, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:34] Decode batch. #running-req: 100, #token: 194718, token usage: 0.79, cuda graph: True, gen throughput (token/s): 1346.65, #queue-req: 0\n",
      "[2025-08-13 19:45:35] INFO:     127.0.0.1:33720 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:36] Prefill batch. #new-seq: 1, #new-token: 2333, #cached-token: 468, token usage: 0.79, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:37] INFO:     127.0.0.1:33758 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:37] Decode batch. #running-req: 100, #token: 195092, token usage: 0.79, cuda graph: True, gen throughput (token/s): 1425.98, #queue-req: 0\n",
      "[2025-08-13 19:45:38] Prefill batch. #new-seq: 1, #new-token: 2258, #cached-token: 143, token usage: 0.80, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:38] INFO:     127.0.0.1:33868 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:39] Prefill batch. #new-seq: 1, #new-token: 2361, #cached-token: 440, token usage: 0.80, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:40] Decode batch. #running-req: 100, #token: 200738, token usage: 0.82, cuda graph: True, gen throughput (token/s): 1318.90, #queue-req: 0\n",
      "[2025-08-13 19:45:42] Decode batch. #running-req: 100, #token: 204738, token usage: 0.83, cuda graph: True, gen throughput (token/s): 1507.72, #queue-req: 0\n",
      "[2025-08-13 19:45:45] Decode batch. #running-req: 100, #token: 208738, token usage: 0.85, cuda graph: True, gen throughput (token/s): 1488.11, #queue-req: 0\n",
      "[2025-08-13 19:45:46] INFO:     127.0.0.1:33880 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:46] Prefill batch. #new-seq: 1, #new-token: 2355, #cached-token: 447, token usage: 0.84, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:47] INFO:     127.0.0.1:33446 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:48] Prefill batch. #new-seq: 1, #new-token: 604, #cached-token: 126, token usage: 0.84, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:48] Decode batch. #running-req: 100, #token: 207138, token usage: 0.84, cuda graph: True, gen throughput (token/s): 1341.90, #queue-req: 0\n",
      "[2025-08-13 19:45:50] INFO:     127.0.0.1:45040 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:51] Prefill batch. #new-seq: 1, #new-token: 2334, #cached-token: 468, token usage: 0.84, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:51] Decode batch. #running-req: 100, #token: 210369, token usage: 0.86, cuda graph: True, gen throughput (token/s): 1369.28, #queue-req: 0\n",
      "[2025-08-13 19:45:52] INFO:     127.0.0.1:33944 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:53] Prefill batch. #new-seq: 1, #new-token: 1001, #cached-token: 156, token usage: 0.86, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:54] Decode batch. #running-req: 100, #token: 214190, token usage: 0.87, cuda graph: True, gen throughput (token/s): 1410.10, #queue-req: 0\n",
      "[2025-08-13 19:45:56] INFO:     127.0.0.1:33894 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:57] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 119, token usage: 0.88, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:45:57] Decode batch. #running-req: 99, #token: 217177, token usage: 0.88, cuda graph: True, gen throughput (token/s): 1427.09, #queue-req: 0\n",
      "[2025-08-13 19:45:58] INFO:     127.0.0.1:50318 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:58] INFO:     127.0.0.1:50334 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:58] INFO:     127.0.0.1:50346 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:58] INFO:     127.0.0.1:50362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:58] INFO:     127.0.0.1:50388 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:58] Prefill batch. #new-seq: 5, #new-token: 104, #cached-token: 13461, token usage: 0.89, #running-req: 95, #queue-req: 0\n",
      "[2025-08-13 19:45:59] INFO:     127.0.0.1:50362 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:59] INFO:     127.0.0.1:50318 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:59] INFO:     127.0.0.1:50334 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:45:59] Decode batch. #running-req: 97, #token: 214981, token usage: 0.87, cuda graph: True, gen throughput (token/s): 1408.98, #queue-req: 0\n",
      "[2025-08-13 19:46:01] Prefill batch. #new-seq: 3, #new-token: 584, #cached-token: 365, token usage: 0.88, #running-req: 97, #queue-req: 0\n",
      "[2025-08-13 19:46:02] Decode batch. #running-req: 100, #token: 219490, token usage: 0.89, cuda graph: True, gen throughput (token/s): 1379.11, #queue-req: 0\n",
      "[2025-08-13 19:46:05] Decode batch. #running-req: 100, #token: 223490, token usage: 0.91, cuda graph: True, gen throughput (token/s): 1416.58, #queue-req: 0\n",
      "[2025-08-13 19:46:07] INFO:     127.0.0.1:50388 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:07] INFO:     127.0.0.1:50346 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:08] Decode batch. #running-req: 98, #token: 221152, token usage: 0.90, cuda graph: True, gen throughput (token/s): 1396.48, #queue-req: 0\n",
      "[2025-08-13 19:46:09] INFO:     127.0.0.1:44956 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:09] INFO:     127.0.0.1:33886 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:09] INFO:     127.0.0.1:33746 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:10] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 151, token usage: 0.87, #running-req: 95, #queue-req: 0\n",
      "[2025-08-13 19:46:11] INFO:     127.0.0.1:45010 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:11] Decode batch. #running-req: 95, #token: 213565, token usage: 0.87, cuda graph: True, gen throughput (token/s): 1287.19, #queue-req: 0\n",
      "[2025-08-13 19:46:11] Prefill batch. #new-seq: 1, #new-token: 2527, #cached-token: 462, token usage: 0.87, #running-req: 95, #queue-req: 0\n",
      "[2025-08-13 19:46:12] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1662, token usage: 0.88, #running-req: 96, #queue-req: 0\n",
      "[2025-08-13 19:46:12] Prefill batch. #new-seq: 1, #new-token: 966, #cached-token: 0, token usage: 0.92, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:46:13] INFO:     127.0.0.1:45020 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:14] INFO:     127.0.0.1:45180 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:14] INFO:     127.0.0.1:33858 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:15] Decode batch. #running-req: 97, #token: 218908, token usage: 0.89, cuda graph: True, gen throughput (token/s): 1019.43, #queue-req: 0\n",
      "[2025-08-13 19:46:15] Prefill batch. #new-seq: 1, #new-token: 2308, #cached-token: 493, token usage: 0.89, #running-req: 97, #queue-req: 0\n",
      "[2025-08-13 19:46:16] Prefill batch. #new-seq: 2, #new-token: 4587, #cached-token: 586, token usage: 0.90, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:46:17] INFO:     127.0.0.1:45224 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:17] Prefill batch. #new-seq: 1, #new-token: 1324, #cached-token: 149, token usage: 0.92, #running-req: 99, #queue-req: 0\n",
      "[2025-08-13 19:46:18] INFO:     127.0.0.1:33750 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:18] Decode batch. #running-req: 99, #token: 225285, token usage: 0.92, cuda graph: True, gen throughput (token/s): 1098.16, #queue-req: 0\n",
      "[2025-08-13 19:46:19] INFO:     127.0.0.1:33708 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:19] Prefill batch. #new-seq: 2, #new-token: 2368, #cached-token: 272, token usage: 0.92, #running-req: 98, #queue-req: 0\n",
      "[2025-08-13 19:46:22] Decode batch. #running-req: 100, #token: 230269, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1279.79, #queue-req: 0\n",
      "[2025-08-13 19:46:24] Decode batch. #running-req: 100, #token: 233180, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1360.02, #queue-req: 0\n",
      "[2025-08-13 19:46:24] INFO:     127.0.0.1:38728 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:26] INFO:     127.0.0.1:44982 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:27] Decode batch. #running-req: 98, #token: 233333, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1334.52, #queue-req: 2\n",
      "[2025-08-13 19:46:30] INFO:     127.0.0.1:57392 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:30] INFO:     127.0.0.1:45110 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:30] Prefill batch. #new-seq: 1, #new-token: 5061, #cached-token: 93, token usage: 0.93, #running-req: 96, #queue-req: 1\n",
      "[2025-08-13 19:46:30] Decode batch. #running-req: 96, #token: 234795, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1304.41, #queue-req: 1\n",
      "[2025-08-13 19:46:32] INFO:     127.0.0.1:44310 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:32] Prefill batch. #new-seq: 1, #new-token: 2508, #cached-token: 463, token usage: 0.94, #running-req: 96, #queue-req: 2\n",
      ".[2025-08-13 19:46:34] INFO:     127.0.0.1:33736 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:34] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 448, token usage: 0.94, #running-req: 96, #queue-req: 2\n",
      "[2025-08-13 19:46:34] Decode batch. #running-req: 97, #token: 233991, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1007.79, #queue-req: 2\n",
      "[2025-08-13 19:46:35] INFO:     127.0.0.1:48188 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:35] Prefill batch. #new-seq: 1, #new-token: 1497, #cached-token: 157, token usage: 0.95, #running-req: 96, #queue-req: 2\n",
      "[2025-08-13 19:46:36] INFO:     127.0.0.1:44980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:36] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 409, token usage: 0.94, #running-req: 96, #queue-req: 2\n",
      "[2025-08-13 19:46:37] Decode batch. #running-req: 97, #token: 233983, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1244.76, #queue-req: 3\n",
      "[2025-08-13 19:46:40] Decode batch. #running-req: 97, #token: 234106, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1302.20, #queue-req: 3\n",
      "[2025-08-13 19:46:40] INFO:     127.0.0.1:33760 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:41] INFO:     127.0.0.1:33700 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:41] Prefill batch. #new-seq: 1, #new-token: 2328, #cached-token: 474, token usage: 0.95, #running-req: 95, #queue-req: 3\n",
      "[2025-08-13 19:46:42] INFO:     127.0.0.1:33926 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:42] Prefill batch. #new-seq: 1, #new-token: 1790, #cached-token: 127, token usage: 0.95, #running-req: 95, #queue-req: 3\n",
      "[2025-08-13 19:46:43] INFO:     127.0.0.1:46732 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:43] Prefill batch. #new-seq: 2, #new-token: 2572, #cached-token: 917, token usage: 0.93, #running-req: 95, #queue-req: 1\n",
      "[2025-08-13 19:46:44] Decode batch. #running-req: 97, #token: 233441, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1090.95, #queue-req: 3\n",
      "[2025-08-13 19:46:45] INFO:     127.0.0.1:57432 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:45] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 122, token usage: 0.95, #running-req: 96, #queue-req: 2\n",
      "[2025-08-13 19:46:47] Decode batch. #running-req: 97, #token: 236314, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1303.69, #queue-req: 3\n",
      "[2025-08-13 19:46:50] Decode batch. #running-req: 97, #token: 240194, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1306.81, #queue-req: 3\n",
      "[2025-08-13 19:46:53] Decode batch. #running-req: 97, #token: 244074, token usage: 0.99, cuda graph: True, gen throughput (token/s): 1290.75, #queue-req: 3\n",
      "[2025-08-13 19:46:54] Decode out of memory happened. #retracted_reqs: 2, #new_token_ratio: 0.0980 -> 0.6654\n",
      "[2025-08-13 19:46:55] INFO:     127.0.0.1:33840 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:56] Decode batch. #running-req: 94, #token: 241071, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1274.04, #queue-req: 6\n",
      "[2025-08-13 19:46:58] INFO:     127.0.0.1:44938 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:46:59] Decode batch. #running-req: 93, #token: 240838, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1261.71, #queue-req: 6\n",
      "[2025-08-13 19:47:01] INFO:     127.0.0.1:45126 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:02] Decode batch. #running-req: 92, #token: 242577, token usage: 0.99, cuda graph: True, gen throughput (token/s): 1244.75, #queue-req: 7\n",
      "[2025-08-13 19:47:02] INFO:     127.0.0.1:33878 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:03] INFO:     127.0.0.1:33872 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:03] INFO:     127.0.0.1:54310 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:04] INFO:     127.0.0.1:45140 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:05] Decode batch. #running-req: 88, #token: 233835, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1237.25, #queue-req: 11\n",
      "[2025-08-13 19:47:06] INFO:     127.0.0.1:44812 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 19:47:08] Decode batch. #running-req: 87, #token: 235278, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1222.99, #queue-req: 13\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:33828 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45082 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44810 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44808 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44832 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45152 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44864 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45164 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45072 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45200 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44848 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44940 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44838 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45188 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45132 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:33694 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45094 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44826 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:33958 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45064 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45208 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44894 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45078 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44920 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44972 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44922 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44924 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:44936 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45104 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45156 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45146 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:45212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:33800 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:33856 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:33788 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] INFO:     127.0.0.1:33814 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:10] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 1522, token usage: 0.60, #running-req: 51, #queue-req: 8\n",
      "[2025-08-13 19:47:10] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 1846, token usage: 0.63, #running-req: 55, #queue-req: 4\n",
      "[2025-08-13 19:47:11] Prefill batch. #new-seq: 7, #new-token: 5964, #cached-token: 4241, token usage: 0.68, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 19:47:11] Prefill batch. #new-seq: 15, #new-token: 6597, #cached-token: 34996, token usage: 0.83, #running-req: 66, #queue-req: 19\n",
      "[2025-08-13 19:47:13] Decode batch. #running-req: 81, #token: 210466, token usage: 0.86, cuda graph: True, gen throughput (token/s): 652.75, #queue-req: 19\n",
      "[2025-08-13 19:47:13] INFO:     127.0.0.1:45152 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:13] INFO:     127.0.0.1:44808 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:13] INFO:     127.0.0.1:45132 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:13] INFO:     127.0.0.1:33694 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:13] INFO:     127.0.0.1:44940 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:13] Prefill batch. #new-seq: 5, #new-token: 2304, #cached-token: 13037, token usage: 0.86, #running-req: 80, #queue-req: 14\n",
      "[2025-08-13 19:47:14] INFO:     127.0.0.1:33788 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:14] INFO:     127.0.0.1:33856 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:14] Prefill batch. #new-seq: 3, #new-token: 2198, #cached-token: 7733, token usage: 0.86, #running-req: 80, #queue-req: 11\n",
      "[2025-08-13 19:47:14] INFO:     127.0.0.1:33800 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:14] Prefill batch. #new-seq: 2, #new-token: 2203, #cached-token: 2901, token usage: 0.87, #running-req: 81, #queue-req: 9\n",
      "[2025-08-13 19:47:15] INFO:     127.0.0.1:44832 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:15] INFO:     127.0.0.1:54304 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:15] Prefill batch. #new-seq: 2, #new-token: 2136, #cached-token: 2992, token usage: 0.87, #running-req: 82, #queue-req: 7\n",
      "[2025-08-13 19:47:16] INFO:     127.0.0.1:44344 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:16] Prefill batch. #new-seq: 2, #new-token: 4558, #cached-token: 244, token usage: 0.86, #running-req: 82, #queue-req: 5\n",
      "[2025-08-13 19:47:17] Decode batch. #running-req: 84, #token: 215443, token usage: 0.88, cuda graph: True, gen throughput (token/s): 849.32, #queue-req: 5\n",
      "[2025-08-13 19:47:17] INFO:     127.0.0.1:33494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:17] Prefill batch. #new-seq: 2, #new-token: 4444, #cached-token: 941, token usage: 0.86, #running-req: 83, #queue-req: 3\n",
      "[2025-08-13 19:47:18] INFO:     127.0.0.1:48264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:18] Prefill batch. #new-seq: 1, #new-token: 2349, #cached-token: 463, token usage: 0.87, #running-req: 84, #queue-req: 2\n",
      "[2025-08-13 19:47:18] INFO:     127.0.0.1:44838 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:19] Prefill batch. #new-seq: 1, #new-token: 2339, #cached-token: 474, token usage: 0.88, #running-req: 84, #queue-req: 2\n",
      "[2025-08-13 19:47:20] Decode batch. #running-req: 85, #token: 219745, token usage: 0.89, cuda graph: True, gen throughput (token/s): 975.55, #queue-req: 2\n",
      "[2025-08-13 19:47:20] INFO:     127.0.0.1:48250 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:20] Prefill batch. #new-seq: 1, #new-token: 2344, #cached-token: 457, token usage: 0.89, #running-req: 84, #queue-req: 1\n",
      "[2025-08-13 19:47:21] INFO:     127.0.0.1:45064 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:21] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2321, token usage: 0.90, #running-req: 84, #queue-req: 0\n",
      "[2025-08-13 19:47:21] INFO:     127.0.0.1:45082 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:22] INFO:     127.0.0.1:45212 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:22] INFO:     127.0.0.1:45094 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:22] Prefill batch. #new-seq: 1, #new-token: 220, #cached-token: 169, token usage: 0.87, #running-req: 82, #queue-req: 0\n",
      ".[2025-08-13 19:47:23] INFO:     127.0.0.1:44810 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:23] Decode batch. #running-req: 82, #token: 214172, token usage: 0.87, cuda graph: True, gen throughput (token/s): 1135.02, #queue-req: 0\n",
      "[2025-08-13 19:47:23] INFO:     127.0.0.1:45104 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:23] INFO:     127.0.0.1:45200 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:23] INFO:     127.0.0.1:44826 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:23] INFO:     127.0.0.1:44924 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:23] INFO:     127.0.0.1:45146 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:23] INFO:     127.0.0.1:44864 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:23] INFO:     127.0.0.1:44848 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:24] INFO:     127.0.0.1:45072 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:24] INFO:     127.0.0.1:44922 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:24] INFO:     127.0.0.1:44936 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:24] INFO:     127.0.0.1:45188 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:24] INFO:     127.0.0.1:33814 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:24] INFO:     127.0.0.1:44894 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:25] INFO:     127.0.0.1:45078 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:25] INFO:     127.0.0.1:45156 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:25] Decode batch. #running-req: 67, #token: 175514, token usage: 0.71, cuda graph: True, gen throughput (token/s): 1187.08, #queue-req: 0\n",
      "[2025-08-13 19:47:25] INFO:     127.0.0.1:54326 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:26] INFO:     127.0.0.1:45164 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:26] INFO:     127.0.0.1:33958 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:26] INFO:     127.0.0.1:45208 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:26] Prefill batch. #new-seq: 6, #new-token: 5557, #cached-token: 1583, token usage: 0.69, #running-req: 63, #queue-req: 0\n",
      "[2025-08-13 19:47:27] Prefill batch. #new-seq: 3, #new-token: 2587, #cached-token: 3626, token usage: 0.72, #running-req: 69, #queue-req: 0\n",
      "[2025-08-13 19:47:27] Prefill batch. #new-seq: 3, #new-token: 5451, #cached-token: 360, token usage: 0.73, #running-req: 72, #queue-req: 0\n",
      "[2025-08-13 19:47:28] INFO:     127.0.0.1:44972 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:28] INFO:     127.0.0.1:44920 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:28] INFO:     127.0.0.1:44330 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:28] INFO:     127.0.0.1:44320 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:28] INFO:     127.0.0.1:44294 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:28] INFO:     127.0.0.1:54332 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:29] Decode batch. #running-req: 69, #token: 169597, token usage: 0.69, cuda graph: True, gen throughput (token/s): 796.49, #queue-req: 0\n",
      "[2025-08-13 19:47:30] INFO:     127.0.0.1:54304 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:30] INFO:     127.0.0.1:52696 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:31] Decode batch. #running-req: 67, #token: 166470, token usage: 0.68, cuda graph: True, gen throughput (token/s): 1232.13, #queue-req: 0\n",
      "[2025-08-13 19:47:33] Decode batch. #running-req: 67, #token: 169150, token usage: 0.69, cuda graph: True, gen throughput (token/s): 1213.65, #queue-req: 0\n",
      "[2025-08-13 19:47:35] INFO:     127.0.0.1:54326 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:35] INFO:     127.0.0.1:44374 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:35] INFO:     127.0.0.1:44358 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:36] Decode batch. #running-req: 64, #token: 163333, token usage: 0.66, cuda graph: True, gen throughput (token/s): 1205.89, #queue-req: 0\n",
      "[2025-08-13 19:47:38] Decode batch. #running-req: 64, #token: 165893, token usage: 0.67, cuda graph: True, gen throughput (token/s): 1225.19, #queue-req: 0\n",
      "[2025-08-13 19:47:38] INFO:     127.0.0.1:48256 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:38] INFO:     127.0.0.1:57404 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:39] INFO:     127.0.0.1:53312 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:40] Decode batch. #running-req: 61, #token: 164515, token usage: 0.67, cuda graph: True, gen throughput (token/s): 1197.46, #queue-req: 0\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "API request failed. Retrying... (1/5)\n",
      "[2025-08-13 19:47:41] Prefill batch. #new-seq: 7, #new-token: 2901, #cached-token: 3857, token usage: 0.68, #running-req: 61, #queue-req: 0\n",
      "[2025-08-13 19:47:42] Decode batch. #running-req: 68, #token: 172337, token usage: 0.70, cuda graph: True, gen throughput (token/s): 1078.29, #queue-req: 0\n",
      "[2025-08-13 19:47:42] INFO:     127.0.0.1:57414 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:42] INFO:     127.0.0.1:57418 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:44] INFO:     127.0.0.1:52688 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:44] Decode batch. #running-req: 65, #token: 163966, token usage: 0.67, cuda graph: True, gen throughput (token/s): 1193.59, #queue-req: 0\n",
      "[2025-08-13 19:47:45] INFO:     127.0.0.1:41196 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:45] INFO:     127.0.0.1:57448 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:46] INFO:     127.0.0.1:46740 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:46] Prefill batch. #new-seq: 7, #new-token: 8134, #cached-token: 13355, token usage: 0.68, #running-req: 62, #queue-req: 0\n",
      "[2025-08-13 19:47:46] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 786, token usage: 0.72, #running-req: 69, #queue-req: 8\n",
      "[2025-08-13 19:47:47] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 1757, token usage: 0.75, #running-req: 71, #queue-req: 8\n",
      "[2025-08-13 19:47:48] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 579, token usage: 0.78, #running-req: 75, #queue-req: 6\n",
      "[2025-08-13 19:47:48] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 613, token usage: 0.82, #running-req: 77, #queue-req: 4\n",
      "[2025-08-13 19:47:49] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1168, token usage: 0.85, #running-req: 79, #queue-req: 17\n",
      "[2025-08-13 19:47:50] Prefill batch. #new-seq: 5, #new-token: 5518, #cached-token: 3355, token usage: 0.89, #running-req: 82, #queue-req: 13\n",
      "[2025-08-13 19:47:51] Decode batch. #running-req: 87, #token: 225423, token usage: 0.92, cuda graph: True, gen throughput (token/s): 383.69, #queue-req: 13\n",
      "[2025-08-13 19:47:52] INFO:     127.0.0.1:41172 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:52] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 2733, token usage: 0.93, #running-req: 86, #queue-req: 10\n",
      "[2025-08-13 19:47:53] INFO:     127.0.0.1:33430 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:53] Prefill batch. #new-seq: 2, #new-token: 4940, #cached-token: 1018, token usage: 0.91, #running-req: 88, #queue-req: 8\n",
      "[2025-08-13 19:47:54] INFO:     127.0.0.1:57404 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:54] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 149, token usage: 0.93, #running-req: 89, #queue-req: 9\n",
      "[2025-08-13 19:47:54] INFO:     127.0.0.1:33512 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:54] INFO:     127.0.0.1:33462 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:54] INFO:     127.0.0.1:33478 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:54] INFO:     127.0.0.1:33500 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:54] Prefill batch. #new-seq: 6, #new-token: 8192, #cached-token: 1665, token usage: 0.86, #running-req: 86, #queue-req: 3\n",
      "[2025-08-13 19:47:54] Prefill batch. #new-seq: 4, #new-token: 2274, #cached-token: 5647, token usage: 0.91, #running-req: 91, #queue-req: 0\n",
      "[2025-08-13 19:47:55] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4408, token usage: 0.94, #running-req: 95, #queue-req: 4\n",
      "[2025-08-13 19:47:55] Decode batch. #running-req: 96, #token: 230642, token usage: 0.94, cuda graph: True, gen throughput (token/s): 860.08, #queue-req: 4\n",
      "[2025-08-13 19:47:58] INFO:     127.0.0.1:33520 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:58] INFO:     127.0.0.1:33522 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:58] Decode batch. #running-req: 96, #token: 225827, token usage: 0.92, cuda graph: True, gen throughput (token/s): 1354.49, #queue-req: 4\n",
      "[2025-08-13 19:47:58] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4970, token usage: 0.94, #running-req: 94, #queue-req: 5\n",
      "[2025-08-13 19:47:58] INFO:     127.0.0.1:57414 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:58] Prefill batch. #new-seq: 1, #new-token: 2020, #cached-token: 2405, token usage: 0.93, #running-req: 94, #queue-req: 4\n",
      "[2025-08-13 19:47:59] INFO:     127.0.0.1:46728 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:47:59] INFO:     127.0.0.1:53302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:01] Decode batch. #running-req: 93, #token: 231829, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1228.51, #queue-req: 7\n",
      "[2025-08-13 19:48:01] INFO:     127.0.0.1:57418 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:01] INFO:     127.0.0.1:57448 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:02] Prefill batch. #new-seq: 2, #new-token: 4340, #cached-token: 2569, token usage: 0.92, #running-req: 91, #queue-req: 5\n",
      "[2025-08-13 19:48:03] INFO:     127.0.0.1:33462 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:03] Prefill batch. #new-seq: 1, #new-token: 4327, #cached-token: 493, token usage: 0.92, #running-req: 92, #queue-req: 4\n",
      "[2025-08-13 19:48:05] Decode batch. #running-req: 93, #token: 233171, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1022.70, #queue-req: 7\n",
      "[2025-08-13 19:48:05] INFO:     127.0.0.1:33430 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:05] Prefill batch. #new-seq: 1, #new-token: 4364, #cached-token: 457, token usage: 0.93, #running-req: 92, #queue-req: 6\n",
      "[2025-08-13 19:48:07] INFO:     127.0.0.1:33512 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:08] INFO:     127.0.0.1:33478 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:08] Prefill batch. #new-seq: 1, #new-token: 2698, #cached-token: 171, token usage: 0.93, #running-req: 91, #queue-req: 6\n",
      "[2025-08-13 19:48:08] Decode batch. #running-req: 92, #token: 230760, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1056.91, #queue-req: 6\n",
      "[2025-08-13 19:48:09] INFO:     127.0.0.1:52748 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:09] INFO:     127.0.0.1:33500 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:09] Prefill batch. #new-seq: 3, #new-token: 4873, #cached-token: 796, token usage: 0.91, #running-req: 91, #queue-req: 5\n",
      "[2025-08-13 19:48:09] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 466, token usage: 0.93, #running-req: 93, #queue-req: 4\n",
      "[2025-08-13 19:48:11] INFO:     127.0.0.1:45946 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:12] Decode batch. #running-req: 93, #token: 231962, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1087.05, #queue-req: 6\n",
      "[2025-08-13 19:48:12] INFO:     127.0.0.1:57936 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:13] Prefill batch. #new-seq: 1, #new-token: 2279, #cached-token: 177, token usage: 0.93, #running-req: 92, #queue-req: 7\n",
      "[2025-08-13 19:48:14] INFO:     127.0.0.1:33520 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:14] Prefill batch. #new-seq: 1, #new-token: 2331, #cached-token: 626, token usage: 0.93, #running-req: 92, #queue-req: 6\n",
      "[2025-08-13 19:48:14] INFO:     127.0.0.1:57944 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:14] Prefill batch. #new-seq: 3, #new-token: 495, #cached-token: 795, token usage: 0.92, #running-req: 92, #queue-req: 3\n",
      "[2025-08-13 19:48:15] Decode batch. #running-req: 95, #token: 227713, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1135.18, #queue-req: 5\n",
      "[2025-08-13 19:48:16] INFO:     127.0.0.1:33522 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:16] Prefill batch. #new-seq: 2, #new-token: 4985, #cached-token: 539, token usage: 0.91, #running-req: 94, #queue-req: 3\n",
      "[2025-08-13 19:48:18] Decode batch. #running-req: 96, #token: 232031, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1165.76, #queue-req: 4\n",
      "[2025-08-13 19:48:19] INFO:     127.0.0.1:46728 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:21] Decode batch. #running-req: 95, #token: 233467, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1340.52, #queue-req: 5\n",
      "[2025-08-13 19:48:22] INFO:     127.0.0.1:43146 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:22] INFO:     127.0.0.1:57960 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:24] Decode batch. #running-req: 93, #token: 231996, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1323.71, #queue-req: 7\n",
      "[2025-08-13 19:48:26] INFO:     127.0.0.1:38742 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:27] Decode batch. #running-req: 92, #token: 231378, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1307.71, #queue-req: 8\n",
      "[2025-08-13 19:48:29] INFO:     127.0.0.1:38748 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:30] Decode batch. #running-req: 91, #token: 232048, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1289.39, #queue-req: 9\n",
      "[2025-08-13 19:48:31] INFO:     127.0.0.1:43000 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:31] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4400, token usage: 0.94, #running-req: 90, #queue-req: 8\n",
      "[2025-08-13 19:48:31] INFO:     127.0.0.1:41136 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:31] INFO:     127.0.0.1:38840 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:32] INFO:     127.0.0.1:57936 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:32] Prefill batch. #new-seq: 1, #new-token: 4380, #cached-token: 440, token usage: 0.93, #running-req: 88, #queue-req: 7\n",
      "[2025-08-13 19:48:33] INFO:     127.0.0.1:38756 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:33] Decode batch. #running-req: 89, #token: 231168, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1104.39, #queue-req: 7\n",
      "[2025-08-13 19:48:33] Prefill batch. #new-seq: 1, #new-token: 2160, #cached-token: 472, token usage: 0.94, #running-req: 88, #queue-req: 6\n",
      "[2025-08-13 19:48:36] Decode batch. #running-req: 89, #token: 236888, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1171.01, #queue-req: 11\n",
      "[2025-08-13 19:48:38] INFO:     127.0.0.1:46446 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:38] INFO:     127.0.0.1:46450 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:38] INFO:     127.0.0.1:46436 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:39] Decode batch. #running-req: 86, #token: 233825, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1233.79, #queue-req: 14\n",
      "[2025-08-13 19:48:39] INFO:     127.0.0.1:43102 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:39] Prefill batch. #new-seq: 1, #new-token: 2158, #cached-token: 474, token usage: 0.94, #running-req: 85, #queue-req: 13\n",
      "[2025-08-13 19:48:40] INFO:     127.0.0.1:52764 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:40] Prefill batch. #new-seq: 1, #new-token: 2160, #cached-token: 156, token usage: 0.94, #running-req: 85, #queue-req: 12\n",
      "[2025-08-13 19:48:40] INFO:     127.0.0.1:40174 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:40] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 447, token usage: 0.94, #running-req: 85, #queue-req: 11\n",
      ".[2025-08-13 19:48:42] INFO:     127.0.0.1:57944 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:42] Prefill batch. #new-seq: 1, #new-token: 414, #cached-token: 93, token usage: 0.95, #running-req: 85, #queue-req: 13\n",
      "[2025-08-13 19:48:42] Decode batch. #running-req: 86, #token: 233947, token usage: 0.95, cuda graph: True, gen throughput (token/s): 941.12, #queue-req: 13\n",
      "[2025-08-13 19:48:45] Decode batch. #running-req: 86, #token: 237387, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1214.71, #queue-req: 14\n",
      "[2025-08-13 19:48:46] INFO:     127.0.0.1:57960 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:47] INFO:     127.0.0.1:43132 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:48] Prefill batch. #new-seq: 1, #new-token: 4354, #cached-token: 468, token usage: 0.94, #running-req: 84, #queue-req: 14\n",
      "[2025-08-13 19:48:48] Decode batch. #running-req: 85, #token: 237227, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1052.28, #queue-req: 14\n",
      "[2025-08-13 19:48:49] INFO:     127.0.0.1:42938 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:49] Prefill batch. #new-seq: 1, #new-token: 3021, #cached-token: 156, token usage: 0.95, #running-req: 84, #queue-req: 14\n",
      "[2025-08-13 19:48:50] INFO:     127.0.0.1:52728 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:50] INFO:     127.0.0.1:52700 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:50] INFO:     127.0.0.1:52714 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:50] INFO:     127.0.0.1:52736 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:50] Prefill batch. #new-seq: 6, #new-token: 8192, #cached-token: 1620, token usage: 0.89, #running-req: 81, #queue-req: 8\n",
      "[2025-08-13 19:48:50] Prefill batch. #new-seq: 3, #new-token: 5713, #cached-token: 249, token usage: 0.92, #running-req: 86, #queue-req: 11\n",
      "[2025-08-13 19:48:53] Decode batch. #running-req: 89, #token: 235202, token usage: 0.96, cuda graph: True, gen throughput (token/s): 821.89, #queue-req: 11\n",
      "[2025-08-13 19:48:53] INFO:     127.0.0.1:47528 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:53] Prefill batch. #new-seq: 1, #new-token: 2595, #cached-token: 544, token usage: 0.94, #running-req: 88, #queue-req: 10\n",
      "[2025-08-13 19:48:54] INFO:     127.0.0.1:52750 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:54] Prefill batch. #new-seq: 2, #new-token: 588, #cached-token: 553, token usage: 0.94, #running-req: 88, #queue-req: 10\n",
      "[2025-08-13 19:48:54] INFO:     127.0.0.1:38756 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:54] Prefill batch. #new-seq: 1, #new-token: 2155, #cached-token: 477, token usage: 0.94, #running-req: 89, #queue-req: 9\n",
      "[2025-08-13 19:48:56] INFO:     127.0.0.1:52428 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:56] INFO:     127.0.0.1:42924 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:56] Prefill batch. #new-seq: 1, #new-token: 2434, #cached-token: 465, token usage: 0.94, #running-req: 88, #queue-req: 9\n",
      "[2025-08-13 19:48:56] Decode batch. #running-req: 89, #token: 232739, token usage: 0.95, cuda graph: True, gen throughput (token/s): 993.11, #queue-req: 9\n",
      "[2025-08-13 19:48:57] INFO:     127.0.0.1:48200 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:57] INFO:     127.0.0.1:48198 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:58] Prefill batch. #new-seq: 1, #new-token: 2846, #cached-token: 392, token usage: 0.93, #running-req: 87, #queue-req: 12\n",
      "[2025-08-13 19:48:59] INFO:     127.0.0.1:40162 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:59] INFO:     127.0.0.1:46446 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:48:59] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 615, token usage: 0.92, #running-req: 86, #queue-req: 10\n",
      "[2025-08-13 19:48:59] Prefill batch. #new-seq: 1, #new-token: 449, #cached-token: 0, token usage: 0.96, #running-req: 87, #queue-req: 10\n",
      "[2025-08-13 19:49:00] Decode batch. #running-req: 88, #token: 231272, token usage: 0.94, cuda graph: True, gen throughput (token/s): 904.32, #queue-req: 10\n",
      "[2025-08-13 19:49:00] INFO:     127.0.0.1:38742 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:00] Prefill batch. #new-seq: 1, #new-token: 4299, #cached-token: 522, token usage: 0.94, #running-req: 87, #queue-req: 9\n",
      "[2025-08-13 19:49:01] INFO:     127.0.0.1:38748 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:02] INFO:     127.0.0.1:46450 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:02] INFO:     127.0.0.1:46436 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:02] Prefill batch. #new-seq: 1, #new-token: 4353, #cached-token: 469, token usage: 0.93, #running-req: 85, #queue-req: 12\n",
      "[2025-08-13 19:49:04] Decode batch. #running-req: 86, #token: 235553, token usage: 0.96, cuda graph: True, gen throughput (token/s): 941.32, #queue-req: 14\n",
      "[2025-08-13 19:49:07] Decode batch. #running-req: 86, #token: 238993, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1181.14, #queue-req: 14\n",
      "[2025-08-13 19:49:08] INFO:     127.0.0.1:43094 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:10] INFO:     127.0.0.1:48212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:10] Decode batch. #running-req: 85, #token: 231920, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1166.90, #queue-req: 15\n",
      "[2025-08-13 19:49:10] INFO:     127.0.0.1:52700 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:10] INFO:     127.0.0.1:52728 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:10] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 309, token usage: 0.91, #running-req: 82, #queue-req: 14\n",
      "[2025-08-13 19:49:10] Prefill batch. #new-seq: 2, #new-token: 821, #cached-token: 461, token usage: 0.94, #running-req: 83, #queue-req: 13\n",
      "[2025-08-13 19:49:11] INFO:     127.0.0.1:52736 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:11] Prefill batch. #new-seq: 3, #new-token: 4029, #cached-token: 412, token usage: 0.91, #running-req: 84, #queue-req: 10\n",
      "[2025-08-13 19:49:11] INFO:     127.0.0.1:48228 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:12] Prefill batch. #new-seq: 3, #new-token: 6606, #cached-token: 474, token usage: 0.93, #running-req: 86, #queue-req: 8\n",
      "[2025-08-13 19:49:13] INFO:     127.0.0.1:45970 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:14] INFO:     127.0.0.1:52714 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:14] Prefill batch. #new-seq: 1, #new-token: 2236, #cached-token: 127, token usage: 0.93, #running-req: 87, #queue-req: 10\n",
      "[2025-08-13 19:49:14] INFO:     127.0.0.1:48236 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:14] Prefill batch. #new-seq: 2, #new-token: 3451, #cached-token: 755, token usage: 0.92, #running-req: 87, #queue-req: 8\n",
      "[2025-08-13 19:49:15] Decode batch. #running-req: 89, #token: 230933, token usage: 0.94, cuda graph: True, gen throughput (token/s): 695.68, #queue-req: 9\n",
      "[2025-08-13 19:49:16] INFO:     127.0.0.1:52226 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:16] Prefill batch. #new-seq: 1, #new-token: 2159, #cached-token: 158, token usage: 0.93, #running-req: 88, #queue-req: 10\n",
      "[2025-08-13 19:49:18] Decode batch. #running-req: 89, #token: 233935, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1171.32, #queue-req: 11\n",
      "[2025-08-13 19:49:19] INFO:     127.0.0.1:41150 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:19] Prefill batch. #new-seq: 1, #new-token: 2151, #cached-token: 164, token usage: 0.94, #running-req: 88, #queue-req: 10\n",
      "[2025-08-13 19:49:21] Decode batch. #running-req: 89, #token: 235732, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1158.45, #queue-req: 11\n",
      "[2025-08-13 19:49:21] INFO:     127.0.0.1:48200 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:22] INFO:     127.0.0.1:48262 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:22] INFO:     127.0.0.1:52750 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:22] Prefill batch. #new-seq: 1, #new-token: 2663, #cached-token: 474, token usage: 0.92, #running-req: 86, #queue-req: 10\n",
      "[2025-08-13 19:49:22] INFO:     127.0.0.1:48198 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:23] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 556, token usage: 0.91, #running-req: 86, #queue-req: 9\n",
      "[2025-08-13 19:49:23] Prefill batch. #new-seq: 1, #new-token: 3416, #cached-token: 0, token usage: 0.95, #running-req: 87, #queue-req: 9\n",
      "[2025-08-13 19:49:23] INFO:     127.0.0.1:48212 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 19:49:24] Prefill batch. #new-seq: 1, #new-token: 2245, #cached-token: 712, token usage: 0.93, #running-req: 87, #queue-req: 12\n",
      "[2025-08-13 19:49:24] INFO:     127.0.0.1:42984 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:24] Prefill batch. #new-seq: 2, #new-token: 4424, #cached-token: 691, token usage: 0.93, #running-req: 87, #queue-req: 10\n",
      "[2025-08-13 19:49:24] INFO:     127.0.0.1:48276 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:25] Prefill batch. #new-seq: 1, #new-token: 4373, #cached-token: 448, token usage: 0.94, #running-req: 88, #queue-req: 9\n",
      "[2025-08-13 19:49:26] INFO:     127.0.0.1:42908 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:26] Decode batch. #running-req: 89, #token: 232730, token usage: 0.95, cuda graph: True, gen throughput (token/s): 687.21, #queue-req: 11\n",
      "[2025-08-13 19:49:28] INFO:     127.0.0.1:47562 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:28] Prefill batch. #new-seq: 1, #new-token: 2274, #cached-token: 142, token usage: 0.93, #running-req: 87, #queue-req: 11\n",
      "[2025-08-13 19:49:28] INFO:     127.0.0.1:42860 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:29] Prefill batch. #new-seq: 2, #new-token: 3660, #cached-token: 573, token usage: 0.93, #running-req: 87, #queue-req: 9\n",
      "[2025-08-13 19:49:29] INFO:     127.0.0.1:43042 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:29] Prefill batch. #new-seq: 1, #new-token: 549, #cached-token: 624, token usage: 0.94, #running-req: 88, #queue-req: 8\n",
      "[2025-08-13 19:49:29] Decode batch. #running-req: 89, #token: 232403, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1032.82, #queue-req: 8\n",
      "[2025-08-13 19:49:32] INFO:     127.0.0.1:43012 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:32] Decode batch. #running-req: 89, #token: 232538, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1247.14, #queue-req: 11\n",
      "[2025-08-13 19:49:33] INFO:     127.0.0.1:42968 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:33] Prefill batch. #new-seq: 1, #new-token: 4367, #cached-token: 455, token usage: 0.94, #running-req: 87, #queue-req: 11\n",
      "[2025-08-13 19:49:34] INFO:     127.0.0.1:40212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:34] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 145, token usage: 0.94, #running-req: 87, #queue-req: 10\n",
      "[2025-08-13 19:49:35] INFO:     127.0.0.1:48228 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:35] Prefill batch. #new-seq: 2, #new-token: 4479, #cached-token: 322, token usage: 0.93, #running-req: 87, #queue-req: 10\n",
      "[2025-08-13 19:49:35] INFO:     127.0.0.1:48236 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:36] Prefill batch. #new-seq: 1, #new-token: 5058, #cached-token: 96, token usage: 0.93, #running-req: 88, #queue-req: 9\n",
      "[2025-08-13 19:49:36] Decode batch. #running-req: 89, #token: 234245, token usage: 0.95, cuda graph: True, gen throughput (token/s): 866.59, #queue-req: 11\n",
      "[2025-08-13 19:49:38] INFO:     127.0.0.1:42882 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:38] Prefill batch. #new-seq: 1, #new-token: 2244, #cached-token: 463, token usage: 0.94, #running-req: 88, #queue-req: 10\n",
      "[2025-08-13 19:49:39] Decode batch. #running-req: 89, #token: 234309, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1145.26, #queue-req: 11\n",
      "[2025-08-13 19:49:41] INFO:     127.0.0.1:57030 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:42] Decode batch. #running-req: 88, #token: 237079, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1225.95, #queue-req: 12\n",
      "[2025-08-13 19:49:43] INFO:     127.0.0.1:40218 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:43] Prefill batch. #new-seq: 1, #new-token: 2685, #cached-token: 463, token usage: 0.94, #running-req: 87, #queue-req: 11\n",
      "[2025-08-13 19:49:43] INFO:     127.0.0.1:43054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:44] INFO:     127.0.0.1:42840 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:44] INFO:     127.0.0.1:48262 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:44] Prefill batch. #new-seq: 1, #new-token: 2416, #cached-token: 553, token usage: 0.93, #running-req: 85, #queue-req: 10\n",
      "[2025-08-13 19:49:45] INFO:     127.0.0.1:47536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:45] Prefill batch. #new-seq: 1, #new-token: 4773, #cached-token: 77, token usage: 0.94, #running-req: 85, #queue-req: 9\n",
      "[2025-08-13 19:49:46] Decode batch. #running-req: 86, #token: 236027, token usage: 0.96, cuda graph: True, gen throughput (token/s): 923.43, #queue-req: 14\n",
      "[2025-08-13 19:49:47] INFO:     127.0.0.1:48276 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:49] Decode batch. #running-req: 85, #token: 237091, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1156.88, #queue-req: 15\n",
      "[2025-08-13 19:49:52] Decode batch. #running-req: 85, #token: 240491, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1143.28, #queue-req: 15\n",
      "[2025-08-13 19:49:53] INFO:     127.0.0.1:56002 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:54] INFO:     127.0.0.1:38810 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:55] INFO:     127.0.0.1:47546 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:55] INFO:     127.0.0.1:47574 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:55] INFO:     127.0.0.1:59008 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:55] INFO:     127.0.0.1:41138 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:55] INFO:     127.0.0.1:41158 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:55] INFO:     127.0.0.1:41184 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:55] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1532, token usage: 0.87, #running-req: 77, #queue-req: 12\n",
      "[2025-08-13 19:49:55] INFO:     127.0.0.1:56998 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:55] Prefill batch. #new-seq: 3, #new-token: 7552, #cached-token: 911, token usage: 0.90, #running-req: 80, #queue-req: 10\n",
      "[2025-08-13 19:49:56] Prefill batch. #new-seq: 1, #new-token: 2707, #cached-token: 409, token usage: 0.93, #running-req: 82, #queue-req: 17\n",
      "[2025-08-13 19:49:57] Decode batch. #running-req: 83, #token: 232806, token usage: 0.95, cuda graph: True, gen throughput (token/s): 739.79, #queue-req: 17\n",
      "[2025-08-13 19:49:57] INFO:     127.0.0.1:40212 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:49:57] Prefill batch. #new-seq: 1, #new-token: 4590, #cached-token: 156, token usage: 0.94, #running-req: 82, #queue-req: 16\n",
      "[2025-08-13 19:50:00] Decode batch. #running-req: 83, #token: 237426, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1001.41, #queue-req: 17\n",
      "[2025-08-13 19:50:02] INFO:     127.0.0.1:57014 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:03] Decode batch. #running-req: 82, #token: 238829, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1130.05, #queue-req: 18\n",
      "[2025-08-13 19:50:03] INFO:     127.0.0.1:57284 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:03] Prefill batch. #new-seq: 1, #new-token: 409, #cached-token: 93, token usage: 0.96, #running-req: 81, #queue-req: 18\n",
      "[2025-08-13 19:50:05] INFO:     127.0.0.1:53222 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:05] INFO:     127.0.0.1:55998 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:05] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.95, #running-req: 80, #queue-req: 18\n",
      "[2025-08-13 19:50:06] Decode batch. #running-req: 81, #token: 235333, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1039.06, #queue-req: 18\n",
      "[2025-08-13 19:50:08] INFO:     127.0.0.1:42868 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:08] Prefill batch. #new-seq: 1, #new-token: 2263, #cached-token: 122, token usage: 0.96, #running-req: 80, #queue-req: 18\n",
      "[2025-08-13 19:50:09] Decode batch. #running-req: 81, #token: 239096, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1047.34, #queue-req: 19\n",
      "[2025-08-13 19:50:10] INFO:     127.0.0.1:53226 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:10] INFO:     127.0.0.1:53228 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:10] INFO:     127.0.0.1:53238 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:10] INFO:     127.0.0.1:53244 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:10] INFO:     127.0.0.1:53260 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:10] INFO:     127.0.0.1:53270 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:10] Prefill batch. #new-seq: 4, #new-token: 5136, #cached-token: 1193, token usage: 0.91, #running-req: 75, #queue-req: 21\n",
      "[2025-08-13 19:50:11] INFO:     127.0.0.1:53274 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:11] INFO:     127.0.0.1:53286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:11] INFO:     127.0.0.1:53298 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:11] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1346, token usage: 0.87, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 19:50:11] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1047, token usage: 0.91, #running-req: 78, #queue-req: 18\n",
      "[2025-08-13 19:50:11] Prefill batch. #new-seq: 2, #new-token: 6004, #cached-token: 448, token usage: 0.94, #running-req: 81, #queue-req: 17\n",
      "[2025-08-13 19:50:14] Decode batch. #running-req: 83, #token: 239134, token usage: 0.97, cuda graph: True, gen throughput (token/s): 630.74, #queue-req: 17\n",
      "[2025-08-13 19:50:15] INFO:     127.0.0.1:42992 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:15] Prefill batch. #new-seq: 1, #new-token: 190, #cached-token: 119, token usage: 0.96, #running-req: 82, #queue-req: 16\n",
      "[2025-08-13 19:50:17] Decode batch. #running-req: 83, #token: 238668, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1152.22, #queue-req: 17\n",
      "[2025-08-13 19:50:19] INFO:     127.0.0.1:47574 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:20] INFO:     127.0.0.1:42954 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:20] Prefill batch. #new-seq: 2, #new-token: 2519, #cached-token: 267, token usage: 0.94, #running-req: 81, #queue-req: 15\n",
      "[2025-08-13 19:50:20] INFO:     127.0.0.1:47536 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:20] Prefill batch. #new-seq: 1, #new-token: 1443, #cached-token: 119, token usage: 0.95, #running-req: 82, #queue-req: 14\n",
      "[2025-08-13 19:50:20] Decode batch. #running-req: 83, #token: 235058, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1031.71, #queue-req: 14\n",
      "[2025-08-13 19:50:21] INFO:     127.0.0.1:38848 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:21] Prefill batch. #new-seq: 1, #new-token: 4379, #cached-token: 441, token usage: 0.95, #running-req: 82, #queue-req: 13\n",
      "[2025-08-13 19:50:23] INFO:     127.0.0.1:47546 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:23] INFO:     127.0.0.1:41158 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:23] INFO:     127.0.0.1:41184 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:23] INFO:     127.0.0.1:41138 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:23] INFO:     127.0.0.1:59008 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:23] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1193, token usage: 0.89, #running-req: 78, #queue-req: 9\n",
      "[2025-08-13 19:50:23] Prefill batch. #new-seq: 3, #new-token: 7477, #cached-token: 636, token usage: 0.93, #running-req: 81, #queue-req: 7\n",
      "[2025-08-13 19:50:24] INFO:     127.0.0.1:47208 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:25] Prefill batch. #new-seq: 1, #new-token: 2300, #cached-token: 146, token usage: 0.95, #running-req: 83, #queue-req: 7\n",
      "[2025-08-13 19:50:25] INFO:     127.0.0.1:58862 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:25] INFO:     127.0.0.1:53222 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:25] Prefill batch. #new-seq: 2, #new-token: 4478, #cached-token: 302, token usage: 0.95, #running-req: 82, #queue-req: 5\n",
      "[2025-08-13 19:50:25] Decode batch. #running-req: 84, #token: 237603, token usage: 0.97, cuda graph: True, gen throughput (token/s): 646.07, #queue-req: 5\n",
      "[2025-08-13 19:50:28] INFO:     127.0.0.1:42890 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:28] Decode batch. #running-req: 84, #token: 236954, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1172.73, #queue-req: 8\n",
      "[2025-08-13 19:50:31] Decode batch. #running-req: 83, #token: 240274, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1169.60, #queue-req: 17\n",
      "[2025-08-13 19:50:32] INFO:     127.0.0.1:53244 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:33] INFO:     127.0.0.1:43116 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:33] INFO:     127.0.0.1:57284 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:33] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 613, token usage: 0.91, #running-req: 80, #queue-req: 15\n",
      "[2025-08-13 19:50:33] INFO:     127.0.0.1:52240 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:33] INFO:     127.0.0.1:52246 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:33] INFO:     127.0.0.1:42828 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:33] INFO:     127.0.0.1:42832 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:33] Prefill batch. #new-seq: 2, #new-token: 5008, #cached-token: 146, token usage: 0.95, #running-req: 81, #queue-req: 14\n",
      "[2025-08-13 19:50:35] INFO:     127.0.0.1:53260 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:35] INFO:     127.0.0.1:53270 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:35] INFO:     127.0.0.1:53228 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:35] INFO:     127.0.0.1:53298 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:35] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1165, token usage: 0.90, #running-req: 75, #queue-req: 14\n",
      "[2025-08-13 19:50:35] Prefill batch. #new-seq: 2, #new-token: 3095, #cached-token: 465, token usage: 0.93, #running-req: 78, #queue-req: 13\n",
      "[2025-08-13 19:50:36] Decode batch. #running-req: 80, #token: 227684, token usage: 0.93, cuda graph: True, gen throughput (token/s): 655.43, #queue-req: 14\n",
      "[2025-08-13 19:50:36] INFO:     127.0.0.1:42916 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:36] Prefill batch. #new-seq: 2, #new-token: 4817, #cached-token: 1095, token usage: 0.93, #running-req: 79, #queue-req: 12\n",
      "[2025-08-13 19:50:37] INFO:     127.0.0.1:53238 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:37] Prefill batch. #new-seq: 1, #new-token: 4565, #cached-token: 146, token usage: 0.93, #running-req: 80, #queue-req: 11\n",
      "[2025-08-13 19:50:37] INFO:     127.0.0.1:53226 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:37] INFO:     127.0.0.1:42888 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:37] Prefill batch. #new-seq: 2, #new-token: 4600, #cached-token: 1180, token usage: 0.92, #running-req: 79, #queue-req: 9\n",
      "[2025-08-13 19:50:38] INFO:     127.0.0.1:36592 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:38] Prefill batch. #new-seq: 2, #new-token: 2795, #cached-token: 565, token usage: 0.93, #running-req: 80, #queue-req: 9\n",
      "[2025-08-13 19:50:39] INFO:     127.0.0.1:43022 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:40] Prefill batch. #new-seq: 3, #new-token: 4848, #cached-token: 444, token usage: 0.93, #running-req: 81, #queue-req: 6\n",
      "[2025-08-13 19:50:41] INFO:     127.0.0.1:52246 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:41] Prefill batch. #new-seq: 2, #new-token: 4514, #cached-token: 651, token usage: 0.94, #running-req: 83, #queue-req: 4\n",
      "[2025-08-13 19:50:41] Decode batch. #running-req: 83, #token: 236172, token usage: 0.96, cuda graph: True, gen throughput (token/s): 696.32, #queue-req: 4\n",
      "[2025-08-13 19:50:42] INFO:     127.0.0.1:36606 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:42] INFO:     127.0.0.1:48460 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:42] Prefill batch. #new-seq: 1, #new-token: 2419, #cached-token: 589, token usage: 0.95, #running-req: 83, #queue-req: 6\n",
      "[2025-08-13 19:50:43] INFO:     127.0.0.1:40190 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:43] Prefill batch. #new-seq: 2, #new-token: 403, #cached-token: 322, token usage: 0.94, #running-req: 83, #queue-req: 4\n",
      "[2025-08-13 19:50:44] INFO:     127.0.0.1:47238 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:44] Prefill batch. #new-seq: 1, #new-token: 2317, #cached-token: 639, token usage: 0.93, #running-req: 84, #queue-req: 3\n",
      "[2025-08-13 19:50:44] INFO:     127.0.0.1:42854 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:44] INFO:     127.0.0.1:42906 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:44] INFO:     127.0.0.1:42936 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:44] INFO:     127.0.0.1:42966 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:44] INFO:     127.0.0.1:43026 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:44] INFO:     127.0.0.1:43036 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:44] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 987, token usage: 0.84, #running-req: 79, #queue-req: 0\n",
      "[2025-08-13 19:50:44] Prefill batch. #new-seq: 1, #new-token: 3209, #cached-token: 0, token usage: 0.88, #running-req: 81, #queue-req: 0\n",
      "[2025-08-13 19:50:45] Prefill batch. #new-seq: 3, #new-token: 2191, #cached-token: 9921, token usage: 0.93, #running-req: 82, #queue-req: 8\n",
      "[2025-08-13 19:50:46] INFO:     127.0.0.1:42966 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:46] Decode batch. #running-req: 85, #token: 223524, token usage: 0.91, cuda graph: True, gen throughput (token/s): 683.99, #queue-req: 8\n",
      "[2025-08-13 19:50:46] Prefill batch. #new-seq: 2, #new-token: 2041, #cached-token: 7609, token usage: 0.94, #running-req: 84, #queue-req: 6\n",
      "[2025-08-13 19:50:46] INFO:     127.0.0.1:48450 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:47] INFO:     127.0.0.1:43052 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:47] INFO:     127.0.0.1:43062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:47] INFO:     127.0.0.1:43078 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:47] Prefill batch. #new-seq: 2, #new-token: 2277, #cached-token: 5156, token usage: 0.93, #running-req: 82, #queue-req: 4\n",
      "[2025-08-13 19:50:48] INFO:     127.0.0.1:42936 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:48] Prefill batch. #new-seq: 1, #new-token: 2670, #cached-token: 477, token usage: 0.93, #running-req: 83, #queue-req: 3\n",
      "[2025-08-13 19:50:48] INFO:     127.0.0.1:53274 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:48] INFO:     127.0.0.1:53286 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:49] Prefill batch. #new-seq: 1, #new-token: 4610, #cached-token: 146, token usage: 0.91, #running-req: 82, #queue-req: 2\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 19:50:49] INFO:     127.0.0.1:43120 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:49] INFO:     127.0.0.1:43128 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:49] INFO:     127.0.0.1:45948 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:49] INFO:     127.0.0.1:45956 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:49] INFO:     127.0.0.1:45960 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:49] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 352, token usage: 0.87, #running-req: 78, #queue-req: 7\n",
      "[2025-08-13 19:50:50] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 653, token usage: 0.90, #running-req: 79, #queue-req: 5\n",
      "[2025-08-13 19:50:50] Prefill batch. #new-seq: 2, #new-token: 3402, #cached-token: 142, token usage: 0.93, #running-req: 81, #queue-req: 4\n",
      "[2025-08-13 19:50:51] Decode batch. #running-req: 83, #token: 233336, token usage: 0.95, cuda graph: True, gen throughput (token/s): 600.87, #queue-req: 4\n",
      "[2025-08-13 19:50:51] INFO:     127.0.0.1:36608 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:52] Prefill batch. #new-seq: 2, #new-token: 4622, #cached-token: 602, token usage: 0.93, #running-req: 82, #queue-req: 2\n",
      "[2025-08-13 19:50:52] INFO:     127.0.0.1:47252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:52] INFO:     127.0.0.1:43062 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:52] Prefill batch. #new-seq: 1, #new-token: 2281, #cached-token: 131, token usage: 0.94, #running-req: 82, #queue-req: 1\n",
      "[2025-08-13 19:50:55] INFO:     127.0.0.1:42828 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:55] Prefill batch. #new-seq: 1, #new-token: 195, #cached-token: 123, token usage: 0.95, #running-req: 82, #queue-req: 9\n",
      "[2025-08-13 19:50:55] Decode batch. #running-req: 82, #token: 232802, token usage: 0.95, cuda graph: True, gen throughput (token/s): 951.72, #queue-req: 9\n",
      "[2025-08-13 19:50:55] INFO:     127.0.0.1:42854 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:55] Prefill batch. #new-seq: 1, #new-token: 2252, #cached-token: 434, token usage: 0.94, #running-req: 82, #queue-req: 8\n",
      "[2025-08-13 19:50:56] INFO:     127.0.0.1:52240 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:56] Prefill batch. #new-seq: 1, #new-token: 2524, #cached-token: 553, token usage: 0.94, #running-req: 82, #queue-req: 7\n",
      "[2025-08-13 19:50:56] INFO:     127.0.0.1:42832 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:56] Prefill batch. #new-seq: 1, #new-token: 2240, #cached-token: 434, token usage: 0.94, #running-req: 82, #queue-req: 6\n",
      "[2025-08-13 19:50:56] INFO:     127.0.0.1:43026 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:57] Prefill batch. #new-seq: 1, #new-token: 4304, #cached-token: 127, token usage: 0.93, #running-req: 82, #queue-req: 5\n",
      "[2025-08-13 19:50:58] INFO:     127.0.0.1:42906 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:50:58] Prefill batch. #new-seq: 1, #new-token: 4704, #cached-token: 464, token usage: 0.94, #running-req: 82, #queue-req: 10\n",
      "[2025-08-13 19:50:59] Decode batch. #running-req: 83, #token: 235981, token usage: 0.96, cuda graph: True, gen throughput (token/s): 772.87, #queue-req: 10\n",
      "[2025-08-13 19:51:01] INFO:     127.0.0.1:43036 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:02] Decode batch. #running-req: 82, #token: 236886, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1159.23, #queue-req: 13\n",
      "[2025-08-13 19:51:02] INFO:     127.0.0.1:45956 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:02] Prefill batch. #new-seq: 1, #new-token: 981, #cached-token: 164, token usage: 0.94, #running-req: 81, #queue-req: 17\n",
      "[2025-08-13 19:51:02] INFO:     127.0.0.1:43078 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:02] INFO:     127.0.0.1:43050 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:03] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 451, token usage: 0.94, #running-req: 80, #queue-req: 16\n",
      "[2025-08-13 19:51:03] INFO:     127.0.0.1:43052 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:05] Decode batch. #running-req: 80, #token: 234028, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1047.20, #queue-req: 16\n",
      "[2025-08-13 19:51:06] INFO:     127.0.0.1:40204 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:06] Prefill batch. #new-seq: 1, #new-token: 2268, #cached-token: 138, token usage: 0.94, #running-req: 79, #queue-req: 15\n",
      "[2025-08-13 19:51:06] INFO:     127.0.0.1:38162 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 19:51:06] INFO:     127.0.0.1:43128 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:06] Prefill batch. #new-seq: 1, #new-token: 2354, #cached-token: 447, token usage: 0.94, #running-req: 78, #queue-req: 15\n",
      "[2025-08-13 19:51:07] INFO:     127.0.0.1:45960 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:07] Prefill batch. #new-seq: 2, #new-token: 2749, #cached-token: 674, token usage: 0.92, #running-req: 78, #queue-req: 17\n",
      "[2025-08-13 19:51:07] INFO:     127.0.0.1:45948 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:07] Prefill batch. #new-seq: 1, #new-token: 2164, #cached-token: 467, token usage: 0.93, #running-req: 79, #queue-req: 16\n",
      "[2025-08-13 19:51:08] INFO:     127.0.0.1:58872 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:08] INFO:     127.0.0.1:55990 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:09] INFO:     127.0.0.1:36616 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:09] INFO:     127.0.0.1:43120 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:09] Prefill batch. #new-seq: 2, #new-token: 5791, #cached-token: 284, token usage: 0.90, #running-req: 76, #queue-req: 15\n",
      "[2025-08-13 19:51:09] Decode batch. #running-req: 76, #token: 228031, token usage: 0.93, cuda graph: True, gen throughput (token/s): 875.63, #queue-req: 15\n",
      "[2025-08-13 19:51:10] INFO:     127.0.0.1:47224 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:10] Prefill batch. #new-seq: 2, #new-token: 4319, #cached-token: 284, token usage: 0.92, #running-req: 77, #queue-req: 14\n",
      "[2025-08-13 19:51:12] INFO:     127.0.0.1:38800 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:12] INFO:     127.0.0.1:38814 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:12] Prefill batch. #new-seq: 2, #new-token: 515, #cached-token: 312, token usage: 0.92, #running-req: 77, #queue-req: 12\n",
      "[2025-08-13 19:51:12] Decode batch. #running-req: 79, #token: 228417, token usage: 0.93, cuda graph: True, gen throughput (token/s): 871.38, #queue-req: 16\n",
      "[2025-08-13 19:51:13] INFO:     127.0.0.1:38824 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:13] Prefill batch. #new-seq: 3, #new-token: 5613, #cached-token: 1340, token usage: 0.91, #running-req: 78, #queue-req: 19\n",
      "[2025-08-13 19:51:15] INFO:     127.0.0.1:34938 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:15] Prefill batch. #new-seq: 1, #new-token: 2597, #cached-token: 550, token usage: 0.93, #running-req: 80, #queue-req: 18\n",
      "[2025-08-13 19:51:16] Decode batch. #running-req: 81, #token: 231983, token usage: 0.94, cuda graph: True, gen throughput (token/s): 934.43, #queue-req: 19\n",
      "[2025-08-13 19:51:19] Decode batch. #running-req: 81, #token: 235223, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1170.61, #queue-req: 19\n",
      "[2025-08-13 19:51:21] Decode batch. #running-req: 81, #token: 238463, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1161.03, #queue-req: 19\n",
      "[2025-08-13 19:51:23] INFO:     127.0.0.1:36576 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:24] Decode batch. #running-req: 80, #token: 238019, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1138.86, #queue-req: 20\n",
      "[2025-08-13 19:51:27] Decode batch. #running-req: 80, #token: 241219, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1119.51, #queue-req: 20\n",
      "[2025-08-13 19:51:27] INFO:     127.0.0.1:53178 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:28] INFO:     127.0.0.1:52420 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:30] Decode batch. #running-req: 78, #token: 235628, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1108.47, #queue-req: 20\n",
      "[2025-08-13 19:51:33] Decode batch. #running-req: 78, #token: 238748, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1091.11, #queue-req: 22\n",
      "[2025-08-13 19:51:35] INFO:     127.0.0.1:38858 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:36] Decode batch. #running-req: 77, #token: 237716, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1084.93, #queue-req: 22\n",
      "[2025-08-13 19:51:36] INFO:     127.0.0.1:48474 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:38] Decode batch. #running-req: 76, #token: 237085, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1070.97, #queue-req: 24\n",
      "[2025-08-13 19:51:41] INFO:     127.0.0.1:38104 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:41] INFO:     127.0.0.1:50680 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:41] Decode batch. #running-req: 74, #token: 234024, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1058.11, #queue-req: 24\n",
      "[2025-08-13 19:51:44] Decode batch. #running-req: 74, #token: 236984, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1034.43, #queue-req: 26\n",
      "[2025-08-13 19:51:45] INFO:     127.0.0.1:43028 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:46] INFO:     127.0.0.1:36558 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:46] Prefill batch. #new-seq: 1, #new-token: 4583, #cached-token: 169, token usage: 0.94, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 19:51:47] Decode batch. #running-req: 73, #token: 235952, token usage: 0.96, cuda graph: True, gen throughput (token/s): 900.55, #queue-req: 27\n",
      "[2025-08-13 19:51:48] INFO:     127.0.0.1:38134 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:48] Prefill batch. #new-seq: 1, #new-token: 4171, #cached-token: 481, token usage: 0.95, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 19:51:48] INFO:     127.0.0.1:55974 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:48] Prefill batch. #new-seq: 2, #new-token: 491, #cached-token: 581, token usage: 0.95, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 19:51:49] INFO:     127.0.0.1:55984 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:49] Prefill batch. #new-seq: 1, #new-token: 2526, #cached-token: 508, token usage: 0.94, #running-req: 73, #queue-req: 26\n",
      "[2025-08-13 19:51:51] Decode batch. #running-req: 74, #token: 235926, token usage: 0.96, cuda graph: True, gen throughput (token/s): 849.64, #queue-req: 26\n",
      "[2025-08-13 19:51:51] INFO:     127.0.0.1:58868 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:52] INFO:     127.0.0.1:45120 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:52] Prefill batch. #new-seq: 1, #new-token: 4554, #cached-token: 196, token usage: 0.94, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 19:51:52] INFO:     127.0.0.1:56992 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:52] Prefill batch. #new-seq: 2, #new-token: 2511, #cached-token: 784, token usage: 0.94, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 19:51:53] INFO:     127.0.0.1:48212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:53] Prefill batch. #new-seq: 3, #new-token: 6564, #cached-token: 1017, token usage: 0.92, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 19:51:55] Decode batch. #running-req: 76, #token: 234535, token usage: 0.95, cuda graph: True, gen throughput (token/s): 744.88, #queue-req: 24\n",
      "[2025-08-13 19:51:57] INFO:     127.0.0.1:38100 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:57] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 151, token usage: 0.95, #running-req: 75, #queue-req: 23\n",
      "[2025-08-13 19:51:58] Decode batch. #running-req: 76, #token: 236303, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1014.38, #queue-req: 24\n",
      "[2025-08-13 19:51:58] INFO:     127.0.0.1:40204 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:51:58] Prefill batch. #new-seq: 2, #new-token: 334, #cached-token: 212, token usage: 0.95, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 19:52:01] Decode batch. #running-req: 77, #token: 235415, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1092.94, #queue-req: 23\n",
      "[2025-08-13 19:52:03] INFO:     127.0.0.1:38814 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:03] INFO:     127.0.0.1:38800 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:03] Prefill batch. #new-seq: 1, #new-token: 2267, #cached-token: 139, token usage: 0.95, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 19:52:04] Decode batch. #running-req: 76, #token: 236157, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1030.37, #queue-req: 22\n",
      "[2025-08-13 19:52:04] INFO:     127.0.0.1:57004 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:04] INFO:     127.0.0.1:36564 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:05] INFO:     127.0.0.1:48458 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:05] Prefill batch. #new-seq: 1, #new-token: 4873, #cached-token: 462, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 19:52:07] Decode batch. #running-req: 74, #token: 235691, token usage: 0.96, cuda graph: True, gen throughput (token/s): 915.44, #queue-req: 26\n",
      "[2025-08-13 19:52:10] Decode batch. #running-req: 74, #token: 238651, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1045.89, #queue-req: 26\n",
      "[2025-08-13 19:52:13] Decode batch. #running-req: 74, #token: 241611, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1036.50, #queue-req: 26\n",
      "[2025-08-13 19:52:14] INFO:     127.0.0.1:47172 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:14] INFO:     127.0.0.1:47188 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:14] Prefill batch. #new-seq: 1, #new-token: 1420, #cached-token: 96, token usage: 0.95, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 19:52:14] INFO:     127.0.0.1:47204 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:15] INFO:     127.0.0.1:39382 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:15] Prefill batch. #new-seq: 2, #new-token: 6899, #cached-token: 934, token usage: 0.93, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 19:52:16] Decode batch. #running-req: 73, #token: 236000, token usage: 0.96, cuda graph: True, gen throughput (token/s): 809.34, #queue-req: 27\n",
      "[2025-08-13 19:52:19] INFO:     127.0.0.1:48448 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:19] Decode batch. #running-req: 72, #token: 236369, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1025.85, #queue-req: 28\n",
      "[2025-08-13 19:52:20] INFO:     127.0.0.1:39208 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:20] Prefill batch. #new-seq: 1, #new-token: 2177, #cached-token: 93, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 19:52:22] Decode batch. #running-req: 72, #token: 238960, token usage: 0.97, cuda graph: True, gen throughput (token/s): 932.03, #queue-req: 28\n",
      "[2025-08-13 19:52:23] INFO:     127.0.0.1:54634 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:24] INFO:     127.0.0.1:34910 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:24] Prefill batch. #new-seq: 2, #new-token: 4236, #cached-token: 580, token usage: 0.94, #running-req: 70, #queue-req: 26\n",
      ".[2025-08-13 19:52:25] INFO:     127.0.0.1:38824 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:25] Prefill batch. #new-seq: 2, #new-token: 2696, #cached-token: 892, token usage: 0.93, #running-req: 71, #queue-req: 24\n",
      "[2025-08-13 19:52:26] Decode batch. #running-req: 73, #token: 231938, token usage: 0.94, cuda graph: True, gen throughput (token/s): 824.56, #queue-req: 25\n",
      "[2025-08-13 19:52:28] INFO:     127.0.0.1:39218 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:28] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 452, token usage: 0.95, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 19:52:29] Decode batch. #running-req: 73, #token: 236627, token usage: 0.96, cuda graph: True, gen throughput (token/s): 959.54, #queue-req: 26\n",
      "[2025-08-13 19:52:29] INFO:     127.0.0.1:50706 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:29] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 454, token usage: 0.95, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 19:52:31] INFO:     127.0.0.1:47278 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:32] Decode batch. #running-req: 72, #token: 236130, token usage: 0.96, cuda graph: True, gen throughput (token/s): 959.33, #queue-req: 27\n",
      "[2025-08-13 19:52:32] INFO:     127.0.0.1:48464 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:32] Prefill batch. #new-seq: 2, #new-token: 5000, #cached-token: 668, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 19:52:34] INFO:     127.0.0.1:47298 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:35] Decode batch. #running-req: 72, #token: 236210, token usage: 0.96, cuda graph: True, gen throughput (token/s): 886.41, #queue-req: 27\n",
      "[2025-08-13 19:52:38] Decode batch. #running-req: 72, #token: 239090, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1013.29, #queue-req: 28\n",
      "[2025-08-13 19:52:41] Decode batch. #running-req: 72, #token: 241970, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1004.53, #queue-req: 28\n",
      "[2025-08-13 19:52:42] INFO:     127.0.0.1:43028 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:42] INFO:     127.0.0.1:38222 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:42] Prefill batch. #new-seq: 1, #new-token: 4685, #cached-token: 474, token usage: 0.96, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 19:52:44] INFO:     127.0.0.1:34926 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:44] INFO:     127.0.0.1:34944 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:44] INFO:     127.0.0.1:34954 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:44] INFO:     127.0.0.1:34958 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:44] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1297, token usage: 0.88, #running-req: 67, #queue-req: 24\n",
      "[2025-08-13 19:52:44] INFO:     127.0.0.1:34966 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:44] Prefill batch. #new-seq: 5, #new-token: 5150, #cached-token: 971, token usage: 0.91, #running-req: 69, #queue-req: 20\n",
      "[2025-08-13 19:52:45] Prefill batch. #new-seq: 3, #new-token: 6804, #cached-token: 1088, token usage: 0.93, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 19:52:46] INFO:     127.0.0.1:54678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:46] Decode batch. #running-req: 76, #token: 235809, token usage: 0.96, cuda graph: True, gen throughput (token/s): 575.62, #queue-req: 24\n",
      "[2025-08-13 19:52:46] INFO:     127.0.0.1:58852 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:46] Prefill batch. #new-seq: 1, #new-token: 2420, #cached-token: 438, token usage: 0.93, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 19:52:49] Decode batch. #running-req: 75, #token: 234678, token usage: 0.95, cuda graph: True, gen throughput (token/s): 973.90, #queue-req: 25\n",
      "[2025-08-13 19:52:49] INFO:     127.0.0.1:39194 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:49] Prefill batch. #new-seq: 1, #new-token: 4494, #cached-token: 120, token usage: 0.94, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 19:52:52] INFO:     127.0.0.1:39258 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:52] INFO:     127.0.0.1:57004 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:52] Decode batch. #running-req: 74, #token: 234948, token usage: 0.96, cuda graph: True, gen throughput (token/s): 911.86, #queue-req: 25\n",
      "[2025-08-13 19:52:52] Prefill batch. #new-seq: 1, #new-token: 2271, #cached-token: 142, token usage: 0.96, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 19:52:53] INFO:     127.0.0.1:38122 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:53] Prefill batch. #new-seq: 1, #new-token: 4683, #cached-token: 474, token usage: 0.95, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 19:52:55] INFO:     127.0.0.1:53536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:55] INFO:     127.0.0.1:55974 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:55] Prefill batch. #new-seq: 1, #new-token: 4497, #cached-token: 480, token usage: 0.95, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 19:52:56] INFO:     127.0.0.1:58866 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:56] Prefill batch. #new-seq: 1, #new-token: 4303, #cached-token: 201, token usage: 0.95, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 19:52:56] Decode batch. #running-req: 73, #token: 237570, token usage: 0.97, cuda graph: True, gen throughput (token/s): 683.52, #queue-req: 27\n",
      "[2025-08-13 19:52:57] INFO:     127.0.0.1:55984 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:57] INFO:     127.0.0.1:56992 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:57] Prefill batch. #new-seq: 3, #new-token: 6467, #cached-token: 913, token usage: 0.93, #running-req: 71, #queue-req: 24\n",
      "[2025-08-13 19:52:57] INFO:     127.0.0.1:36564 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:57] Prefill batch. #new-seq: 1, #new-token: 2667, #cached-token: 507, token usage: 0.95, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 19:52:58] INFO:     127.0.0.1:48448 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:52:59] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 409, token usage: 0.96, #running-req: 73, #queue-req: 22\n",
      "[2025-08-13 19:53:00] Decode batch. #running-req: 74, #token: 237147, token usage: 0.96, cuda graph: True, gen throughput (token/s): 804.60, #queue-req: 26\n",
      "[2025-08-13 19:53:01] INFO:     127.0.0.1:58874 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:01] INFO:     127.0.0.1:51770 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:01] INFO:     127.0.0.1:51784 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:01] Prefill batch. #new-seq: 2, #new-token: 7135, #cached-token: 555, token usage: 0.92, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 19:53:03] INFO:     127.0.0.1:39396 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:03] Prefill batch. #new-seq: 2, #new-token: 2523, #cached-token: 548, token usage: 0.94, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 19:53:03] INFO:     127.0.0.1:47204 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:03] Prefill batch. #new-seq: 1, #new-token: 4691, #cached-token: 477, token usage: 0.94, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 19:53:04] INFO:     127.0.0.1:53184 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:04] Prefill batch. #new-seq: 1, #new-token: 2159, #cached-token: 126, token usage: 0.94, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 19:53:04] Decode batch. #running-req: 74, #token: 233685, token usage: 0.95, cuda graph: True, gen throughput (token/s): 675.82, #queue-req: 24\n",
      "[2025-08-13 19:53:05] INFO:     127.0.0.1:51794 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:05] Prefill batch. #new-seq: 1, #new-token: 4374, #cached-token: 446, token usage: 0.94, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 19:53:06] INFO:     127.0.0.1:47172 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:06] Prefill batch. #new-seq: 1, #new-token: 4702, #cached-token: 464, token usage: 0.95, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 19:53:08] INFO:     127.0.0.1:47188 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:08] Prefill batch. #new-seq: 1, #new-token: 6714, #cached-token: 463, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 19:53:08] INFO:     127.0.0.1:34926 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:08] Decode batch. #running-req: 73, #token: 235935, token usage: 0.96, cuda graph: True, gen throughput (token/s): 792.65, #queue-req: 25\n",
      "[2025-08-13 19:53:11] INFO:     127.0.0.1:51810 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:12] Decode batch. #running-req: 72, #token: 236644, token usage: 0.96, cuda graph: True, gen throughput (token/s): 835.15, #queue-req: 28\n",
      "[2025-08-13 19:53:13] INFO:     127.0.0.1:47220 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:13] Prefill batch. #new-seq: 1, #new-token: 4724, #cached-token: 412, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 19:53:14] INFO:     127.0.0.1:39406 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:14] INFO:     127.0.0.1:45104 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:14] Prefill batch. #new-seq: 1, #new-token: 4614, #cached-token: 589, token usage: 0.95, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 19:53:15] INFO:     127.0.0.1:48464 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:15] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 451, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 19:53:15] Decode batch. #running-req: 70, #token: 235859, token usage: 0.96, cuda graph: True, gen throughput (token/s): 767.85, #queue-req: 28\n",
      "[2025-08-13 19:53:16] INFO:     127.0.0.1:34944 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:17] Prefill batch. #new-seq: 1, #new-token: 2017, #cached-token: 469, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 19:53:18] INFO:     127.0.0.1:34958 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:18] Prefill batch. #new-seq: 2, #new-token: 6679, #cached-token: 315, token usage: 0.93, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 19:53:19] Decode batch. #running-req: 72, #token: 236134, token usage: 0.96, cuda graph: True, gen throughput (token/s): 747.25, #queue-req: 28\n",
      "[2025-08-13 19:53:19] INFO:     127.0.0.1:54668 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:19] Prefill batch. #new-seq: 2, #new-token: 3593, #cached-token: 572, token usage: 0.94, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 19:53:20] INFO:     127.0.0.1:54692 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:20] Prefill batch. #new-seq: 2, #new-token: 3227, #cached-token: 899, token usage: 0.94, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 19:53:23] Decode batch. #running-req: 74, #token: 236576, token usage: 0.96, cuda graph: True, gen throughput (token/s): 854.53, #queue-req: 26\n",
      "[2025-08-13 19:53:24] INFO:     127.0.0.1:47218 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:25] INFO:     127.0.0.1:34966 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:25] Prefill batch. #new-seq: 2, #new-token: 5889, #cached-token: 616, token usage: 0.94, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 19:53:26] INFO:     127.0.0.1:53170 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:26] INFO:     127.0.0.1:53192 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:26] Prefill batch. #new-seq: 1, #new-token: 4782, #cached-token: 544, token usage: 0.94, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 19:53:26] Decode batch. #running-req: 73, #token: 235834, token usage: 0.96, cuda graph: True, gen throughput (token/s): 772.70, #queue-req: 27\n",
      "[2025-08-13 19:53:27] INFO:     127.0.0.1:38114 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:27] Prefill batch. #new-seq: 1, #new-token: 5032, #cached-token: 392, token usage: 0.93, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 19:53:28] INFO:     127.0.0.1:38146 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:28] INFO:     127.0.0.1:58852 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:28] Prefill batch. #new-seq: 3, #new-token: 7787, #cached-token: 987, token usage: 0.91, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 19:53:29] INFO:     127.0.0.1:38178 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:29] INFO:     127.0.0.1:38194 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:29] Prefill batch. #new-seq: 2, #new-token: 7004, #cached-token: 849, token usage: 0.92, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 19:53:31] Decode batch. #running-req: 74, #token: 234473, token usage: 0.95, cuda graph: True, gen throughput (token/s): 638.50, #queue-req: 26\n",
      "[2025-08-13 19:53:31] INFO:     127.0.0.1:55840 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:31] Prefill batch. #new-seq: 1, #new-token: 4318, #cached-token: 446, token usage: 0.95, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 19:53:33] INFO:     127.0.0.1:38210 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:33] INFO:     127.0.0.1:38214 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:33] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 96, token usage: 0.96, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 19:53:34] INFO:     127.0.0.1:50682 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:34] INFO:     127.0.0.1:50692 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:34] Prefill batch. #new-seq: 3, #new-token: 6765, #cached-token: 390, token usage: 0.91, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 19:53:35] Decode batch. #running-req: 74, #token: 230043, token usage: 0.94, cuda graph: True, gen throughput (token/s): 759.20, #queue-req: 26\n",
      "[2025-08-13 19:53:35] INFO:     127.0.0.1:55100 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:35] Prefill batch. #new-seq: 1, #new-token: 4850, #cached-token: 474, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 19:53:36] INFO:     127.0.0.1:58874 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:36] Prefill batch. #new-seq: 1, #new-token: 4360, #cached-token: 471, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 19:53:37] INFO:     127.0.0.1:47222 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:37] Prefill batch. #new-seq: 1, #new-token: 2596, #cached-token: 709, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 19:53:38] INFO:     127.0.0.1:39270 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:38] Prefill batch. #new-seq: 1, #new-token: 2298, #cached-token: 123, token usage: 0.95, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 19:53:38] INFO:     127.0.0.1:50710 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:38] INFO:     127.0.0.1:50718 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:38] Prefill batch. #new-seq: 3, #new-token: 7308, #cached-token: 989, token usage: 0.91, #running-req: 73, #queue-req: 21\n",
      "[2025-08-13 19:53:39] INFO:     127.0.0.1:50720 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:39] INFO:     127.0.0.1:50722 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:39] INFO:     127.0.0.1:42966 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:39] INFO:     127.0.0.1:58866 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:39] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1406, token usage: 0.85, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 19:53:40] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 77, token usage: 0.88, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 19:53:40] Prefill batch. #new-seq: 3, #new-token: 7288, #cached-token: 973, token usage: 0.91, #running-req: 75, #queue-req: 23\n",
      "[2025-08-13 19:53:42] Prefill batch. #new-seq: 1, #new-token: 2404, #cached-token: 409, token usage: 0.94, #running-req: 77, #queue-req: 22\n",
      "[2025-08-13 19:53:42] Decode batch. #running-req: 77, #token: 234134, token usage: 0.95, cuda graph: True, gen throughput (token/s): 435.70, #queue-req: 22\n",
      "[2025-08-13 19:53:42] INFO:     127.0.0.1:50726 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:42] Prefill batch. #new-seq: 1, #new-token: 1104, #cached-token: 139, token usage: 0.94, #running-req: 77, #queue-req: 22\n",
      "[2025-08-13 19:53:42] INFO:     127.0.0.1:43176 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:42] Prefill batch. #new-seq: 1, #new-token: 4380, #cached-token: 450, token usage: 0.91, #running-req: 77, #queue-req: 21\n",
      "[2025-08-13 19:53:42] INFO:     127.0.0.1:50730 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:43] Prefill batch. #new-seq: 1, #new-token: 6539, #cached-token: 191, token usage: 0.93, #running-req: 77, #queue-req: 20\n",
      "[2025-08-13 19:53:45] INFO:     127.0.0.1:39200 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:45] INFO:     127.0.0.1:51770 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:46] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 447, token usage: 0.94, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 19:53:46] INFO:     127.0.0.1:50742 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:46] Decode batch. #running-req: 77, #token: 234138, token usage: 0.95, cuda graph: True, gen throughput (token/s): 690.40, #queue-req: 21\n",
      "[2025-08-13 19:53:47] INFO:     127.0.0.1:51784 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:49] Decode batch. #running-req: 75, #token: 232708, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1097.54, #queue-req: 25\n",
      "[2025-08-13 19:53:49] INFO:     127.0.0.1:55830 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:49] INFO:     127.0.0.1:51794 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:49] Prefill batch. #new-seq: 1, #new-token: 4650, #cached-token: 156, token usage: 0.93, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 19:53:52] INFO:     127.0.0.1:51810 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:52] Decode batch. #running-req: 73, #token: 227782, token usage: 0.93, cuda graph: True, gen throughput (token/s): 920.04, #queue-req: 26\n",
      "[2025-08-13 19:53:52] INFO:     127.0.0.1:45104 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:52] INFO:     127.0.0.1:39406 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:52] Prefill batch. #new-seq: 2, #new-token: 6632, #cached-token: 295, token usage: 0.93, #running-req: 71, #queue-req: 24\n",
      "[2025-08-13 19:53:52] INFO:     127.0.0.1:55822 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:53] INFO:     127.0.0.1:53192 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:53] Prefill batch. #new-seq: 2, #new-token: 7349, #cached-token: 217, token usage: 0.92, #running-req: 71, #queue-req: 22\n",
      "[2025-08-13 19:53:53] INFO:     127.0.0.1:53170 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:54] Prefill batch. #new-seq: 1, #new-token: 2371, #cached-token: 77, token usage: 0.95, #running-req: 72, #queue-req: 21\n",
      "[2025-08-13 19:53:54] INFO:     127.0.0.1:38178 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:55] INFO:     127.0.0.1:38114 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:55] Prefill batch. #new-seq: 1, #new-token: 6611, #cached-token: 168, token usage: 0.93, #running-req: 71, #queue-req: 20\n",
      "[2025-08-13 19:53:56] INFO:     127.0.0.1:50692 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:56] Prefill batch. #new-seq: 1, #new-token: 6500, #cached-token: 191, token usage: 0.93, #running-req: 71, #queue-req: 19\n",
      "[2025-08-13 19:53:58] Decode batch. #running-req: 72, #token: 236207, token usage: 0.96, cuda graph: True, gen throughput (token/s): 530.35, #queue-req: 20\n",
      ".[2025-08-13 19:53:58] INFO:     127.0.0.1:38146 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:58] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 208, token usage: 0.94, #running-req: 71, #queue-req: 22\n",
      "[2025-08-13 19:53:58] INFO:     127.0.0.1:47228 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:59] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 455, token usage: 0.93, #running-req: 71, #queue-req: 24\n",
      "[2025-08-13 19:53:59] INFO:     127.0.0.1:47232 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:59] INFO:     127.0.0.1:47240 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:59] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 696, token usage: 0.90, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 19:53:59] INFO:     127.0.0.1:47256 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:53:59] Prefill batch. #new-seq: 2, #new-token: 5111, #cached-token: 171, token usage: 0.93, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 19:54:01] Prefill batch. #new-seq: 1, #new-token: 388, #cached-token: 437, token usage: 0.95, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 19:54:02] INFO:     127.0.0.1:47272 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:02] Decode batch. #running-req: 73, #token: 229070, token usage: 0.93, cuda graph: True, gen throughput (token/s): 677.73, #queue-req: 27\n",
      "[2025-08-13 19:54:02] Prefill batch. #new-seq: 1, #new-token: 6586, #cached-token: 156, token usage: 0.93, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 19:54:03] INFO:     127.0.0.1:47284 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:03] INFO:     127.0.0.1:50720 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:03] Prefill batch. #new-seq: 1, #new-token: 6603, #cached-token: 172, token usage: 0.92, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 19:54:04] INFO:     127.0.0.1:50722 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:04] Prefill batch. #new-seq: 1, #new-token: 6957, #cached-token: 146, token usage: 0.92, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 19:54:06] INFO:     127.0.0.1:38214 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:06] Prefill batch. #new-seq: 1, #new-token: 2563, #cached-token: 553, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 19:54:06] INFO:     127.0.0.1:54608 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:06] INFO:     127.0.0.1:54622 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:06] Prefill batch. #new-seq: 1, #new-token: 4373, #cached-token: 446, token usage: 0.93, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 19:54:07] Decode batch. #running-req: 71, #token: 234725, token usage: 0.95, cuda graph: True, gen throughput (token/s): 538.66, #queue-req: 29\n",
      "[2025-08-13 19:54:08] INFO:     127.0.0.1:38194 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:08] Prefill batch. #new-seq: 1, #new-token: 4290, #cached-token: 139, token usage: 0.94, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 19:54:09] INFO:     127.0.0.1:54650 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:09] INFO:     127.0.0.1:54658 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:09] INFO:     127.0.0.1:50718 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:09] INFO:     127.0.0.1:38210 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:09] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1494, token usage: 0.89, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 19:54:09] Prefill batch. #new-seq: 2, #new-token: 3811, #cached-token: 465, token usage: 0.93, #running-req: 71, #queue-req: 26\n",
      ".[2025-08-13 19:54:10] Prefill batch. #new-seq: 2, #new-token: 522, #cached-token: 300, token usage: 0.94, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 19:54:10] INFO:     127.0.0.1:54666 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:11] INFO:     127.0.0.1:50682 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:11] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 379, token usage: 0.90, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 19:54:11] Prefill batch. #new-seq: 2, #new-token: 1171, #cached-token: 122, token usage: 0.94, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 19:54:12] Decode batch. #running-req: 75, #token: 232003, token usage: 0.94, cuda graph: True, gen throughput (token/s): 570.68, #queue-req: 25\n",
      "[2025-08-13 19:54:14] INFO:     127.0.0.1:50710 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:14] Prefill batch. #new-seq: 1, #new-token: 2165, #cached-token: 467, token usage: 0.93, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 19:54:15] Decode batch. #running-req: 75, #token: 232264, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1010.38, #queue-req: 24\n",
      "[2025-08-13 19:54:17] INFO:     127.0.0.1:42966 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:17] Prefill batch. #new-seq: 1, #new-token: 2152, #cached-token: 480, token usage: 0.92, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 19:54:18] INFO:     127.0.0.1:50726 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:18] Prefill batch. #new-seq: 2, #new-token: 2952, #cached-token: 578, token usage: 0.92, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 19:54:18] Decode batch. #running-req: 74, #token: 228705, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1007.48, #queue-req: 23\n",
      "[2025-08-13 19:54:19] INFO:     127.0.0.1:39246 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:20] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 146, token usage: 0.91, #running-req: 75, #queue-req: 23\n",
      "[2025-08-13 19:54:20] INFO:     127.0.0.1:50730 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:20] Prefill batch. #new-seq: 2, #new-token: 5094, #cached-token: 444, token usage: 0.93, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 19:54:21] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 412, token usage: 0.95, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 19:54:21] INFO:     127.0.0.1:50742 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:21] Prefill batch. #new-seq: 1, #new-token: 2155, #cached-token: 476, token usage: 0.94, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 19:54:23] Decode batch. #running-req: 77, #token: 234311, token usage: 0.95, cuda graph: True, gen throughput (token/s): 679.69, #queue-req: 23\n",
      "[2025-08-13 19:54:25] Decode batch. #running-req: 77, #token: 237391, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1085.77, #queue-req: 23\n",
      "[2025-08-13 19:54:28] INFO:     127.0.0.1:53844 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:28] Decode batch. #running-req: 76, #token: 239807, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1077.62, #queue-req: 23\n",
      "[2025-08-13 19:54:30] INFO:     127.0.0.1:47228 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:31] Decode batch. #running-req: 75, #token: 238327, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1063.29, #queue-req: 25\n",
      "[2025-08-13 19:54:32] INFO:     127.0.0.1:45058 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:34] INFO:     127.0.0.1:54716 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:34] Decode batch. #running-req: 73, #token: 235988, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1052.17, #queue-req: 26\n",
      "[2025-08-13 19:54:36] INFO:     127.0.0.1:59024 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:37] Decode batch. #running-req: 72, #token: 235621, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1035.17, #queue-req: 27\n",
      "[2025-08-13 19:54:37] INFO:     127.0.0.1:52546 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:39] INFO:     127.0.0.1:60654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:40] Decode batch. #running-req: 70, #token: 234491, token usage: 0.95, cuda graph: True, gen throughput (token/s): 975.96, #queue-req: 29\n",
      "[2025-08-13 19:54:41] INFO:     127.0.0.1:35262 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 19:54:43] Decode batch. #running-req: 69, #token: 236682, token usage: 0.96, cuda graph: True, gen throughput (token/s): 979.81, #queue-req: 31\n",
      "[2025-08-13 19:54:45] Decode batch. #running-req: 69, #token: 239442, token usage: 0.97, cuda graph: True, gen throughput (token/s): 983.70, #queue-req: 31\n",
      "[2025-08-13 19:54:46] INFO:     127.0.0.1:54674 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:48] Decode batch. #running-req: 68, #token: 239706, token usage: 0.97, cuda graph: True, gen throughput (token/s): 953.13, #queue-req: 32\n",
      "[2025-08-13 19:54:49] INFO:     127.0.0.1:54708 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:50] INFO:     127.0.0.1:45732 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:50] Prefill batch. #new-seq: 1, #new-token: 4775, #cached-token: 392, token usage: 0.94, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 19:54:51] INFO:     127.0.0.1:45742 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:51] Prefill batch. #new-seq: 1, #new-token: 4171, #cached-token: 480, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 19:54:52] Decode batch. #running-req: 67, #token: 239125, token usage: 0.97, cuda graph: True, gen throughput (token/s): 729.25, #queue-req: 32\n",
      "[2025-08-13 19:54:53] INFO:     127.0.0.1:59016 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:53] Prefill batch. #new-seq: 1, #new-token: 2026, #cached-token: 144, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      ".[2025-08-13 19:54:53] INFO:     127.0.0.1:47256 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:53] INFO:     127.0.0.1:44378 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:53] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 279, token usage: 0.92, #running-req: 65, #queue-req: 30\n",
      "[2025-08-13 19:54:53] Prefill batch. #new-seq: 1, #new-token: 2688, #cached-token: 0, token usage: 0.96, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 19:54:56] Decode batch. #running-req: 67, #token: 239689, token usage: 0.97, cuda graph: True, gen throughput (token/s): 664.97, #queue-req: 33\n",
      "[2025-08-13 19:54:56] INFO:     127.0.0.1:60662 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:56] Prefill batch. #new-seq: 1, #new-token: 4590, #cached-token: 180, token usage: 0.94, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 19:54:57] INFO:     127.0.0.1:39234 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:58] INFO:     127.0.0.1:47272 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:54:58] Prefill batch. #new-seq: 2, #new-token: 6988, #cached-token: 318, token usage: 0.93, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 19:55:00] Decode batch. #running-req: 67, #token: 237140, token usage: 0.96, cuda graph: True, gen throughput (token/s): 696.29, #queue-req: 33\n",
      "[2025-08-13 19:55:02] INFO:     127.0.0.1:47232 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:02] Prefill batch. #new-seq: 1, #new-token: 265, #cached-token: 149, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 19:55:02] INFO:     127.0.0.1:39242 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:02] Prefill batch. #new-seq: 2, #new-token: 4172, #cached-token: 314, token usage: 0.94, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 19:55:03] Decode batch. #running-req: 68, #token: 235081, token usage: 0.96, cuda graph: True, gen throughput (token/s): 842.44, #queue-req: 32\n",
      "[2025-08-13 19:55:03] INFO:     127.0.0.1:44932 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:03] Prefill batch. #new-seq: 1, #new-token: 4367, #cached-token: 443, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 19:55:05] INFO:     127.0.0.1:47284 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:05] Prefill batch. #new-seq: 1, #new-token: 2578, #cached-token: 589, token usage: 0.96, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 19:55:05] INFO:     127.0.0.1:45080 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:05] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 77, token usage: 0.95, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 19:55:06] Decode batch. #running-req: 68, #token: 234910, token usage: 0.96, cuda graph: True, gen throughput (token/s): 778.41, #queue-req: 32\n",
      "[2025-08-13 19:55:06] INFO:     127.0.0.1:34382 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:08] INFO:     127.0.0.1:45068 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:08] Prefill batch. #new-seq: 1, #new-token: 4485, #cached-token: 122, token usage: 0.94, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 19:55:09] INFO:     127.0.0.1:54622 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:09] Prefill batch. #new-seq: 1, #new-token: 4774, #cached-token: 392, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 19:55:10] INFO:     127.0.0.1:58990 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:10] Decode batch. #running-req: 66, #token: 235122, token usage: 0.96, cuda graph: True, gen throughput (token/s): 734.17, #queue-req: 33\n",
      "[2025-08-13 19:55:10] INFO:     127.0.0.1:54666 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:10] Prefill batch. #new-seq: 1, #new-token: 4563, #cached-token: 191, token usage: 0.94, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 19:55:13] Decode batch. #running-req: 66, #token: 237535, token usage: 0.97, cuda graph: True, gen throughput (token/s): 840.96, #queue-req: 34\n",
      "[2025-08-13 19:55:14] INFO:     127.0.0.1:54650 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:15] INFO:     127.0.0.1:54658 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:15] Prefill batch. #new-seq: 1, #new-token: 4856, #cached-token: 477, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 19:55:16] INFO:     127.0.0.1:37484 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:16] Decode batch. #running-req: 64, #token: 233603, token usage: 0.95, cuda graph: True, gen throughput (token/s): 823.39, #queue-req: 34\n",
      "[2025-08-13 19:55:18] INFO:     127.0.0.1:34404 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:19] Decode batch. #running-req: 63, #token: 233846, token usage: 0.95, cuda graph: True, gen throughput (token/s): 964.91, #queue-req: 37\n",
      "[2025-08-13 19:55:21] INFO:     127.0.0.1:53838 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:22] Decode batch. #running-req: 62, #token: 230185, token usage: 0.94, cuda graph: True, gen throughput (token/s): 937.88, #queue-req: 38\n",
      "[2025-08-13 19:55:23] INFO:     127.0.0.1:43184 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:23] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 146, token usage: 0.93, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 19:55:24] Prefill batch. #new-seq: 1, #new-token: 1093, #cached-token: 0, token usage: 0.96, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 19:55:25] INFO:     127.0.0.1:43188 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:25] INFO:     127.0.0.1:43192 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:25] Prefill batch. #new-seq: 1, #new-token: 2488, #cached-token: 626, token usage: 0.94, #running-req: 60, #queue-req: 39\n",
      "[2025-08-13 19:55:26] Decode batch. #running-req: 61, #token: 233456, token usage: 0.95, cuda graph: True, gen throughput (token/s): 633.07, #queue-req: 39\n",
      "[2025-08-13 19:55:28] Decode batch. #running-req: 61, #token: 235896, token usage: 0.96, cuda graph: True, gen throughput (token/s): 887.58, #queue-req: 39\n",
      "[2025-08-13 19:55:29] INFO:     127.0.0.1:37494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:29] Prefill batch. #new-seq: 1, #new-token: 5102, #cached-token: 392, token usage: 0.94, #running-req: 60, #queue-req: 39\n",
      "[2025-08-13 19:55:32] Decode batch. #running-req: 61, #token: 239091, token usage: 0.97, cuda graph: True, gen throughput (token/s): 752.89, #queue-req: 39\n",
      "[2025-08-13 19:55:34] INFO:     127.0.0.1:55142 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:34] INFO:     127.0.0.1:45062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:34] Prefill batch. #new-seq: 1, #new-token: 2163, #cached-token: 151, token usage: 0.95, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 19:55:35] Decode batch. #running-req: 60, #token: 235627, token usage: 0.96, cuda graph: True, gen throughput (token/s): 818.48, #queue-req: 38\n",
      "[2025-08-13 19:55:37] Decode batch. #running-req: 60, #token: 234077, token usage: 0.95, cuda graph: True, gen throughput (token/s): 864.41, #queue-req: 40\n",
      "[2025-08-13 19:55:37] INFO:     127.0.0.1:52532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:37] Prefill batch. #new-seq: 1, #new-token: 2415, #cached-token: 149, token usage: 0.95, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 19:55:40] Decode batch. #running-req: 60, #token: 238890, token usage: 0.97, cuda graph: True, gen throughput (token/s): 822.97, #queue-req: 40\n",
      "[2025-08-13 19:55:42] INFO:     127.0.0.1:45772 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:42] Prefill batch. #new-seq: 1, #new-token: 422, #cached-token: 146, token usage: 0.97, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 19:55:43] INFO:     127.0.0.1:55826 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:43] INFO:     127.0.0.1:55828 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:43] Prefill batch. #new-seq: 2, #new-token: 4237, #cached-token: 947, token usage: 0.94, #running-req: 58, #queue-req: 40\n",
      "[2025-08-13 19:55:43] Decode batch. #running-req: 60, #token: 236194, token usage: 0.96, cuda graph: True, gen throughput (token/s): 761.47, #queue-req: 40\n",
      "[2025-08-13 19:55:44] INFO:     127.0.0.1:45066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:44] Prefill batch. #new-seq: 2, #new-token: 3122, #cached-token: 896, token usage: 0.94, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 19:55:44] INFO:     127.0.0.1:59044 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:44] Prefill batch. #new-seq: 3, #new-token: 2538, #cached-token: 928, token usage: 0.93, #running-req: 60, #queue-req: 36\n",
      "[2025-08-13 19:55:47] Decode batch. #running-req: 63, #token: 234094, token usage: 0.95, cuda graph: True, gen throughput (token/s): 784.61, #queue-req: 37\n",
      "[2025-08-13 19:55:49] Decode batch. #running-req: 63, #token: 236614, token usage: 0.96, cuda graph: True, gen throughput (token/s): 932.65, #queue-req: 37\n",
      "[2025-08-13 19:55:49] INFO:     127.0.0.1:40616 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:50] Prefill batch. #new-seq: 1, #new-token: 2484, #cached-token: 438, token usage: 0.96, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 19:55:50] INFO:     127.0.0.1:44356 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:50] Prefill batch. #new-seq: 1, #new-token: 6677, #cached-token: 93, token usage: 0.95, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 19:55:52] INFO:     127.0.0.1:54708 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:52] Prefill batch. #new-seq: 2, #new-token: 1362, #cached-token: 488, token usage: 0.95, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 19:55:53] Decode batch. #running-req: 64, #token: 235646, token usage: 0.96, cuda graph: True, gen throughput (token/s): 677.33, #queue-req: 36\n",
      "[2025-08-13 19:55:53] INFO:     127.0.0.1:43536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:53] INFO:     127.0.0.1:60630 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:53] INFO:     127.0.0.1:60642 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:53] Prefill batch. #new-seq: 3, #new-token: 7830, #cached-token: 742, token usage: 0.91, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 19:55:56] INFO:     127.0.0.1:44924 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:56] Prefill batch. #new-seq: 1, #new-token: 7032, #cached-token: 462, token usage: 0.93, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 19:55:57] Decode batch. #running-req: 64, #token: 237056, token usage: 0.96, cuda graph: True, gen throughput (token/s): 631.17, #queue-req: 36\n",
      "[2025-08-13 19:55:59] INFO:     127.0.0.1:55114 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:59] INFO:     127.0.0.1:55128 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:55:59] Prefill batch. #new-seq: 1, #new-token: 2159, #cached-token: 119, token usage: 0.95, #running-req: 62, #queue-req: 37\n",
      "[2025-08-13 19:56:00] Decode batch. #running-req: 63, #token: 235228, token usage: 0.96, cuda graph: True, gen throughput (token/s): 872.75, #queue-req: 37\n",
      "[2025-08-13 19:56:01] INFO:     127.0.0.1:54674 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:01] Prefill batch. #new-seq: 1, #new-token: 4582, #cached-token: 208, token usage: 0.95, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 19:56:02] INFO:     127.0.0.1:40614 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:03] Decode batch. #running-req: 62, #token: 236786, token usage: 0.96, cuda graph: True, gen throughput (token/s): 809.48, #queue-req: 38\n",
      "[2025-08-13 19:56:06] Decode batch. #running-req: 62, #token: 239266, token usage: 0.97, cuda graph: True, gen throughput (token/s): 926.20, #queue-req: 38\n",
      "[2025-08-13 19:56:06] INFO:     127.0.0.1:39234 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:08] INFO:     127.0.0.1:52528 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:08] Prefill batch. #new-seq: 1, #new-token: 4294, #cached-token: 131, token usage: 0.94, #running-req: 60, #queue-req: 39\n",
      "[2025-08-13 19:56:09] INFO:     127.0.0.1:44362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:09] Prefill batch. #new-seq: 1, #new-token: 4870, #cached-token: 464, token usage: 0.94, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 19:56:09] INFO:     127.0.0.1:59032 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:09] Prefill batch. #new-seq: 1, #new-token: 264, #cached-token: 392, token usage: 0.95, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 19:56:09] Decode batch. #running-req: 61, #token: 234713, token usage: 0.95, cuda graph: True, gen throughput (token/s): 686.52, #queue-req: 37\n",
      "[2025-08-13 19:56:12] INFO:     127.0.0.1:40610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:12] Prefill batch. #new-seq: 2, #new-token: 2359, #cached-token: 264, token usage: 0.95, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 19:56:12] INFO:     127.0.0.1:52552 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:12] Prefill batch. #new-seq: 2, #new-token: 1500, #cached-token: 824, token usage: 0.95, #running-req: 61, #queue-req: 35\n",
      "[2025-08-13 19:56:12] Decode batch. #running-req: 63, #token: 236020, token usage: 0.96, cuda graph: True, gen throughput (token/s): 804.97, #queue-req: 35\n",
      "[2025-08-13 19:56:13] INFO:     127.0.0.1:45752 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:13] INFO:     127.0.0.1:45766 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:13] Prefill batch. #new-seq: 1, #new-token: 4589, #cached-token: 191, token usage: 0.93, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 19:56:14] INFO:     127.0.0.1:46626 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:14] Prefill batch. #new-seq: 2, #new-token: 5104, #cached-token: 1004, token usage: 0.93, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 19:56:15] INFO:     127.0.0.1:46638 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:15] Prefill batch. #new-seq: 3, #new-token: 5455, #cached-token: 1612, token usage: 0.93, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 19:56:16] Decode batch. #running-req: 65, #token: 233769, token usage: 0.95, cuda graph: True, gen throughput (token/s): 623.21, #queue-req: 35\n",
      "[2025-08-13 19:56:19] INFO:     127.0.0.1:45776 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:19] INFO:     127.0.0.1:39242 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:19] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 829, token usage: 0.91, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 19:56:19] Prefill batch. #new-seq: 1, #new-token: 1214, #cached-token: 0, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 19:56:20] Decode batch. #running-req: 67, #token: 234494, token usage: 0.95, cuda graph: True, gen throughput (token/s): 707.00, #queue-req: 33\n",
      "[2025-08-13 19:56:21] INFO:     127.0.0.1:44380 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:21] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 448, token usage: 0.95, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 19:56:23] INFO:     127.0.0.1:44392 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:23] Decode batch. #running-req: 66, #token: 234720, token usage: 0.95, cuda graph: True, gen throughput (token/s): 813.31, #queue-req: 33\n",
      "[2025-08-13 19:56:26] INFO:     127.0.0.1:44390 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:26] Prefill batch. #new-seq: 3, #new-token: 4693, #cached-token: 1059, token usage: 0.93, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 19:56:26] INFO:     127.0.0.1:41152 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:26] Prefill batch. #new-seq: 1, #new-token: 568, #cached-token: 639, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 19:56:27] INFO:     127.0.0.1:44974 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:27] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 733, token usage: 0.92, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 19:56:27] INFO:     127.0.0.1:44394 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:27] Prefill batch. #new-seq: 1, #new-token: 889, #cached-token: 0, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 19:56:28] Decode batch. #running-req: 69, #token: 235623, token usage: 0.96, cuda graph: True, gen throughput (token/s): 631.04, #queue-req: 31\n",
      "[2025-08-13 19:56:29] INFO:     127.0.0.1:46642 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:29] Prefill batch. #new-seq: 1, #new-token: 4441, #cached-token: 437, token usage: 0.95, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 19:56:30] INFO:     127.0.0.1:46650 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:30] Prefill batch. #new-seq: 1, #new-token: 2849, #cached-token: 412, token usage: 0.95, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 19:56:30] INFO:     127.0.0.1:55358 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:31] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 119, token usage: 0.96, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 19:56:31] INFO:     127.0.0.1:46662 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:31] INFO:     127.0.0.1:59002 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:31] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 588, token usage: 0.90, #running-req: 67, #queue-req: 28\n",
      "[2025-08-13 19:56:31] Decode batch. #running-req: 67, #token: 230674, token usage: 0.94, cuda graph: True, gen throughput (token/s): 764.19, #queue-req: 28\n",
      "[2025-08-13 19:56:31] Prefill batch. #new-seq: 1, #new-token: 1638, #cached-token: 0, token usage: 0.94, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 19:56:32] INFO:     127.0.0.1:43184 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:32] INFO:     127.0.0.1:43192 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:32] Prefill batch. #new-seq: 2, #new-token: 7901, #cached-token: 306, token usage: 0.92, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 19:56:35] INFO:     127.0.0.1:43188 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:35] Prefill batch. #new-seq: 1, #new-token: 4731, #cached-token: 462, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 19:56:36] Decode batch. #running-req: 69, #token: 236346, token usage: 0.96, cuda graph: True, gen throughput (token/s): 565.69, #queue-req: 31\n",
      "[2025-08-13 19:56:36] INFO:     127.0.0.1:60642 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:36] Prefill batch. #new-seq: 2, #new-token: 4093, #cached-token: 269, token usage: 0.94, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 19:56:37] INFO:     127.0.0.1:44068 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:37] INFO:     127.0.0.1:55128 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:37] Prefill batch. #new-seq: 1, #new-token: 4380, #cached-token: 440, token usage: 0.95, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 19:56:40] INFO:     127.0.0.1:37494 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:40] Decode batch. #running-req: 68, #token: 234887, token usage: 0.96, cuda graph: True, gen throughput (token/s): 759.48, #queue-req: 31\n",
      "[2025-08-13 19:56:40] INFO:     127.0.0.1:41138 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:40] INFO:     127.0.0.1:53836 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:40] INFO:     127.0.0.1:55826 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:40] INFO:     127.0.0.1:55828 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:40] INFO:     127.0.0.1:43536 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:40] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1303, token usage: 0.89, #running-req: 64, #queue-req: 27\n",
      "[2025-08-13 19:56:40] Prefill batch. #new-seq: 4, #new-token: 7551, #cached-token: 726, token usage: 0.92, #running-req: 67, #queue-req: 25\n",
      "[2025-08-13 19:56:43] INFO:     127.0.0.1:45066 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:43] Prefill batch. #new-seq: 2, #new-token: 4550, #cached-token: 574, token usage: 0.94, #running-req: 69, #queue-req: 23\n",
      "[2025-08-13 19:56:44] Decode batch. #running-req: 71, #token: 236150, token usage: 0.96, cuda graph: True, gen throughput (token/s): 599.51, #queue-req: 27\n",
      "[2025-08-13 19:56:45] INFO:     127.0.0.1:60630 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:45] Prefill batch. #new-seq: 1, #new-token: 4862, #cached-token: 464, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 19:56:48] INFO:     127.0.0.1:40638 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:48] Decode batch. #running-req: 71, #token: 233548, token usage: 0.95, cuda graph: True, gen throughput (token/s): 846.97, #queue-req: 29\n",
      "[2025-08-13 19:56:48] INFO:     127.0.0.1:52552 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:49] INFO:     127.0.0.1:44918 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:49] Prefill batch. #new-seq: 1, #new-token: 5009, #cached-token: 474, token usage: 0.93, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 19:56:50] INFO:     127.0.0.1:55114 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:50] Prefill batch. #new-seq: 1, #new-token: 4211, #cached-token: 639, token usage: 0.93, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 19:56:51] Decode batch. #running-req: 69, #token: 234455, token usage: 0.95, cuda graph: True, gen throughput (token/s): 758.80, #queue-req: 31\n",
      "[2025-08-13 19:56:52] INFO:     127.0.0.1:52528 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:52] Prefill batch. #new-seq: 1, #new-token: 6883, #cached-token: 463, token usage: 0.93, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 19:56:54] INFO:     127.0.0.1:46900 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:54] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 949, token usage: 0.90, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 19:56:54] INFO:     127.0.0.1:44946 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:54] Prefill batch. #new-seq: 2, #new-token: 2017, #cached-token: 126, token usage: 0.93, #running-req: 71, #queue-req: 26\n",
      ".[2025-08-13 19:56:55] Prefill batch. #new-seq: 1, #new-token: 4302, #cached-token: 131, token usage: 0.94, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 19:56:55] INFO:     127.0.0.1:35312 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:56] Prefill batch. #new-seq: 1, #new-token: 2362, #cached-token: 440, token usage: 0.95, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 19:56:56] Decode batch. #running-req: 73, #token: 235257, token usage: 0.96, cuda graph: True, gen throughput (token/s): 573.00, #queue-req: 26\n",
      "[2025-08-13 19:56:56] INFO:     127.0.0.1:45752 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:56] Prefill batch. #new-seq: 1, #new-token: 4616, #cached-token: 709, token usage: 0.95, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 19:56:58] INFO:     127.0.0.1:44958 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:58] INFO:     127.0.0.1:44960 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:58] INFO:     127.0.0.1:35254 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:58] INFO:     127.0.0.1:35266 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:58] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1189, token usage: 0.91, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 19:56:58] Prefill batch. #new-seq: 1, #new-token: 1193, #cached-token: 0, token usage: 0.94, #running-req: 71, #queue-req: 29\n",
      "[2025-08-13 19:56:59] INFO:     127.0.0.1:45766 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:56:59] Prefill batch. #new-seq: 1, #new-token: 6864, #cached-token: 463, token usage: 0.93, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 19:57:00] INFO:     127.0.0.1:35278 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:00] INFO:     127.0.0.1:35294 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:00] INFO:     127.0.0.1:35308 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:00] Prefill batch. #new-seq: 3, #new-token: 8069, #cached-token: 1146, token usage: 0.89, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 19:57:02] Decode batch. #running-req: 71, #token: 228485, token usage: 0.93, cuda graph: True, gen throughput (token/s): 525.42, #queue-req: 29\n",
      "[2025-08-13 19:57:03] INFO:     127.0.0.1:55346 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:03] Prefill batch. #new-seq: 2, #new-token: 4982, #cached-token: 983, token usage: 0.92, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 19:57:04] INFO:     127.0.0.1:46662 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:04] Prefill batch. #new-seq: 3, #new-token: 7780, #cached-token: 408, token usage: 0.92, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 19:57:05] INFO:     127.0.0.1:35310 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:05] Prefill batch. #new-seq: 2, #new-token: 2595, #cached-token: 787, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 19:57:06] INFO:     127.0.0.1:53836 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:06] Decode batch. #running-req: 75, #token: 225506, token usage: 0.92, cuda graph: True, gen throughput (token/s): 694.48, #queue-req: 25\n",
      "[2025-08-13 19:57:06] Prefill batch. #new-seq: 2, #new-token: 6654, #cached-token: 594, token usage: 0.92, #running-req: 74, #queue-req: 23\n",
      ".[2025-08-13 19:57:08] INFO:     127.0.0.1:41134 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:08] Prefill batch. #new-seq: 1, #new-token: 1493, #cached-token: 129, token usage: 0.95, #running-req: 75, #queue-req: 23\n",
      "[2025-08-13 19:57:08] INFO:     127.0.0.1:45776 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:08] Prefill batch. #new-seq: 2, #new-token: 4332, #cached-token: 617, token usage: 0.92, #running-req: 75, #queue-req: 21\n",
      "[2025-08-13 19:57:09] INFO:     127.0.0.1:46642 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:09] Prefill batch. #new-seq: 1, #new-token: 5029, #cached-token: 463, token usage: 0.92, #running-req: 76, #queue-req: 20\n",
      "[2025-08-13 19:57:10] INFO:     127.0.0.1:44380 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:10] INFO:     127.0.0.1:44390 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:10] Prefill batch. #new-seq: 3, #new-token: 6860, #cached-token: 1051, token usage: 0.91, #running-req: 75, #queue-req: 17\n",
      "[2025-08-13 19:57:10] INFO:     127.0.0.1:44394 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:10] INFO:     127.0.0.1:35318 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:10] INFO:     127.0.0.1:35332 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:11] Prefill batch. #new-seq: 1, #new-token: 6800, #cached-token: 589, token usage: 0.91, #running-req: 75, #queue-req: 19\n",
      "[2025-08-13 19:57:11] Decode batch. #running-req: 75, #token: 229794, token usage: 0.93, cuda graph: True, gen throughput (token/s): 621.15, #queue-req: 19\n",
      "[2025-08-13 19:57:13] INFO:     127.0.0.1:34380 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:13] Prefill batch. #new-seq: 3, #new-token: 6961, #cached-token: 1472, token usage: 0.90, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 19:57:14] INFO:     127.0.0.1:59002 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:14] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1378, token usage: 0.87, #running-req: 77, #queue-req: 19\n",
      "[2025-08-13 19:57:14] INFO:     127.0.0.1:34388 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:14] INFO:     127.0.0.1:46650 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:14] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 640, token usage: 0.90, #running-req: 79, #queue-req: 17\n",
      "[2025-08-13 19:57:14] Prefill batch. #new-seq: 1, #new-token: 1813, #cached-token: 0, token usage: 0.94, #running-req: 81, #queue-req: 17\n",
      "[2025-08-13 19:57:16] INFO:     127.0.0.1:35648 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:16] Decode batch. #running-req: 79, #token: 221351, token usage: 0.90, cuda graph: True, gen throughput (token/s): 552.91, #queue-req: 20\n",
      "[2025-08-13 19:57:16] INFO:     127.0.0.1:35254 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:16] INFO:     127.0.0.1:44958 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:16] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 648, token usage: 0.89, #running-req: 77, #queue-req: 18\n",
      "[2025-08-13 19:57:16] INFO:     127.0.0.1:35656 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:17] Prefill batch. #new-seq: 2, #new-token: 3610, #cached-token: 122, token usage: 0.92, #running-req: 78, #queue-req: 17\n",
      "[2025-08-13 19:57:20] INFO:     127.0.0.1:44040 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:20] Decode batch. #running-req: 78, #token: 229215, token usage: 0.93, cuda graph: True, gen throughput (token/s): 818.51, #queue-req: 21\n",
      "[2025-08-13 19:57:20] INFO:     127.0.0.1:51196 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:23] Decode batch. #running-req: 77, #token: 231826, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1103.15, #queue-req: 23\n",
      "[2025-08-13 19:57:23] INFO:     127.0.0.1:44918 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:24] INFO:     127.0.0.1:55336 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:24] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 221, token usage: 0.91, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 19:57:24] INFO:     127.0.0.1:46902 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:24] Prefill batch. #new-seq: 1, #new-token: 431, #cached-token: 0, token usage: 0.94, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 19:57:25] INFO:     127.0.0.1:35278 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:25] Prefill batch. #new-seq: 2, #new-token: 7373, #cached-token: 921, token usage: 0.91, #running-req: 75, #queue-req: 20\n",
      "[2025-08-13 19:57:25] Prefill batch. #new-seq: 1, #new-token: 4175, #cached-token: 476, token usage: 0.94, #running-req: 76, #queue-req: 19\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 19:57:27] INFO:     127.0.0.1:44946 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:27] Prefill batch. #new-seq: 2, #new-token: 427, #cached-token: 531, token usage: 0.94, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 19:57:27] INFO:     127.0.0.1:40712 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:27] INFO:     127.0.0.1:44960 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:27] Prefill batch. #new-seq: 2, #new-token: 6981, #cached-token: 589, token usage: 0.92, #running-req: 76, #queue-req: 19\n",
      "[2025-08-13 19:57:28] INFO:     127.0.0.1:35266 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:28] Decode batch. #running-req: 77, #token: 231577, token usage: 0.94, cuda graph: True, gen throughput (token/s): 574.81, #queue-req: 19\n",
      "[2025-08-13 19:57:29] INFO:     127.0.0.1:35640 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:29] INFO:     127.0.0.1:35294 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:29] INFO:     127.0.0.1:35308 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:29] Prefill batch. #new-seq: 1, #new-token: 6969, #cached-token: 544, token usage: 0.91, #running-req: 74, #queue-req: 19\n",
      "[2025-08-13 19:57:31] INFO:     127.0.0.1:35652 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:31] Prefill batch. #new-seq: 1, #new-token: 2755, #cached-token: 709, token usage: 0.93, #running-req: 74, #queue-req: 18\n",
      "[2025-08-13 19:57:32] Decode batch. #running-req: 75, #token: 231477, token usage: 0.94, cuda graph: True, gen throughput (token/s): 801.07, #queue-req: 18\n",
      "[2025-08-13 19:57:32] INFO:     127.0.0.1:35318 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:32] Prefill batch. #new-seq: 1, #new-token: 4553, #cached-token: 119, token usage: 0.92, #running-req: 74, #queue-req: 19\n",
      "[2025-08-13 19:57:34] INFO:     127.0.0.1:35310 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:34] Prefill batch. #new-seq: 1, #new-token: 2490, #cached-token: 624, token usage: 0.93, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 19:57:36] Decode batch. #running-req: 75, #token: 232609, token usage: 0.95, cuda graph: True, gen throughput (token/s): 870.19, #queue-req: 25\n",
      "[2025-08-13 19:57:38] INFO:     127.0.0.1:35332 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 19:57:38] Decode batch. #running-req: 74, #token: 233086, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1065.86, #queue-req: 25\n",
      "[2025-08-13 19:57:41] Decode batch. #running-req: 74, #token: 236046, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1050.36, #queue-req: 26\n",
      "[2025-08-13 19:57:43] INFO:     127.0.0.1:40622 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:43] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 151, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 19:57:44] Decode batch. #running-req: 74, #token: 234960, token usage: 0.96, cuda graph: True, gen throughput (token/s): 982.88, #queue-req: 26\n",
      "[2025-08-13 19:57:46] INFO:     127.0.0.1:60708 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:46] INFO:     127.0.0.1:40708 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:46] INFO:     127.0.0.1:46834 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:47] Decode batch. #running-req: 71, #token: 231223, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1044.37, #queue-req: 26\n",
      "[2025-08-13 19:57:49] INFO:     127.0.0.1:47642 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:50] Decode batch. #running-req: 70, #token: 231258, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1022.97, #queue-req: 30\n",
      "[2025-08-13 19:57:50] INFO:     127.0.0.1:35642 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:50] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 191, token usage: 0.92, #running-req: 69, #queue-req: 29\n",
      ".[2025-08-13 19:57:50] Prefill batch. #new-seq: 1, #new-token: 2691, #cached-token: 0, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 19:57:52] INFO:     127.0.0.1:52816 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:54] Decode batch. #running-req: 69, #token: 236738, token usage: 0.96, cuda graph: True, gen throughput (token/s): 701.80, #queue-req: 31\n",
      "[2025-08-13 19:57:54] INFO:     127.0.0.1:34408 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:54] Prefill batch. #new-seq: 1, #new-token: 4184, #cached-token: 467, token usage: 0.94, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 19:57:55] INFO:     127.0.0.1:34412 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:57:56] Prefill batch. #new-seq: 1, #new-token: 4994, #cached-token: 463, token usage: 0.93, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 19:57:57] Decode batch. #running-req: 69, #token: 235388, token usage: 0.96, cuda graph: True, gen throughput (token/s): 755.76, #queue-req: 31\n",
      "[2025-08-13 19:58:00] INFO:     127.0.0.1:40604 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:00] Decode batch. #running-req: 68, #token: 235875, token usage: 0.96, cuda graph: True, gen throughput (token/s): 970.12, #queue-req: 32\n",
      "[2025-08-13 19:58:01] INFO:     127.0.0.1:34380 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:01] Prefill batch. #new-seq: 3, #new-token: 4449, #cached-token: 1011, token usage: 0.92, #running-req: 67, #queue-req: 29\n",
      ".[2025-08-13 19:58:03] Decode batch. #running-req: 70, #token: 232075, token usage: 0.94, cuda graph: True, gen throughput (token/s): 860.09, #queue-req: 30\n",
      "[2025-08-13 19:58:04] INFO:     127.0.0.1:34388 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:04] Prefill batch. #new-seq: 2, #new-token: 2678, #cached-token: 884, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 19:58:06] INFO:     127.0.0.1:52824 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:06] Prefill batch. #new-seq: 2, #new-token: 3429, #cached-token: 830, token usage: 0.92, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 19:58:06] INFO:     127.0.0.1:48132 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:06] Prefill batch. #new-seq: 1, #new-token: 6676, #cached-token: 149, token usage: 0.91, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 19:58:07] Decode batch. #running-req: 72, #token: 231825, token usage: 0.94, cuda graph: True, gen throughput (token/s): 713.19, #queue-req: 28\n",
      "[2025-08-13 19:58:08] INFO:     127.0.0.1:40624 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:08] Prefill batch. #new-seq: 3, #new-token: 5996, #cached-token: 1007, token usage: 0.92, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 19:58:10] INFO:     127.0.0.1:48872 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:10] Prefill batch. #new-seq: 1, #new-token: 4364, #cached-token: 466, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 19:58:11] INFO:     127.0.0.1:47648 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:11] Decode batch. #running-req: 73, #token: 228083, token usage: 0.93, cuda graph: True, gen throughput (token/s): 792.91, #queue-req: 25\n",
      "[2025-08-13 19:58:11] INFO:     127.0.0.1:46848 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:11] Prefill batch. #new-seq: 1, #new-token: 4877, #cached-token: 93, token usage: 0.93, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 19:58:14] INFO:     127.0.0.1:56988 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:14] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 460, token usage: 0.94, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 19:58:15] Decode batch. #running-req: 73, #token: 234620, token usage: 0.95, cuda graph: True, gen throughput (token/s): 840.80, #queue-req: 27\n",
      "[2025-08-13 19:58:17] Decode batch. #running-req: 73, #token: 237540, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1031.39, #queue-req: 27\n",
      "[2025-08-13 19:58:18] INFO:     127.0.0.1:60674 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:20] INFO:     127.0.0.1:55330 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:20] Decode batch. #running-req: 72, #token: 237250, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1018.43, #queue-req: 28\n",
      ".[2025-08-13 19:58:22] INFO:     127.0.0.1:35654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:23] Decode batch. #running-req: 70, #token: 236567, token usage: 0.96, cuda graph: True, gen throughput (token/s): 990.34, #queue-req: 30\n",
      "[2025-08-13 19:58:25] INFO:     127.0.0.1:55404 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:25] INFO:     127.0.0.1:55390 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:26] Decode batch. #running-req: 68, #token: 233915, token usage: 0.95, cuda graph: True, gen throughput (token/s): 979.58, #queue-req: 30\n",
      "[2025-08-13 19:58:26] INFO:     127.0.0.1:46906 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:26] Prefill batch. #new-seq: 1, #new-token: 4503, #cached-token: 119, token usage: 0.92, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 19:58:26] INFO:     127.0.0.1:55408 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:27] Prefill batch. #new-seq: 1, #new-token: 6541, #cached-token: 139, token usage: 0.93, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 19:58:29] INFO:     127.0.0.1:56972 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:30] Decode batch. #running-req: 67, #token: 235863, token usage: 0.96, cuda graph: True, gen throughput (token/s): 704.61, #queue-req: 32\n",
      "[2025-08-13 19:58:32] INFO:     127.0.0.1:51212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:32] INFO:     127.0.0.1:46914 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:32] Prefill batch. #new-seq: 2, #new-token: 4137, #cached-token: 230, token usage: 0.94, #running-req: 65, #queue-req: 31\n",
      "[2025-08-13 19:58:33] Decode batch. #running-req: 67, #token: 235507, token usage: 0.96, cuda graph: True, gen throughput (token/s): 839.49, #queue-req: 33\n",
      "[2025-08-13 19:58:35] INFO:     127.0.0.1:41120 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:36] Decode batch. #running-req: 66, #token: 235627, token usage: 0.96, cuda graph: True, gen throughput (token/s): 952.29, #queue-req: 33\n",
      "[2025-08-13 19:58:36] INFO:     127.0.0.1:46920 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:36] Prefill batch. #new-seq: 1, #new-token: 2915, #cached-token: 550, token usage: 0.94, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 19:58:38] INFO:     127.0.0.1:49666 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:38] Prefill batch. #new-seq: 1, #new-token: 2615, #cached-token: 409, token usage: 0.95, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 19:58:39] Decode batch. #running-req: 66, #token: 236357, token usage: 0.96, cuda graph: True, gen throughput (token/s): 781.92, #queue-req: 33\n",
      "[2025-08-13 19:58:42] Decode batch. #running-req: 66, #token: 238997, token usage: 0.97, cuda graph: True, gen throughput (token/s): 907.97, #queue-req: 34\n",
      "[2025-08-13 19:58:42] INFO:     127.0.0.1:48866 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:43] INFO:     127.0.0.1:55364 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:43] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 448, token usage: 0.95, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 19:58:43] INFO:     127.0.0.1:44054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:43] INFO:     127.0.0.1:44062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:43] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 409, token usage: 0.94, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 19:58:45] Decode batch. #running-req: 64, #token: 232211, token usage: 0.94, cuda graph: True, gen throughput (token/s): 871.07, #queue-req: 36\n",
      "[2025-08-13 19:58:47] INFO:     127.0.0.1:48854 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:47] Prefill batch. #new-seq: 1, #new-token: 6218, #cached-token: 201, token usage: 0.94, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 19:58:48] Decode batch. #running-req: 64, #token: 237373, token usage: 0.97, cuda graph: True, gen throughput (token/s): 783.49, #queue-req: 36\n",
      "[2025-08-13 19:58:50] INFO:     127.0.0.1:51190 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:50] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 452, token usage: 0.96, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 19:58:51] Decode batch. #running-req: 64, #token: 238502, token usage: 0.97, cuda graph: True, gen throughput (token/s): 912.20, #queue-req: 36\n",
      "[2025-08-13 19:58:51] INFO:     127.0.0.1:41140 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:51] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 147, token usage: 0.95, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 19:58:53] INFO:     127.0.0.1:60688 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:53] INFO:     127.0.0.1:35312 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:53] Prefill batch. #new-seq: 3, #new-token: 4551, #cached-token: 653, token usage: 0.92, #running-req: 62, #queue-req: 33\n",
      "[2025-08-13 19:58:53] INFO:     127.0.0.1:56942 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:53] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 602, token usage: 0.91, #running-req: 64, #queue-req: 31\n",
      "[2025-08-13 19:58:54] Prefill batch. #new-seq: 2, #new-token: 7488, #cached-token: 172, token usage: 0.94, #running-req: 65, #queue-req: 30\n",
      "[2025-08-13 19:58:56] INFO:     127.0.0.1:34408 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:56] INFO:     127.0.0.1:34412 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:58:56] Decode batch. #running-req: 67, #token: 225852, token usage: 0.92, cuda graph: True, gen throughput (token/s): 559.07, #queue-req: 33\n",
      "[2025-08-13 19:58:56] Prefill batch. #new-seq: 3, #new-token: 6747, #cached-token: 683, token usage: 0.92, #running-req: 65, #queue-req: 30\n",
      "..[2025-08-13 19:58:59] Decode batch. #running-req: 68, #token: 235319, token usage: 0.96, cuda graph: True, gen throughput (token/s): 772.96, #queue-req: 32\n",
      "[2025-08-13 19:59:00] INFO:     127.0.0.1:56958 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:00] Prefill batch. #new-seq: 1, #new-token: 5190, #cached-token: 462, token usage: 0.93, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 19:59:03] INFO:     127.0.0.1:40604 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:03] Decode batch. #running-req: 68, #token: 234220, token usage: 0.95, cuda graph: True, gen throughput (token/s): 801.51, #queue-req: 32\n",
      "[2025-08-13 19:59:03] INFO:     127.0.0.1:50434 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:03] Prefill batch. #new-seq: 1, #new-token: 5351, #cached-token: 392, token usage: 0.94, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 19:59:06] Decode batch. #running-req: 67, #token: 239423, token usage: 0.97, cuda graph: True, gen throughput (token/s): 779.25, #queue-req: 33\n",
      "[2025-08-13 19:59:09] INFO:     127.0.0.1:56968 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:09] Decode batch. #running-req: 66, #token: 235158, token usage: 0.96, cuda graph: True, gen throughput (token/s): 901.80, #queue-req: 34\n",
      "[2025-08-13 19:59:10] INFO:     127.0.0.1:51242 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:10] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 589, token usage: 0.92, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 19:59:10] INFO:     127.0.0.1:48148 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:10] Prefill batch. #new-seq: 1, #new-token: 793, #cached-token: 0, token usage: 0.96, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 19:59:12] INFO:     127.0.0.1:52832 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:12] INFO:     127.0.0.1:57002 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:12] Prefill batch. #new-seq: 1, #new-token: 5352, #cached-token: 208, token usage: 0.94, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 19:59:13] INFO:     127.0.0.1:35626 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:13] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 144, token usage: 0.95, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 19:59:13] Decode batch. #running-req: 64, #token: 234593, token usage: 0.95, cuda graph: True, gen throughput (token/s): 627.49, #queue-req: 35\n",
      "[2025-08-13 19:59:14] INFO:     127.0.0.1:35348 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 19:59:15] Prefill batch. #new-seq: 1, #new-token: 2280, #cached-token: 126, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 19:59:15] INFO:     127.0.0.1:35650 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:15] Prefill batch. #new-seq: 2, #new-token: 486, #cached-token: 216, token usage: 0.94, #running-req: 64, #queue-req: 32\n",
      "[2025-08-13 19:59:16] INFO:     127.0.0.1:35668 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:16] INFO:     127.0.0.1:40694 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:16] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 914, token usage: 0.92, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 19:59:16] Prefill batch. #new-seq: 1, #new-token: 1208, #cached-token: 0, token usage: 0.95, #running-req: 65, #queue-req: 34\n",
      "[2025-08-13 19:59:17] INFO:     127.0.0.1:55372 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:17] Decode batch. #running-req: 66, #token: 231614, token usage: 0.94, cuda graph: True, gen throughput (token/s): 660.18, #queue-req: 34\n",
      "[2025-08-13 19:59:17] Prefill batch. #new-seq: 1, #new-token: 2360, #cached-token: 441, token usage: 0.94, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 19:59:18] INFO:     127.0.0.1:52844 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:18] Prefill batch. #new-seq: 1, #new-token: 1245, #cached-token: 160, token usage: 0.95, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 19:59:20] Decode batch. #running-req: 66, #token: 229346, token usage: 0.93, cuda graph: True, gen throughput (token/s): 812.31, #queue-req: 34\n",
      "[2025-08-13 19:59:20] INFO:     127.0.0.1:46906 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:20] Prefill batch. #new-seq: 2, #new-token: 2656, #cached-token: 580, token usage: 0.93, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 19:59:21] INFO:     127.0.0.1:48880 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:22] Prefill batch. #new-seq: 2, #new-token: 6071, #cached-token: 276, token usage: 0.93, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 19:59:23] INFO:     127.0.0.1:40624 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:23] INFO:     127.0.0.1:46914 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:23] Prefill batch. #new-seq: 3, #new-token: 7323, #cached-token: 1042, token usage: 0.92, #running-req: 66, #queue-req: 29\n",
      ".[2025-08-13 19:59:24] INFO:     127.0.0.1:46920 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:24] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1294, token usage: 0.93, #running-req: 68, #queue-req: 26\n",
      "[2025-08-13 19:59:24] Prefill batch. #new-seq: 1, #new-token: 536, #cached-token: 0, token usage: 0.96, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 19:59:25] Decode batch. #running-req: 71, #token: 237705, token usage: 0.97, cuda graph: True, gen throughput (token/s): 541.72, #queue-req: 29\n",
      "[2025-08-13 19:59:28] INFO:     127.0.0.1:42190 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:28] INFO:     127.0.0.1:42204 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:28] Prefill batch. #new-seq: 1, #new-token: 2287, #cached-token: 124, token usage: 0.95, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 19:59:28] INFO:     127.0.0.1:35646 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:28] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 409, token usage: 0.96, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 19:59:28] INFO:     127.0.0.1:43046 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:28] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 121, token usage: 0.96, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 19:59:29] Decode batch. #running-req: 69, #token: 235752, token usage: 0.96, cuda graph: True, gen throughput (token/s): 887.78, #queue-req: 29\n",
      "[2025-08-13 19:59:31] INFO:     127.0.0.1:48122 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:31] INFO:     127.0.0.1:48142 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:31] Decode batch. #running-req: 69, #token: 229767, token usage: 0.93, cuda graph: True, gen throughput (token/s): 991.66, #queue-req: 31\n",
      "[2025-08-13 19:59:31] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 444, token usage: 0.93, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 19:59:35] Decode batch. #running-req: 69, #token: 236902, token usage: 0.96, cuda graph: True, gen throughput (token/s): 852.14, #queue-req: 31\n",
      "[2025-08-13 19:59:35] INFO:     127.0.0.1:55364 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:35] INFO:     127.0.0.1:44062 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:35] INFO:     127.0.0.1:44054 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:35] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 544, token usage: 0.93, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 19:59:35] Prefill batch. #new-seq: 1, #new-token: 778, #cached-token: 0, token usage: 0.96, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 19:59:39] Decode batch. #running-req: 67, #token: 239443, token usage: 0.97, cuda graph: True, gen throughput (token/s): 693.56, #queue-req: 33\n",
      "[2025-08-13 19:59:39] INFO:     127.0.0.1:57366 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:41] INFO:     127.0.0.1:51214 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:41] Prefill batch. #new-seq: 1, #new-token: 2355, #cached-token: 446, token usage: 0.95, #running-req: 65, #queue-req: 34\n",
      "[2025-08-13 19:59:41] INFO:     127.0.0.1:35336 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:41] INFO:     127.0.0.1:43052 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:41] Prefill batch. #new-seq: 3, #new-token: 227, #cached-token: 928, token usage: 0.93, #running-req: 64, #queue-req: 31\n",
      "[2025-08-13 19:59:42] Decode batch. #running-req: 67, #token: 229453, token usage: 0.93, cuda graph: True, gen throughput (token/s): 857.13, #queue-req: 31\n",
      "[2025-08-13 19:59:42] INFO:     127.0.0.1:41140 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:42] Prefill batch. #new-seq: 2, #new-token: 6862, #cached-token: 212, token usage: 0.92, #running-req: 66, #queue-req: 29\n",
      "[2025-08-13 19:59:45] Decode batch. #running-req: 68, #token: 234522, token usage: 0.95, cuda graph: True, gen throughput (token/s): 774.63, #queue-req: 32\n",
      "[2025-08-13 19:59:46] INFO:     127.0.0.1:56942 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:46] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 838, token usage: 0.92, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 19:59:46] Prefill batch. #new-seq: 1, #new-token: 1119, #cached-token: 0, token usage: 0.95, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 19:59:47] INFO:     127.0.0.1:51228 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:47] Prefill batch. #new-seq: 2, #new-token: 4119, #cached-token: 617, token usage: 0.93, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 19:59:48] INFO:     127.0.0.1:55380 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:48] Prefill batch. #new-seq: 3, #new-token: 5303, #cached-token: 1011, token usage: 0.92, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 19:59:49] INFO:     127.0.0.1:56968 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:49] Prefill batch. #new-seq: 3, #new-token: 6962, #cached-token: 1484, token usage: 0.92, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 19:59:50] INFO:     127.0.0.1:57002 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:50] Prefill batch. #new-seq: 1, #new-token: 4764, #cached-token: 589, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 19:59:50] INFO:     127.0.0.1:55342 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:51] Decode batch. #running-req: 73, #token: 234049, token usage: 0.95, cuda graph: True, gen throughput (token/s): 505.80, #queue-req: 25\n",
      "[2025-08-13 19:59:52] INFO:     127.0.0.1:50446 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:52] Prefill batch. #new-seq: 2, #new-token: 2591, #cached-token: 844, token usage: 0.93, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 19:59:53] INFO:     127.0.0.1:47640 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:53] Prefill batch. #new-seq: 1, #new-token: 7133, #cached-token: 464, token usage: 0.92, #running-req: 73, #queue-req: 26\n",
      "[2025-08-13 19:59:54] Decode batch. #running-req: 74, #token: 235029, token usage: 0.96, cuda graph: True, gen throughput (token/s): 792.20, #queue-req: 26\n",
      "[2025-08-13 19:59:55] INFO:     127.0.0.1:41222 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:55] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 450, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 19:59:55] INFO:     127.0.0.1:35668 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:55] Prefill batch. #new-seq: 2, #new-token: 2345, #cached-token: 241, token usage: 0.93, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 19:59:56] INFO:     127.0.0.1:56958 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:56] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1311, token usage: 0.91, #running-req: 74, #queue-req: 19\n",
      "[2025-08-13 19:59:56] Prefill batch. #new-seq: 2, #new-token: 1299, #cached-token: 469, token usage: 0.94, #running-req: 77, #queue-req: 18\n",
      ".[2025-08-13 19:59:58] INFO:     127.0.0.1:42190 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:58] Prefill batch. #new-seq: 1, #new-token: 2125, #cached-token: 159, token usage: 0.94, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 19:59:58] INFO:     127.0.0.1:48858 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 19:59:59] Decode batch. #running-req: 78, #token: 231442, token usage: 0.94, cuda graph: True, gen throughput (token/s): 713.77, #queue-req: 22\n",
      "[2025-08-13 20:00:00] INFO:     127.0.0.1:56376 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:00] INFO:     127.0.0.1:55324 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:00] Prefill batch. #new-seq: 1, #new-token: 6708, #cached-token: 146, token usage: 0.93, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:00:01] INFO:     127.0.0.1:48142 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:00:01] Prefill batch. #new-seq: 2, #new-token: 4393, #cached-token: 869, token usage: 0.93, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:00:02] INFO:     127.0.0.1:56380 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:02] Prefill batch. #new-seq: 2, #new-token: 534, #cached-token: 539, token usage: 0.94, #running-req: 77, #queue-req: 20\n",
      "[2025-08-13 20:00:02] INFO:     127.0.0.1:60302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:02] INFO:     127.0.0.1:35626 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:02] Prefill batch. #new-seq: 2, #new-token: 6923, #cached-token: 614, token usage: 0.93, #running-req: 77, #queue-req: 18\n",
      "[2025-08-13 20:00:02] INFO:     127.0.0.1:55348 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:02] INFO:     127.0.0.1:55356 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:03] Prefill batch. #new-seq: 2, #new-token: 3986, #cached-token: 600, token usage: 0.93, #running-req: 77, #queue-req: 16\n",
      "[2025-08-13 20:00:03] INFO:     127.0.0.1:35650 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:03] INFO:     127.0.0.1:40694 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:04] Decode batch. #running-req: 77, #token: 225736, token usage: 0.92, cuda graph: True, gen throughput (token/s): 640.58, #queue-req: 18\n",
      "[2025-08-13 20:00:06] INFO:     127.0.0.1:60664 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:06] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 462, token usage: 0.90, #running-req: 76, #queue-req: 17\n",
      "[2025-08-13 20:00:06] Prefill batch. #new-seq: 1, #new-token: 1026, #cached-token: 0, token usage: 0.93, #running-req: 76, #queue-req: 17\n",
      "[2025-08-13 20:00:07] INFO:     127.0.0.1:60698 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:07] Decode batch. #running-req: 77, #token: 222163, token usage: 0.90, cuda graph: True, gen throughput (token/s): 811.93, #queue-req: 19\n",
      "[2025-08-13 20:00:07] Prefill batch. #new-seq: 1, #new-token: 7029, #cached-token: 474, token usage: 0.90, #running-req: 76, #queue-req: 18\n",
      "[2025-08-13 20:00:07] INFO:     127.0.0.1:48122 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:08] Prefill batch. #new-seq: 1, #new-token: 6407, #cached-token: 195, token usage: 0.92, #running-req: 76, #queue-req: 17\n",
      "[2025-08-13 20:00:10] INFO:     127.0.0.1:60720 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:10] INFO:     127.0.0.1:35320 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:10] Prefill batch. #new-seq: 2, #new-token: 5310, #cached-token: 586, token usage: 0.92, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:00:11] INFO:     127.0.0.1:42204 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:11] INFO:     127.0.0.1:35646 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:11] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 96, token usage: 0.93, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:00:12] Decode batch. #running-req: 76, #token: 228624, token usage: 0.93, cuda graph: True, gen throughput (token/s): 667.10, #queue-req: 22\n",
      "[2025-08-13 20:00:15] Decode batch. #running-req: 76, #token: 227366, token usage: 0.92, cuda graph: True, gen throughput (token/s): 1084.63, #queue-req: 24\n",
      "[2025-08-13 20:00:15] INFO:     127.0.0.1:51214 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:15] Prefill batch. #new-seq: 1, #new-token: 5501, #cached-token: 216, token usage: 0.93, #running-req: 75, #queue-req: 23\n",
      "[2025-08-13 20:00:17] INFO:     127.0.0.1:50430 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:17] Prefill batch. #new-seq: 2, #new-token: 5129, #cached-token: 275, token usage: 0.93, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:00:18] INFO:     127.0.0.1:35302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:18] Prefill batch. #new-seq: 2, #new-token: 2872, #cached-token: 675, token usage: 0.93, #running-req: 76, #queue-req: 20\n",
      "[2025-08-13 20:00:18] INFO:     127.0.0.1:47640 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:18] Prefill batch. #new-seq: 2, #new-token: 3609, #cached-token: 560, token usage: 0.93, #running-req: 77, #queue-req: 18\n",
      "[2025-08-13 20:00:18] INFO:     127.0.0.1:55254 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:19] Prefill batch. #new-seq: 1, #new-token: 4891, #cached-token: 462, token usage: 0.93, #running-req: 78, #queue-req: 17\n",
      "[2025-08-13 20:00:20] Decode batch. #running-req: 79, #token: 234527, token usage: 0.95, cuda graph: True, gen throughput (token/s): 640.33, #queue-req: 17\n",
      "[2025-08-13 20:00:20] INFO:     127.0.0.1:51228 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:20] Prefill batch. #new-seq: 1, #new-token: 498, #cached-token: 144, token usage: 0.93, #running-req: 78, #queue-req: 18\n",
      "[2025-08-13 20:00:20] INFO:     127.0.0.1:49634 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:20] Prefill batch. #new-seq: 2, #new-token: 6880, #cached-token: 240, token usage: 0.91, #running-req: 78, #queue-req: 16\n",
      "[2025-08-13 20:00:21] INFO:     127.0.0.1:52840 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:21] Prefill batch. #new-seq: 1, #new-token: 4512, #cached-token: 624, token usage: 0.91, #running-req: 79, #queue-req: 15\n",
      "[2025-08-13 20:00:22] INFO:     127.0.0.1:35288 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:23] Prefill batch. #new-seq: 1, #new-token: 6962, #cached-token: 550, token usage: 0.93, #running-req: 79, #queue-req: 20\n",
      "[2025-08-13 20:00:24] Decode batch. #running-req: 80, #token: 235536, token usage: 0.96, cuda graph: True, gen throughput (token/s): 703.27, #queue-req: 20\n",
      "[2025-08-13 20:00:25] INFO:     127.0.0.1:35300 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:25] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 136, token usage: 0.92, #running-req: 79, #queue-req: 20\n",
      "[2025-08-13 20:00:26] INFO:     127.0.0.1:48242 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:27] INFO:     127.0.0.1:49676 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:27] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 507, token usage: 0.92, #running-req: 78, #queue-req: 19\n",
      "[2025-08-13 20:00:27] Prefill batch. #new-seq: 1, #new-token: 709, #cached-token: 0, token usage: 0.95, #running-req: 78, #queue-req: 19\n",
      "[2025-08-13 20:00:28] Decode batch. #running-req: 79, #token: 235625, token usage: 0.96, cuda graph: True, gen throughput (token/s): 850.79, #queue-req: 21\n",
      "[2025-08-13 20:00:28] INFO:     127.0.0.1:60664 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:28] Prefill batch. #new-seq: 2, #new-token: 2827, #cached-token: 556, token usage: 0.93, #running-req: 78, #queue-req: 19\n",
      "[2025-08-13 20:00:29] INFO:     127.0.0.1:60698 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:29] Prefill batch. #new-seq: 3, #new-token: 4709, #cached-token: 980, token usage: 0.91, #running-req: 79, #queue-req: 17\n",
      "[2025-08-13 20:00:29] INFO:     127.0.0.1:55242 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:29] Prefill batch. #new-seq: 1, #new-token: 4367, #cached-token: 454, token usage: 0.93, #running-req: 81, #queue-req: 16\n",
      "[2025-08-13 20:00:30] INFO:     127.0.0.1:60506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:30] Prefill batch. #new-seq: 1, #new-token: 2286, #cached-token: 127, token usage: 0.92, #running-req: 81, #queue-req: 15\n",
      "[2025-08-13 20:00:31] INFO:     127.0.0.1:35314 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:31] Prefill batch. #new-seq: 2, #new-token: 4872, #cached-token: 873, token usage: 0.92, #running-req: 81, #queue-req: 13\n",
      "[2025-08-13 20:00:31] INFO:     127.0.0.1:50418 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:31] Prefill batch. #new-seq: 2, #new-token: 2436, #cached-token: 273, token usage: 0.91, #running-req: 82, #queue-req: 15\n",
      "[2025-08-13 20:00:33] Decode batch. #running-req: 84, #token: 228282, token usage: 0.93, cuda graph: True, gen throughput (token/s): 680.10, #queue-req: 16\n",
      "[2025-08-13 20:00:33] INFO:     127.0.0.1:48858 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:33] INFO:     127.0.0.1:55324 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:33] Prefill batch. #new-seq: 3, #new-token: 5750, #cached-token: 1001, token usage: 0.90, #running-req: 83, #queue-req: 13\n",
      "[2025-08-13 20:00:33] Prefill batch. #new-seq: 1, #new-token: 7037, #cached-token: 477, token usage: 0.92, #running-req: 85, #queue-req: 12\n",
      "[2025-08-13 20:00:35] INFO:     127.0.0.1:55356 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:35] INFO:     127.0.0.1:55348 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:36] INFO:     127.0.0.1:53980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:37] Decode batch. #running-req: 83, #token: 228215, token usage: 0.93, cuda graph: True, gen throughput (token/s): 812.61, #queue-req: 14\n",
      "[2025-08-13 20:00:38] INFO:     127.0.0.1:50816 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:40] Decode batch. #running-req: 82, #token: 230639, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1135.69, #queue-req: 18\n",
      "[2025-08-13 20:00:41] INFO:     127.0.0.1:48258 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:41] INFO:     127.0.0.1:60720 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:42] INFO:     127.0.0.1:41234 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:43] Decode batch. #running-req: 79, #token: 227710, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1120.92, #queue-req: 20\n",
      "[2025-08-13 20:00:43] INFO:     127.0.0.1:52840 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:44] Prefill batch. #new-seq: 1, #new-token: 7196, #cached-token: 474, token usage: 0.90, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 20:00:44] INFO:     127.0.0.1:56386 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:44] Prefill batch. #new-seq: 2, #new-token: 5648, #cached-token: 517, token usage: 0.92, #running-req: 78, #queue-req: 19\n",
      "[2025-08-13 20:00:47] Decode batch. #running-req: 80, #token: 233314, token usage: 0.95, cuda graph: True, gen throughput (token/s): 782.71, #queue-req: 20\n",
      "[2025-08-13 20:00:50] Decode batch. #running-req: 80, #token: 236514, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1091.45, #queue-req: 20\n",
      "[2025-08-13 20:00:52] INFO:     127.0.0.1:60498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:52] Decode batch. #running-req: 79, #token: 238474, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1086.27, #queue-req: 20\n",
      "[2025-08-13 20:00:54] INFO:     127.0.0.1:35328 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:54] INFO:     127.0.0.1:35054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:54] INFO:     127.0.0.1:35288 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:00:55] Decode batch. #running-req: 76, #token: 231322, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1088.85, #queue-req: 22\n",
      "[2025-08-13 20:00:58] Decode batch. #running-req: 76, #token: 234362, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1075.95, #queue-req: 24\n",
      "[2025-08-13 20:00:59] INFO:     127.0.0.1:49600 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:01] Decode batch. #running-req: 75, #token: 235086, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1064.87, #queue-req: 25\n",
      "[2025-08-13 20:01:02] INFO:     127.0.0.1:49608 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:02] INFO:     127.0.0.1:49624 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:03] INFO:     127.0.0.1:49650 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:03] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.93, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 20:01:03] Prefill batch. #new-seq: 1, #new-token: 877, #cached-token: 0, token usage: 0.96, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 20:01:04] INFO:     127.0.0.1:35278 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:04] Prefill batch. #new-seq: 2, #new-token: 1286, #cached-token: 547, token usage: 0.93, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:01:05] Decode batch. #running-req: 74, #token: 230672, token usage: 0.94, cuda graph: True, gen throughput (token/s): 758.79, #queue-req: 26\n",
      "[2025-08-13 20:01:05] INFO:     127.0.0.1:49692 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:05] Prefill batch. #new-seq: 1, #new-token: 5188, #cached-token: 463, token usage: 0.92, #running-req: 73, #queue-req: 26\n",
      "[2025-08-13 20:01:08] INFO:     127.0.0.1:35300 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:08] Prefill batch. #new-seq: 1, #new-token: 6950, #cached-token: 589, token usage: 0.92, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:01:09] Decode batch. #running-req: 74, #token: 232299, token usage: 0.94, cuda graph: True, gen throughput (token/s): 743.09, #queue-req: 26\n",
      "[2025-08-13 20:01:12] Decode batch. #running-req: 74, #token: 235259, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1039.21, #queue-req: 26\n",
      "[2025-08-13 20:01:15] Decode batch. #running-req: 74, #token: 238219, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1031.24, #queue-req: 26\n",
      "[2025-08-13 20:01:16] INFO:     127.0.0.1:59192 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:17] Decode batch. #running-req: 73, #token: 234959, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1027.71, #queue-req: 27\n",
      "[2025-08-13 20:01:20] Decode batch. #running-req: 73, #token: 237879, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1032.18, #queue-req: 27\n",
      "[2025-08-13 20:01:22] INFO:     127.0.0.1:50258 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:22] INFO:     127.0.0.1:47194 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:23] INFO:     127.0.0.1:57364 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:23] Prefill batch. #new-seq: 2, #new-token: 4843, #cached-token: 559, token usage: 0.94, #running-req: 70, #queue-req: 25\n",
      "[2025-08-13 20:01:24] Decode batch. #running-req: 72, #token: 237021, token usage: 0.96, cuda graph: True, gen throughput (token/s): 879.64, #queue-req: 25\n",
      "[2025-08-13 20:01:24] INFO:     127.0.0.1:50444 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:24] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 461, token usage: 0.94, #running-req: 71, #queue-req: 28\n",
      "[2025-08-13 20:01:25] INFO:     127.0.0.1:60282 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:25] Prefill batch. #new-seq: 1, #new-token: 4154, #cached-token: 553, token usage: 0.93, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:01:27] Decode batch. #running-req: 72, #token: 233997, token usage: 0.95, cuda graph: True, gen throughput (token/s): 896.60, #queue-req: 28\n",
      "[2025-08-13 20:01:29] INFO:     127.0.0.1:50454 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:29] INFO:     127.0.0.1:50460 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:29] Prefill batch. #new-seq: 1, #new-token: 2810, #cached-token: 465, token usage: 0.93, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:01:30] Decode batch. #running-req: 71, #token: 231637, token usage: 0.94, cuda graph: True, gen throughput (token/s): 935.00, #queue-req: 29\n",
      "[2025-08-13 20:01:31] INFO:     127.0.0.1:35314 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:31] Prefill batch. #new-seq: 1, #new-token: 5013, #cached-token: 507, token usage: 0.93, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:01:33] INFO:     127.0.0.1:53954 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:33] Prefill batch. #new-seq: 1, #new-token: 2303, #cached-token: 96, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:01:33] INFO:     127.0.0.1:39082 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:33] Decode batch. #running-req: 70, #token: 233046, token usage: 0.95, cuda graph: True, gen throughput (token/s): 815.30, #queue-req: 28\n",
      "[2025-08-13 20:01:33] INFO:     127.0.0.1:50470 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:34] Prefill batch. #new-seq: 2, #new-token: 4981, #cached-token: 584, token usage: 0.93, #running-req: 69, #queue-req: 26\n",
      "[2025-08-13 20:01:35] INFO:     127.0.0.1:59176 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:35] Prefill batch. #new-seq: 4, #new-token: 3633, #cached-token: 811, token usage: 0.92, #running-req: 70, #queue-req: 25\n",
      "[2025-08-13 20:01:36] INFO:     127.0.0.1:50486 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:37] Prefill batch. #new-seq: 1, #new-token: 7204, #cached-token: 477, token usage: 0.92, #running-req: 73, #queue-req: 26\n",
      "[2025-08-13 20:01:38] Decode batch. #running-req: 74, #token: 234699, token usage: 0.95, cuda graph: True, gen throughput (token/s): 675.99, #queue-req: 26\n",
      "[2025-08-13 20:01:39] INFO:     127.0.0.1:53968 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:39] Prefill batch. #new-seq: 1, #new-token: 908, #cached-token: 472, token usage: 0.95, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:01:41] Decode batch. #running-req: 74, #token: 237353, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1009.51, #queue-req: 26\n",
      "[2025-08-13 20:01:41] INFO:     127.0.0.1:50494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:41] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 93, token usage: 0.95, #running-req: 73, #queue-req: 26\n",
      "[2025-08-13 20:01:43] Decode batch. #running-req: 74, #token: 236081, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1025.05, #queue-req: 26\n",
      "[2025-08-13 20:01:44] INFO:     127.0.0.1:50236 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:01:46] INFO:     127.0.0.1:38998 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:46] Decode batch. #running-req: 72, #token: 236438, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1030.51, #queue-req: 27\n",
      "[2025-08-13 20:01:48] INFO:     127.0.0.1:43068 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:49] INFO:     127.0.0.1:39012 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:49] INFO:     127.0.0.1:41218 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:49] Decode batch. #running-req: 70, #token: 229579, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1017.03, #queue-req: 29\n",
      "[2025-08-13 20:01:49] Prefill batch. #new-seq: 2, #new-token: 7211, #cached-token: 932, token usage: 0.93, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:01:50] INFO:     127.0.0.1:48246 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:50] INFO:     127.0.0.1:57354 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:50] Prefill batch. #new-seq: 1, #new-token: 2650, #cached-token: 96, token usage: 0.95, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:01:52] INFO:     127.0.0.1:57358 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:52] INFO:     127.0.0.1:57374 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:52] Prefill batch. #new-seq: 3, #new-token: 7319, #cached-token: 1341, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:01:52] INFO:     127.0.0.1:41792 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:53] Prefill batch. #new-seq: 1, #new-token: 2330, #cached-token: 438, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:01:53] INFO:     127.0.0.1:35026 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:54] Decode batch. #running-req: 70, #token: 232576, token usage: 0.95, cuda graph: True, gen throughput (token/s): 612.38, #queue-req: 29\n",
      "[2025-08-13 20:01:54] INFO:     127.0.0.1:33062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:56] Decode batch. #running-req: 69, #token: 234243, token usage: 0.95, cuda graph: True, gen throughput (token/s): 977.84, #queue-req: 31\n",
      "[2025-08-13 20:01:57] INFO:     127.0.0.1:41188 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:57] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 93, token usage: 0.93, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:01:58] Prefill batch. #new-seq: 1, #new-token: 560, #cached-token: 0, token usage: 0.96, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:01:59] INFO:     127.0.0.1:35328 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:01:59] Prefill batch. #new-seq: 1, #new-token: 4376, #cached-token: 444, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:01:59] INFO:     127.0.0.1:35278 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:00] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 544, token usage: 0.92, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:02:00] Prefill batch. #new-seq: 1, #new-token: 880, #cached-token: 0, token usage: 0.95, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:02:01] Decode batch. #running-req: 69, #token: 236382, token usage: 0.96, cuda graph: True, gen throughput (token/s): 553.42, #queue-req: 31\n",
      "[2025-08-13 20:02:02] INFO:     127.0.0.1:41202 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:02] Prefill batch. #new-seq: 3, #new-token: 2245, #cached-token: 822, token usage: 0.93, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:02:04] INFO:     127.0.0.1:49600 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:04] INFO:     127.0.0.1:49608 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:04] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 434, token usage: 0.92, #running-req: 69, #queue-req: 26\n",
      "[2025-08-13 20:02:04] INFO:     127.0.0.1:49650 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:04] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 0, token usage: 0.95, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:02:05] INFO:     127.0.0.1:50444 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:05] Prefill batch. #new-seq: 2, #new-token: 8097, #cached-token: 310, token usage: 0.93, #running-req: 70, #queue-req: 24\n",
      "[2025-08-13 20:02:05] Decode batch. #running-req: 70, #token: 236500, token usage: 0.96, cuda graph: True, gen throughput (token/s): 765.89, #queue-req: 24\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:02:07] INFO:     127.0.0.1:33010 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:08] INFO:     127.0.0.1:42318 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:09] Decode batch. #running-req: 70, #token: 237687, token usage: 0.97, cuda graph: True, gen throughput (token/s): 817.77, #queue-req: 28\n",
      "[2025-08-13 20:02:09] INFO:     127.0.0.1:47302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:09] Prefill batch. #new-seq: 1, #new-token: 2349, #cached-token: 451, token usage: 0.96, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:02:10] INFO:     127.0.0.1:47264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:11] INFO:     127.0.0.1:49692 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:11] Prefill batch. #new-seq: 1, #new-token: 5022, #cached-token: 462, token usage: 0.95, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:02:12] Decode batch. #running-req: 69, #token: 240003, token usage: 0.98, cuda graph: True, gen throughput (token/s): 788.53, #queue-req: 31\n",
      "[2025-08-13 20:02:14] INFO:     127.0.0.1:41244 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:14] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 212, token usage: 0.96, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:02:15] INFO:     127.0.0.1:56382 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:15] Prefill batch. #new-seq: 1, #new-token: 2265, #cached-token: 145, token usage: 0.95, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:02:15] Decode batch. #running-req: 69, #token: 236539, token usage: 0.96, cuda graph: True, gen throughput (token/s): 897.69, #queue-req: 31\n",
      "[2025-08-13 20:02:16] INFO:     127.0.0.1:50454 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:16] INFO:     127.0.0.1:50460 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:16] Prefill batch. #new-seq: 3, #new-token: 6753, #cached-token: 682, token usage: 0.93, #running-req: 67, #queue-req: 28\n",
      "[2025-08-13 20:02:17] INFO:     127.0.0.1:56394 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:17] Prefill batch. #new-seq: 2, #new-token: 4481, #cached-token: 527, token usage: 0.95, #running-req: 69, #queue-req: 26\n",
      "[2025-08-13 20:02:19] Decode batch. #running-req: 71, #token: 238992, token usage: 0.97, cuda graph: True, gen throughput (token/s): 723.76, #queue-req: 29\n",
      "[2025-08-13 20:02:19] INFO:     127.0.0.1:60294 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:19] Prefill batch. #new-seq: 1, #new-token: 552, #cached-token: 132, token usage: 0.96, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:02:21] INFO:     127.0.0.1:50486 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:21] Prefill batch. #new-seq: 1, #new-token: 2231, #cached-token: 454, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:02:21] INFO:     127.0.0.1:60304 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:21] Prefill batch. #new-seq: 1, #new-token: 2730, #cached-token: 626, token usage: 0.95, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:02:22] INFO:     127.0.0.1:50470 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:22] Prefill batch. #new-seq: 1, #new-token: 4384, #cached-token: 553, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:02:23] Decode batch. #running-req: 71, #token: 236955, token usage: 0.96, cuda graph: True, gen throughput (token/s): 758.07, #queue-req: 28\n",
      "[2025-08-13 20:02:24] INFO:     127.0.0.1:52784 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:25] INFO:     127.0.0.1:47198 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:25] Prefill batch. #new-seq: 2, #new-token: 2336, #cached-token: 606, token usage: 0.94, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:02:25] INFO:     127.0.0.1:50814 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:25] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 450, token usage: 0.95, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:02:26] Decode batch. #running-req: 71, #token: 239241, token usage: 0.97, cuda graph: True, gen throughput (token/s): 816.52, #queue-req: 29\n",
      "[2025-08-13 20:02:28] INFO:     127.0.0.1:50494 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:29] Decode batch. #running-req: 70, #token: 237562, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1003.26, #queue-req: 30\n",
      "[2025-08-13 20:02:31] INFO:     127.0.0.1:50830 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:31] INFO:     127.0.0.1:43068 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:31] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 446, token usage: 0.96, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:02:32] Decode batch. #running-req: 69, #token: 240422, token usage: 0.98, cuda graph: True, gen throughput (token/s): 860.98, #queue-req: 31\n",
      "[2025-08-13 20:02:35] Decode batch. #running-req: 69, #token: 240843, token usage: 0.98, cuda graph: True, gen throughput (token/s): 962.90, #queue-req: 31\n",
      "[2025-08-13 20:02:35] INFO:     127.0.0.1:57354 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:35] INFO:     127.0.0.1:57358 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:36] INFO:     127.0.0.1:39056 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:36] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 454, token usage: 0.95, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:02:38] INFO:     127.0.0.1:50818 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:38] Prefill batch. #new-seq: 1, #new-token: 2627, #cached-token: 712, token usage: 0.95, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:02:38] Decode batch. #running-req: 67, #token: 235838, token usage: 0.96, cuda graph: True, gen throughput (token/s): 833.90, #queue-req: 33\n",
      "[2025-08-13 20:02:41] INFO:     127.0.0.1:57374 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:41] Prefill batch. #new-seq: 1, #new-token: 1103, #cached-token: 446, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:02:41] Decode batch. #running-req: 66, #token: 235050, token usage: 0.96, cuda graph: True, gen throughput (token/s): 932.92, #queue-req: 32\n",
      "[2025-08-13 20:02:42] INFO:     127.0.0.1:48274 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:42] Prefill batch. #new-seq: 1, #new-token: 6962, #cached-token: 709, token usage: 0.94, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:02:43] INFO:     127.0.0.1:35040 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:44] INFO:     127.0.0.1:35048 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:44] Prefill batch. #new-seq: 1, #new-token: 5144, #cached-token: 463, token usage: 0.95, #running-req: 65, #queue-req: 34\n",
      "[2025-08-13 20:02:45] Decode batch. #running-req: 66, #token: 238730, token usage: 0.97, cuda graph: True, gen throughput (token/s): 653.67, #queue-req: 34\n",
      "[2025-08-13 20:02:46] INFO:     127.0.0.1:41782 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:46] Prefill batch. #new-seq: 1, #new-token: 2288, #cached-token: 126, token usage: 0.96, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:02:46] INFO:     127.0.0.1:44978 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:47] INFO:     127.0.0.1:55182 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:47] INFO:     127.0.0.1:55194 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:47] Prefill batch. #new-seq: 1, #new-token: 7369, #cached-token: 393, token usage: 0.92, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 20:02:48] INFO:     127.0.0.1:39062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:48] Prefill batch. #new-seq: 1, #new-token: 4503, #cached-token: 119, token usage: 0.94, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:02:49] INFO:     127.0.0.1:55206 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:49] Prefill batch. #new-seq: 1, #new-token: 4821, #cached-token: 480, token usage: 0.92, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:02:50] Decode batch. #running-req: 64, #token: 232237, token usage: 0.94, cuda graph: True, gen throughput (token/s): 574.07, #queue-req: 36\n",
      "[2025-08-13 20:02:50] INFO:     127.0.0.1:55216 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:50] Prefill batch. #new-seq: 2, #new-token: 7229, #cached-token: 862, token usage: 0.93, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:02:51] INFO:     127.0.0.1:55230 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:51] Prefill batch. #new-seq: 2, #new-token: 1013, #cached-token: 201, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:02:52] INFO:     127.0.0.1:39396 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:52] Prefill batch. #new-seq: 2, #new-token: 2477, #cached-token: 561, token usage: 0.94, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:02:52] INFO:     127.0.0.1:41188 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:52] Prefill batch. #new-seq: 2, #new-token: 6928, #cached-token: 773, token usage: 0.92, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:02:52] INFO:     127.0.0.1:57766 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:53] Prefill batch. #new-seq: 1, #new-token: 4365, #cached-token: 455, token usage: 0.95, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:02:55] Decode batch. #running-req: 68, #token: 238529, token usage: 0.97, cuda graph: True, gen throughput (token/s): 554.62, #queue-req: 32\n",
      "[2025-08-13 20:02:56] INFO:     127.0.0.1:32980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:56] Prefill batch. #new-seq: 1, #new-token: 3265, #cached-token: 160, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:02:57] INFO:     127.0.0.1:41732 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:57] INFO:     127.0.0.1:41746 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:57] Prefill batch. #new-seq: 2, #new-token: 2334, #cached-token: 239, token usage: 0.93, #running-req: 66, #queue-req: 29\n",
      "[2025-08-13 20:02:57] INFO:     127.0.0.1:41750 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:57] INFO:     127.0.0.1:41752 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:57] INFO:     127.0.0.1:56394 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:57] Prefill batch. #new-seq: 3, #new-token: 7412, #cached-token: 1255, token usage: 0.91, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:02:58] INFO:     127.0.0.1:41766 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:02:58] Prefill batch. #new-seq: 2, #new-token: 5573, #cached-token: 699, token usage: 0.93, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:02:59] Decode batch. #running-req: 69, #token: 233814, token usage: 0.95, cuda graph: True, gen throughput (token/s): 606.46, #queue-req: 31\n",
      "[2025-08-13 20:03:01] INFO:     127.0.0.1:41202 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:01] Prefill batch. #new-seq: 4, #new-token: 6705, #cached-token: 1197, token usage: 0.91, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:03:01] INFO:     127.0.0.1:42338 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:02] Prefill batch. #new-seq: 1, #new-token: 2220, #cached-token: 412, token usage: 0.94, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:03:02] INFO:     127.0.0.1:41798 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:02] Prefill batch. #new-seq: 3, #new-token: 7410, #cached-token: 892, token usage: 0.91, #running-req: 71, #queue-req: 23\n",
      "[2025-08-13 20:03:03] Decode batch. #running-req: 74, #token: 230943, token usage: 0.94, cuda graph: True, gen throughput (token/s): 650.73, #queue-req: 26\n",
      "[2025-08-13 20:03:05] INFO:     127.0.0.1:59178 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:05] INFO:     127.0.0.1:59184 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:05] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1361, token usage: 0.91, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:03:05] INFO:     127.0.0.1:45074 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:05] Prefill batch. #new-seq: 1, #new-token: 2714, #cached-token: 0, token usage: 0.94, #running-req: 74, #queue-req: 25\n",
      "[2025-08-13 20:03:06] INFO:     127.0.0.1:59188 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:06] INFO:     127.0.0.1:41244 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:06] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1186, token usage: 0.92, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:03:06] INFO:     127.0.0.1:56382 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:06] Prefill batch. #new-seq: 2, #new-token: 5215, #cached-token: 452, token usage: 0.94, #running-req: 75, #queue-req: 23\n",
      "[2025-08-13 20:03:08] INFO:     127.0.0.1:35040 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:08] Decode batch. #running-req: 74, #token: 233045, token usage: 0.95, cuda graph: True, gen throughput (token/s): 600.64, #queue-req: 25\n",
      "[2025-08-13 20:03:09] INFO:     127.0.0.1:32996 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:10] INFO:     127.0.0.1:55194 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:10] INFO:     127.0.0.1:44966 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:10] Prefill batch. #new-seq: 1, #new-token: 6429, #cached-token: 201, token usage: 0.93, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:03:12] INFO:     127.0.0.1:60304 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:12] Prefill batch. #new-seq: 1, #new-token: 1991, #cached-token: 446, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:03:12] Decode batch. #running-req: 72, #token: 234551, token usage: 0.95, cuda graph: True, gen throughput (token/s): 804.29, #queue-req: 27\n",
      "[2025-08-13 20:03:13] INFO:     127.0.0.1:47280 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:13] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 461, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:03:14] INFO:     127.0.0.1:59198 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:14] INFO:     127.0.0.1:35048 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:14] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.90, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 20:03:14] INFO:     127.0.0.1:59208 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:14] Prefill batch. #new-seq: 2, #new-token: 5336, #cached-token: 446, token usage: 0.94, #running-req: 70, #queue-req: 25\n",
      "[2025-08-13 20:03:16] INFO:     127.0.0.1:50814 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:16] INFO:     127.0.0.1:55206 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:16] Decode batch. #running-req: 70, #token: 224918, token usage: 0.91, cuda graph: True, gen throughput (token/s): 689.05, #queue-req: 29\n",
      "[2025-08-13 20:03:16] Prefill batch. #new-seq: 2, #new-token: 6496, #cached-token: 614, token usage: 0.91, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:03:17] INFO:     127.0.0.1:48142 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:17] INFO:     127.0.0.1:55882 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:17] Prefill batch. #new-seq: 2, #new-token: 7429, #cached-token: 634, token usage: 0.91, #running-req: 69, #queue-req: 25\n",
      "[2025-08-13 20:03:19] INFO:     127.0.0.1:39068 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:19] INFO:     127.0.0.1:50818 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:19] INFO:     127.0.0.1:48274 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:20] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 937, token usage: 0.89, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:03:20] Prefill batch. #new-seq: 4, #new-token: 7308, #cached-token: 1167, token usage: 0.93, #running-req: 69, #queue-req: 24\n",
      "[2025-08-13 20:03:21] INFO:     127.0.0.1:55182 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:21] Prefill batch. #new-seq: 1, #new-token: 1017, #cached-token: 142, token usage: 0.94, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 20:03:22] Decode batch. #running-req: 73, #token: 232530, token usage: 0.95, cuda graph: True, gen throughput (token/s): 514.69, #queue-req: 23\n",
      "[2025-08-13 20:03:22] INFO:     127.0.0.1:41732 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:22] INFO:     127.0.0.1:41746 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:22] Prefill batch. #new-seq: 1, #new-token: 4540, #cached-token: 712, token usage: 0.91, #running-req: 71, #queue-req: 22\n",
      "[2025-08-13 20:03:23] INFO:     127.0.0.1:53996 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:25] INFO:     127.0.0.1:50242 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:25] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 544, token usage: 0.91, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:03:25] Prefill batch. #new-seq: 1, #new-token: 2964, #cached-token: 0, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:03:26] Decode batch. #running-req: 71, #token: 236319, token usage: 0.96, cuda graph: True, gen throughput (token/s): 642.99, #queue-req: 29\n",
      "[2025-08-13 20:03:26] INFO:     127.0.0.1:39006 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:27] INFO:     127.0.0.1:55230 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:27] INFO:     127.0.0.1:41798 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:27] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 529, token usage: 0.88, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:03:27] INFO:     127.0.0.1:39028 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:27] INFO:     127.0.0.1:39040 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:27] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 514, token usage: 0.89, #running-req: 69, #queue-req: 26\n",
      "[2025-08-13 20:03:28] Prefill batch. #new-seq: 3, #new-token: 5275, #cached-token: 335, token usage: 0.92, #running-req: 71, #queue-req: 24\n",
      "[2025-08-13 20:03:29] Prefill batch. #new-seq: 1, #new-token: 2165, #cached-token: 151, token usage: 0.95, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 20:03:31] INFO:     127.0.0.1:55216 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:31] Prefill batch. #new-seq: 1, #new-token: 2156, #cached-token: 476, token usage: 0.94, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:03:31] Decode batch. #running-req: 73, #token: 234361, token usage: 0.95, cuda graph: True, gen throughput (token/s): 543.04, #queue-req: 26\n",
      "[2025-08-13 20:03:32] INFO:     127.0.0.1:50240 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:32] Prefill batch. #new-seq: 2, #new-token: 1884, #cached-token: 278, token usage: 0.93, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:03:32] INFO:     127.0.0.1:39396 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:32] Prefill batch. #new-seq: 2, #new-token: 739, #cached-token: 900, token usage: 0.93, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:03:33] INFO:     127.0.0.1:33036 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:33] Prefill batch. #new-seq: 1, #new-token: 2704, #cached-token: 412, token usage: 0.93, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 20:03:33] INFO:     127.0.0.1:52778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:33] Prefill batch. #new-seq: 1, #new-token: 2963, #cached-token: 125, token usage: 0.94, #running-req: 74, #queue-req: 22\n",
      "[2025-08-13 20:03:34] INFO:     127.0.0.1:55918 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:35] INFO:     127.0.0.1:41750 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:35] INFO:     127.0.0.1:41752 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:35] Prefill batch. #new-seq: 1, #new-token: 4810, #cached-token: 589, token usage: 0.93, #running-req: 72, #queue-req: 21\n",
      "[2025-08-13 20:03:35] Decode batch. #running-req: 73, #token: 234250, token usage: 0.95, cuda graph: True, gen throughput (token/s): 735.33, #queue-req: 22\n",
      "[2025-08-13 20:03:36] INFO:     127.0.0.1:41766 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:36] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.94, #running-req: 72, #queue-req: 21\n",
      "[2025-08-13 20:03:37] INFO:     127.0.0.1:59188 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:37] Prefill batch. #new-seq: 1, #new-token: 391, #cached-token: 438, token usage: 0.94, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 20:03:38] INFO:     127.0.0.1:56888 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:39] Decode batch. #running-req: 72, #token: 232128, token usage: 0.94, cuda graph: True, gen throughput (token/s): 935.04, #queue-req: 26\n",
      "[2025-08-13 20:03:40] INFO:     127.0.0.1:59184 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:40] INFO:     127.0.0.1:59178 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:40] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 528, token usage: 0.91, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 20:03:40] Prefill batch. #new-seq: 1, #new-token: 1144, #cached-token: 0, token usage: 0.94, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:03:42] INFO:     127.0.0.1:48142 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:03:42] Decode batch. #running-req: 71, #token: 227882, token usage: 0.93, cuda graph: True, gen throughput (token/s): 748.43, #queue-req: 28\n",
      "[2025-08-13 20:03:43] INFO:     127.0.0.1:50268 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:43] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 465, token usage: 0.89, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:03:44] Prefill batch. #new-seq: 2, #new-token: 1539, #cached-token: 93, token usage: 0.93, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:03:45] INFO:     127.0.0.1:50274 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:45] Prefill batch. #new-seq: 2, #new-token: 4973, #cached-token: 1119, token usage: 0.91, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:03:46] INFO:     127.0.0.1:59198 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:46] Prefill batch. #new-seq: 2, #new-token: 4311, #cached-token: 608, token usage: 0.92, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:03:47] INFO:     127.0.0.1:33030 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:47] Prefill batch. #new-seq: 1, #new-token: 2161, #cached-token: 472, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:03:47] Decode batch. #running-req: 74, #token: 230918, token usage: 0.94, cuda graph: True, gen throughput (token/s): 592.56, #queue-req: 25\n",
      "[2025-08-13 20:03:48] INFO:     127.0.0.1:59208 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:48] Prefill batch. #new-seq: 2, #new-token: 4714, #cached-token: 886, token usage: 0.92, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:03:48] INFO:     127.0.0.1:56850 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:48] Prefill batch. #new-seq: 1, #new-token: 1952, #cached-token: 168, token usage: 0.93, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 20:03:51] Decode batch. #running-req: 75, #token: 233166, token usage: 0.95, cuda graph: True, gen throughput (token/s): 865.20, #queue-req: 25\n",
      "[2025-08-13 20:03:54] Decode batch. #running-req: 75, #token: 236166, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1031.76, #queue-req: 25\n",
      "[2025-08-13 20:03:54] INFO:     127.0.0.1:58738 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:55] INFO:     127.0.0.1:53996 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:56] INFO:     127.0.0.1:47668 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:57] Decode batch. #running-req: 72, #token: 235618, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1002.61, #queue-req: 27\n",
      "[2025-08-13 20:03:59] INFO:     127.0.0.1:33052 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:03:59] Prefill batch. #new-seq: 1, #new-token: 4405, #cached-token: 412, token usage: 0.93, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:04:00] Decode batch. #running-req: 72, #token: 234178, token usage: 0.95, cuda graph: True, gen throughput (token/s): 844.37, #queue-req: 27\n",
      "[2025-08-13 20:04:01] INFO:     127.0.0.1:39006 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:01] Prefill batch. #new-seq: 1, #new-token: 4240, #cached-token: 412, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:04:03] Decode batch. #running-req: 72, #token: 236877, token usage: 0.96, cuda graph: True, gen throughput (token/s): 855.19, #queue-req: 28\n",
      "[2025-08-13 20:04:04] INFO:     127.0.0.1:57776 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:04:06] INFO:     127.0.0.1:47208 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:06] INFO:     127.0.0.1:47212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:06] Prefill batch. #new-seq: 1, #new-token: 2183, #cached-token: 77, token usage: 0.95, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:04:06] Decode batch. #running-req: 70, #token: 234953, token usage: 0.96, cuda graph: True, gen throughput (token/s): 915.48, #queue-req: 30\n",
      "[2025-08-13 20:04:07] INFO:     127.0.0.1:47224 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:09] INFO:     127.0.0.1:44998 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:09] INFO:     127.0.0.1:39028 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:09] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.91, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:04:09] Prefill batch. #new-seq: 1, #new-token: 1176, #cached-token: 0, token usage: 0.94, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:04:10] INFO:     127.0.0.1:47236 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:10] Prefill batch. #new-seq: 2, #new-token: 4260, #cached-token: 647, token usage: 0.91, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:04:11] Decode batch. #running-req: 69, #token: 228889, token usage: 0.93, cuda graph: True, gen throughput (token/s): 657.70, #queue-req: 31\n",
      "[2025-08-13 20:04:13] Decode batch. #running-req: 69, #token: 231649, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1003.73, #queue-req: 31\n",
      "[2025-08-13 20:04:14] INFO:     127.0.0.1:60338 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:14] Prefill batch. #new-seq: 1, #new-token: 5180, #cached-token: 463, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:04:15] INFO:     127.0.0.1:32952 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:15] INFO:     127.0.0.1:39040 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:15] Prefill batch. #new-seq: 1, #new-token: 2385, #cached-token: 412, token usage: 0.95, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:04:16] INFO:     127.0.0.1:32940 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:16] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 144, token usage: 0.95, #running-req: 67, #queue-req: 28\n",
      "[2025-08-13 20:04:17] Decode batch. #running-req: 68, #token: 233910, token usage: 0.95, cuda graph: True, gen throughput (token/s): 777.70, #queue-req: 28\n",
      "[2025-08-13 20:04:17] INFO:     127.0.0.1:56846 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:20] Decode batch. #running-req: 67, #token: 235748, token usage: 0.96, cuda graph: True, gen throughput (token/s): 962.75, #queue-req: 33\n",
      "[2025-08-13 20:04:20] INFO:     127.0.0.1:60314 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:20] Prefill batch. #new-seq: 1, #new-token: 5662, #cached-token: 96, token usage: 0.93, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:04:22] INFO:     127.0.0.1:58798 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:22] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 460, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:04:23] Decode batch. #running-req: 67, #token: 234692, token usage: 0.95, cuda graph: True, gen throughput (token/s): 790.65, #queue-req: 33\n",
      "[2025-08-13 20:04:24] INFO:     127.0.0.1:50240 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:24] Prefill batch. #new-seq: 1, #new-token: 2580, #cached-token: 409, token usage: 0.94, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:04:26] INFO:     127.0.0.1:47252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:26] Prefill batch. #new-seq: 1, #new-token: 2240, #cached-token: 77, token usage: 0.94, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:04:26] Decode batch. #running-req: 67, #token: 234785, token usage: 0.95, cuda graph: True, gen throughput (token/s): 821.65, #queue-req: 33\n",
      "[2025-08-13 20:04:28] INFO:     127.0.0.1:47268 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:28] Prefill batch. #new-seq: 2, #new-token: 2556, #cached-token: 555, token usage: 0.94, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:04:29] Decode batch. #running-req: 68, #token: 233960, token usage: 0.95, cuda graph: True, gen throughput (token/s): 888.35, #queue-req: 32\n",
      "[2025-08-13 20:04:32] Decode batch. #running-req: 68, #token: 236680, token usage: 0.96, cuda graph: True, gen throughput (token/s): 964.94, #queue-req: 32\n",
      "[2025-08-13 20:04:33] INFO:     127.0.0.1:47296 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:33] Prefill batch. #new-seq: 2, #new-token: 2341, #cached-token: 272, token usage: 0.94, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:04:35] Decode batch. #running-req: 69, #token: 234705, token usage: 0.95, cuda graph: True, gen throughput (token/s): 905.22, #queue-req: 31\n",
      "[2025-08-13 20:04:36] INFO:     127.0.0.1:55906 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:37] INFO:     127.0.0.1:33024 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:38] INFO:     127.0.0.1:56894 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:38] Prefill batch. #new-seq: 1, #new-token: 7217, #cached-token: 463, token usage: 0.93, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:04:38] Decode batch. #running-req: 66, #token: 235728, token usage: 0.96, cuda graph: True, gen throughput (token/s): 932.92, #queue-req: 32\n",
      "[2025-08-13 20:04:39] INFO:     127.0.0.1:47638 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:39] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 392, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:04:42] Decode batch. #running-req: 67, #token: 236669, token usage: 0.96, cuda graph: True, gen throughput (token/s): 728.74, #queue-req: 33\n",
      "[2025-08-13 20:04:43] INFO:     127.0.0.1:46506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:45] Decode batch. #running-req: 66, #token: 238928, token usage: 0.97, cuda graph: True, gen throughput (token/s): 899.71, #queue-req: 34\n",
      "[2025-08-13 20:04:48] Decode batch. #running-req: 66, #token: 241568, token usage: 0.98, cuda graph: True, gen throughput (token/s): 896.89, #queue-req: 34\n",
      "[2025-08-13 20:04:48] INFO:     127.0.0.1:44622 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:51] Decode batch. #running-req: 65, #token: 238546, token usage: 0.97, cuda graph: True, gen throughput (token/s): 892.30, #queue-req: 35\n",
      "[2025-08-13 20:04:51] INFO:     127.0.0.1:42334 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:51] INFO:     127.0.0.1:46518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:53] INFO:     127.0.0.1:56834 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:53] Decode batch. #running-req: 62, #token: 235896, token usage: 0.96, cuda graph: True, gen throughput (token/s): 929.93, #queue-req: 38\n",
      "[2025-08-13 20:04:56] INFO:     127.0.0.1:32954 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:56] Decode batch. #running-req: 61, #token: 237315, token usage: 0.97, cuda graph: True, gen throughput (token/s): 901.20, #queue-req: 38\n",
      "[2025-08-13 20:04:58] INFO:     127.0.0.1:48986 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:04:58] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 474, token usage: 0.93, #running-req: 60, #queue-req: 39\n",
      "[2025-08-13 20:04:58] Prefill batch. #new-seq: 1, #new-token: 1024, #cached-token: 0, token usage: 0.96, #running-req: 60, #queue-req: 39\n",
      "[2025-08-13 20:05:00] Decode batch. #running-req: 61, #token: 237828, token usage: 0.97, cuda graph: True, gen throughput (token/s): 654.79, #queue-req: 39\n",
      "[2025-08-13 20:05:00] INFO:     127.0.0.1:50268 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:00] Prefill batch. #new-seq: 1, #new-token: 5227, #cached-token: 463, token usage: 0.93, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:05:00] INFO:     127.0.0.1:52790 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:00] Prefill batch. #new-seq: 1, #new-token: 6780, #cached-token: 208, token usage: 0.94, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:05:04] INFO:     127.0.0.1:52792 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:04] INFO:     127.0.0.1:52802 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:04] Prefill batch. #new-seq: 1, #new-token: 2354, #cached-token: 448, token usage: 0.95, #running-req: 59, #queue-req: 40\n",
      "[2025-08-13 20:05:04] Decode batch. #running-req: 59, #token: 236640, token usage: 0.96, cuda graph: True, gen throughput (token/s): 625.44, #queue-req: 40\n",
      "[2025-08-13 20:05:07] Decode batch. #running-req: 60, #token: 239100, token usage: 0.97, cuda graph: True, gen throughput (token/s): 829.67, #queue-req: 40\n",
      "[2025-08-13 20:05:07] INFO:     127.0.0.1:45062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:08] INFO:     127.0.0.1:50274 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:08] Prefill batch. #new-seq: 1, #new-token: 5058, #cached-token: 509, token usage: 0.94, #running-req: 58, #queue-req: 40\n",
      "[2025-08-13 20:05:10] Decode batch. #running-req: 59, #token: 236885, token usage: 0.96, cuda graph: True, gen throughput (token/s): 750.80, #queue-req: 41\n",
      "[2025-08-13 20:05:11] INFO:     127.0.0.1:32932 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:11] Prefill batch. #new-seq: 2, #new-token: 2556, #cached-token: 585, token usage: 0.95, #running-req: 58, #queue-req: 39\n",
      "[2025-08-13 20:05:12] INFO:     127.0.0.1:45082 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:12] Prefill batch. #new-seq: 2, #new-token: 704, #cached-token: 173, token usage: 0.95, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:05:13] Decode batch. #running-req: 61, #token: 234859, token usage: 0.96, cuda graph: True, gen throughput (token/s): 790.38, #queue-req: 39\n",
      "[2025-08-13 20:05:13] INFO:     127.0.0.1:46508 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:13] Prefill batch. #new-seq: 1, #new-token: 7377, #cached-token: 464, token usage: 0.93, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:05:14] INFO:     127.0.0.1:45098 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:14] INFO:     127.0.0.1:57760 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:14] Prefill batch. #new-seq: 3, #new-token: 5476, #cached-token: 996, token usage: 0.94, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:05:15] INFO:     127.0.0.1:58744 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:15] Prefill batch. #new-seq: 1, #new-token: 2252, #cached-token: 434, token usage: 0.95, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:05:15] INFO:     127.0.0.1:47212 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:15] Prefill batch. #new-seq: 1, #new-token: 7121, #cached-token: 550, token usage: 0.95, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 20:05:17] INFO:     127.0.0.1:60358 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:18] Decode batch. #running-req: 61, #token: 239352, token usage: 0.97, cuda graph: True, gen throughput (token/s): 513.61, #queue-req: 38\n",
      "[2025-08-13 20:05:18] INFO:     127.0.0.1:56508 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:18] INFO:     127.0.0.1:46312 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:18] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 460, token usage: 0.96, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:05:19] INFO:     127.0.0.1:56484 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:19] Prefill batch. #new-seq: 1, #new-token: 2354, #cached-token: 448, token usage: 0.96, #running-req: 59, #queue-req: 37\n",
      ".[2025-08-13 20:05:21] Decode batch. #running-req: 60, #token: 239146, token usage: 0.97, cuda graph: True, gen throughput (token/s): 809.24, #queue-req: 38\n",
      "[2025-08-13 20:05:23] INFO:     127.0.0.1:44986 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:23] Decode batch. #running-req: 59, #token: 239313, token usage: 0.97, cuda graph: True, gen throughput (token/s): 875.46, #queue-req: 41\n",
      "[2025-08-13 20:05:25] INFO:     127.0.0.1:47208 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:25] INFO:     127.0.0.1:46490 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:25] INFO:     127.0.0.1:47224 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:25] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 462, token usage: 0.93, #running-req: 56, #queue-req: 40\n",
      "[2025-08-13 20:05:25] Prefill batch. #new-seq: 2, #new-token: 1255, #cached-token: 437, token usage: 0.96, #running-req: 56, #queue-req: 39\n",
      "[2025-08-13 20:05:27] Decode batch. #running-req: 58, #token: 238365, token usage: 0.97, cuda graph: True, gen throughput (token/s): 629.68, #queue-req: 39\n",
      "[2025-08-13 20:05:27] INFO:     127.0.0.1:47236 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:27] Prefill batch. #new-seq: 4, #new-token: 3175, #cached-token: 864, token usage: 0.93, #running-req: 57, #queue-req: 35\n",
      "[2025-08-13 20:05:28] INFO:     127.0.0.1:46986 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:28] Prefill batch. #new-seq: 2, #new-token: 4050, #cached-token: 279, token usage: 0.93, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:05:30] INFO:     127.0.0.1:46980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:30] Decode batch. #running-req: 61, #token: 233212, token usage: 0.95, cuda graph: True, gen throughput (token/s): 741.67, #queue-req: 38\n",
      "[2025-08-13 20:05:31] INFO:     127.0.0.1:58706 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:31] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1455, token usage: 0.91, #running-req: 60, #queue-req: 36\n",
      "[2025-08-13 20:05:31] INFO:     127.0.0.1:56872 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:32] Prefill batch. #new-seq: 1, #new-token: 5178, #cached-token: 0, token usage: 0.94, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:05:34] Decode batch. #running-req: 62, #token: 238178, token usage: 0.97, cuda graph: True, gen throughput (token/s): 627.44, #queue-req: 38\n",
      "[2025-08-13 20:05:35] INFO:     127.0.0.1:44988 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:36] INFO:     127.0.0.1:47268 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:36] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 558, token usage: 0.93, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:05:36] Prefill batch. #new-seq: 1, #new-token: 1364, #cached-token: 0, token usage: 0.97, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:05:37] INFO:     127.0.0.1:44992 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:38] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 93, token usage: 0.95, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 20:05:38] Decode batch. #running-req: 62, #token: 235309, token usage: 0.96, cuda graph: True, gen throughput (token/s): 675.55, #queue-req: 38\n",
      "[2025-08-13 20:05:38] INFO:     127.0.0.1:47296 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:38] Prefill batch. #new-seq: 3, #new-token: 3841, #cached-token: 408, token usage: 0.93, #running-req: 61, #queue-req: 35\n",
      "[2025-08-13 20:05:41] Decode batch. #running-req: 64, #token: 234611, token usage: 0.95, cuda graph: True, gen throughput (token/s): 852.61, #queue-req: 36\n",
      "[2025-08-13 20:05:42] INFO:     127.0.0.1:47252 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:42] Prefill batch. #new-seq: 2, #new-token: 4598, #cached-token: 889, token usage: 0.95, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:05:43] INFO:     127.0.0.1:47654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:43] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 438, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      ".[2025-08-13 20:05:43] INFO:     127.0.0.1:46284 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:43] Prefill batch. #new-seq: 2, #new-token: 4769, #cached-token: 605, token usage: 0.93, #running-req: 64, #queue-req: 32\n",
      "[2025-08-13 20:05:44] Decode batch. #running-req: 66, #token: 233591, token usage: 0.95, cuda graph: True, gen throughput (token/s): 710.55, #queue-req: 34\n",
      "[2025-08-13 20:05:45] INFO:     127.0.0.1:46288 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:46] INFO:     127.0.0.1:50444 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:46] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 462, token usage: 0.91, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:05:46] Prefill batch. #new-seq: 2, #new-token: 5879, #cached-token: 480, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:05:48] INFO:     127.0.0.1:46296 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:48] INFO:     127.0.0.1:48986 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:48] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 625, token usage: 0.89, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:05:48] INFO:     127.0.0.1:33024 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:48] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 595, token usage: 0.92, #running-req: 65, #queue-req: 31\n",
      "[2025-08-13 20:05:49] Prefill batch. #new-seq: 1, #new-token: 1138, #cached-token: 0, token usage: 0.96, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:05:50] INFO:     127.0.0.1:52802 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:05:50] Prefill batch. #new-seq: 1, #new-token: 3437, #cached-token: 393, token usage: 0.95, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:05:51] INFO:     127.0.0.1:58752 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:51] Decode batch. #running-req: 67, #token: 232811, token usage: 0.95, cuda graph: True, gen throughput (token/s): 425.84, #queue-req: 33\n",
      "[2025-08-13 20:05:51] Prefill batch. #new-seq: 1, #new-token: 2263, #cached-token: 143, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:05:51] INFO:     127.0.0.1:46310 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:51] Prefill batch. #new-seq: 2, #new-token: 5330, #cached-token: 291, token usage: 0.93, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:05:52] INFO:     127.0.0.1:55890 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:52] Prefill batch. #new-seq: 2, #new-token: 6152, #cached-token: 273, token usage: 0.94, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:05:53] INFO:     127.0.0.1:55928 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:53] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 450, token usage: 0.95, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:05:53] INFO:     127.0.0.1:45098 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:54] Prefill batch. #new-seq: 2, #new-token: 1439, #cached-token: 242, token usage: 0.95, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:05:55] Decode batch. #running-req: 70, #token: 235207, token usage: 0.96, cuda graph: True, gen throughput (token/s): 635.92, #queue-req: 30\n",
      "[2025-08-13 20:05:56] INFO:     127.0.0.1:42334 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:56] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 469, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:05:57] INFO:     127.0.0.1:56838 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:57] INFO:     127.0.0.1:56834 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:57] Prefill batch. #new-seq: 3, #new-token: 4697, #cached-token: 1262, token usage: 0.92, #running-req: 69, #queue-req: 26\n",
      "[2025-08-13 20:05:57] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 412, token usage: 0.94, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:05:58] INFO:     127.0.0.1:56856 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:05:58] Prefill batch. #new-seq: 1, #new-token: 2346, #cached-token: 455, token usage: 0.93, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:05:59] Decode batch. #running-req: 72, #token: 231316, token usage: 0.94, cuda graph: True, gen throughput (token/s): 772.53, #queue-req: 28\n",
      "[2025-08-13 20:06:01] INFO:     127.0.0.1:44608 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:01] INFO:     127.0.0.1:44610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:01] Prefill batch. #new-seq: 1, #new-token: 7361, #cached-token: 478, token usage: 0.92, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:06:02] INFO:     127.0.0.1:52790 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:02] INFO:     127.0.0.1:44638 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:02] INFO:     127.0.0.1:46966 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:02] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1031, token usage: 0.90, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:06:02] Prefill batch. #new-seq: 3, #new-token: 1813, #cached-token: 581, token usage: 0.93, #running-req: 69, #queue-req: 25\n",
      "[2025-08-13 20:06:03] Decode batch. #running-req: 72, #token: 230961, token usage: 0.94, cuda graph: True, gen throughput (token/s): 641.86, #queue-req: 28\n",
      "[2025-08-13 20:06:03] INFO:     127.0.0.1:52792 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:03] INFO:     127.0.0.1:45062 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:03] Prefill batch. #new-seq: 2, #new-token: 7279, #cached-token: 1017, token usage: 0.91, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 20:06:05] INFO:     127.0.0.1:56522 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:05] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1088, token usage: 0.91, #running-req: 71, #queue-req: 24\n",
      "[2025-08-13 20:06:05] Prefill batch. #new-seq: 1, #new-token: 234, #cached-token: 0, token usage: 0.95, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:06:06] INFO:     127.0.0.1:45082 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:06] Prefill batch. #new-seq: 1, #new-token: 5172, #cached-token: 508, token usage: 0.93, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 20:06:06] INFO:     127.0.0.1:57760 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:06] Prefill batch. #new-seq: 1, #new-token: 26, #cached-token: 144, token usage: 0.94, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:06:08] Decode batch. #running-req: 73, #token: 233497, token usage: 0.95, cuda graph: True, gen throughput (token/s): 608.02, #queue-req: 27\n",
      "[2025-08-13 20:06:10] INFO:     127.0.0.1:44986 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:11] INFO:     127.0.0.1:60326 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:11] Decode batch. #running-req: 71, #token: 230042, token usage: 0.94, cuda graph: True, gen throughput (token/s): 996.14, #queue-req: 27\n",
      "[2025-08-13 20:06:14] Decode batch. #running-req: 71, #token: 232882, token usage: 0.95, cuda graph: True, gen throughput (token/s): 972.11, #queue-req: 29\n",
      "[2025-08-13 20:06:14] INFO:     127.0.0.1:60344 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:15] Prefill batch. #new-seq: 2, #new-token: 7268, #cached-token: 540, token usage: 0.91, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:06:16] INFO:     127.0.0.1:44992 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:16] Prefill batch. #new-seq: 1, #new-token: 4308, #cached-token: 126, token usage: 0.93, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:06:17] INFO:     127.0.0.1:60364 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:17] Prefill batch. #new-seq: 1, #new-token: 6523, #cached-token: 119, token usage: 0.93, #running-req: 71, #queue-req: 28\n",
      "[2025-08-13 20:06:18] Decode batch. #running-req: 72, #token: 235348, token usage: 0.96, cuda graph: True, gen throughput (token/s): 622.93, #queue-req: 28\n",
      "[2025-08-13 20:06:19] INFO:     127.0.0.1:53628 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:21] Decode batch. #running-req: 71, #token: 237408, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1014.68, #queue-req: 29\n",
      "[2025-08-13 20:06:22] INFO:     127.0.0.1:47650 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:22] Prefill batch. #new-seq: 1, #new-token: 6856, #cached-token: 465, token usage: 0.93, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:06:24] INFO:     127.0.0.1:46296 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:25] Decode batch. #running-req: 70, #token: 230683, token usage: 0.94, cuda graph: True, gen throughput (token/s): 809.39, #queue-req: 30\n",
      "[2025-08-13 20:06:25] INFO:     127.0.0.1:53844 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:25] INFO:     127.0.0.1:32970 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:25] INFO:     127.0.0.1:32986 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:25] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 545, token usage: 0.91, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:06:25] Prefill batch. #new-seq: 1, #new-token: 2948, #cached-token: 0, token usage: 0.94, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:06:27] INFO:     127.0.0.1:32996 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:27] Prefill batch. #new-seq: 1, #new-token: 4440, #cached-token: 122, token usage: 0.93, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:06:27] INFO:     127.0.0.1:55618 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:06:27] Prefill batch. #new-seq: 1, #new-token: 1394, #cached-token: 150, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:06:28] INFO:     127.0.0.1:46284 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:28] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.93, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:06:29] INFO:     127.0.0.1:46288 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:29] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 505, token usage: 0.92, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:06:29] Prefill batch. #new-seq: 1, #new-token: 1089, #cached-token: 0, token usage: 0.96, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:06:30] INFO:     127.0.0.1:50444 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:30] Prefill batch. #new-seq: 1, #new-token: 4669, #cached-token: 626, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:06:30] Decode batch. #running-req: 68, #token: 234873, token usage: 0.96, cuda graph: True, gen throughput (token/s): 485.29, #queue-req: 30\n",
      "[2025-08-13 20:06:31] INFO:     127.0.0.1:55890 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:32] INFO:     127.0.0.1:33010 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:32] INFO:     127.0.0.1:55928 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:32] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 317, token usage: 0.91, #running-req: 66, #queue-req: 28\n",
      "[2025-08-13 20:06:32] Prefill batch. #new-seq: 1, #new-token: 2760, #cached-token: 0, token usage: 0.95, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:06:33] INFO:     127.0.0.1:33016 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:34] INFO:     127.0.0.1:54498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:34] Prefill batch. #new-seq: 2, #new-token: 7111, #cached-token: 889, token usage: 0.93, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:06:35] Decode batch. #running-req: 68, #token: 236109, token usage: 0.96, cuda graph: True, gen throughput (token/s): 548.95, #queue-req: 32\n",
      "[2025-08-13 20:06:37] INFO:     127.0.0.1:46520 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:37] Prefill batch. #new-seq: 1, #new-token: 2210, #cached-token: 444, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:06:38] INFO:     127.0.0.1:58722 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:38] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1144, token usage: 0.92, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:06:38] Prefill batch. #new-seq: 1, #new-token: 2898, #cached-token: 0, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:06:39] Decode batch. #running-req: 70, #token: 236864, token usage: 0.96, cuda graph: True, gen throughput (token/s): 654.31, #queue-req: 30\n",
      "[2025-08-13 20:06:40] INFO:     127.0.0.1:46310 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:40] INFO:     127.0.0.1:46966 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:40] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 561, token usage: 0.92, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:06:41] Prefill batch. #new-seq: 1, #new-token: 828, #cached-token: 0, token usage: 0.95, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:06:41] INFO:     127.0.0.1:58742 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:42] Prefill batch. #new-seq: 1, #new-token: 2651, #cached-token: 624, token usage: 0.94, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:06:42] INFO:     127.0.0.1:58218 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:42] INFO:     127.0.0.1:44638 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:42] Prefill batch. #new-seq: 2, #new-token: 6658, #cached-token: 275, token usage: 0.92, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:06:44] INFO:     127.0.0.1:58762 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:44] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 151, token usage: 0.94, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:06:44] Decode batch. #running-req: 69, #token: 232242, token usage: 0.94, cuda graph: True, gen throughput (token/s): 617.62, #queue-req: 30\n",
      "[2025-08-13 20:06:45] INFO:     127.0.0.1:58776 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:45] INFO:     127.0.0.1:58792 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:45] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 568, token usage: 0.91, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:06:45] Prefill batch. #new-seq: 1, #new-token: 296, #cached-token: 0, token usage: 0.95, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:06:46] INFO:     127.0.0.1:56838 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:47] Prefill batch. #new-seq: 1, #new-token: 2428, #cached-token: 392, token usage: 0.93, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:06:47] INFO:     127.0.0.1:60700 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:47] INFO:     127.0.0.1:44608 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:47] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.92, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:06:47] Prefill batch. #new-seq: 1, #new-token: 1162, #cached-token: 0, token usage: 0.96, #running-req: 68, #queue-req: 28\n",
      ".[2025-08-13 20:06:48] INFO:     127.0.0.1:44610 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:49] INFO:     127.0.0.1:56856 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:49] Prefill batch. #new-seq: 1, #new-token: 2427, #cached-token: 440, token usage: 0.94, #running-req: 67, #queue-req: 27\n",
      "[2025-08-13 20:06:49] Decode batch. #running-req: 68, #token: 232555, token usage: 0.95, cuda graph: True, gen throughput (token/s): 528.43, #queue-req: 28\n",
      "[2025-08-13 20:06:51] INFO:     127.0.0.1:49606 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:51] Prefill batch. #new-seq: 1, #new-token: 4585, #cached-token: 624, token usage: 0.94, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:06:52] Decode batch. #running-req: 68, #token: 237123, token usage: 0.96, cuda graph: True, gen throughput (token/s): 806.40, #queue-req: 32\n",
      "[2025-08-13 20:06:53] INFO:     127.0.0.1:51230 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:53] INFO:     127.0.0.1:60344 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:53] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 438, token usage: 0.93, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:06:53] INFO:     127.0.0.1:55604 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:53] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 393, token usage: 0.92, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:06:54] Prefill batch. #new-seq: 1, #new-token: 1362, #cached-token: 0, token usage: 0.95, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:06:56] INFO:     127.0.0.1:47650 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:56] Prefill batch. #new-seq: 3, #new-token: 7130, #cached-token: 1350, token usage: 0.92, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:06:57] Decode batch. #running-req: 69, #token: 235176, token usage: 0.96, cuda graph: True, gen throughput (token/s): 594.54, #queue-req: 31\n",
      "[2025-08-13 20:06:58] INFO:     127.0.0.1:46492 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:58] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 392, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:06:58] INFO:     127.0.0.1:60326 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:06:58] Prefill batch. #new-seq: 2, #new-token: 4835, #cached-token: 469, token usage: 0.93, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:07:00] INFO:     127.0.0.1:32996 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:00] INFO:     127.0.0.1:56476 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:00] Prefill batch. #new-seq: 1, #new-token: 7331, #cached-token: 463, token usage: 0.92, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:07:01] Decode batch. #running-req: 69, #token: 233307, token usage: 0.95, cuda graph: True, gen throughput (token/s): 661.30, #queue-req: 29\n",
      "[2025-08-13 20:07:03] INFO:     127.0.0.1:60364 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:04] Decode batch. #running-req: 68, #token: 231344, token usage: 0.94, cuda graph: True, gen throughput (token/s): 899.55, #queue-req: 31\n",
      "[2025-08-13 20:07:05] INFO:     127.0.0.1:32970 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:07] INFO:     127.0.0.1:32986 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:07] Prefill batch. #new-seq: 1, #new-token: 6817, #cached-token: 96, token usage: 0.93, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:07:08] Decode batch. #running-req: 67, #token: 235841, token usage: 0.96, cuda graph: True, gen throughput (token/s): 726.95, #queue-req: 33\n",
      "[2025-08-13 20:07:11] INFO:     127.0.0.1:46478 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:11] Prefill batch. #new-seq: 1, #new-token: 4367, #cached-token: 454, token usage: 0.92, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:07:11] INFO:     127.0.0.1:46482 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:11] Prefill batch. #new-seq: 1, #new-token: 6748, #cached-token: 160, token usage: 0.92, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:07:11] Decode batch. #running-req: 66, #token: 234102, token usage: 0.95, cuda graph: True, gen throughput (token/s): 773.76, #queue-req: 33\n",
      "[2025-08-13 20:07:15] Decode batch. #running-req: 67, #token: 236849, token usage: 0.96, cuda graph: True, gen throughput (token/s): 752.00, #queue-req: 33\n",
      "[2025-08-13 20:07:16] INFO:     127.0.0.1:58200 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:16] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 191, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:07:18] Decode batch. #running-req: 67, #token: 235279, token usage: 0.96, cuda graph: True, gen throughput (token/s): 926.53, #queue-req: 33\n",
      "[2025-08-13 20:07:18] INFO:     127.0.0.1:55588 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:21] Decode batch. #running-req: 66, #token: 236581, token usage: 0.96, cuda graph: True, gen throughput (token/s): 877.35, #queue-req: 34\n",
      "[2025-08-13 20:07:21] INFO:     127.0.0.1:33010 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:21] Prefill batch. #new-seq: 1, #new-token: 2355, #cached-token: 447, token usage: 0.95, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:07:24] Decode batch. #running-req: 66, #token: 237080, token usage: 0.96, cuda graph: True, gen throughput (token/s): 856.09, #queue-req: 34\n",
      "[2025-08-13 20:07:25] INFO:     127.0.0.1:54486 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:25] Prefill batch. #new-seq: 1, #new-token: 2412, #cached-token: 437, token usage: 0.95, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:07:27] INFO:     127.0.0.1:39602 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:27] Prefill batch. #new-seq: 1, #new-token: 5506, #cached-token: 463, token usage: 0.94, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:07:27] INFO:     127.0.0.1:46532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:27] INFO:     127.0.0.1:39572 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:28] Decode batch. #running-req: 64, #token: 237057, token usage: 0.96, cuda graph: True, gen throughput (token/s): 726.03, #queue-req: 34\n",
      "[2025-08-13 20:07:29] INFO:     127.0.0.1:56478 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:30] Decode batch. #running-req: 63, #token: 237366, token usage: 0.97, cuda graph: True, gen throughput (token/s): 932.98, #queue-req: 37\n",
      "[2025-08-13 20:07:33] Decode batch. #running-req: 63, #token: 239886, token usage: 0.98, cuda graph: True, gen throughput (token/s): 922.95, #queue-req: 37\n",
      "[2025-08-13 20:07:34] INFO:     127.0.0.1:56502 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:34] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 409, token usage: 0.94, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:07:34] INFO:     127.0.0.1:56492 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:35] INFO:     127.0.0.1:33016 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:36] Decode batch. #running-req: 61, #token: 229175, token usage: 0.93, cuda graph: True, gen throughput (token/s): 836.66, #queue-req: 39\n",
      "[2025-08-13 20:07:36] INFO:     127.0.0.1:45172 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:07:36] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 465, token usage: 0.92, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:07:36] Prefill batch. #new-seq: 1, #new-token: 1170, #cached-token: 0, token usage: 0.96, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:07:40] Decode batch. #running-req: 61, #token: 238809, token usage: 0.97, cuda graph: True, gen throughput (token/s): 657.69, #queue-req: 39\n",
      "[2025-08-13 20:07:42] Decode batch. #running-req: 61, #token: 241249, token usage: 0.98, cuda graph: True, gen throughput (token/s): 883.56, #queue-req: 39\n",
      "[2025-08-13 20:07:43] INFO:     127.0.0.1:36470 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:44] INFO:     127.0.0.1:58216 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:45] Decode batch. #running-req: 59, #token: 239629, token usage: 0.97, cuda graph: True, gen throughput (token/s): 852.36, #queue-req: 41\n",
      "[2025-08-13 20:07:48] INFO:     127.0.0.1:53632 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:48] INFO:     127.0.0.1:39592 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:48] Prefill batch. #new-seq: 1, #new-token: 4856, #cached-token: 624, token usage: 0.95, #running-req: 57, #queue-req: 40\n",
      "[2025-08-13 20:07:49] Decode batch. #running-req: 58, #token: 238861, token usage: 0.97, cuda graph: True, gen throughput (token/s): 722.36, #queue-req: 40\n",
      "[2025-08-13 20:07:51] INFO:     127.0.0.1:45170 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:51] Decode batch. #running-req: 57, #token: 237598, token usage: 0.97, cuda graph: True, gen throughput (token/s): 836.13, #queue-req: 42\n",
      "[2025-08-13 20:07:54] Decode batch. #running-req: 57, #token: 239878, token usage: 0.98, cuda graph: True, gen throughput (token/s): 833.09, #queue-req: 43\n",
      "[2025-08-13 20:07:57] Decode batch. #running-req: 57, #token: 242158, token usage: 0.98, cuda graph: True, gen throughput (token/s): 826.29, #queue-req: 43\n",
      "[2025-08-13 20:07:57] INFO:     127.0.0.1:58742 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:57] INFO:     127.0.0.1:56816 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:57] Prefill batch. #new-seq: 2, #new-token: 4702, #cached-token: 899, token usage: 0.94, #running-req: 55, #queue-req: 41\n",
      "[2025-08-13 20:07:58] INFO:     127.0.0.1:54496 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:07:58] Prefill batch. #new-seq: 2, #new-token: 2194, #cached-token: 269, token usage: 0.94, #running-req: 56, #queue-req: 39\n",
      "[2025-08-13 20:08:00] Decode batch. #running-req: 58, #token: 235007, token usage: 0.96, cuda graph: True, gen throughput (token/s): 693.39, #queue-req: 42\n",
      "[2025-08-13 20:08:03] INFO:     127.0.0.1:53818 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:03] Decode batch. #running-req: 58, #token: 232972, token usage: 0.95, cuda graph: True, gen throughput (token/s): 846.35, #queue-req: 42\n",
      "[2025-08-13 20:08:03] Prefill batch. #new-seq: 1, #new-token: 4187, #cached-token: 466, token usage: 0.95, #running-req: 57, #queue-req: 41\n",
      "[2025-08-13 20:08:04] INFO:     127.0.0.1:57128 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:04] Prefill batch. #new-seq: 1, #new-token: 4374, #cached-token: 446, token usage: 0.95, #running-req: 57, #queue-req: 41\n",
      "[2025-08-13 20:08:06] Decode batch. #running-req: 58, #token: 238471, token usage: 0.97, cuda graph: True, gen throughput (token/s): 663.78, #queue-req: 42\n",
      "[2025-08-13 20:08:08] INFO:     127.0.0.1:53828 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:08] Prefill batch. #new-seq: 1, #new-token: 4376, #cached-token: 444, token usage: 0.95, #running-req: 57, #queue-req: 42\n",
      "[2025-08-13 20:08:09] INFO:     127.0.0.1:48638 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:09] Prefill batch. #new-seq: 1, #new-token: 2526, #cached-token: 171, token usage: 0.96, #running-req: 57, #queue-req: 41\n",
      "[2025-08-13 20:08:10] Decode batch. #running-req: 58, #token: 239637, token usage: 0.97, cuda graph: True, gen throughput (token/s): 690.72, #queue-req: 42\n",
      "[2025-08-13 20:08:10] INFO:     127.0.0.1:49682 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:10] Prefill batch. #new-seq: 1, #new-token: 2348, #cached-token: 454, token usage: 0.96, #running-req: 57, #queue-req: 41\n",
      "[2025-08-13 20:08:11] INFO:     127.0.0.1:53846 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:11] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 93, token usage: 0.96, #running-req: 57, #queue-req: 42\n",
      "[2025-08-13 20:08:12] INFO:     127.0.0.1:53860 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:12] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 144, token usage: 0.96, #running-req: 57, #queue-req: 42\n",
      "[2025-08-13 20:08:13] Decode batch. #running-req: 58, #token: 236677, token usage: 0.96, cuda graph: True, gen throughput (token/s): 774.77, #queue-req: 42\n",
      "[2025-08-13 20:08:13] INFO:     127.0.0.1:39582 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:13] Prefill batch. #new-seq: 3, #new-token: 7504, #cached-token: 1333, token usage: 0.93, #running-req: 57, #queue-req: 40\n",
      "[2025-08-13 20:08:14] INFO:     127.0.0.1:58762 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:15] INFO:     127.0.0.1:58792 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:15] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 710, token usage: 0.92, #running-req: 58, #queue-req: 40\n",
      "[2025-08-13 20:08:15] Prefill batch. #new-seq: 1, #new-token: 1010, #cached-token: 0, token usage: 0.96, #running-req: 58, #queue-req: 40\n",
      "[2025-08-13 20:08:16] INFO:     127.0.0.1:36490 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:16] Prefill batch. #new-seq: 1, #new-token: 1006, #cached-token: 151, token usage: 0.95, #running-req: 58, #queue-req: 40\n",
      "[2025-08-13 20:08:17] Decode batch. #running-req: 59, #token: 235019, token usage: 0.96, cuda graph: True, gen throughput (token/s): 529.40, #queue-req: 41\n",
      "[2025-08-13 20:08:19] INFO:     127.0.0.1:58776 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:20] INFO:     127.0.0.1:51226 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:20] Prefill batch. #new-seq: 1, #new-token: 7694, #cached-token: 393, token usage: 0.93, #running-req: 57, #queue-req: 40\n",
      "[2025-08-13 20:08:21] Decode batch. #running-req: 58, #token: 236586, token usage: 0.96, cuda graph: True, gen throughput (token/s): 671.17, #queue-req: 40\n",
      "[2025-08-13 20:08:23] Decode batch. #running-req: 58, #token: 238906, token usage: 0.97, cuda graph: True, gen throughput (token/s): 851.90, #queue-req: 42\n",
      "[2025-08-13 20:08:25] INFO:     127.0.0.1:53646 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:26] Decode batch. #running-req: 57, #token: 238866, token usage: 0.97, cuda graph: True, gen throughput (token/s): 841.73, #queue-req: 43\n",
      "[2025-08-13 20:08:26] INFO:     127.0.0.1:54434 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:26] INFO:     127.0.0.1:54448 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:26] INFO:     127.0.0.1:54454 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:26] INFO:     127.0.0.1:54470 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:26] Prefill batch. #new-seq: 2, #new-token: 7411, #cached-token: 851, token usage: 0.93, #running-req: 53, #queue-req: 45\n",
      "[2025-08-13 20:08:29] Decode batch. #running-req: 55, #token: 237305, token usage: 0.97, cuda graph: True, gen throughput (token/s): 665.77, #queue-req: 45\n",
      "[2025-08-13 20:08:29] INFO:     127.0.0.1:57140 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:08:30] Prefill batch. #new-seq: 1, #new-token: 2344, #cached-token: 458, token usage: 0.95, #running-req: 54, #queue-req: 44\n",
      "[2025-08-13 20:08:32] Decode batch. #running-req: 55, #token: 238293, token usage: 0.97, cuda graph: True, gen throughput (token/s): 757.71, #queue-req: 45\n",
      "[2025-08-13 20:08:34] INFO:     127.0.0.1:55598 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:35] Decode batch. #running-req: 54, #token: 236360, token usage: 0.96, cuda graph: True, gen throughput (token/s): 812.73, #queue-req: 45\n",
      "[2025-08-13 20:08:38] Decode batch. #running-req: 54, #token: 238520, token usage: 0.97, cuda graph: True, gen throughput (token/s): 812.45, #queue-req: 46\n",
      "[2025-08-13 20:08:38] INFO:     127.0.0.1:60690 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:39] INFO:     127.0.0.1:60692 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:39] Prefill batch. #new-seq: 1, #new-token: 4877, #cached-token: 553, token usage: 0.95, #running-req: 52, #queue-req: 47\n",
      "[2025-08-13 20:08:40] INFO:     127.0.0.1:36478 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:40] Prefill batch. #new-seq: 2, #new-token: 2833, #cached-token: 827, token usage: 0.95, #running-req: 52, #queue-req: 45\n",
      ".[2025-08-13 20:08:41] Decode batch. #running-req: 54, #token: 235799, token usage: 0.96, cuda graph: True, gen throughput (token/s): 634.19, #queue-req: 46\n",
      "[2025-08-13 20:08:43] INFO:     127.0.0.1:45028 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:43] INFO:     127.0.0.1:45168 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:43] Prefill batch. #new-seq: 1, #new-token: 4836, #cached-token: 626, token usage: 0.91, #running-req: 53, #queue-req: 46\n",
      "[2025-08-13 20:08:44] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 545, token usage: 0.93, #running-req: 53, #queue-req: 46\n",
      "[2025-08-13 20:08:44] Prefill batch. #new-seq: 1, #new-token: 3114, #cached-token: 0, token usage: 0.96, #running-req: 53, #queue-req: 46\n",
      "[2025-08-13 20:08:45] Decode batch. #running-req: 54, #token: 239377, token usage: 0.97, cuda graph: True, gen throughput (token/s): 494.83, #queue-req: 46\n",
      "[2025-08-13 20:08:47] INFO:     127.0.0.1:36492 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:47] Prefill batch. #new-seq: 1, #new-token: 4199, #cached-token: 96, token usage: 0.96, #running-req: 53, #queue-req: 45\n",
      "[2025-08-13 20:08:47] INFO:     127.0.0.1:45174 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:47] Prefill batch. #new-seq: 2, #new-token: 5649, #cached-token: 675, token usage: 0.94, #running-req: 53, #queue-req: 43\n",
      "[2025-08-13 20:08:47] INFO:     127.0.0.1:45180 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:47] INFO:     127.0.0.1:51214 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:49] Decode batch. #running-req: 53, #token: 237621, token usage: 0.97, cuda graph: True, gen throughput (token/s): 592.87, #queue-req: 47\n",
      "[2025-08-13 20:08:50] INFO:     127.0.0.1:51224 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:51] INFO:     127.0.0.1:49610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:51] Prefill batch. #new-seq: 1, #new-token: 2968, #cached-token: 465, token usage: 0.95, #running-req: 51, #queue-req: 48\n",
      "[2025-08-13 20:08:52] Decode batch. #running-req: 52, #token: 236141, token usage: 0.96, cuda graph: True, gen throughput (token/s): 708.49, #queue-req: 48\n",
      "[2025-08-13 20:08:53] INFO:     127.0.0.1:52766 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:53] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 280, token usage: 0.93, #running-req: 51, #queue-req: 46\n",
      "[2025-08-13 20:08:53] Prefill batch. #new-seq: 2, #new-token: 1195, #cached-token: 409, token usage: 0.96, #running-req: 52, #queue-req: 45\n",
      "[2025-08-13 20:08:55] INFO:     127.0.0.1:44556 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:55] Prefill batch. #new-seq: 1, #new-token: 525, #cached-token: 93, token usage: 0.96, #running-req: 53, #queue-req: 45\n",
      "[2025-08-13 20:08:55] INFO:     127.0.0.1:49624 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:55] Prefill batch. #new-seq: 2, #new-token: 6434, #cached-token: 271, token usage: 0.93, #running-req: 53, #queue-req: 43\n",
      "[2025-08-13 20:08:56] INFO:     127.0.0.1:49634 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:56] INFO:     127.0.0.1:49636 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:56] INFO:     127.0.0.1:49646 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:56] INFO:     127.0.0.1:49658 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:56] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 944, token usage: 0.88, #running-req: 51, #queue-req: 46\n",
      "[2025-08-13 20:08:56] Prefill batch. #new-seq: 5, #new-token: 4984, #cached-token: 1066, token usage: 0.91, #running-req: 52, #queue-req: 42\n",
      "[2025-08-13 20:08:57] Decode batch. #running-req: 57, #token: 229622, token usage: 0.93, cuda graph: True, gen throughput (token/s): 399.03, #queue-req: 43\n",
      "[2025-08-13 20:08:58] INFO:     127.0.0.1:49670 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:58] INFO:     127.0.0.1:46478 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:58] Prefill batch. #new-seq: 6, #new-token: 8192, #cached-token: 1711, token usage: 0.86, #running-req: 56, #queue-req: 38\n",
      "[2025-08-13 20:08:58] INFO:     127.0.0.1:46482 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:08:58] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 709, token usage: 0.87, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 20:08:58] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1017, token usage: 0.91, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 20:08:59] Prefill batch. #new-seq: 2, #new-token: 3566, #cached-token: 96, token usage: 0.94, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:09:00] INFO:     127.0.0.1:53846 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:09:01] INFO:     127.0.0.1:53860 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:01] INFO:     127.0.0.1:58202 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:01] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.91, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:09:01] Prefill batch. #new-seq: 1, #new-token: 1204, #cached-token: 0, token usage: 0.94, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:09:03] INFO:     127.0.0.1:52744 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:04] Decode batch. #running-req: 63, #token: 233255, token usage: 0.95, cuda graph: True, gen throughput (token/s): 407.37, #queue-req: 36\n",
      "[2025-08-13 20:09:04] INFO:     127.0.0.1:56796 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:04] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1314, token usage: 0.90, #running-req: 62, #queue-req: 33\n",
      "[2025-08-13 20:09:04] Prefill batch. #new-seq: 2, #new-token: 3086, #cached-token: 474, token usage: 0.93, #running-req: 64, #queue-req: 32\n",
      "[2025-08-13 20:09:07] Decode batch. #running-req: 66, #token: 234146, token usage: 0.95, cuda graph: True, gen throughput (token/s): 694.70, #queue-req: 34\n",
      "[2025-08-13 20:09:09] INFO:     127.0.0.1:46532 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:09] Prefill batch. #new-seq: 2, #new-token: 2516, #cached-token: 899, token usage: 0.94, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:09:10] INFO:     127.0.0.1:56478 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:10] INFO:     127.0.0.1:56492 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:10] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 695, token usage: 0.93, #running-req: 65, #queue-req: 30\n",
      "[2025-08-13 20:09:10] Decode batch. #running-req: 65, #token: 236363, token usage: 0.96, cuda graph: True, gen throughput (token/s): 858.47, #queue-req: 30\n",
      "[2025-08-13 20:09:10] Prefill batch. #new-seq: 1, #new-token: 554, #cached-token: 0, token usage: 0.96, #running-req: 67, #queue-req: 30\n",
      ".[2025-08-13 20:09:12] INFO:     127.0.0.1:53828 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:12] Prefill batch. #new-seq: 3, #new-token: 2729, #cached-token: 725, token usage: 0.94, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:09:13] INFO:     127.0.0.1:39582 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:13] Prefill batch. #new-seq: 3, #new-token: 6803, #cached-token: 1306, token usage: 0.91, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:09:15] Decode batch. #running-req: 72, #token: 232535, token usage: 0.95, cuda graph: True, gen throughput (token/s): 629.93, #queue-req: 28\n",
      "[2025-08-13 20:09:17] INFO:     127.0.0.1:32814 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:18] Decode batch. #running-req: 71, #token: 234560, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1012.35, #queue-req: 28\n",
      "[2025-08-13 20:09:19] INFO:     127.0.0.1:52802 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:20] INFO:     127.0.0.1:53646 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:21] Decode batch. #running-req: 69, #token: 231519, token usage: 0.94, cuda graph: True, gen throughput (token/s): 961.72, #queue-req: 30\n",
      "[2025-08-13 20:09:21] INFO:     127.0.0.1:54470 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:21] INFO:     127.0.0.1:54454 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:21] INFO:     127.0.0.1:54448 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:21] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.91, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:09:21] Prefill batch. #new-seq: 1, #new-token: 1194, #cached-token: 0, token usage: 0.94, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:09:22] INFO:     127.0.0.1:45028 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:22] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 917, token usage: 0.91, #running-req: 66, #queue-req: 28\n",
      "[2025-08-13 20:09:22] Prefill batch. #new-seq: 2, #new-token: 4679, #cached-token: 146, token usage: 0.94, #running-req: 67, #queue-req: 27\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:09:24] INFO:     127.0.0.1:56800 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:24] Prefill batch. #new-seq: 1, #new-token: 2381, #cached-token: 77, token usage: 0.94, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:09:24] INFO:     127.0.0.1:56810 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:25] INFO:     127.0.0.1:54434 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:25] Prefill batch. #new-seq: 2, #new-token: 6986, #cached-token: 1181, token usage: 0.92, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:09:25] Prefill batch. #new-seq: 1, #new-token: 4371, #cached-token: 450, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:09:27] INFO:     127.0.0.1:60690 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:27] INFO:     127.0.0.1:60692 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:27] Prefill batch. #new-seq: 1, #new-token: 2211, #cached-token: 125, token usage: 0.94, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:09:27] Decode batch. #running-req: 69, #token: 233581, token usage: 0.95, cuda graph: True, gen throughput (token/s): 430.27, #queue-req: 29\n",
      "[2025-08-13 20:09:27] INFO:     127.0.0.1:52762 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:27] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.92, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:09:27] Prefill batch. #new-seq: 1, #new-token: 1203, #cached-token: 0, token usage: 0.95, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:09:30] INFO:     127.0.0.1:57088 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:30] Prefill batch. #new-seq: 1, #new-token: 2157, #cached-token: 126, token usage: 0.94, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:09:31] Decode batch. #running-req: 69, #token: 235038, token usage: 0.96, cuda graph: True, gen throughput (token/s): 690.90, #queue-req: 31\n",
      "[2025-08-13 20:09:31] INFO:     127.0.0.1:45180 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:31] Prefill batch. #new-seq: 2, #new-token: 4586, #cached-token: 580, token usage: 0.94, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:09:33] INFO:     127.0.0.1:57102 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:34] Decode batch. #running-req: 69, #token: 235011, token usage: 0.96, cuda graph: True, gen throughput (token/s): 856.65, #queue-req: 31\n",
      "[2025-08-13 20:09:35] INFO:     127.0.0.1:57106 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:36] INFO:     127.0.0.1:45168 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:36] INFO:     127.0.0.1:45174 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:36] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.88, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:09:36] INFO:     127.0.0.1:57114 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:36] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1017, token usage: 0.92, #running-req: 66, #queue-req: 29\n",
      "[2025-08-13 20:09:36] Prefill batch. #new-seq: 1, #new-token: 2162, #cached-token: 0, token usage: 0.95, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:09:38] INFO:     127.0.0.1:51214 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:38] INFO:     127.0.0.1:32878 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:38] INFO:     127.0.0.1:51224 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:38] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.88, #running-req: 65, #queue-req: 31\n",
      "[2025-08-13 20:09:38] INFO:     127.0.0.1:49610 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:38] INFO:     127.0.0.1:49634 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:38] Prefill batch. #new-seq: 3, #new-token: 5895, #cached-token: 287, token usage: 0.91, #running-req: 65, #queue-req: 29\n",
      ".[2025-08-13 20:09:40] Prefill batch. #new-seq: 1, #new-token: 7192, #cached-token: 508, token usage: 0.94, #running-req: 66, #queue-req: 28\n",
      "[2025-08-13 20:09:41] Decode batch. #running-req: 67, #token: 237741, token usage: 0.97, cuda graph: True, gen throughput (token/s): 399.56, #queue-req: 28\n",
      "[2025-08-13 20:09:42] INFO:     127.0.0.1:58202 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:42] Prefill batch. #new-seq: 2, #new-token: 374, #cached-token: 197, token usage: 0.94, #running-req: 66, #queue-req: 26\n",
      "[2025-08-13 20:09:42] INFO:     127.0.0.1:49624 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:42] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 545, token usage: 0.90, #running-req: 67, #queue-req: 26\n",
      "[2025-08-13 20:09:42] Prefill batch. #new-seq: 1, #new-token: 3107, #cached-token: 0, token usage: 0.94, #running-req: 67, #queue-req: 26\n",
      "[2025-08-13 20:09:45] INFO:     127.0.0.1:49670 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:45] Prefill batch. #new-seq: 2, #new-token: 4553, #cached-token: 269, token usage: 0.93, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:09:46] Decode batch. #running-req: 69, #token: 232578, token usage: 0.95, cuda graph: True, gen throughput (token/s): 595.24, #queue-req: 30\n",
      "[2025-08-13 20:09:46] INFO:     127.0.0.1:49646 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:46] INFO:     127.0.0.1:49658 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:46] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 77, token usage: 0.93, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:09:46] INFO:     127.0.0.1:52108 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:46] Prefill batch. #new-seq: 1, #new-token: 7289, #cached-token: 463, token usage: 0.92, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:09:48] INFO:     127.0.0.1:52752 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:49] Decode batch. #running-req: 67, #token: 226500, token usage: 0.92, cuda graph: True, gen throughput (token/s): 766.48, #queue-req: 29\n",
      "[2025-08-13 20:09:49] INFO:     127.0.0.1:48626 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:50] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.91, #running-req: 66, #queue-req: 28\n",
      "[2025-08-13 20:09:50] Prefill batch. #new-seq: 1, #new-token: 1371, #cached-token: 0, token usage: 0.95, #running-req: 66, #queue-req: 28\n",
      "[2025-08-13 20:09:52] INFO:     127.0.0.1:48636 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:52] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 136, token usage: 0.94, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:09:53] Decode batch. #running-req: 67, #token: 232154, token usage: 0.94, cuda graph: True, gen throughput (token/s): 681.02, #queue-req: 33\n",
      "[2025-08-13 20:09:53] INFO:     127.0.0.1:52112 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:53] Prefill batch. #new-seq: 2, #new-token: 1532, #cached-token: 592, token usage: 0.93, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:09:55] INFO:     127.0.0.1:36796 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:56] Decode batch. #running-req: 67, #token: 233224, token usage: 0.95, cuda graph: True, gen throughput (token/s): 880.43, #queue-req: 33\n",
      "[2025-08-13 20:09:58] INFO:     127.0.0.1:43220 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:59] Decode batch. #running-req: 66, #token: 230039, token usage: 0.94, cuda graph: True, gen throughput (token/s): 923.03, #queue-req: 34\n",
      "[2025-08-13 20:09:59] INFO:     127.0.0.1:51702 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:09:59] Prefill batch. #new-seq: 1, #new-token: 7367, #cached-token: 463, token usage: 0.91, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:10:03] Decode batch. #running-req: 66, #token: 233918, token usage: 0.95, cuda graph: True, gen throughput (token/s): 717.59, #queue-req: 34\n",
      "[2025-08-13 20:10:06] Decode batch. #running-req: 66, #token: 236558, token usage: 0.96, cuda graph: True, gen throughput (token/s): 877.79, #queue-req: 34\n",
      "[2025-08-13 20:10:06] INFO:     127.0.0.1:43294 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:07] INFO:     127.0.0.1:42754 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:09] Decode batch. #running-req: 64, #token: 238069, token usage: 0.97, cuda graph: True, gen throughput (token/s): 902.22, #queue-req: 36\n",
      "[2025-08-13 20:10:10] INFO:     127.0.0.1:52770 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:11] Decode batch. #running-req: 63, #token: 238313, token usage: 0.97, cuda graph: True, gen throughput (token/s): 904.88, #queue-req: 37\n",
      "[2025-08-13 20:10:14] Decode batch. #running-req: 63, #token: 240833, token usage: 0.98, cuda graph: True, gen throughput (token/s): 912.52, #queue-req: 37\n",
      "[2025-08-13 20:10:14] INFO:     127.0.0.1:32866 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:14] Prefill batch. #new-seq: 3, #new-token: 6563, #cached-token: 702, token usage: 0.92, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 20:10:14] INFO:     127.0.0.1:52780 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:17] Decode batch. #running-req: 64, #token: 235089, token usage: 0.96, cuda graph: True, gen throughput (token/s): 794.64, #queue-req: 36\n",
      "[2025-08-13 20:10:19] INFO:     127.0.0.1:38264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:20] INFO:     127.0.0.1:52784 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:20] Prefill batch. #new-seq: 1, #new-token: 6462, #cached-token: 122, token usage: 0.93, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:10:21] Decode batch. #running-req: 63, #token: 236130, token usage: 0.96, cuda graph: True, gen throughput (token/s): 774.99, #queue-req: 37\n",
      "[2025-08-13 20:10:21] INFO:     127.0.0.1:56800 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:21] Prefill batch. #new-seq: 1, #new-token: 4368, #cached-token: 454, token usage: 0.94, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:10:23] INFO:     127.0.0.1:58628 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:24] Decode batch. #running-req: 62, #token: 235971, token usage: 0.96, cuda graph: True, gen throughput (token/s): 799.17, #queue-req: 37\n",
      "[2025-08-13 20:10:24] INFO:     127.0.0.1:32894 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:24] Prefill batch. #new-seq: 2, #new-token: 6704, #cached-token: 532, token usage: 0.92, #running-req: 61, #queue-req: 36\n",
      ".[2025-08-13 20:10:26] INFO:     127.0.0.1:50410 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:26] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 466, token usage: 0.95, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:10:27] Decode batch. #running-req: 63, #token: 235707, token usage: 0.96, cuda graph: True, gen throughput (token/s): 719.74, #queue-req: 37\n",
      "[2025-08-13 20:10:28] INFO:     127.0.0.1:44522 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:28] Prefill batch. #new-seq: 1, #new-token: 2279, #cached-token: 129, token usage: 0.94, #running-req: 62, #queue-req: 37\n",
      "[2025-08-13 20:10:29] INFO:     127.0.0.1:48526 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:29] Prefill batch. #new-seq: 1, #new-token: 4408, #cached-token: 409, token usage: 0.95, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:10:29] INFO:     127.0.0.1:56810 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:30] Prefill batch. #new-seq: 1, #new-token: 1197, #cached-token: 93, token usage: 0.95, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:10:31] INFO:     127.0.0.1:57088 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:31] Decode batch. #running-req: 63, #token: 231278, token usage: 0.94, cuda graph: True, gen throughput (token/s): 737.86, #queue-req: 35\n",
      "[2025-08-13 20:10:31] Prefill batch. #new-seq: 1, #new-token: 4224, #cached-token: 449, token usage: 0.94, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 20:10:31] INFO:     127.0.0.1:53846 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:31] Prefill batch. #new-seq: 1, #new-token: 4495, #cached-token: 438, token usage: 0.95, #running-req: 62, #queue-req: 33\n",
      "[2025-08-13 20:10:32] INFO:     127.0.0.1:44532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:32] Prefill batch. #new-seq: 1, #new-token: 4883, #cached-token: 412, token usage: 0.93, #running-req: 62, #queue-req: 32\n",
      "[2025-08-13 20:10:35] Decode batch. #running-req: 63, #token: 235076, token usage: 0.96, cuda graph: True, gen throughput (token/s): 643.49, #queue-req: 37\n",
      "[2025-08-13 20:10:36] INFO:     127.0.0.1:40300 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:36] Prefill batch. #new-seq: 1, #new-token: 5624, #cached-token: 393, token usage: 0.94, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:10:38] Decode batch. #running-req: 63, #token: 237816, token usage: 0.97, cuda graph: True, gen throughput (token/s): 775.64, #queue-req: 37\n",
      "[2025-08-13 20:10:40] INFO:     127.0.0.1:57106 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:40] Prefill batch. #new-seq: 2, #new-token: 2464, #cached-token: 585, token usage: 0.94, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:10:40] INFO:     127.0.0.1:57114 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:40] Prefill batch. #new-seq: 1, #new-token: 2223, #cached-token: 409, token usage: 0.95, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:10:41] INFO:     127.0.0.1:52182 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:41] Decode batch. #running-req: 64, #token: 232209, token usage: 0.94, cuda graph: True, gen throughput (token/s): 793.96, #queue-req: 34\n",
      "[2025-08-13 20:10:41] Prefill batch. #new-seq: 1, #new-token: 2164, #cached-token: 469, token usage: 0.94, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 20:10:42] INFO:     127.0.0.1:57102 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:42] INFO:     127.0.0.1:50372 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:42] Prefill batch. #new-seq: 2, #new-token: 7341, #cached-token: 667, token usage: 0.92, #running-req: 62, #queue-req: 31\n",
      "[2025-08-13 20:10:45] Decode batch. #running-req: 64, #token: 234268, token usage: 0.95, cuda graph: True, gen throughput (token/s): 711.68, #queue-req: 32\n",
      "[2025-08-13 20:10:45] INFO:     127.0.0.1:52094 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:45] Prefill batch. #new-seq: 1, #new-token: 5331, #cached-token: 508, token usage: 0.94, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:10:48] Decode batch. #running-req: 64, #token: 238446, token usage: 0.97, cuda graph: True, gen throughput (token/s): 790.67, #queue-req: 36\n",
      "[2025-08-13 20:10:49] INFO:     127.0.0.1:51688 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:50] INFO:     127.0.0.1:38282 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:50] INFO:     127.0.0.1:32840 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:50] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 478, token usage: 0.92, #running-req: 61, #queue-req: 35\n",
      "[2025-08-13 20:10:50] Prefill batch. #new-seq: 1, #new-token: 1355, #cached-token: 0, token usage: 0.95, #running-req: 61, #queue-req: 35\n",
      "[2025-08-13 20:10:52] Decode batch. #running-req: 62, #token: 235035, token usage: 0.96, cuda graph: True, gen throughput (token/s): 678.84, #queue-req: 35\n",
      "[2025-08-13 20:10:54] INFO:     127.0.0.1:38290 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:54] Decode batch. #running-req: 61, #token: 234874, token usage: 0.96, cuda graph: True, gen throughput (token/s): 896.91, #queue-req: 38\n",
      "[2025-08-13 20:10:55] INFO:     127.0.0.1:44540 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:55] INFO:     127.0.0.1:44550 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:55] Prefill batch. #new-seq: 2, #new-token: 7591, #cached-token: 695, token usage: 0.92, #running-req: 59, #queue-req: 36\n",
      "[2025-08-13 20:10:56] INFO:     127.0.0.1:50380 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:10:56] Prefill batch. #new-seq: 2, #new-token: 4776, #cached-token: 872, token usage: 0.93, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:10:56] INFO:     127.0.0.1:44564 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:10:56] Prefill batch. #new-seq: 1, #new-token: 1761, #cached-token: 134, token usage: 0.95, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 20:10:58] Decode batch. #running-req: 62, #token: 237390, token usage: 0.97, cuda graph: True, gen throughput (token/s): 622.06, #queue-req: 38\n",
      "[2025-08-13 20:11:01] Decode batch. #running-req: 62, #token: 239870, token usage: 0.98, cuda graph: True, gen throughput (token/s): 904.89, #queue-req: 38\n",
      "[2025-08-13 20:11:02] INFO:     127.0.0.1:32826 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:04] Decode batch. #running-req: 61, #token: 240143, token usage: 0.98, cuda graph: True, gen throughput (token/s): 878.88, #queue-req: 39\n",
      "[2025-08-13 20:11:05] INFO:     127.0.0.1:43248 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:05] INFO:     127.0.0.1:60190 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:05] INFO:     127.0.0.1:48626 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:06] INFO:     127.0.0.1:32782 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:06] Prefill batch. #new-seq: 1, #new-token: 7481, #cached-token: 463, token usage: 0.93, #running-req: 57, #queue-req: 38\n",
      "[2025-08-13 20:11:07] Decode batch. #running-req: 58, #token: 237388, token usage: 0.97, cuda graph: True, gen throughput (token/s): 678.04, #queue-req: 42\n",
      "[2025-08-13 20:11:07] INFO:     127.0.0.1:32798 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:08] Prefill batch. #new-seq: 1, #new-token: 4370, #cached-token: 451, token usage: 0.95, #running-req: 57, #queue-req: 42\n",
      "[2025-08-13 20:11:10] INFO:     127.0.0.1:49512 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:10] Decode batch. #running-req: 57, #token: 237028, token usage: 0.96, cuda graph: True, gen throughput (token/s): 743.97, #queue-req: 42\n",
      "[2025-08-13 20:11:11] INFO:     127.0.0.1:32844 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:11] INFO:     127.0.0.1:32858 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:11] Prefill batch. #new-seq: 2, #new-token: 2421, #cached-token: 900, token usage: 0.94, #running-req: 55, #queue-req: 40\n",
      "[2025-08-13 20:11:13] INFO:     127.0.0.1:58640 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:13] Decode batch. #running-req: 57, #token: 224569, token usage: 0.91, cuda graph: True, gen throughput (token/s): 779.15, #queue-req: 43\n",
      "[2025-08-13 20:11:13] Prefill batch. #new-seq: 5, #new-token: 5842, #cached-token: 1723, token usage: 0.91, #running-req: 56, #queue-req: 38\n",
      "[2025-08-13 20:11:15] INFO:     127.0.0.1:40304 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:15] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 447, token usage: 0.93, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:11:16] INFO:     127.0.0.1:39164 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:17] INFO:     127.0.0.1:52120 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:17] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.92, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:11:17] Prefill batch. #new-seq: 1, #new-token: 1416, #cached-token: 0, token usage: 0.95, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:11:18] Decode batch. #running-req: 60, #token: 235397, token usage: 0.96, cuda graph: True, gen throughput (token/s): 527.95, #queue-req: 38\n",
      "[2025-08-13 20:11:19] INFO:     127.0.0.1:48636 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:19] Prefill batch. #new-seq: 1, #new-token: 7524, #cached-token: 464, token usage: 0.94, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:11:20] INFO:     127.0.0.1:52784 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:20] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 77, token usage: 0.94, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:11:21] INFO:     127.0.0.1:39902 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:21] Decode batch. #running-req: 60, #token: 230822, token usage: 0.94, cuda graph: True, gen throughput (token/s): 696.73, #queue-req: 40\n",
      "[2025-08-13 20:11:21] Prefill batch. #new-seq: 1, #new-token: 6696, #cached-token: 149, token usage: 0.94, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:11:25] Decode batch. #running-req: 60, #token: 239918, token usage: 0.98, cuda graph: True, gen throughput (token/s): 713.46, #queue-req: 40\n",
      "[2025-08-13 20:11:25] INFO:     127.0.0.1:43214 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:25] Prefill batch. #new-seq: 2, #new-token: 242, #cached-token: 212, token usage: 0.96, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:11:25] INFO:     127.0.0.1:52770 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:25] Prefill batch. #new-seq: 1, #new-token: 2215, #cached-token: 440, token usage: 0.95, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:11:26] INFO:     127.0.0.1:36810 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:26] Prefill batch. #new-seq: 1, #new-token: 4759, #cached-token: 409, token usage: 0.95, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:11:26] INFO:     127.0.0.1:52106 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:26] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 124, token usage: 0.95, #running-req: 60, #queue-req: 36\n",
      "..[2025-08-13 20:11:27] INFO:     127.0.0.1:60214 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:27] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.93, #running-req: 60, #queue-req: 35\n",
      "[2025-08-13 20:11:27] INFO:     127.0.0.1:52780 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:27] Prefill batch. #new-seq: 2, #new-token: 5320, #cached-token: 470, token usage: 0.94, #running-req: 60, #queue-req: 34\n",
      "[2025-08-13 20:11:28] INFO:     127.0.0.1:44532 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:28] Prefill batch. #new-seq: 3, #new-token: 2899, #cached-token: 997, token usage: 0.92, #running-req: 61, #queue-req: 32\n",
      "[2025-08-13 20:11:29] Prefill batch. #new-seq: 1, #new-token: 4888, #cached-token: 553, token usage: 0.93, #running-req: 63, #queue-req: 31\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:11:30] Decode batch. #running-req: 64, #token: 234230, token usage: 0.95, cuda graph: True, gen throughput (token/s): 447.14, #queue-req: 36\n",
      "[2025-08-13 20:11:30] INFO:     127.0.0.1:43234 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:30] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.94, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:11:33] Decode batch. #running-req: 64, #token: 234791, token usage: 0.96, cuda graph: True, gen throughput (token/s): 873.00, #queue-req: 36\n",
      "[2025-08-13 20:11:35] INFO:     127.0.0.1:46184 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:35] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 450, token usage: 0.94, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:11:35] INFO:     127.0.0.1:38304 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:35] Prefill batch. #new-seq: 2, #new-token: 3323, #cached-token: 904, token usage: 0.94, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:11:36] Decode batch. #running-req: 65, #token: 235240, token usage: 0.96, cuda graph: True, gen throughput (token/s): 782.53, #queue-req: 35\n",
      "[2025-08-13 20:11:38] INFO:     127.0.0.1:44522 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:38] Prefill batch. #new-seq: 1, #new-token: 4886, #cached-token: 639, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:11:40] Decode batch. #running-req: 65, #token: 237840, token usage: 0.97, cuda graph: True, gen throughput (token/s): 771.17, #queue-req: 35\n",
      "[2025-08-13 20:11:42] INFO:     127.0.0.1:43236 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:42] Prefill batch. #new-seq: 1, #new-token: 2358, #cached-token: 444, token usage: 0.95, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:11:42] INFO:     127.0.0.1:43264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:42] Prefill batch. #new-seq: 1, #new-token: 2269, #cached-token: 132, token usage: 0.95, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:11:43] INFO:     127.0.0.1:42766 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:43] Decode batch. #running-req: 65, #token: 223067, token usage: 0.91, cuda graph: True, gen throughput (token/s): 770.75, #queue-req: 35\n",
      "[2025-08-13 20:11:43] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 841, token usage: 0.91, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:11:43] Prefill batch. #new-seq: 2, #new-token: 5686, #cached-token: 450, token usage: 0.94, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:11:45] INFO:     127.0.0.1:38280 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:47] Decode batch. #running-req: 66, #token: 238242, token usage: 0.97, cuda graph: True, gen throughput (token/s): 639.02, #queue-req: 34\n",
      "[2025-08-13 20:11:49] INFO:     127.0.0.1:44550 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:50] INFO:     127.0.0.1:58614 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:11:50] Prefill batch. #new-seq: 1, #new-token: 2346, #cached-token: 455, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:11:50] Decode batch. #running-req: 65, #token: 235011, token usage: 0.96, cuda graph: True, gen throughput (token/s): 840.81, #queue-req: 34\n",
      "[2025-08-13 20:11:51] INFO:     127.0.0.1:49500 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:51] Prefill batch. #new-seq: 2, #new-token: 2255, #cached-token: 528, token usage: 0.95, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:11:52] INFO:     127.0.0.1:59638 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:52] Prefill batch. #new-seq: 1, #new-token: 406, #cached-token: 120, token usage: 0.96, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:11:53] INFO:     127.0.0.1:60206 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:53] Prefill batch. #new-seq: 1, #new-token: 4568, #cached-token: 149, token usage: 0.94, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:11:54] Decode batch. #running-req: 66, #token: 236058, token usage: 0.96, cuda graph: True, gen throughput (token/s): 735.17, #queue-req: 34\n",
      "[2025-08-13 20:11:55] INFO:     127.0.0.1:44540 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:55] INFO:     127.0.0.1:46150 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:55] Prefill batch. #new-seq: 1, #new-token: 6298, #cached-token: 626, token usage: 0.94, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:11:56] INFO:     127.0.0.1:49278 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:57] INFO:     127.0.0.1:46154 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:57] Prefill batch. #new-seq: 1, #new-token: 475, #cached-token: 77, token usage: 0.95, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:11:57] INFO:     127.0.0.1:60336 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:57] Prefill batch. #new-seq: 2, #new-token: 6538, #cached-token: 916, token usage: 0.93, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 20:11:58] INFO:     127.0.0.1:46168 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:58] INFO:     127.0.0.1:36812 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:58] INFO:     127.0.0.1:48518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:58] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1350, token usage: 0.89, #running-req: 62, #queue-req: 30\n",
      "[2025-08-13 20:11:58] INFO:     127.0.0.1:38278 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:58] Prefill batch. #new-seq: 1, #new-token: 768, #cached-token: 0, token usage: 0.92, #running-req: 64, #queue-req: 30\n",
      ".[2025-08-13 20:11:59] Decode batch. #running-req: 64, #token: 227340, token usage: 0.92, cuda graph: True, gen throughput (token/s): 529.89, #queue-req: 34\n",
      "[2025-08-13 20:11:59] INFO:     127.0.0.1:48522 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:59] INFO:     127.0.0.1:40274 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:59] INFO:     127.0.0.1:40284 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:11:59] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.89, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:11:59] Prefill batch. #new-seq: 3, #new-token: 4126, #cached-token: 850, token usage: 0.92, #running-req: 61, #queue-req: 35\n",
      "[2025-08-13 20:12:03] INFO:     127.0.0.1:50396 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:12:03] Prefill batch. #new-seq: 2, #new-token: 5134, #cached-token: 599, token usage: 0.93, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:12:03] Decode batch. #running-req: 65, #token: 234290, token usage: 0.95, cuda graph: True, gen throughput (token/s): 573.34, #queue-req: 34\n",
      "[2025-08-13 20:12:04] INFO:     127.0.0.1:44564 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:04] Prefill batch. #new-seq: 1, #new-token: 7327, #cached-token: 710, token usage: 0.93, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:12:04] INFO:     127.0.0.1:52170 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:07] Decode batch. #running-req: 64, #token: 232592, token usage: 0.95, cuda graph: True, gen throughput (token/s): 737.01, #queue-req: 36\n",
      "[2025-08-13 20:12:07] INFO:     127.0.0.1:32782 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:07] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.95, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:12:08] INFO:     127.0.0.1:58636 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:08] INFO:     127.0.0.1:58360 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:08] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 532, token usage: 0.91, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 20:12:08] Prefill batch. #new-seq: 1, #new-token: 762, #cached-token: 0, token usage: 0.94, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:12:10] INFO:     127.0.0.1:52198 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:10] INFO:     127.0.0.1:43214 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:10] INFO:     127.0.0.1:45362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:10] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.90, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 20:12:10] INFO:     127.0.0.1:32798 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:10] Prefill batch. #new-seq: 3, #new-token: 1337, #cached-token: 821, token usage: 0.93, #running-req: 61, #queue-req: 34\n",
      "[2025-08-13 20:12:11] Prefill batch. #new-seq: 2, #new-token: 3219, #cached-token: 751, token usage: 0.94, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 20:12:12] Decode batch. #running-req: 65, #token: 233545, token usage: 0.95, cuda graph: True, gen throughput (token/s): 504.92, #queue-req: 32\n",
      "[2025-08-13 20:12:12] INFO:     127.0.0.1:32858 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:12] INFO:     127.0.0.1:32844 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:12] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1011, token usage: 0.92, #running-req: 63, #queue-req: 30\n",
      "[2025-08-13 20:12:12] Prefill batch. #new-seq: 1, #new-token: 820, #cached-token: 0, token usage: 0.96, #running-req: 64, #queue-req: 30\n",
      "[2025-08-13 20:12:14] INFO:     127.0.0.1:39176 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:16] Decode batch. #running-req: 64, #token: 236130, token usage: 0.96, cuda graph: True, gen throughput (token/s): 713.69, #queue-req: 36\n",
      "[2025-08-13 20:12:17] INFO:     127.0.0.1:39950 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:18] Decode batch. #running-req: 63, #token: 237552, token usage: 0.97, cuda graph: True, gen throughput (token/s): 923.11, #queue-req: 37\n",
      "[2025-08-13 20:12:21] Decode batch. #running-req: 63, #token: 240072, token usage: 0.98, cuda graph: True, gen throughput (token/s): 905.52, #queue-req: 37\n",
      "[2025-08-13 20:12:22] INFO:     127.0.0.1:60368 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:22] INFO:     127.0.0.1:43234 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:22] INFO:     127.0.0.1:46184 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:22] Prefill batch. #new-seq: 1, #new-token: 2210, #cached-token: 126, token usage: 0.94, #running-req: 60, #queue-req: 36\n",
      "[2025-08-13 20:12:24] Decode batch. #running-req: 61, #token: 234753, token usage: 0.95, cuda graph: True, gen throughput (token/s): 826.76, #queue-req: 36\n",
      "[2025-08-13 20:12:25] INFO:     127.0.0.1:39914 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:27] Decode batch. #running-req: 60, #token: 235688, token usage: 0.96, cuda graph: True, gen throughput (token/s): 857.25, #queue-req: 40\n",
      "[2025-08-13 20:12:28] INFO:     127.0.0.1:42728 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:28] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1048, token usage: 0.91, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:12:28] Prefill batch. #new-seq: 2, #new-token: 4087, #cached-token: 392, token usage: 0.94, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:12:31] Decode batch. #running-req: 62, #token: 236914, token usage: 0.96, cuda graph: True, gen throughput (token/s): 630.37, #queue-req: 38\n",
      "[2025-08-13 20:12:33] INFO:     127.0.0.1:42736 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:33] Decode batch. #running-req: 61, #token: 235178, token usage: 0.96, cuda graph: True, gen throughput (token/s): 903.78, #queue-req: 39\n",
      "[2025-08-13 20:12:34] INFO:     127.0.0.1:42744 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:35] INFO:     127.0.0.1:43236 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:35] INFO:     127.0.0.1:44514 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:36] INFO:     127.0.0.1:58612 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:36] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.91, #running-req: 57, #queue-req: 39\n",
      "[2025-08-13 20:12:36] Prefill batch. #new-seq: 1, #new-token: 3347, #cached-token: 0, token usage: 0.94, #running-req: 57, #queue-req: 39\n",
      "[2025-08-13 20:12:37] Decode batch. #running-req: 58, #token: 235118, token usage: 0.96, cuda graph: True, gen throughput (token/s): 592.30, #queue-req: 42\n",
      "[2025-08-13 20:12:38] INFO:     127.0.0.1:49514 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:38] Prefill batch. #new-seq: 1, #new-token: 422, #cached-token: 434, token usage: 0.94, #running-req: 57, #queue-req: 41\n",
      "[2025-08-13 20:12:39] INFO:     127.0.0.1:58358 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:39] Prefill batch. #new-seq: 2, #new-token: 3165, #cached-token: 489, token usage: 0.93, #running-req: 57, #queue-req: 39\n",
      "[2025-08-13 20:12:40] INFO:     127.0.0.1:43264 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:40] Prefill batch. #new-seq: 1, #new-token: 2355, #cached-token: 446, token usage: 0.94, #running-req: 58, #queue-req: 38\n",
      "[2025-08-13 20:12:41] Decode batch. #running-req: 59, #token: 233553, token usage: 0.95, cuda graph: True, gen throughput (token/s): 712.72, #queue-req: 39\n",
      "[2025-08-13 20:12:41] INFO:     127.0.0.1:40538 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:41] Prefill batch. #new-seq: 2, #new-token: 5303, #cached-token: 560, token usage: 0.94, #running-req: 58, #queue-req: 37\n",
      "[2025-08-13 20:12:42] INFO:     127.0.0.1:60326 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:42] Prefill batch. #new-seq: 1, #new-token: 2201, #cached-token: 462, token usage: 0.96, #running-req: 59, #queue-req: 36\n",
      "[2025-08-13 20:12:43] INFO:     127.0.0.1:60206 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:43] Prefill batch. #new-seq: 1, #new-token: 2881, #cached-token: 553, token usage: 0.95, #running-req: 59, #queue-req: 37\n",
      "[2025-08-13 20:12:43] INFO:     127.0.0.1:46150 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:43] Prefill batch. #new-seq: 1, #new-token: 2447, #cached-token: 191, token usage: 0.95, #running-req: 59, #queue-req: 36\n",
      "[2025-08-13 20:12:44] INFO:     127.0.0.1:39924 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:44] Prefill batch. #new-seq: 1, #new-token: 2372, #cached-token: 392, token usage: 0.95, #running-req: 59, #queue-req: 36\n",
      "[2025-08-13 20:12:45] Decode batch. #running-req: 60, #token: 235905, token usage: 0.96, cuda graph: True, gen throughput (token/s): 578.92, #queue-req: 37\n",
      "[2025-08-13 20:12:46] INFO:     127.0.0.1:45028 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:46] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.93, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:12:46] Prefill batch. #new-seq: 1, #new-token: 1204, #cached-token: 0, token usage: 0.96, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:12:47] INFO:     127.0.0.1:38318 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:12:47] Prefill batch. #new-seq: 2, #new-token: 2423, #cached-token: 559, token usage: 0.94, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:12:49] Decode batch. #running-req: 61, #token: 234754, token usage: 0.95, cuda graph: True, gen throughput (token/s): 604.58, #queue-req: 39\n",
      "[2025-08-13 20:12:52] Decode batch. #running-req: 61, #token: 237194, token usage: 0.96, cuda graph: True, gen throughput (token/s): 859.12, #queue-req: 39\n",
      "[2025-08-13 20:12:54] INFO:     127.0.0.1:49312 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:54] INFO:     127.0.0.1:46154 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:54] Prefill batch. #new-seq: 2, #new-token: 2244, #cached-token: 221, token usage: 0.95, #running-req: 59, #queue-req: 37\n",
      "[2025-08-13 20:12:55] INFO:     127.0.0.1:48518 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:55] Prefill batch. #new-seq: 1, #new-token: 2692, #cached-token: 392, token usage: 0.95, #running-req: 60, #queue-req: 36\n",
      "[2025-08-13 20:12:55] Decode batch. #running-req: 61, #token: 235655, token usage: 0.96, cuda graph: True, gen throughput (token/s): 738.96, #queue-req: 36\n",
      "[2025-08-13 20:12:57] INFO:     127.0.0.1:46168 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:57] Prefill batch. #new-seq: 3, #new-token: 4523, #cached-token: 951, token usage: 0.93, #running-req: 60, #queue-req: 33\n",
      "[2025-08-13 20:12:57] INFO:     127.0.0.1:36812 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:57] Prefill batch. #new-seq: 2, #new-token: 4778, #cached-token: 469, token usage: 0.94, #running-req: 62, #queue-req: 32\n",
      "[2025-08-13 20:12:59] Decode batch. #running-req: 64, #token: 235556, token usage: 0.96, cuda graph: True, gen throughput (token/s): 679.24, #queue-req: 36\n",
      "[2025-08-13 20:12:59] INFO:     127.0.0.1:52170 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:12:59] Prefill batch. #new-seq: 2, #new-token: 4444, #cached-token: 586, token usage: 0.94, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:13:02] Decode batch. #running-req: 65, #token: 237986, token usage: 0.97, cuda graph: True, gen throughput (token/s): 804.56, #queue-req: 35\n",
      "[2025-08-13 20:13:03] INFO:     127.0.0.1:51924 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:05] Decode batch. #running-req: 64, #token: 239853, token usage: 0.98, cuda graph: True, gen throughput (token/s): 921.65, #queue-req: 36\n",
      "[2025-08-13 20:13:05] INFO:     127.0.0.1:48522 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:05] INFO:     127.0.0.1:48842 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:07] INFO:     127.0.0.1:52198 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:07] Prefill batch. #new-seq: 1, #new-token: 7402, #cached-token: 509, token usage: 0.93, #running-req: 61, #queue-req: 35\n",
      "[2025-08-13 20:13:08] INFO:     127.0.0.1:40284 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:08] Prefill batch. #new-seq: 1, #new-token: 810, #cached-token: 470, token usage: 0.95, #running-req: 61, #queue-req: 35\n",
      "[2025-08-13 20:13:08] Decode batch. #running-req: 62, #token: 234020, token usage: 0.95, cuda graph: True, gen throughput (token/s): 706.46, #queue-req: 35\n",
      "[2025-08-13 20:13:11] Decode batch. #running-req: 62, #token: 236500, token usage: 0.96, cuda graph: True, gen throughput (token/s): 877.58, #queue-req: 38\n",
      "[2025-08-13 20:13:14] INFO:     127.0.0.1:45366 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:14] Decode batch. #running-req: 61, #token: 235403, token usage: 0.96, cuda graph: True, gen throughput (token/s): 873.72, #queue-req: 38\n",
      "[2025-08-13 20:13:17] Decode batch. #running-req: 61, #token: 237843, token usage: 0.97, cuda graph: True, gen throughput (token/s): 887.18, #queue-req: 39\n",
      "[2025-08-13 20:13:18] INFO:     127.0.0.1:58374 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:13:18] INFO:     127.0.0.1:57576 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:18] Prefill batch. #new-seq: 1, #new-token: 2451, #cached-token: 392, token usage: 0.96, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:13:19] INFO:     127.0.0.1:37000 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:19] Prefill batch. #new-seq: 1, #new-token: 2220, #cached-token: 93, token usage: 0.96, #running-req: 59, #queue-req: 37\n",
      ".[2025-08-13 20:13:20] Decode batch. #running-req: 60, #token: 238045, token usage: 0.97, cuda graph: True, gen throughput (token/s): 745.21, #queue-req: 38\n",
      "[2025-08-13 20:13:21] INFO:     127.0.0.1:40544 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:22] INFO:     127.0.0.1:49516 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:22] Prefill batch. #new-seq: 1, #new-token: 2322, #cached-token: 447, token usage: 0.95, #running-req: 58, #queue-req: 39\n",
      "[2025-08-13 20:13:23] Decode batch. #running-req: 59, #token: 237162, token usage: 0.96, cuda graph: True, gen throughput (token/s): 777.86, #queue-req: 41\n",
      "[2025-08-13 20:13:24] INFO:     127.0.0.1:58454 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:26] Decode batch. #running-req: 58, #token: 238464, token usage: 0.97, cuda graph: True, gen throughput (token/s): 851.59, #queue-req: 42\n",
      "[2025-08-13 20:13:26] INFO:     127.0.0.1:45800 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:27] INFO:     127.0.0.1:36980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:27] Prefill batch. #new-seq: 2, #new-token: 4383, #cached-token: 881, token usage: 0.94, #running-req: 56, #queue-req: 41\n",
      "[2025-08-13 20:13:27] INFO:     127.0.0.1:39898 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:27] Prefill batch. #new-seq: 1, #new-token: 2389, #cached-token: 409, token usage: 0.96, #running-req: 57, #queue-req: 40\n",
      "[2025-08-13 20:13:29] Decode batch. #running-req: 58, #token: 238522, token usage: 0.97, cuda graph: True, gen throughput (token/s): 691.58, #queue-req: 42\n",
      "[2025-08-13 20:13:29] INFO:     127.0.0.1:39176 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:29] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 93, token usage: 0.96, #running-req: 57, #queue-req: 41\n",
      "[2025-08-13 20:13:32] Decode batch. #running-req: 58, #token: 234434, token usage: 0.95, cuda graph: True, gen throughput (token/s): 838.23, #queue-req: 42\n",
      "[2025-08-13 20:13:32] INFO:     127.0.0.1:39930 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:32] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 136, token usage: 0.95, #running-req: 57, #queue-req: 42\n",
      "[2025-08-13 20:13:33] INFO:     127.0.0.1:39940 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:33] Prefill batch. #new-seq: 3, #new-token: 6641, #cached-token: 919, token usage: 0.92, #running-req: 57, #queue-req: 40\n",
      "[2025-08-13 20:13:35] INFO:     127.0.0.1:51794 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:35] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 545, token usage: 0.92, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:13:35] Prefill batch. #new-seq: 1, #new-token: 3430, #cached-token: 0, token usage: 0.95, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:13:36] INFO:     127.0.0.1:39974 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:36] Decode batch. #running-req: 60, #token: 226020, token usage: 0.92, cuda graph: True, gen throughput (token/s): 504.40, #queue-req: 40\n",
      "[2025-08-13 20:13:36] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 372, token usage: 0.92, #running-req: 59, #queue-req: 37\n",
      "[2025-08-13 20:13:37] Prefill batch. #new-seq: 2, #new-token: 2886, #cached-token: 438, token usage: 0.95, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 20:13:38] INFO:     127.0.0.1:39964 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:38] Prefill batch. #new-seq: 2, #new-token: 5133, #cached-token: 529, token usage: 0.94, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:13:41] Decode batch. #running-req: 64, #token: 237405, token usage: 0.97, cuda graph: True, gen throughput (token/s): 614.64, #queue-req: 36\n",
      "[2025-08-13 20:13:42] INFO:     127.0.0.1:48886 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:43] Decode batch. #running-req: 63, #token: 236370, token usage: 0.96, cuda graph: True, gen throughput (token/s): 929.57, #queue-req: 36\n",
      "[2025-08-13 20:13:44] INFO:     127.0.0.1:48874 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:44] Prefill batch. #new-seq: 2, #new-token: 4993, #cached-token: 552, token usage: 0.92, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:13:45] INFO:     127.0.0.1:51810 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:45] Prefill batch. #new-seq: 2, #new-token: 3243, #cached-token: 744, token usage: 0.93, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:13:46] INFO:     127.0.0.1:42744 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:46] Prefill batch. #new-seq: 2, #new-token: 2740, #cached-token: 863, token usage: 0.93, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:13:47] INFO:     127.0.0.1:58612 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:47] Prefill batch. #new-seq: 1, #new-token: 2360, #cached-token: 441, token usage: 0.93, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:13:47] Decode batch. #running-req: 65, #token: 230941, token usage: 0.94, cuda graph: True, gen throughput (token/s): 687.88, #queue-req: 33\n",
      "[2025-08-13 20:13:48] INFO:     127.0.0.1:39990 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:48] INFO:     127.0.0.1:42736 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:48] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1320, token usage: 0.89, #running-req: 64, #queue-req: 32\n",
      "[2025-08-13 20:13:48] Prefill batch. #new-seq: 1, #new-token: 1775, #cached-token: 0, token usage: 0.93, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:13:51] Decode batch. #running-req: 67, #token: 231784, token usage: 0.94, cuda graph: True, gen throughput (token/s): 662.94, #queue-req: 33\n",
      "[2025-08-13 20:13:54] Decode batch. #running-req: 67, #token: 234464, token usage: 0.95, cuda graph: True, gen throughput (token/s): 904.48, #queue-req: 33\n",
      "[2025-08-13 20:13:55] INFO:     127.0.0.1:51900 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:13:55] Prefill batch. #new-seq: 1, #new-token: 4871, #cached-token: 93, token usage: 0.94, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:13:58] Decode batch. #running-req: 67, #token: 238082, token usage: 0.97, cuda graph: True, gen throughput (token/s): 776.83, #queue-req: 33\n",
      "[2025-08-13 20:14:00] INFO:     127.0.0.1:58380 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:00] Prefill batch. #new-seq: 1, #new-token: 2507, #cached-token: 435, token usage: 0.94, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:14:01] Decode batch. #running-req: 67, #token: 233788, token usage: 0.95, cuda graph: True, gen throughput (token/s): 824.85, #queue-req: 33\n",
      "[2025-08-13 20:14:03] INFO:     127.0.0.1:48854 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:03] INFO:     127.0.0.1:45812 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:04] Decode batch. #running-req: 65, #token: 231779, token usage: 0.94, cuda graph: True, gen throughput (token/s): 888.83, #queue-req: 33\n",
      "[2025-08-13 20:14:04] INFO:     127.0.0.1:58394 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:04] INFO:     127.0.0.1:58402 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:04] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 551, token usage: 0.92, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 20:14:04] Prefill batch. #new-seq: 1, #new-token: 1283, #cached-token: 0, token usage: 0.95, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 20:14:06] INFO:     127.0.0.1:49284 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:06] Prefill batch. #new-seq: 2, #new-token: 4878, #cached-token: 558, token usage: 0.93, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:14:08] Decode batch. #running-req: 65, #token: 233499, token usage: 0.95, cuda graph: True, gen throughput (token/s): 602.04, #queue-req: 35\n",
      "[2025-08-13 20:14:08] INFO:     127.0.0.1:40548 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:08] Prefill batch. #new-seq: 1, #new-token: 299, #cached-token: 470, token usage: 0.95, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:14:11] INFO:     127.0.0.1:59644 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:11] Prefill batch. #new-seq: 3, #new-token: 4630, #cached-token: 1321, token usage: 0.91, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:14:11] Decode batch. #running-req: 67, #token: 229483, token usage: 0.93, cuda graph: True, gen throughput (token/s): 766.43, #queue-req: 33\n",
      "[2025-08-13 20:14:14] Decode batch. #running-req: 67, #token: 232163, token usage: 0.94, cuda graph: True, gen throughput (token/s): 950.37, #queue-req: 33\n",
      "[2025-08-13 20:14:14] INFO:     127.0.0.1:42538 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:14] Prefill batch. #new-seq: 4, #new-token: 2818, #cached-token: 1604, token usage: 0.92, #running-req: 66, #queue-req: 29\n",
      "[2025-08-13 20:14:17] Decode batch. #running-req: 70, #token: 232438, token usage: 0.95, cuda graph: True, gen throughput (token/s): 906.60, #queue-req: 30\n",
      "[2025-08-13 20:14:18] INFO:     127.0.0.1:60352 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:18] Prefill batch. #new-seq: 2, #new-token: 3255, #cached-token: 558, token usage: 0.94, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:14:18] INFO:     127.0.0.1:60372 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:18] Prefill batch. #new-seq: 1, #new-token: 5164, #cached-token: 553, token usage: 0.94, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:14:19] INFO:     127.0.0.1:45354 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:19] Prefill batch. #new-seq: 1, #new-token: 1000, #cached-token: 449, token usage: 0.95, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:14:19] INFO:     127.0.0.1:49516 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:19] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 204, token usage: 0.94, #running-req: 70, #queue-req: 28\n",
      ".[2025-08-13 20:14:20] INFO:     127.0.0.1:45368 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:20] Prefill batch. #new-seq: 1, #new-token: 7528, #cached-token: 509, token usage: 0.93, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:14:21] INFO:     127.0.0.1:45772 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:22] INFO:     127.0.0.1:51766 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:22] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 542, token usage: 0.95, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:14:22] INFO:     127.0.0.1:39898 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:22] Prefill batch. #new-seq: 1, #new-token: 4524, #cached-token: 120, token usage: 0.93, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:14:22] Decode batch. #running-req: 69, #token: 231952, token usage: 0.94, cuda graph: True, gen throughput (token/s): 624.00, #queue-req: 27\n",
      "[2025-08-13 20:14:22] INFO:     127.0.0.1:49286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:23] Prefill batch. #new-seq: 1, #new-token: 4184, #cached-token: 469, token usage: 0.93, #running-req: 69, #queue-req: 26\n",
      "[2025-08-13 20:14:24] INFO:     127.0.0.1:36760 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:25] INFO:     127.0.0.1:58480 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:25] Decode batch. #running-req: 68, #token: 231026, token usage: 0.94, cuda graph: True, gen throughput (token/s): 764.26, #queue-req: 30\n",
      "[2025-08-13 20:14:26] INFO:     127.0.0.1:58470 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:26] INFO:     127.0.0.1:55956 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:27] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.93, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:14:27] Prefill batch. #new-seq: 1, #new-token: 1205, #cached-token: 0, token usage: 0.96, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:14:28] INFO:     127.0.0.1:39940 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:28] Prefill batch. #new-seq: 1, #new-token: 7803, #cached-token: 393, token usage: 0.93, #running-req: 66, #queue-req: 30\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:14:29] INFO:     127.0.0.1:58460 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:29] INFO:     127.0.0.1:49298 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:29] INFO:     127.0.0.1:49314 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:30] Decode batch. #running-req: 64, #token: 228186, token usage: 0.93, cuda graph: True, gen throughput (token/s): 575.90, #queue-req: 36\n",
      "[2025-08-13 20:14:31] INFO:     127.0.0.1:49330 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:31] INFO:     127.0.0.1:51772 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:14:31] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.90, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:14:32] Prefill batch. #new-seq: 1, #new-token: 1528, #cached-token: 0, token usage: 0.93, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:14:33] INFO:     127.0.0.1:39930 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:33] Prefill batch. #new-seq: 2, #new-token: 7659, #cached-token: 855, token usage: 0.92, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:14:35] Decode batch. #running-req: 64, #token: 230468, token usage: 0.94, cuda graph: True, gen throughput (token/s): 568.58, #queue-req: 36\n",
      "[2025-08-13 20:14:35] INFO:     127.0.0.1:36990 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:35] INFO:     127.0.0.1:39964 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:35] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.91, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:14:35] Prefill batch. #new-seq: 2, #new-token: 1858, #cached-token: 412, token usage: 0.94, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 20:14:37] INFO:     127.0.0.1:36970 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:37] Prefill batch. #new-seq: 2, #new-token: 391, #cached-token: 293, token usage: 0.95, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:14:37] INFO:     127.0.0.1:44490 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:37] Prefill batch. #new-seq: 1, #new-token: 7525, #cached-token: 464, token usage: 0.93, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:14:38] INFO:     127.0.0.1:44498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:39] Prefill batch. #new-seq: 1, #new-token: 2223, #cached-token: 93, token usage: 0.95, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:14:39] Decode batch. #running-req: 65, #token: 228383, token usage: 0.93, cuda graph: True, gen throughput (token/s): 528.34, #queue-req: 35\n",
      "[2025-08-13 20:14:39] INFO:     127.0.0.1:44506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:40] Prefill batch. #new-seq: 1, #new-token: 3057, #cached-token: 409, token usage: 0.93, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:14:43] Decode batch. #running-req: 65, #token: 234038, token usage: 0.95, cuda graph: True, gen throughput (token/s): 798.62, #queue-req: 35\n",
      "[2025-08-13 20:14:45] INFO:     127.0.0.1:48850 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:45] INFO:     127.0.0.1:44508 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:46] Decode batch. #running-req: 63, #token: 229893, token usage: 0.94, cuda graph: True, gen throughput (token/s): 880.61, #queue-req: 35\n",
      "[2025-08-13 20:14:46] INFO:     127.0.0.1:39990 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:46] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.90, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:14:46] Prefill batch. #new-seq: 2, #new-token: 3541, #cached-token: 452, token usage: 0.94, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 20:14:48] INFO:     127.0.0.1:51816 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:48] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1467, token usage: 0.89, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 20:14:48] INFO:     127.0.0.1:58380 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:48] Prefill batch. #new-seq: 2, #new-token: 2955, #cached-token: 672, token usage: 0.92, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:14:49] INFO:     127.0.0.1:54784 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:51] Decode batch. #running-req: 66, #token: 229421, token usage: 0.93, cuda graph: True, gen throughput (token/s): 522.67, #queue-req: 34\n",
      "[2025-08-13 20:14:53] INFO:     127.0.0.1:48862 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:54] Decode batch. #running-req: 65, #token: 227699, token usage: 0.93, cuda graph: True, gen throughput (token/s): 875.64, #queue-req: 35\n",
      "[2025-08-13 20:14:54] INFO:     127.0.0.1:44986 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:56] INFO:     127.0.0.1:51782 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:14:56] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.90, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:14:56] Prefill batch. #new-seq: 3, #new-token: 5878, #cached-token: 259, token usage: 0.94, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:14:58] Decode batch. #running-req: 66, #token: 236284, token usage: 0.96, cuda graph: True, gen throughput (token/s): 604.06, #queue-req: 34\n",
      "[2025-08-13 20:14:59] INFO:     127.0.0.1:58402 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:00] INFO:     127.0.0.1:58394 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:00] INFO:     127.0.0.1:40548 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:00] Prefill batch. #new-seq: 2, #new-token: 6585, #cached-token: 570, token usage: 0.93, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 20:15:02] Decode batch. #running-req: 65, #token: 236619, token usage: 0.96, cuda graph: True, gen throughput (token/s): 718.04, #queue-req: 35\n",
      "[2025-08-13 20:15:02] INFO:     127.0.0.1:48926 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:02] Prefill batch. #new-seq: 1, #new-token: 2505, #cached-token: 77, token usage: 0.96, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:15:03] INFO:     127.0.0.1:45368 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:03] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 77, token usage: 0.96, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:15:05] INFO:     127.0.0.1:44532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:05] INFO:     127.0.0.1:36998 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:05] Prefill batch. #new-seq: 3, #new-token: 6222, #cached-token: 1002, token usage: 0.91, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:15:05] Prefill batch. #new-seq: 2, #new-token: 3213, #cached-token: 1002, token usage: 0.94, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:15:06] Decode batch. #running-req: 68, #token: 233631, token usage: 0.95, cuda graph: True, gen throughput (token/s): 624.02, #queue-req: 32\n",
      "[2025-08-13 20:15:08] INFO:     127.0.0.1:59644 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:08] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 902, token usage: 0.91, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:15:08] Prefill batch. #new-seq: 1, #new-token: 1548, #cached-token: 0, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:15:10] Decode batch. #running-req: 69, #token: 234361, token usage: 0.95, cuda graph: True, gen throughput (token/s): 697.27, #queue-req: 31\n",
      "[2025-08-13 20:15:10] INFO:     127.0.0.1:60352 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:10] Prefill batch. #new-seq: 1, #new-token: 2361, #cached-token: 441, token usage: 0.95, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:15:12] INFO:     127.0.0.1:45762 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:15:12] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 469, token usage: 0.95, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:15:12] INFO:     127.0.0.1:60372 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:12] INFO:     127.0.0.1:45354 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:12] Prefill batch. #new-seq: 2, #new-token: 6742, #cached-token: 894, token usage: 0.92, #running-req: 67, #queue-req: 28\n",
      "[2025-08-13 20:15:13] Decode batch. #running-req: 69, #token: 233572, token usage: 0.95, cuda graph: True, gen throughput (token/s): 716.76, #queue-req: 28\n",
      ".[2025-08-13 20:15:16] Decode batch. #running-req: 69, #token: 236332, token usage: 0.96, cuda graph: True, gen throughput (token/s): 910.11, #queue-req: 31\n",
      "[2025-08-13 20:15:20] Decode batch. #running-req: 69, #token: 239092, token usage: 0.97, cuda graph: True, gen throughput (token/s): 902.64, #queue-req: 31\n",
      "[2025-08-13 20:15:23] Decode batch. #running-req: 69, #token: 234856, token usage: 0.96, cuda graph: True, gen throughput (token/s): 895.17, #queue-req: 31\n",
      "[2025-08-13 20:15:23] INFO:     127.0.0.1:49298 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:23] INFO:     127.0.0.1:49314 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:23] INFO:     127.0.0.1:39410 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:23] INFO:     127.0.0.1:45786 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:23] Prefill batch. #new-seq: 1, #new-token: 2242, #cached-token: 446, token usage: 0.95, #running-req: 65, #queue-req: 30\n",
      "[2025-08-13 20:15:26] Decode batch. #running-req: 66, #token: 237168, token usage: 0.96, cuda graph: True, gen throughput (token/s): 793.80, #queue-req: 30\n",
      "[2025-08-13 20:15:29] Decode batch. #running-req: 66, #token: 239808, token usage: 0.98, cuda graph: True, gen throughput (token/s): 836.67, #queue-req: 34\n",
      "[2025-08-13 20:15:32] INFO:     127.0.0.1:51908 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:32] Prefill batch. #new-seq: 2, #new-token: 6996, #cached-token: 717, token usage: 0.93, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:15:33] Decode batch. #running-req: 67, #token: 235991, token usage: 0.96, cuda graph: True, gen throughput (token/s): 693.66, #queue-req: 33\n",
      "[2025-08-13 20:15:34] INFO:     127.0.0.1:49330 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:34] Prefill batch. #new-seq: 2, #new-token: 4718, #cached-token: 886, token usage: 0.93, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:15:35] INFO:     127.0.0.1:57570 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:35] Prefill batch. #new-seq: 1, #new-token: 5490, #cached-token: 508, token usage: 0.94, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:15:36] INFO:     127.0.0.1:57578 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:36] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 447, token usage: 0.94, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:15:37] Decode batch. #running-req: 68, #token: 237132, token usage: 0.96, cuda graph: True, gen throughput (token/s): 638.14, #queue-req: 32\n",
      "[2025-08-13 20:15:37] INFO:     127.0.0.1:57580 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:37] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 392, token usage: 0.96, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:15:39] INFO:     127.0.0.1:57596 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:39] Prefill batch. #new-seq: 1, #new-token: 4278, #cached-token: 143, token usage: 0.94, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:15:40] INFO:     127.0.0.1:36736 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:40] INFO:     127.0.0.1:58430 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:40] INFO:     127.0.0.1:44498 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:40] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 846, token usage: 0.92, #running-req: 65, #queue-req: 30\n",
      "[2025-08-13 20:15:40] Prefill batch. #new-seq: 1, #new-token: 3331, #cached-token: 0, token usage: 0.95, #running-req: 66, #queue-req: 30\n",
      "..[2025-08-13 20:15:41] INFO:     127.0.0.1:44506 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:41] Prefill batch. #new-seq: 1, #new-token: 196, #cached-token: 123, token usage: 0.93, #running-req: 66, #queue-req: 29\n",
      "[2025-08-13 20:15:42] Decode batch. #running-req: 67, #token: 230131, token usage: 0.94, cuda graph: True, gen throughput (token/s): 612.08, #queue-req: 29\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:15:43] INFO:     127.0.0.1:45748 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:43] Prefill batch. #new-seq: 1, #new-token: 5577, #cached-token: 551, token usage: 0.93, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:15:45] INFO:     127.0.0.1:58446 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:45] Prefill batch. #new-seq: 2, #new-token: 6986, #cached-token: 310, token usage: 0.92, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:15:46] Decode batch. #running-req: 68, #token: 233938, token usage: 0.95, cuda graph: True, gen throughput (token/s): 659.74, #queue-req: 31\n",
      "[2025-08-13 20:15:46] INFO:     127.0.0.1:54784 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:15:48] INFO:     127.0.0.1:36706 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:48] INFO:     127.0.0.1:44490 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:48] Prefill batch. #new-seq: 1, #new-token: 7631, #cached-token: 463, token usage: 0.92, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:15:48] INFO:     127.0.0.1:42066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:49] Prefill batch. #new-seq: 1, #new-token: 4370, #cached-token: 452, token usage: 0.95, #running-req: 65, #queue-req: 31\n",
      "[2025-08-13 20:15:50] Decode batch. #running-req: 66, #token: 237424, token usage: 0.97, cuda graph: True, gen throughput (token/s): 645.57, #queue-req: 31\n",
      "[2025-08-13 20:15:52] INFO:     127.0.0.1:38836 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:52] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 93, token usage: 0.96, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:15:52] INFO:     127.0.0.1:45770 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:53] Decode batch. #running-req: 65, #token: 234374, token usage: 0.95, cuda graph: True, gen throughput (token/s): 884.87, #queue-req: 33\n",
      "[2025-08-13 20:15:53] INFO:     127.0.0.1:44508 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:53] Prefill batch. #new-seq: 1, #new-token: 7016, #cached-token: 465, token usage: 0.94, #running-req: 64, #queue-req: 32\n",
      "[2025-08-13 20:15:55] INFO:     127.0.0.1:51782 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:55] Prefill batch. #new-seq: 1, #new-token: 2224, #cached-token: 409, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:15:56] INFO:     127.0.0.1:48896 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:56] Prefill batch. #new-seq: 1, #new-token: 2385, #cached-token: 412, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:15:57] Decode batch. #running-req: 65, #token: 235951, token usage: 0.96, cuda graph: True, gen throughput (token/s): 648.65, #queue-req: 34\n",
      "[2025-08-13 20:15:59] INFO:     127.0.0.1:42572 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:15:59] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 412, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:16:00] Decode batch. #running-req: 65, #token: 236181, token usage: 0.96, cuda graph: True, gen throughput (token/s): 810.07, #queue-req: 34\n",
      "[2025-08-13 20:16:00] INFO:     127.0.0.1:48862 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:00] Prefill batch. #new-seq: 2, #new-token: 769, #cached-token: 511, token usage: 0.94, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:16:01] INFO:     127.0.0.1:45010 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:03] Decode batch. #running-req: 65, #token: 232129, token usage: 0.94, cuda graph: True, gen throughput (token/s): 895.00, #queue-req: 35\n",
      "[2025-08-13 20:16:06] Decode batch. #running-req: 65, #token: 234729, token usage: 0.95, cuda graph: True, gen throughput (token/s): 912.41, #queue-req: 35\n",
      "[2025-08-13 20:16:06] INFO:     127.0.0.1:39416 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:08] Decode batch. #running-req: 64, #token: 235984, token usage: 0.96, cuda graph: True, gen throughput (token/s): 930.36, #queue-req: 36\n",
      "[2025-08-13 20:16:11] Decode batch. #running-req: 64, #token: 238544, token usage: 0.97, cuda graph: True, gen throughput (token/s): 927.46, #queue-req: 36\n",
      "[2025-08-13 20:16:14] Decode batch. #running-req: 64, #token: 241104, token usage: 0.98, cuda graph: True, gen throughput (token/s): 919.45, #queue-req: 36\n",
      "[2025-08-13 20:16:17] Decode batch. #running-req: 64, #token: 243664, token usage: 0.99, cuda graph: True, gen throughput (token/s): 911.15, #queue-req: 36\n",
      "[2025-08-13 20:16:18] INFO:     127.0.0.1:59256 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:18] INFO:     127.0.0.1:46232 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:16:19] INFO:     127.0.0.1:42114 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:19] INFO:     127.0.0.1:58462 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:20] Decode batch. #running-req: 60, #token: 236653, token usage: 0.96, cuda graph: True, gen throughput (token/s): 893.73, #queue-req: 38\n",
      "[2025-08-13 20:16:20] INFO:     127.0.0.1:39400 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:20] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 551, token usage: 0.92, #running-req: 59, #queue-req: 37\n",
      "[2025-08-13 20:16:20] Prefill batch. #new-seq: 2, #new-token: 5536, #cached-token: 124, token usage: 0.95, #running-req: 59, #queue-req: 36\n",
      ".[2025-08-13 20:16:24] Decode batch. #running-req: 61, #token: 241738, token usage: 0.98, cuda graph: True, gen throughput (token/s): 586.52, #queue-req: 39\n",
      "[2025-08-13 20:16:24] INFO:     127.0.0.1:42632 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:24] INFO:     127.0.0.1:44532 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:24] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 710, token usage: 0.90, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:16:25] INFO:     127.0.0.1:38860 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:25] Prefill batch. #new-seq: 4, #new-token: 3665, #cached-token: 652, token usage: 0.93, #running-req: 59, #queue-req: 35\n",
      "[2025-08-13 20:16:26] Prefill batch. #new-seq: 2, #new-token: 2247, #cached-token: 883, token usage: 0.94, #running-req: 62, #queue-req: 33\n",
      "[2025-08-13 20:16:26] INFO:     127.0.0.1:58466 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:26] INFO:     127.0.0.1:59244 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:26] Prefill batch. #new-seq: 2, #new-token: 7407, #cached-token: 991, token usage: 0.93, #running-req: 63, #queue-req: 31\n",
      "[2025-08-13 20:16:27] Prefill batch. #new-seq: 1, #new-token: 344, #cached-token: 438, token usage: 0.96, #running-req: 64, #queue-req: 31\n",
      "[2025-08-13 20:16:29] Decode batch. #running-req: 65, #token: 236764, token usage: 0.96, cuda graph: True, gen throughput (token/s): 512.01, #queue-req: 35\n",
      "[2025-08-13 20:16:32] Decode batch. #running-req: 65, #token: 239364, token usage: 0.97, cuda graph: True, gen throughput (token/s): 881.59, #queue-req: 35\n",
      "[2025-08-13 20:16:32] INFO:     127.0.0.1:44996 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:32] INFO:     127.0.0.1:48888 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:32] INFO:     127.0.0.1:36998 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:16:33] INFO:     127.0.0.1:44998 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:33] INFO:     127.0.0.1:45008 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:33] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 545, token usage: 0.92, #running-req: 60, #queue-req: 35\n",
      "[2025-08-13 20:16:33] Prefill batch. #new-seq: 1, #new-token: 5286, #cached-token: 0, token usage: 0.95, #running-req: 60, #queue-req: 35\n",
      "[2025-08-13 20:16:35] INFO:     127.0.0.1:56522 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:35] INFO:     127.0.0.1:38846 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:35] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 439, token usage: 0.96, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:16:36] INFO:     127.0.0.1:46344 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:36] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1004, token usage: 0.90, #running-req: 59, #queue-req: 36\n",
      "[2025-08-13 20:16:36] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 489, token usage: 0.94, #running-req: 60, #queue-req: 34\n",
      "[2025-08-13 20:16:36] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 0, token usage: 0.97, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:16:38] Decode batch. #running-req: 63, #token: 236475, token usage: 0.96, cuda graph: True, gen throughput (token/s): 424.23, #queue-req: 37\n",
      "[2025-08-13 20:16:38] INFO:     127.0.0.1:46348 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:38] INFO:     127.0.0.1:46364 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:39] INFO:     127.0.0.1:51908 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:39] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 1777, token usage: 0.90, #running-req: 60, #queue-req: 34\n",
      "[2025-08-13 20:16:39] Prefill batch. #new-seq: 1, #new-token: 1678, #cached-token: 0, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:16:41] INFO:     127.0.0.1:57596 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:41] Prefill batch. #new-seq: 2, #new-token: 7646, #cached-token: 605, token usage: 0.93, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:16:42] Decode batch. #running-req: 66, #token: 235667, token usage: 0.96, cuda graph: True, gen throughput (token/s): 568.17, #queue-req: 34\n",
      "[2025-08-13 20:16:44] INFO:     127.0.0.1:51490 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:16:44] Prefill batch. #new-seq: 1, #new-token: 4993, #cached-token: 626, token usage: 0.94, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:16:45] INFO:     127.0.0.1:42596 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:45] Prefill batch. #new-seq: 2, #new-token: 346, #cached-token: 571, token usage: 0.95, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:16:45] Decode batch. #running-req: 67, #token: 233270, token usage: 0.95, cuda graph: True, gen throughput (token/s): 774.47, #queue-req: 32\n",
      "[2025-08-13 20:16:46] INFO:     127.0.0.1:42552 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:46] INFO:     127.0.0.1:42556 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:46] Prefill batch. #new-seq: 2, #new-token: 7258, #cached-token: 771, token usage: 0.92, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:16:47] INFO:     127.0.0.1:57580 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:47] Prefill batch. #new-seq: 2, #new-token: 4503, #cached-token: 931, token usage: 0.94, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:16:48] INFO:     127.0.0.1:42588 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:48] Prefill batch. #new-seq: 2, #new-token: 649, #cached-token: 887, token usage: 0.95, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:16:48] INFO:     127.0.0.1:36746 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:48] Prefill batch. #new-seq: 2, #new-token: 3488, #cached-token: 586, token usage: 0.93, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:16:49] INFO:     127.0.0.1:51504 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:49] Prefill batch. #new-seq: 5, #new-token: 7400, #cached-token: 1561, token usage: 0.90, #running-req: 69, #queue-req: 25\n",
      "[2025-08-13 20:16:49] INFO:     127.0.0.1:42608 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:16:50] Prefill batch. #new-seq: 2, #new-token: 4192, #cached-token: 646, token usage: 0.93, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 20:16:51] INFO:     127.0.0.1:42622 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:51] Decode batch. #running-req: 75, #token: 229747, token usage: 0.93, cuda graph: True, gen throughput (token/s): 525.37, #queue-req: 25\n",
      "[2025-08-13 20:16:51] INFO:     127.0.0.1:37120 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:51] INFO:     127.0.0.1:57570 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:51] INFO:     127.0.0.1:57578 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:51] Prefill batch. #new-seq: 1, #new-token: 7684, #cached-token: 464, token usage: 0.90, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:16:52] INFO:     127.0.0.1:58466 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:52] INFO:     127.0.0.1:55962 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:52] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.89, #running-req: 70, #queue-req: 24\n",
      "[2025-08-13 20:16:52] Prefill batch. #new-seq: 2, #new-token: 3722, #cached-token: 438, token usage: 0.93, #running-req: 70, #queue-req: 23\n",
      "[2025-08-13 20:16:55] INFO:     127.0.0.1:45748 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:16:55] Prefill batch. #new-seq: 1, #new-token: 2397, #cached-token: 446, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:16:56] Decode batch. #running-req: 72, #token: 233865, token usage: 0.95, cuda graph: True, gen throughput (token/s): 557.32, #queue-req: 27\n",
      "[2025-08-13 20:16:59] Decode batch. #running-req: 72, #token: 236745, token usage: 0.96, cuda graph: True, gen throughput (token/s): 973.25, #queue-req: 28\n",
      "[2025-08-13 20:17:00] INFO:     127.0.0.1:36694 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:00] Prefill batch. #new-seq: 1, #new-token: 2110, #cached-token: 175, token usage: 0.94, #running-req: 71, #queue-req: 28\n",
      "[2025-08-13 20:17:02] INFO:     127.0.0.1:58462 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:02] Prefill batch. #new-seq: 1, #new-token: 4374, #cached-token: 448, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:17:02] Decode batch. #running-req: 71, #token: 234793, token usage: 0.96, cuda graph: True, gen throughput (token/s): 899.89, #queue-req: 27\n",
      "[2025-08-13 20:17:04] INFO:     127.0.0.1:39382 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:04] Prefill batch. #new-seq: 3, #new-token: 5085, #cached-token: 1350, token usage: 0.92, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:17:06] Decode batch. #running-req: 74, #token: 231596, token usage: 0.94, cuda graph: True, gen throughput (token/s): 769.03, #queue-req: 26\n",
      "[2025-08-13 20:17:07] INFO:     127.0.0.1:42102 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:17:08] INFO:     127.0.0.1:44998 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:08] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 475, token usage: 0.90, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:17:08] Prefill batch. #new-seq: 1, #new-token: 5520, #cached-token: 0, token usage: 0.94, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:17:10] Decode batch. #running-req: 73, #token: 236281, token usage: 0.96, cuda graph: True, gen throughput (token/s): 664.05, #queue-req: 27\n",
      "[2025-08-13 20:17:10] INFO:     127.0.0.1:44996 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:10] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 146, token usage: 0.95, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:17:11] INFO:     127.0.0.1:36720 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:11] Prefill batch. #new-seq: 3, #new-token: 6817, #cached-token: 1433, token usage: 0.91, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 20:17:14] Decode batch. #running-req: 75, #token: 232397, token usage: 0.95, cuda graph: True, gen throughput (token/s): 862.40, #queue-req: 25\n",
      "[2025-08-13 20:17:14] INFO:     127.0.0.1:37122 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:14] INFO:     127.0.0.1:45008 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:15] INFO:     127.0.0.1:46564 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:15] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.90, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:17:15] Prefill batch. #new-seq: 1, #new-token: 5452, #cached-token: 0, token usage: 0.93, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:17:18] INFO:     127.0.0.1:36774 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:18] INFO:     127.0.0.1:38840 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:18] Prefill batch. #new-seq: 2, #new-token: 2349, #cached-token: 937, token usage: 0.93, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:17:18] Decode batch. #running-req: 73, #token: 232062, token usage: 0.94, cuda graph: True, gen throughput (token/s): 627.30, #queue-req: 27\n",
      "[2025-08-13 20:17:19] INFO:     127.0.0.1:52726 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:19] Prefill batch. #new-seq: 1, #new-token: 2945, #cached-token: 465, token usage: 0.94, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:17:21] INFO:     127.0.0.1:37138 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:21] Decode batch. #running-req: 72, #token: 236905, token usage: 0.96, cuda graph: True, gen throughput (token/s): 925.52, #queue-req: 27\n",
      "[2025-08-13 20:17:22] INFO:     127.0.0.1:48894 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:22] INFO:     127.0.0.1:46344 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:22] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 535, token usage: 0.90, #running-req: 70, #queue-req: 25\n",
      "[2025-08-13 20:17:22] Prefill batch. #new-seq: 3, #new-token: 3629, #cached-token: 197, token usage: 0.93, #running-req: 71, #queue-req: 23\n",
      "[2025-08-13 20:17:24] INFO:     127.0.0.1:46348 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:24] INFO:     127.0.0.1:46364 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:24] Prefill batch. #new-seq: 2, #new-token: 6801, #cached-token: 924, token usage: 0.93, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:17:24] INFO:     127.0.0.1:42556 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:25] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 412, token usage: 0.94, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 20:17:25] INFO:     127.0.0.1:36746 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:25] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 902, token usage: 0.93, #running-req: 73, #queue-req: 21\n",
      "[2025-08-13 20:17:25] Prefill batch. #new-seq: 1, #new-token: 548, #cached-token: 0, token usage: 0.96, #running-req: 74, #queue-req: 21\n",
      "[2025-08-13 20:17:27] Decode batch. #running-req: 75, #token: 237462, token usage: 0.97, cuda graph: True, gen throughput (token/s): 555.04, #queue-req: 22\n",
      "[2025-08-13 20:17:27] INFO:     127.0.0.1:48910 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:28] Prefill batch. #new-seq: 2, #new-token: 2380, #cached-token: 570, token usage: 0.94, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:17:28] INFO:     127.0.0.1:48928 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:28] Prefill batch. #new-seq: 1, #new-token: 2224, #cached-token: 409, token usage: 0.94, #running-req: 75, #queue-req: 24\n",
      "[2025-08-13 20:17:30] INFO:     127.0.0.1:51482 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:30] Decode batch. #running-req: 75, #token: 233619, token usage: 0.95, cuda graph: True, gen throughput (token/s): 906.52, #queue-req: 25\n",
      "[2025-08-13 20:17:30] INFO:     127.0.0.1:60724 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:30] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 447, token usage: 0.95, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:17:31] INFO:     127.0.0.1:42552 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:17:31] Prefill batch. #new-seq: 1, #new-token: 2165, #cached-token: 467, token usage: 0.94, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:17:33] Decode batch. #running-req: 75, #token: 235791, token usage: 0.96, cuda graph: True, gen throughput (token/s): 901.28, #queue-req: 25\n",
      "[2025-08-13 20:17:34] INFO:     127.0.0.1:42588 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:35] INFO:     127.0.0.1:42608 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:36] INFO:     127.0.0.1:56506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:36] INFO:     127.0.0.1:42622 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:36] INFO:     127.0.0.1:55962 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:36] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 664, token usage: 0.90, #running-req: 70, #queue-req: 25\n",
      "[2025-08-13 20:17:36] Decode batch. #running-req: 70, #token: 229380, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1002.99, #queue-req: 25\n",
      "[2025-08-13 20:17:36] Prefill batch. #new-seq: 1, #new-token: 760, #cached-token: 0, token usage: 0.93, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:17:38] INFO:     127.0.0.1:36694 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:38] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.91, #running-req: 71, #queue-req: 24\n",
      "[2025-08-13 20:17:38] Prefill batch. #new-seq: 1, #new-token: 1687, #cached-token: 0, token usage: 0.94, #running-req: 71, #queue-req: 24\n",
      ".[2025-08-13 20:17:40] INFO:     127.0.0.1:46238 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:40] Prefill batch. #new-seq: 2, #new-token: 2354, #cached-token: 629, token usage: 0.93, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:17:40] INFO:     127.0.0.1:39392 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:41] INFO:     127.0.0.1:46550 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:41] Decode batch. #running-req: 71, #token: 228593, token usage: 0.93, cuda graph: True, gen throughput (token/s): 580.25, #queue-req: 28\n",
      "[2025-08-13 20:17:43] INFO:     127.0.0.1:45758 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:43] INFO:     127.0.0.1:58770 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:43] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.89, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:17:43] Prefill batch. #new-seq: 2, #new-token: 5673, #cached-token: 96, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:17:46] Decode batch. #running-req: 71, #token: 234266, token usage: 0.95, cuda graph: True, gen throughput (token/s): 655.41, #queue-req: 29\n",
      "[2025-08-13 20:17:46] INFO:     127.0.0.1:45782 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:46] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 450, token usage: 0.93, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:17:46] INFO:     127.0.0.1:46536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:46] Prefill batch. #new-seq: 1, #new-token: 3113, #cached-token: 480, token usage: 0.94, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:17:49] Decode batch. #running-req: 71, #token: 236861, token usage: 0.96, cuda graph: True, gen throughput (token/s): 832.37, #queue-req: 29\n",
      "[2025-08-13 20:17:50] INFO:     127.0.0.1:46540 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:50] Prefill batch. #new-seq: 1, #new-token: 337, #cached-token: 439, token usage: 0.94, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:17:51] INFO:     127.0.0.1:36754 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:52] INFO:     127.0.0.1:60748 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:52] Prefill batch. #new-seq: 2, #new-token: 6879, #cached-token: 876, token usage: 0.94, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:17:53] INFO:     127.0.0.1:60760 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:53] Decode batch. #running-req: 71, #token: 237287, token usage: 0.97, cuda graph: True, gen throughput (token/s): 785.36, #queue-req: 27\n",
      "[2025-08-13 20:17:54] INFO:     127.0.0.1:51536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:54] INFO:     127.0.0.1:51552 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:54] INFO:     127.0.0.1:39876 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:54] Prefill batch. #new-seq: 3, #new-token: 2521, #cached-token: 1097, token usage: 0.93, #running-req: 67, #queue-req: 24\n",
      "[2025-08-13 20:17:54] INFO:     127.0.0.1:56542 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:54] INFO:     127.0.0.1:37104 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:55] INFO:     127.0.0.1:60734 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:55] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 545, token usage: 0.90, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:17:55] Prefill batch. #new-seq: 1, #new-token: 5616, #cached-token: 0, token usage: 0.94, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:17:57] INFO:     127.0.0.1:36720 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:17:57] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1178, token usage: 0.91, #running-req: 67, #queue-req: 27\n",
      "[2025-08-13 20:17:57] Prefill batch. #new-seq: 1, #new-token: 910, #cached-token: 0, token usage: 0.95, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:17:58] Decode batch. #running-req: 69, #token: 234053, token usage: 0.95, cuda graph: True, gen throughput (token/s): 498.99, #queue-req: 31\n",
      "[2025-08-13 20:18:01] Decode batch. #running-req: 69, #token: 236813, token usage: 0.96, cuda graph: True, gen throughput (token/s): 982.90, #queue-req: 31\n",
      "[2025-08-13 20:18:03] INFO:     127.0.0.1:39246 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:04] INFO:     127.0.0.1:48894 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:04] INFO:     127.0.0.1:39880 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:04] Prefill batch. #new-seq: 1, #new-token: 2897, #cached-token: 392, token usage: 0.94, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:18:04] Decode batch. #running-req: 66, #token: 234459, token usage: 0.95, cuda graph: True, gen throughput (token/s): 950.44, #queue-req: 31\n",
      "[2025-08-13 20:18:05] INFO:     127.0.0.1:36774 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:05] INFO:     127.0.0.1:38840 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:05] Prefill batch. #new-seq: 1, #new-token: 2808, #cached-token: 462, token usage: 0.93, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:18:06] INFO:     127.0.0.1:59234 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:06] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 757, token usage: 0.93, #running-req: 65, #queue-req: 30\n",
      "[2025-08-13 20:18:06] Prefill batch. #new-seq: 1, #new-token: 1078, #cached-token: 0, token usage: 0.96, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:18:08] Decode batch. #running-req: 67, #token: 238400, token usage: 0.97, cuda graph: True, gen throughput (token/s): 610.37, #queue-req: 33\n",
      "[2025-08-13 20:18:11] INFO:     127.0.0.1:42076 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:11] INFO:     127.0.0.1:42086 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:11] Prefill batch. #new-seq: 2, #new-token: 2524, #cached-token: 1059, token usage: 0.95, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:18:11] INFO:     127.0.0.1:42116 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:11] Decode batch. #running-req: 66, #token: 236610, token usage: 0.96, cuda graph: True, gen throughput (token/s): 851.09, #queue-req: 34\n",
      "[2025-08-13 20:18:14] INFO:     127.0.0.1:42132 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:14] INFO:     127.0.0.1:39940 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:14] Prefill batch. #new-seq: 3, #new-token: 5014, #cached-token: 595, token usage: 0.91, #running-req: 64, #queue-req: 32\n",
      "[2025-08-13 20:18:15] INFO:     127.0.0.1:48928 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:15] Prefill batch. #new-seq: 2, #new-token: 3894, #cached-token: 877, token usage: 0.93, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:18:15] Decode batch. #running-req: 68, #token: 232130, token usage: 0.94, cuda graph: True, gen throughput (token/s): 705.59, #queue-req: 31\n",
      "[2025-08-13 20:18:16] INFO:     127.0.0.1:56474 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:16] Prefill batch. #new-seq: 2, #new-token: 2332, #cached-token: 488, token usage: 0.93, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:18:18] INFO:     127.0.0.1:56490 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:18] INFO:     127.0.0.1:48910 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:18] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 924, token usage: 0.91, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:18:18] Prefill batch. #new-seq: 3, #new-token: 3511, #cached-token: 534, token usage: 0.94, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:18:19] INFO:     127.0.0.1:40996 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:19] Decode batch. #running-req: 70, #token: 232404, token usage: 0.95, cuda graph: True, gen throughput (token/s): 650.17, #queue-req: 29\n",
      "[2025-08-13 20:18:22] Decode batch. #running-req: 70, #token: 235204, token usage: 0.96, cuda graph: True, gen throughput (token/s): 947.27, #queue-req: 30\n",
      "[2025-08-13 20:18:23] INFO:     127.0.0.1:51482 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:25] INFO:     127.0.0.1:46238 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:25] Decode batch. #running-req: 68, #token: 228805, token usage: 0.93, cuda graph: True, gen throughput (token/s): 946.32, #queue-req: 31\n",
      "[2025-08-13 20:18:26] INFO:     127.0.0.1:39392 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:27] Prefill batch. #new-seq: 1, #new-token: 7780, #cached-token: 464, token usage: 0.93, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:18:29] INFO:     127.0.0.1:45758 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:29] Decode batch. #running-req: 67, #token: 234665, token usage: 0.95, cuda graph: True, gen throughput (token/s): 733.48, #queue-req: 32\n",
      "[2025-08-13 20:18:32] Decode batch. #running-req: 67, #token: 237345, token usage: 0.97, cuda graph: True, gen throughput (token/s): 918.61, #queue-req: 33\n",
      "[2025-08-13 20:18:33] INFO:     127.0.0.1:41282 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:35] Decode batch. #running-req: 66, #token: 236545, token usage: 0.96, cuda graph: True, gen throughput (token/s): 915.87, #queue-req: 34\n",
      "[2025-08-13 20:18:37] INFO:     127.0.0.1:48898 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:37] INFO:     127.0.0.1:48888 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:38] Decode batch. #running-req: 64, #token: 237994, token usage: 0.97, cuda graph: True, gen throughput (token/s): 910.18, #queue-req: 34\n",
      "[2025-08-13 20:18:38] INFO:     127.0.0.1:44506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:38] Prefill batch. #new-seq: 2, #new-token: 5078, #cached-token: 675, token usage: 0.94, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 20:18:39] INFO:     127.0.0.1:56530 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:39] INFO:     127.0.0.1:56532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:39] Prefill batch. #new-seq: 3, #new-token: 4592, #cached-token: 1236, token usage: 0.93, #running-req: 63, #queue-req: 29\n",
      "[2025-08-13 20:18:40] INFO:     127.0.0.1:46036 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:40] Prefill batch. #new-seq: 1, #new-token: 4377, #cached-token: 444, token usage: 0.94, #running-req: 65, #queue-req: 28\n",
      "[2025-08-13 20:18:42] Decode batch. #running-req: 66, #token: 236725, token usage: 0.96, cuda graph: True, gen throughput (token/s): 605.70, #queue-req: 34\n",
      "[2025-08-13 20:18:42] INFO:     127.0.0.1:46222 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:45] Decode batch. #running-req: 65, #token: 237148, token usage: 0.96, cuda graph: True, gen throughput (token/s): 841.29, #queue-req: 35\n",
      "[2025-08-13 20:18:46] INFO:     127.0.0.1:41266 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:46] Prefill batch. #new-seq: 3, #new-token: 5549, #cached-token: 1230, token usage: 0.92, #running-req: 64, #queue-req: 32\n",
      "[2025-08-13 20:18:48] INFO:     127.0.0.1:39872 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:48] Prefill batch. #new-seq: 2, #new-token: 5785, #cached-token: 627, token usage: 0.93, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:18:49] INFO:     127.0.0.1:58762 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:49] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 146, token usage: 0.93, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:18:49] Decode batch. #running-req: 67, #token: 228996, token usage: 0.93, cuda graph: True, gen throughput (token/s): 674.17, #queue-req: 30\n",
      "[2025-08-13 20:18:50] INFO:     127.0.0.1:45782 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:50] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.91, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:18:50] Prefill batch. #new-seq: 1, #new-token: 3557, #cached-token: 0, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:18:52] INFO:     127.0.0.1:51552 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:52] Prefill batch. #new-seq: 1, #new-token: 2169, #cached-token: 450, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:18:52] INFO:     127.0.0.1:51536 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:52] Prefill batch. #new-seq: 2, #new-token: 2418, #cached-token: 216, token usage: 0.95, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:18:54] Decode batch. #running-req: 69, #token: 236055, token usage: 0.96, cuda graph: True, gen throughput (token/s): 607.83, #queue-req: 31\n",
      "[2025-08-13 20:18:55] INFO:     127.0.0.1:58776 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:56] INFO:     127.0.0.1:58596 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:56] Decode batch. #running-req: 67, #token: 236039, token usage: 0.96, cuda graph: True, gen throughput (token/s): 947.85, #queue-req: 32\n",
      "[2025-08-13 20:18:58] INFO:     127.0.0.1:39876 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:58] INFO:     127.0.0.1:59226 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:58] Prefill batch. #new-seq: 1, #new-token: 4663, #cached-token: 480, token usage: 0.93, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:18:59] INFO:     127.0.0.1:41310 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:59] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 466, token usage: 0.95, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:18:59] INFO:     127.0.0.1:41268 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:18:59] Prefill batch. #new-seq: 1, #new-token: 2360, #cached-token: 441, token usage: 0.95, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:19:00] Decode batch. #running-req: 66, #token: 236015, token usage: 0.96, cuda graph: True, gen throughput (token/s): 701.93, #queue-req: 32\n",
      "[2025-08-13 20:19:02] INFO:     127.0.0.1:36770 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:03] Prefill batch. #new-seq: 1, #new-token: 2120, #cached-token: 146, token usage: 0.95, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:19:03] INFO:     127.0.0.1:39880 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:03] Prefill batch. #new-seq: 1, #new-token: 2413, #cached-token: 409, token usage: 0.95, #running-req: 65, #queue-req: 32\n",
      ".[2025-08-13 20:19:04] Decode batch. #running-req: 66, #token: 237436, token usage: 0.97, cuda graph: True, gen throughput (token/s): 785.01, #queue-req: 32\n",
      "[2025-08-13 20:19:04] INFO:     127.0.0.1:42076 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:04] Prefill batch. #new-seq: 1, #new-token: 2499, #cached-token: 449, token usage: 0.96, #running-req: 65, #queue-req: 31\n",
      "[2025-08-13 20:19:04] INFO:     127.0.0.1:59266 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:05] INFO:     127.0.0.1:40976 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:07] INFO:     127.0.0.1:33450 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:07] Decode batch. #running-req: 64, #token: 236823, token usage: 0.96, cuda graph: True, gen throughput (token/s): 844.46, #queue-req: 36\n",
      "[2025-08-13 20:19:09] Decode batch. #running-req: 63, #token: 239343, token usage: 0.97, cuda graph: True, gen throughput (token/s): 909.39, #queue-req: 37\n",
      "[2025-08-13 20:19:10] INFO:     127.0.0.1:43236 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:12] INFO:     127.0.0.1:46578 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:12] INFO:     127.0.0.1:42086 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:12] Decode batch. #running-req: 60, #token: 231787, token usage: 0.94, cuda graph: True, gen throughput (token/s): 900.51, #queue-req: 38\n",
      "[2025-08-13 20:19:13] INFO:     127.0.0.1:42116 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:13] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 393, token usage: 0.93, #running-req: 59, #queue-req: 37\n",
      "[2025-08-13 20:19:13] Prefill batch. #new-seq: 1, #new-token: 1275, #cached-token: 0, token usage: 0.97, #running-req: 59, #queue-req: 37\n",
      "[2025-08-13 20:19:15] INFO:     127.0.0.1:39940 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:15] Prefill batch. #new-seq: 2, #new-token: 2628, #cached-token: 508, token usage: 0.94, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:19:16] Decode batch. #running-req: 61, #token: 234190, token usage: 0.95, cuda graph: True, gen throughput (token/s): 610.21, #queue-req: 39\n",
      "[2025-08-13 20:19:17] INFO:     127.0.0.1:52730 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:17] Prefill batch. #new-seq: 2, #new-token: 6592, #cached-token: 914, token usage: 0.95, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:19:19] Decode batch. #running-req: 62, #token: 241554, token usage: 0.98, cuda graph: True, gen throughput (token/s): 734.13, #queue-req: 38\n",
      "[2025-08-13 20:19:21] INFO:     127.0.0.1:41846 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:22] Decode batch. #running-req: 61, #token: 239959, token usage: 0.98, cuda graph: True, gen throughput (token/s): 877.51, #queue-req: 39\n",
      "[2025-08-13 20:19:24] INFO:     127.0.0.1:46566 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:19:25] Decode batch. #running-req: 60, #token: 238370, token usage: 0.97, cuda graph: True, gen throughput (token/s): 864.95, #queue-req: 40\n",
      "[2025-08-13 20:19:26] INFO:     127.0.0.1:56474 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:26] INFO:     127.0.0.1:56490 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:26] Prefill batch. #new-seq: 1, #new-token: 2544, #cached-token: 437, token usage: 0.95, #running-req: 58, #queue-req: 39\n",
      "[2025-08-13 20:19:27] INFO:     127.0.0.1:43222 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:27] Prefill batch. #new-seq: 1, #new-token: 2261, #cached-token: 124, token usage: 0.95, #running-req: 58, #queue-req: 38\n",
      "[2025-08-13 20:19:28] Decode batch. #running-req: 59, #token: 236496, token usage: 0.96, cuda graph: True, gen throughput (token/s): 737.89, #queue-req: 38\n",
      "[2025-08-13 20:19:29] INFO:     127.0.0.1:37100 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:29] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1397, token usage: 0.92, #running-req: 58, #queue-req: 39\n",
      "[2025-08-13 20:19:29] Prefill batch. #new-seq: 1, #new-token: 320, #cached-token: 0, token usage: 0.95, #running-req: 60, #queue-req: 39\n",
      "[2025-08-13 20:19:30] INFO:     127.0.0.1:41850 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:30] INFO:     127.0.0.1:41860 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:30] INFO:     127.0.0.1:41868 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:30] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1029, token usage: 0.90, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:19:31] Prefill batch. #new-seq: 3, #new-token: 5236, #cached-token: 602, token usage: 0.93, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:19:33] Decode batch. #running-req: 63, #token: 232026, token usage: 0.94, cuda graph: True, gen throughput (token/s): 520.11, #queue-req: 37\n",
      "[2025-08-13 20:19:33] INFO:     127.0.0.1:48920 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:33] Prefill batch. #new-seq: 1, #new-token: 5295, #cached-token: 393, token usage: 0.94, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:19:36] INFO:     127.0.0.1:36744 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:36] Prefill batch. #new-seq: 1, #new-token: 617, #cached-token: 449, token usage: 0.96, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:19:36] Decode batch. #running-req: 63, #token: 238377, token usage: 0.97, cuda graph: True, gen throughput (token/s): 760.45, #queue-req: 36\n",
      "[2025-08-13 20:19:38] INFO:     127.0.0.1:58594 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:39] INFO:     127.0.0.1:50236 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:39] INFO:     127.0.0.1:41322 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:39] Prefill batch. #new-seq: 2, #new-token: 4555, #cached-token: 909, token usage: 0.94, #running-req: 60, #queue-req: 35\n",
      "[2025-08-13 20:19:39] Decode batch. #running-req: 62, #token: 235816, token usage: 0.96, cuda graph: True, gen throughput (token/s): 794.22, #queue-req: 36\n",
      "[2025-08-13 20:19:40] INFO:     127.0.0.1:48906 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:41] INFO:     127.0.0.1:52714 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:41] INFO:     127.0.0.1:56530 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:41] INFO:     127.0.0.1:56532 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:41] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.90, #running-req: 58, #queue-req: 39\n",
      "[2025-08-13 20:19:42] Prefill batch. #new-seq: 1, #new-token: 3434, #cached-token: 0, token usage: 0.93, #running-req: 58, #queue-req: 39\n",
      "[2025-08-13 20:19:43] INFO:     127.0.0.1:52734 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:43] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 521, token usage: 0.91, #running-req: 58, #queue-req: 40\n",
      "[2025-08-13 20:19:43] Prefill batch. #new-seq: 1, #new-token: 858, #cached-token: 0, token usage: 0.94, #running-req: 59, #queue-req: 40\n",
      "[2025-08-13 20:19:44] Decode batch. #running-req: 60, #token: 232684, token usage: 0.95, cuda graph: True, gen throughput (token/s): 502.71, #queue-req: 40\n",
      "[2025-08-13 20:19:47] INFO:     127.0.0.1:46556 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:47] Decode batch. #running-req: 59, #token: 233081, token usage: 0.95, cuda graph: True, gen throughput (token/s): 859.53, #queue-req: 41\n",
      "[2025-08-13 20:19:48] INFO:     127.0.0.1:46580 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:48] Prefill batch. #new-seq: 1, #new-token: 5244, #cached-token: 409, token usage: 0.93, #running-req: 58, #queue-req: 41\n",
      "[2025-08-13 20:19:49] INFO:     127.0.0.1:43208 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:49] Prefill batch. #new-seq: 1, #new-token: 2239, #cached-token: 77, token usage: 0.95, #running-req: 58, #queue-req: 41\n",
      "[2025-08-13 20:19:50] INFO:     127.0.0.1:43240 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:50] Prefill batch. #new-seq: 2, #new-token: 4363, #cached-token: 579, token usage: 0.94, #running-req: 58, #queue-req: 40\n",
      "[2025-08-13 20:19:50] INFO:     127.0.0.1:36802 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:50] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 160, token usage: 0.95, #running-req: 59, #queue-req: 40\n",
      "[2025-08-13 20:19:51] Decode batch. #running-req: 60, #token: 235287, token usage: 0.96, cuda graph: True, gen throughput (token/s): 619.46, #queue-req: 40\n",
      "[2025-08-13 20:19:51] INFO:     127.0.0.1:46222 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:51] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 965, token usage: 0.91, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:19:51] INFO:     127.0.0.1:41264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:51] Prefill batch. #new-seq: 2, #new-token: 1312, #cached-token: 469, token usage: 0.94, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:19:52] Prefill batch. #new-seq: 2, #new-token: 2863, #cached-token: 599, token usage: 0.95, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:19:53] INFO:     127.0.0.1:59226 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:54] INFO:     127.0.0.1:39842 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:54] Prefill batch. #new-seq: 1, #new-token: 5297, #cached-token: 412, token usage: 0.94, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 20:19:55] Decode batch. #running-req: 62, #token: 233986, token usage: 0.95, cuda graph: True, gen throughput (token/s): 581.06, #queue-req: 38\n",
      "[2025-08-13 20:19:55] INFO:     127.0.0.1:36784 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:55] Prefill batch. #new-seq: 2, #new-token: 266, #cached-token: 555, token usage: 0.95, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 20:19:55] INFO:     127.0.0.1:58762 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:56] Prefill batch. #new-seq: 3, #new-token: 2644, #cached-token: 803, token usage: 0.93, #running-req: 62, #queue-req: 33\n",
      ".[2025-08-13 20:19:57] INFO:     127.0.0.1:33508 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:57] Prefill batch. #new-seq: 3, #new-token: 5071, #cached-token: 1323, token usage: 0.92, #running-req: 64, #queue-req: 30\n",
      "[2025-08-13 20:19:57] INFO:     127.0.0.1:39874 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:19:57] Prefill batch. #new-seq: 2, #new-token: 7699, #cached-token: 925, token usage: 0.91, #running-req: 66, #queue-req: 29\n",
      "[2025-08-13 20:19:59] Decode batch. #running-req: 68, #token: 231740, token usage: 0.94, cuda graph: True, gen throughput (token/s): 622.22, #queue-req: 32\n",
      "[2025-08-13 20:20:02] INFO:     127.0.0.1:58776 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:02] Prefill batch. #new-seq: 1, #new-token: 2204, #cached-token: 454, token usage: 0.94, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:20:02] Decode batch. #running-req: 68, #token: 234415, token usage: 0.95, cuda graph: True, gen throughput (token/s): 889.04, #queue-req: 31\n",
      "[2025-08-13 20:20:03] INFO:     127.0.0.1:59266 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:03] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 483, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:20:04] INFO:     127.0.0.1:41294 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:04] Prefill batch. #new-seq: 1, #new-token: 2219, #cached-token: 412, token usage: 0.94, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:20:05] INFO:     127.0.0.1:39244 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:05] Prefill batch. #new-seq: 1, #new-token: 2220, #cached-token: 412, token usage: 0.94, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:20:06] Decode batch. #running-req: 68, #token: 235126, token usage: 0.96, cuda graph: True, gen throughput (token/s): 814.33, #queue-req: 31\n",
      "[2025-08-13 20:20:08] INFO:     127.0.0.1:58612 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:08] Prefill batch. #new-seq: 1, #new-token: 3166, #cached-token: 624, token usage: 0.93, #running-req: 67, #queue-req: 31\n",
      ".[2025-08-13 20:20:09] Decode batch. #running-req: 68, #token: 232055, token usage: 0.94, cuda graph: True, gen throughput (token/s): 859.94, #queue-req: 31\n",
      "[2025-08-13 20:20:09] INFO:     127.0.0.1:41312 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:11] INFO:     127.0.0.1:39856 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:12] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 465, token usage: 0.88, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:20:12] Prefill batch. #new-seq: 2, #new-token: 5923, #cached-token: 439, token usage: 0.92, #running-req: 66, #queue-req: 31\n",
      ".[2025-08-13 20:20:13] Decode batch. #running-req: 68, #token: 231386, token usage: 0.94, cuda graph: True, gen throughput (token/s): 604.73, #queue-req: 32\n",
      "[2025-08-13 20:20:14] INFO:     127.0.0.1:39226 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:14] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 624, token usage: 0.88, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:20:15] Prefill batch. #new-seq: 4, #new-token: 6625, #cached-token: 906, token usage: 0.91, #running-req: 67, #queue-req: 28\n",
      ".[2025-08-13 20:20:17] INFO:     127.0.0.1:55874 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:17] Prefill batch. #new-seq: 1, #new-token: 2420, #cached-token: 438, token usage: 0.94, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:20:18] INFO:     127.0.0.1:39234 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:18] Prefill batch. #new-seq: 2, #new-token: 2505, #cached-token: 912, token usage: 0.94, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:20:18] Decode batch. #running-req: 72, #token: 232878, token usage: 0.95, cuda graph: True, gen throughput (token/s): 584.45, #queue-req: 28\n",
      "[2025-08-13 20:20:20] INFO:     127.0.0.1:37100 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:20] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 715, token usage: 0.91, #running-req: 71, #queue-req: 25\n",
      ".[2025-08-13 20:20:21] Prefill batch. #new-seq: 1, #new-token: 569, #cached-token: 0, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:20:22] Decode batch. #running-req: 74, #token: 232676, token usage: 0.95, cuda graph: True, gen throughput (token/s): 779.06, #queue-req: 26\n",
      "[2025-08-13 20:20:22] INFO:     127.0.0.1:60808 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:22] Prefill batch. #new-seq: 1, #new-token: 2967, #cached-token: 626, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:20:25] Decode batch. #running-req: 74, #token: 237328, token usage: 0.97, cuda graph: True, gen throughput (token/s): 929.27, #queue-req: 26\n",
      "[2025-08-13 20:20:25] INFO:     127.0.0.1:41860 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:26] INFO:     127.0.0.1:36778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:27] INFO:     127.0.0.1:41850 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:27] INFO:     127.0.0.1:41868 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:27] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 508, token usage: 0.91, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:20:27] Prefill batch. #new-seq: 2, #new-token: 3409, #cached-token: 267, token usage: 0.94, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 20:20:29] INFO:     127.0.0.1:50236 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:29] Decode batch. #running-req: 72, #token: 233043, token usage: 0.95, cuda graph: True, gen throughput (token/s): 703.34, #queue-req: 28\n",
      "[2025-08-13 20:20:29] Prefill batch. #new-seq: 1, #new-token: 4373, #cached-token: 449, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:20:30] INFO:     127.0.0.1:36796 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:30] Prefill batch. #new-seq: 1, #new-token: 2234, #cached-token: 452, token usage: 0.95, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:20:31] INFO:     127.0.0.1:36804 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:31] Prefill batch. #new-seq: 1, #new-token: 3335, #cached-token: 126, token usage: 0.94, #running-req: 71, #queue-req: 28\n",
      "[2025-08-13 20:20:33] INFO:     127.0.0.1:52714 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:33] Prefill batch. #new-seq: 1, #new-token: 2250, #cached-token: 119, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:20:33] Decode batch. #running-req: 71, #token: 235093, token usage: 0.96, cuda graph: True, gen throughput (token/s): 722.14, #queue-req: 27\n",
      "[2025-08-13 20:20:34] INFO:     127.0.0.1:55866 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:35] INFO:     127.0.0.1:52734 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:36] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.92, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:20:36] Prefill batch. #new-seq: 1, #new-token: 1513, #cached-token: 0, token usage: 0.96, #running-req: 70, #queue-req: 27\n",
      ".[2025-08-13 20:20:37] Decode batch. #running-req: 71, #token: 237262, token usage: 0.97, cuda graph: True, gen throughput (token/s): 677.02, #queue-req: 29\n",
      "[2025-08-13 20:20:38] INFO:     127.0.0.1:41264 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:38] Prefill batch. #new-seq: 2, #new-token: 4782, #cached-token: 850, token usage: 0.93, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:20:39] INFO:     127.0.0.1:46052 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:39] Prefill batch. #new-seq: 4, #new-token: 4968, #cached-token: 1883, token usage: 0.90, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:20:40] INFO:     127.0.0.1:46556 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:40] Prefill batch. #new-seq: 2, #new-token: 6908, #cached-token: 528, token usage: 0.92, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 20:20:41] INFO:     127.0.0.1:40980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:41] Prefill batch. #new-seq: 3, #new-token: 2820, #cached-token: 1018, token usage: 0.93, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:20:42] INFO:     127.0.0.1:41224 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:42] Decode batch. #running-req: 78, #token: 231170, token usage: 0.94, cuda graph: True, gen throughput (token/s): 657.96, #queue-req: 22\n",
      "[2025-08-13 20:20:42] Prefill batch. #new-seq: 2, #new-token: 2274, #cached-token: 170, token usage: 0.94, #running-req: 77, #queue-req: 20\n",
      "[2025-08-13 20:20:43] INFO:     127.0.0.1:46580 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:43] Prefill batch. #new-seq: 2, #new-token: 166, #cached-token: 189, token usage: 0.93, #running-req: 78, #queue-req: 18\n",
      "[2025-08-13 20:20:43] INFO:     127.0.0.1:41312 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:43] Prefill batch. #new-seq: 2, #new-token: 4903, #cached-token: 843, token usage: 0.93, #running-req: 79, #queue-req: 16\n",
      "[2025-08-13 20:20:44] INFO:     127.0.0.1:43208 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:44] Prefill batch. #new-seq: 2, #new-token: 136, #cached-token: 1124, token usage: 0.94, #running-req: 80, #queue-req: 14\n",
      "[2025-08-13 20:20:44] INFO:     127.0.0.1:43240 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:44] Prefill batch. #new-seq: 2, #new-token: 4290, #cached-token: 630, token usage: 0.93, #running-req: 81, #queue-req: 13\n",
      "[2025-08-13 20:20:46] Decode batch. #running-req: 83, #token: 233787, token usage: 0.95, cuda graph: True, gen throughput (token/s): 779.12, #queue-req: 14\n",
      "[2025-08-13 20:20:46] INFO:     127.0.0.1:41012 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:46] Prefill batch. #new-seq: 1, #new-token: 2224, #cached-token: 410, token usage: 0.93, #running-req: 82, #queue-req: 13\n",
      "[2025-08-13 20:20:47] INFO:     127.0.0.1:41014 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:47] INFO:     127.0.0.1:36802 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:47] Prefill batch. #new-seq: 1, #new-token: 4384, #cached-token: 446, token usage: 0.91, #running-req: 82, #queue-req: 17\n",
      "[2025-08-13 20:20:47] Prefill batch. #new-seq: 1, #new-token: 4369, #cached-token: 451, token usage: 0.93, #running-req: 82, #queue-req: 16\n",
      "[2025-08-13 20:20:50] Decode batch. #running-req: 83, #token: 236313, token usage: 0.96, cuda graph: True, gen throughput (token/s): 788.69, #queue-req: 17\n",
      "[2025-08-13 20:20:51] INFO:     127.0.0.1:42362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:51] INFO:     127.0.0.1:41026 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:52] INFO:     127.0.0.1:41294 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:53] Decode batch. #running-req: 80, #token: 234186, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1067.96, #queue-req: 20\n",
      "[2025-08-13 20:20:54] INFO:     127.0.0.1:39846 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:55] INFO:     127.0.0.1:36778 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:55] Prefill batch. #new-seq: 1, #new-token: 7022, #cached-token: 626, token usage: 0.92, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 20:20:55] INFO:     127.0.0.1:39234 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:57] Decode batch. #running-req: 78, #token: 235424, token usage: 0.96, cuda graph: True, gen throughput (token/s): 892.93, #queue-req: 22\n",
      "[2025-08-13 20:20:58] INFO:     127.0.0.1:36796 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:59] INFO:     127.0.0.1:41212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:20:59] Prefill batch. #new-seq: 2, #new-token: 6408, #cached-token: 560, token usage: 0.93, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:21:00] Decode batch. #running-req: 78, #token: 234665, token usage: 0.95, cuda graph: True, gen throughput (token/s): 909.87, #queue-req: 22\n",
      "[2025-08-13 20:21:03] INFO:     127.0.0.1:48874 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:03] Decode batch. #running-req: 78, #token: 232957, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1075.29, #queue-req: 22\n",
      "[2025-08-13 20:21:03] Prefill batch. #new-seq: 1, #new-token: 153, #cached-token: 145, token usage: 0.95, #running-req: 77, #queue-req: 22\n",
      "[2025-08-13 20:21:03] INFO:     127.0.0.1:36934 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:03] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 483, token usage: 0.93, #running-req: 77, #queue-req: 21\n",
      "[2025-08-13 20:21:04] INFO:     127.0.0.1:48884 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:04] Prefill batch. #new-seq: 1, #new-token: 7843, #cached-token: 464, token usage: 0.92, #running-req: 77, #queue-req: 20\n",
      "[2025-08-13 20:21:07] Decode batch. #running-req: 78, #token: 235625, token usage: 0.96, cuda graph: True, gen throughput (token/s): 842.23, #queue-req: 22\n",
      "[2025-08-13 20:21:08] INFO:     127.0.0.1:57492 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:09] INFO:     127.0.0.1:36804 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:10] Decode batch. #running-req: 76, #token: 233592, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1053.49, #queue-req: 23\n",
      "[2025-08-13 20:21:13] INFO:     127.0.0.1:58576 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:13] INFO:     127.0.0.1:58580 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:13] Decode batch. #running-req: 74, #token: 228802, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1039.71, #queue-req: 26\n",
      "[2025-08-13 20:21:15] INFO:     127.0.0.1:58604 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:16] Decode batch. #running-req: 73, #token: 229379, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1046.89, #queue-req: 27\n",
      "[2025-08-13 20:21:17] INFO:     127.0.0.1:59172 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:18] Decode batch. #running-req: 72, #token: 231774, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1028.92, #queue-req: 27\n",
      "[2025-08-13 20:21:21] Decode batch. #running-req: 72, #token: 234654, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1004.18, #queue-req: 28\n",
      "[2025-08-13 20:21:24] Decode batch. #running-req: 72, #token: 237534, token usage: 0.97, cuda graph: True, gen throughput (token/s): 995.84, #queue-req: 28\n",
      "[2025-08-13 20:21:25] INFO:     127.0.0.1:33494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:26] INFO:     127.0.0.1:49754 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:27] INFO:     127.0.0.1:41068 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:27] INFO:     127.0.0.1:45024 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:27] Decode batch. #running-req: 68, #token: 232055, token usage: 0.94, cuda graph: True, gen throughput (token/s): 959.58, #queue-req: 30\n",
      "[2025-08-13 20:21:30] INFO:     127.0.0.1:34746 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:30] Decode batch. #running-req: 67, #token: 233462, token usage: 0.95, cuda graph: True, gen throughput (token/s): 897.00, #queue-req: 32\n",
      "[2025-08-13 20:21:31] INFO:     127.0.0.1:41208 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:33] INFO:     127.0.0.1:60816 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:33] Decode batch. #running-req: 65, #token: 232285, token usage: 0.94, cuda graph: True, gen throughput (token/s): 921.20, #queue-req: 34\n",
      "[2025-08-13 20:21:34] INFO:     127.0.0.1:60782 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:34] INFO:     127.0.0.1:60794 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:34] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 551, token usage: 0.92, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:21:34] Prefill batch. #new-seq: 1, #new-token: 3620, #cached-token: 0, token usage: 0.95, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:21:36] INFO:     127.0.0.1:33464 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:36] Prefill batch. #new-seq: 3, #new-token: 4834, #cached-token: 995, token usage: 0.92, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 20:21:37] INFO:     127.0.0.1:57498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:37] Prefill batch. #new-seq: 1, #new-token: 5155, #cached-token: 465, token usage: 0.93, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:21:37] INFO:     127.0.0.1:46052 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:37] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1158, token usage: 0.91, #running-req: 65, #queue-req: 28\n",
      "[2025-08-13 20:21:37] Prefill batch. #new-seq: 1, #new-token: 1121, #cached-token: 0, token usage: 0.94, #running-req: 68, #queue-req: 28\n",
      ".[2025-08-13 20:21:38] INFO:     127.0.0.1:41072 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:38] Prefill batch. #new-seq: 2, #new-token: 7473, #cached-token: 702, token usage: 0.93, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:21:40] Decode batch. #running-req: 70, #token: 235852, token usage: 0.96, cuda graph: True, gen throughput (token/s): 407.78, #queue-req: 28\n",
      "[2025-08-13 20:21:41] INFO:     127.0.0.1:36342 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:41] Prefill batch. #new-seq: 2, #new-token: 2680, #cached-token: 900, token usage: 0.95, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:21:43] Decode batch. #running-req: 71, #token: 238243, token usage: 0.97, cuda graph: True, gen throughput (token/s): 901.32, #queue-req: 29\n",
      "[2025-08-13 20:21:43] INFO:     127.0.0.1:60810 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:43] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 462, token usage: 0.96, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:21:45] INFO:     127.0.0.1:33428 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:45] INFO:     127.0.0.1:33442 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:45] Prefill batch. #new-seq: 3, #new-token: 5359, #cached-token: 1171, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:21:46] Decode batch. #running-req: 72, #token: 228711, token usage: 0.93, cuda graph: True, gen throughput (token/s): 849.94, #queue-req: 28\n",
      "[2025-08-13 20:21:46] INFO:     127.0.0.1:41014 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:46] Prefill batch. #new-seq: 2, #new-token: 2428, #cached-token: 910, token usage: 0.93, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:21:47] INFO:     127.0.0.1:59184 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:47] Prefill batch. #new-seq: 1, #new-token: 4917, #cached-token: 392, token usage: 0.94, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:21:48] INFO:     127.0.0.1:33480 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:48] Prefill batch. #new-seq: 1, #new-token: 4827, #cached-token: 462, token usage: 0.95, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 20:21:49] INFO:     127.0.0.1:40980 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:49] INFO:     127.0.0.1:48884 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:49] INFO:     127.0.0.1:36952 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:49] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1457, token usage: 0.90, #running-req: 71, #queue-req: 24\n",
      "[2025-08-13 20:21:49] INFO:     127.0.0.1:41012 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:50] Prefill batch. #new-seq: 2, #new-token: 4757, #cached-token: 412, token usage: 0.93, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 20:21:51] Decode batch. #running-req: 73, #token: 234095, token usage: 0.95, cuda graph: True, gen throughput (token/s): 568.03, #queue-req: 23\n",
      "[2025-08-13 20:21:53] INFO:     127.0.0.1:41026 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:54] Decode batch. #running-req: 72, #token: 234520, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1022.78, #queue-req: 27\n",
      "[2025-08-13 20:21:55] INFO:     127.0.0.1:36360 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:55] INFO:     127.0.0.1:48874 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:55] Prefill batch. #new-seq: 2, #new-token: 7520, #cached-token: 921, token usage: 0.93, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 20:21:57] INFO:     127.0.0.1:57974 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:57] Prefill batch. #new-seq: 2, #new-token: 3399, #cached-token: 303, token usage: 0.93, #running-req: 71, #queue-req: 24\n",
      "[2025-08-13 20:21:57] INFO:     127.0.0.1:57978 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:57] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 149, token usage: 0.95, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 20:21:58] Decode batch. #running-req: 73, #token: 234098, token usage: 0.95, cuda graph: True, gen throughput (token/s): 737.23, #queue-req: 27\n",
      "[2025-08-13 20:21:58] INFO:     127.0.0.1:39846 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:21:58] Prefill batch. #new-seq: 1, #new-token: 2361, #cached-token: 441, token usage: 0.94, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:21:59] INFO:     127.0.0.1:36964 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:00] Prefill batch. #new-seq: 3, #new-token: 2627, #cached-token: 1174, token usage: 0.93, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:22:01] Decode batch. #running-req: 75, #token: 232298, token usage: 0.94, cuda graph: True, gen throughput (token/s): 900.26, #queue-req: 25\n",
      "[2025-08-13 20:22:01] INFO:     127.0.0.1:58576 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:01] Prefill batch. #new-seq: 2, #new-token: 2235, #cached-token: 331, token usage: 0.93, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 20:22:04] Decode batch. #running-req: 76, #token: 234656, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1001.13, #queue-req: 24\n",
      "[2025-08-13 20:22:06] INFO:     127.0.0.1:58580 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:06] INFO:     127.0.0.1:58604 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:06] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 447, token usage: 0.93, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 20:22:07] Decode batch. #running-req: 75, #token: 234275, token usage: 0.95, cuda graph: True, gen throughput (token/s): 928.81, #queue-req: 23\n",
      "[2025-08-13 20:22:10] INFO:     127.0.0.1:60782 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:10] Decode batch. #running-req: 74, #token: 233910, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1044.02, #queue-req: 25\n",
      "[2025-08-13 20:22:10] INFO:     127.0.0.1:59174 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:12] INFO:     127.0.0.1:57988 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:12] INFO:     127.0.0.1:57990 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:13] Decode batch. #running-req: 71, #token: 230219, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1017.56, #queue-req: 29\n",
      "[2025-08-13 20:22:15] INFO:     127.0.0.1:60794 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:16] INFO:     127.0.0.1:49756 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:16] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 551, token usage: 0.91, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:22:16] Prefill batch. #new-seq: 1, #new-token: 3629, #cached-token: 0, token usage: 0.95, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:22:17] Decode batch. #running-req: 70, #token: 236886, token usage: 0.96, cuda graph: True, gen throughput (token/s): 705.27, #queue-req: 28\n",
      "[2025-08-13 20:22:18] INFO:     127.0.0.1:34774 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:18] Prefill batch. #new-seq: 2, #new-token: 218, #cached-token: 951, token usage: 0.95, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:22:20] Decode batch. #running-req: 71, #token: 236178, token usage: 0.96, cuda graph: True, gen throughput (token/s): 924.20, #queue-req: 29\n",
      "[2025-08-13 20:22:20] INFO:     127.0.0.1:33128 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:23] Decode batch. #running-req: 70, #token: 236541, token usage: 0.96, cuda graph: True, gen throughput (token/s): 921.45, #queue-req: 30\n",
      "[2025-08-13 20:22:23] INFO:     127.0.0.1:57512 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:25] INFO:     127.0.0.1:36942 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:26] Decode batch. #running-req: 68, #token: 231687, token usage: 0.94, cuda graph: True, gen throughput (token/s): 961.55, #queue-req: 32\n",
      "[2025-08-13 20:22:27] INFO:     127.0.0.1:34160 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:27] Prefill batch. #new-seq: 1, #new-token: 7214, #cached-token: 553, token usage: 0.94, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:22:28] INFO:     127.0.0.1:34170 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:28] INFO:     127.0.0.1:34186 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:28] Prefill batch. #new-seq: 2, #new-token: 5628, #cached-token: 1101, token usage: 0.93, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:22:30] Decode batch. #running-req: 68, #token: 236239, token usage: 0.96, cuda graph: True, gen throughput (token/s): 661.18, #queue-req: 32\n",
      "[2025-08-13 20:22:30] INFO:     127.0.0.1:55868 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:30] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 582, token usage: 0.93, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:22:30] Prefill batch. #new-seq: 1, #new-token: 1678, #cached-token: 0, token usage: 0.97, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:22:33] INFO:     127.0.0.1:55888 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:34] Decode batch. #running-req: 68, #token: 237251, token usage: 0.97, cuda graph: True, gen throughput (token/s): 693.32, #queue-req: 32\n",
      "[2025-08-13 20:22:35] INFO:     127.0.0.1:41086 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:35] Prefill batch. #new-seq: 2, #new-token: 2461, #cached-token: 612, token usage: 0.95, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:22:35] INFO:     127.0.0.1:42372 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:35] Prefill batch. #new-seq: 1, #new-token: 4185, #cached-token: 454, token usage: 0.96, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:22:37] INFO:     127.0.0.1:33668 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:38] INFO:     127.0.0.1:33442 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:38] Decode batch. #running-req: 67, #token: 238115, token usage: 0.97, cuda graph: True, gen throughput (token/s): 743.81, #queue-req: 30\n",
      "[2025-08-13 20:22:39] INFO:     127.0.0.1:60810 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:40] INFO:     127.0.0.1:55896 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:40] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1271, token usage: 0.91, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:22:40] Prefill batch. #new-seq: 2, #new-token: 2365, #cached-token: 455, token usage: 0.94, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:22:41] INFO:     127.0.0.1:50214 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:41] INFO:     127.0.0.1:35482 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:41] Prefill batch. #new-seq: 1, #new-token: 7182, #cached-token: 626, token usage: 0.92, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:22:42] INFO:     127.0.0.1:43152 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:42] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 923, token usage: 0.94, #running-req: 67, #queue-req: 28\n",
      "[2025-08-13 20:22:42] Prefill batch. #new-seq: 1, #new-token: 358, #cached-token: 0, token usage: 0.97, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:22:43] Decode batch. #running-req: 69, #token: 238972, token usage: 0.97, cuda graph: True, gen throughput (token/s): 494.31, #queue-req: 28\n",
      "[2025-08-13 20:22:44] INFO:     127.0.0.1:33428 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:44] Prefill batch. #new-seq: 2, #new-token: 3298, #cached-token: 899, token usage: 0.94, #running-req: 68, #queue-req: 29\n",
      ".[2025-08-13 20:22:46] Decode batch. #running-req: 70, #token: 237216, token usage: 0.96, cuda graph: True, gen throughput (token/s): 883.54, #queue-req: 30\n",
      "[2025-08-13 20:22:47] INFO:     127.0.0.1:40924 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:47] Prefill batch. #new-seq: 1, #new-token: 2164, #cached-token: 469, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:22:48] INFO:     127.0.0.1:43164 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:48] Prefill batch. #new-seq: 1, #new-token: 7490, #cached-token: 464, token usage: 0.94, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:22:49] INFO:     127.0.0.1:36964 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:22:49] INFO:     127.0.0.1:43176 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:49] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1351, token usage: 0.90, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:22:49] INFO:     127.0.0.1:33480 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:49] Prefill batch. #new-seq: 3, #new-token: 979, #cached-token: 237, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:22:50] Prefill batch. #new-seq: 2, #new-token: 6618, #cached-token: 558, token usage: 0.94, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:22:51] INFO:     127.0.0.1:43180 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:51] INFO:     127.0.0.1:41188 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:51] INFO:     127.0.0.1:57990 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:51] Prefill batch. #new-seq: 1, #new-token: 5150, #cached-token: 628, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:22:52] INFO:     127.0.0.1:42368 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:52] INFO:     127.0.0.1:57988 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:52] Decode batch. #running-req: 72, #token: 227357, token usage: 0.92, cuda graph: True, gen throughput (token/s): 501.57, #queue-req: 28\n",
      "[2025-08-13 20:22:52] Prefill batch. #new-seq: 2, #new-token: 4705, #cached-token: 896, token usage: 0.92, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 20:22:53] INFO:     127.0.0.1:41192 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:53] INFO:     127.0.0.1:41198 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:53] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 642, token usage: 0.91, #running-req: 70, #queue-req: 23\n",
      "[2025-08-13 20:22:53] Prefill batch. #new-seq: 3, #new-token: 5365, #cached-token: 901, token usage: 0.94, #running-req: 72, #queue-req: 21\n",
      "[2025-08-13 20:22:55] INFO:     127.0.0.1:34186 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:56] INFO:     127.0.0.1:47266 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:56] Prefill batch. #new-seq: 1, #new-token: 2074, #cached-token: 96, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:22:57] Decode batch. #running-req: 74, #token: 231831, token usage: 0.94, cuda graph: True, gen throughput (token/s): 633.17, #queue-req: 25\n",
      "[2025-08-13 20:22:57] INFO:     127.0.0.1:41238 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:57] Prefill batch. #new-seq: 1, #new-token: 7314, #cached-token: 393, token usage: 0.93, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:22:57] INFO:     127.0.0.1:57974 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:58] Prefill batch. #new-seq: 1, #new-token: 223, #cached-token: 410, token usage: 0.95, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:22:58] INFO:     127.0.0.1:57978 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:58] Prefill batch. #new-seq: 3, #new-token: 3088, #cached-token: 996, token usage: 0.93, #running-req: 73, #queue-req: 21\n",
      "[2025-08-13 20:22:58] INFO:     127.0.0.1:41254 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:58] INFO:     127.0.0.1:34756 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:58] Prefill batch. #new-seq: 2, #new-token: 2661, #cached-token: 531, token usage: 0.92, #running-req: 74, #queue-req: 21\n",
      "[2025-08-13 20:22:59] INFO:     127.0.0.1:55868 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:59] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 551, token usage: 0.90, #running-req: 75, #queue-req: 23\n",
      "[2025-08-13 20:22:59] INFO:     127.0.0.1:34764 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:22:59] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 443, token usage: 0.91, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:22:59] INFO:     127.0.0.1:34766 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:00] Prefill batch. #new-seq: 2, #new-token: 1948, #cached-token: 144, token usage: 0.94, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:23:01] INFO:     127.0.0.1:34778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:02] Prefill batch. #new-seq: 3, #new-token: 4725, #cached-token: 666, token usage: 0.91, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:23:03] INFO:     127.0.0.1:45030 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:03] Prefill batch. #new-seq: 1, #new-token: 7263, #cached-token: 409, token usage: 0.92, #running-req: 77, #queue-req: 21\n",
      "[2025-08-13 20:23:04] Decode batch. #running-req: 78, #token: 233427, token usage: 0.95, cuda graph: True, gen throughput (token/s): 430.46, #queue-req: 22\n",
      "[2025-08-13 20:23:06] INFO:     127.0.0.1:36942 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:06] INFO:     127.0.0.1:42370 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:07] Prefill batch. #new-seq: 1, #new-token: 5823, #cached-token: 464, token usage: 0.93, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:23:07] Decode batch. #running-req: 77, #token: 233760, token usage: 0.95, cuda graph: True, gen throughput (token/s): 896.49, #queue-req: 23\n",
      "[2025-08-13 20:23:08] INFO:     127.0.0.1:34160 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:08] Prefill batch. #new-seq: 1, #new-token: 4187, #cached-token: 149, token usage: 0.94, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:23:10] INFO:     127.0.0.1:43152 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:10] INFO:     127.0.0.1:42376 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:10] Prefill batch. #new-seq: 1, #new-token: 3287, #cached-token: 465, token usage: 0.93, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:23:11] Decode batch. #running-req: 76, #token: 233077, token usage: 0.95, cuda graph: True, gen throughput (token/s): 842.46, #queue-req: 24\n",
      "[2025-08-13 20:23:11] INFO:     127.0.0.1:45058 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:11] Prefill batch. #new-seq: 1, #new-token: 4181, #cached-token: 470, token usage: 0.94, #running-req: 75, #queue-req: 23\n",
      "[2025-08-13 20:23:13] INFO:     127.0.0.1:55896 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:13] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 783, token usage: 0.91, #running-req: 75, #queue-req: 21\n",
      "[2025-08-13 20:23:13] Prefill batch. #new-seq: 2, #new-token: 3429, #cached-token: 542, token usage: 0.94, #running-req: 77, #queue-req: 20\n",
      ".[2025-08-13 20:23:15] INFO:     127.0.0.1:42382 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:15] Prefill batch. #new-seq: 1, #new-token: 2209, #cached-token: 446, token usage: 0.94, #running-req: 78, #queue-req: 21\n",
      "[2025-08-13 20:23:15] Decode batch. #running-req: 79, #token: 233148, token usage: 0.95, cuda graph: True, gen throughput (token/s): 678.47, #queue-req: 21\n",
      "[2025-08-13 20:23:16] INFO:     127.0.0.1:43164 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:16] INFO:     127.0.0.1:41192 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:16] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 1661, token usage: 0.89, #running-req: 77, #queue-req: 16\n",
      "[2025-08-13 20:23:16] Prefill batch. #new-seq: 2, #new-token: 3439, #cached-token: 441, token usage: 0.92, #running-req: 81, #queue-req: 15\n",
      "[2025-08-13 20:23:17] INFO:     127.0.0.1:46654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:17] Prefill batch. #new-seq: 2, #new-token: 4904, #cached-token: 852, token usage: 0.91, #running-req: 82, #queue-req: 13\n",
      "[2025-08-13 20:23:20] Decode batch. #running-req: 84, #token: 230381, token usage: 0.94, cuda graph: True, gen throughput (token/s): 746.72, #queue-req: 16\n",
      "[2025-08-13 20:23:20] INFO:     127.0.0.1:43180 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:20] Prefill batch. #new-seq: 2, #new-token: 6876, #cached-token: 926, token usage: 0.92, #running-req: 83, #queue-req: 14\n",
      "[2025-08-13 20:23:22] INFO:     127.0.0.1:42396 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:22] INFO:     127.0.0.1:42406 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:22] Prefill batch. #new-seq: 1, #new-token: 5454, #cached-token: 393, token usage: 0.92, #running-req: 83, #queue-req: 16\n",
      "[2025-08-13 20:23:23] INFO:     127.0.0.1:43176 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:24] INFO:     127.0.0.1:49728 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:24] INFO:     127.0.0.1:49738 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:24] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.91, #running-req: 81, #queue-req: 18\n",
      "[2025-08-13 20:23:24] Decode batch. #running-req: 81, #token: 231675, token usage: 0.94, cuda graph: True, gen throughput (token/s): 784.46, #queue-req: 18\n",
      "[2025-08-13 20:23:24] Prefill batch. #new-seq: 1, #new-token: 1408, #cached-token: 0, token usage: 0.94, #running-req: 81, #queue-req: 18\n",
      "[2025-08-13 20:23:25] INFO:     127.0.0.1:34778 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:23:25] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 842, token usage: 0.91, #running-req: 81, #queue-req: 17\n",
      "[2025-08-13 20:23:25] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 0, token usage: 0.94, #running-req: 82, #queue-req: 17\n",
      "[2025-08-13 20:23:27] INFO:     127.0.0.1:41238 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:27] INFO:     127.0.0.1:41254 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:28] Prefill batch. #new-seq: 1, #new-token: 2360, #cached-token: 96, token usage: 0.93, #running-req: 81, #queue-req: 16\n",
      "[2025-08-13 20:23:29] INFO:     127.0.0.1:41198 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:29] Prefill batch. #new-seq: 1, #new-token: 2220, #cached-token: 412, token usage: 0.94, #running-req: 81, #queue-req: 15\n",
      "[2025-08-13 20:23:29] INFO:     127.0.0.1:41188 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:29] Prefill batch. #new-seq: 1, #new-token: 4242, #cached-token: 409, token usage: 0.94, #running-req: 81, #queue-req: 14\n",
      "[2025-08-13 20:23:30] Decode batch. #running-req: 82, #token: 235254, token usage: 0.96, cuda graph: True, gen throughput (token/s): 577.29, #queue-req: 14\n",
      "[2025-08-13 20:23:30] INFO:     127.0.0.1:49764 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:30] Prefill batch. #new-seq: 1, #new-token: 2179, #cached-token: 412, token usage: 0.94, #running-req: 81, #queue-req: 13\n",
      "[2025-08-13 20:23:31] INFO:     127.0.0.1:34756 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:31] Prefill batch. #new-seq: 3, #new-token: 5403, #cached-token: 765, token usage: 0.91, #running-req: 81, #queue-req: 15\n",
      "[2025-08-13 20:23:31] INFO:     127.0.0.1:42376 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:32] Prefill batch. #new-seq: 1, #new-token: 2355, #cached-token: 446, token usage: 0.94, #running-req: 83, #queue-req: 14\n",
      "[2025-08-13 20:23:33] INFO:     127.0.0.1:42370 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:23:34] INFO:     127.0.0.1:42382 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:34] Prefill batch. #new-seq: 1, #new-token: 7430, #cached-token: 410, token usage: 0.91, #running-req: 82, #queue-req: 15\n",
      "[2025-08-13 20:23:35] Decode batch. #running-req: 83, #token: 232644, token usage: 0.95, cuda graph: True, gen throughput (token/s): 684.28, #queue-req: 15\n",
      "[2025-08-13 20:23:36] INFO:     127.0.0.1:34766 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:36] INFO:     127.0.0.1:34764 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:36] Prefill batch. #new-seq: 2, #new-token: 2676, #cached-token: 899, token usage: 0.92, #running-req: 81, #queue-req: 15\n",
      "[2025-08-13 20:23:38] Decode batch. #running-req: 83, #token: 231506, token usage: 0.94, cuda graph: True, gen throughput (token/s): 974.62, #queue-req: 17\n",
      "[2025-08-13 20:23:39] INFO:     127.0.0.1:47252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:41] Decode batch. #running-req: 82, #token: 233942, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1034.73, #queue-req: 18\n",
      "[2025-08-13 20:23:42] INFO:     127.0.0.1:50226 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:44] INFO:     127.0.0.1:36228 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:44] Decode batch. #running-req: 80, #token: 235138, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1029.71, #queue-req: 19\n",
      "[2025-08-13 20:23:45] INFO:     127.0.0.1:36352 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:45] Prefill batch. #new-seq: 1, #new-token: 4757, #cached-token: 409, token usage: 0.94, #running-req: 79, #queue-req: 18\n",
      "[2025-08-13 20:23:46] INFO:     127.0.0.1:36376 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:46] Prefill batch. #new-seq: 1, #new-token: 2673, #cached-token: 77, token usage: 0.94, #running-req: 79, #queue-req: 20\n",
      "[2025-08-13 20:23:47] INFO:     127.0.0.1:45042 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:47] INFO:     127.0.0.1:45054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:47] Prefill batch. #new-seq: 1, #new-token: 6484, #cached-token: 126, token usage: 0.91, #running-req: 78, #queue-req: 21\n",
      "[2025-08-13 20:23:48] INFO:     127.0.0.1:45072 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:48] Prefill batch. #new-seq: 1, #new-token: 4370, #cached-token: 452, token usage: 0.93, #running-req: 78, #queue-req: 21\n",
      "[2025-08-13 20:23:49] Decode batch. #running-req: 79, #token: 234830, token usage: 0.96, cuda graph: True, gen throughput (token/s): 690.81, #queue-req: 21\n",
      "[2025-08-13 20:23:50] INFO:     127.0.0.1:57502 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:50] Prefill batch. #new-seq: 1, #new-token: 2174, #cached-token: 460, token usage: 0.95, #running-req: 78, #queue-req: 21\n",
      "[2025-08-13 20:23:52] INFO:     127.0.0.1:46594 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:23:52] Decode batch. #running-req: 78, #token: 237513, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1004.75, #queue-req: 21\n",
      "[2025-08-13 20:23:53] INFO:     127.0.0.1:42406 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:23:53] INFO:     127.0.0.1:33112 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:53] INFO:     127.0.0.1:36180 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:55] Decode batch. #running-req: 75, #token: 233802, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1011.20, #queue-req: 22\n",
      "[2025-08-13 20:23:56] INFO:     127.0.0.1:42396 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:57] INFO:     127.0.0.1:36174 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:58] INFO:     127.0.0.1:49738 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:58] Prefill batch. #new-seq: 1, #new-token: 7580, #cached-token: 410, token usage: 0.93, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:23:59] INFO:     127.0.0.1:41092 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:59] Prefill batch. #new-seq: 1, #new-token: 319, #cached-token: 93, token usage: 0.95, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 20:23:59] INFO:     127.0.0.1:49728 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:23:59] Prefill batch. #new-seq: 2, #new-token: 5084, #cached-token: 770, token usage: 0.93, #running-req: 72, #queue-req: 21\n",
      "[2025-08-13 20:23:59] Decode batch. #running-req: 74, #token: 234913, token usage: 0.96, cuda graph: True, gen throughput (token/s): 694.35, #queue-req: 21\n",
      "[2025-08-13 20:24:00] INFO:     127.0.0.1:33110 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:00] INFO:     127.0.0.1:36202 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:00] INFO:     127.0.0.1:49764 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:01] Prefill batch. #new-seq: 2, #new-token: 4407, #cached-token: 619, token usage: 0.92, #running-req: 71, #queue-req: 20\n",
      "[2025-08-13 20:24:01] INFO:     127.0.0.1:41078 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:01] Prefill batch. #new-seq: 4, #new-token: 6912, #cached-token: 1445, token usage: 0.90, #running-req: 72, #queue-req: 17\n",
      "[2025-08-13 20:24:02] INFO:     127.0.0.1:46558 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:02] Prefill batch. #new-seq: 2, #new-token: 4902, #cached-token: 879, token usage: 0.92, #running-req: 75, #queue-req: 15\n",
      "[2025-08-13 20:24:04] Decode batch. #running-req: 77, #token: 232675, token usage: 0.95, cuda graph: True, gen throughput (token/s): 708.77, #queue-req: 15\n",
      "[2025-08-13 20:24:07] Decode batch. #running-req: 77, #token: 235755, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1080.07, #queue-req: 23\n",
      "[2025-08-13 20:24:08] INFO:     127.0.0.1:55442 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:08] INFO:     127.0.0.1:46570 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:08] Prefill batch. #new-seq: 2, #new-token: 668, #cached-token: 932, token usage: 0.94, #running-req: 75, #queue-req: 21\n",
      "[2025-08-13 20:24:10] Decode batch. #running-req: 77, #token: 231838, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1032.48, #queue-req: 21\n",
      "[2025-08-13 20:24:10] INFO:     127.0.0.1:41090 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:10] Prefill batch. #new-seq: 1, #new-token: 4367, #cached-token: 455, token usage: 0.94, #running-req: 76, #queue-req: 20\n",
      "[2025-08-13 20:24:10] INFO:     127.0.0.1:40860 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:11] Prefill batch. #new-seq: 2, #new-token: 5220, #cached-token: 596, token usage: 0.92, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:24:13] INFO:     127.0.0.1:35484 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:13] Decode batch. #running-req: 77, #token: 232997, token usage: 0.95, cuda graph: True, gen throughput (token/s): 817.96, #queue-req: 22\n",
      "[2025-08-13 20:24:14] INFO:     127.0.0.1:41736 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:14] Prefill batch. #new-seq: 1, #new-token: 4377, #cached-token: 443, token usage: 0.94, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:24:17] Decode batch. #running-req: 77, #token: 237601, token usage: 0.97, cuda graph: True, gen throughput (token/s): 911.74, #queue-req: 23\n",
      "[2025-08-13 20:24:18] INFO:     127.0.0.1:52300 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:20] Decode batch. #running-req: 76, #token: 232536, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1031.08, #queue-req: 23\n",
      "[2025-08-13 20:24:20] INFO:     127.0.0.1:36352 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:20] Prefill batch. #new-seq: 1, #new-token: 6509, #cached-token: 146, token usage: 0.93, #running-req: 75, #queue-req: 23\n",
      "[2025-08-13 20:24:21] INFO:     127.0.0.1:36376 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:22] Prefill batch. #new-seq: 2, #new-token: 4571, #cached-token: 874, token usage: 0.94, #running-req: 75, #queue-req: 21\n",
      "[2025-08-13 20:24:22] INFO:     127.0.0.1:45054 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:22] Prefill batch. #new-seq: 3, #new-token: 300, #cached-token: 1437, token usage: 0.93, #running-req: 76, #queue-req: 18\n",
      "[2025-08-13 20:24:24] Decode batch. #running-req: 79, #token: 231493, token usage: 0.94, cuda graph: True, gen throughput (token/s): 778.26, #queue-req: 21\n",
      "[2025-08-13 20:24:24] INFO:     127.0.0.1:47238 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:24] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1408, token usage: 0.89, #running-req: 78, #queue-req: 17\n",
      "[2025-08-13 20:24:24] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 0, token usage: 0.92, #running-req: 81, #queue-req: 17\n",
      ".[2025-08-13 20:24:26] INFO:     127.0.0.1:45042 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:26] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 553, token usage: 0.91, #running-req: 81, #queue-req: 17\n",
      "[2025-08-13 20:24:26] Prefill batch. #new-seq: 2, #new-token: 1103, #cached-token: 463, token usage: 0.94, #running-req: 81, #queue-req: 16\n",
      "[2025-08-13 20:24:28] Decode batch. #running-req: 83, #token: 234632, token usage: 0.95, cuda graph: True, gen throughput (token/s): 714.26, #queue-req: 17\n",
      "[2025-08-13 20:24:29] INFO:     127.0.0.1:52284 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:31] INFO:     127.0.0.1:45836 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:31] Decode batch. #running-req: 81, #token: 234267, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1103.94, #queue-req: 18\n",
      "[2025-08-13 20:24:32] INFO:     127.0.0.1:45072 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:33] INFO:     127.0.0.1:57502 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:33] Prefill batch. #new-seq: 1, #new-token: 2224, #cached-token: 409, token usage: 0.94, #running-req: 79, #queue-req: 18\n",
      "[2025-08-13 20:24:34] INFO:     127.0.0.1:41078 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:34] Prefill batch. #new-seq: 3, #new-token: 3166, #cached-token: 973, token usage: 0.92, #running-req: 79, #queue-req: 15\n",
      "[2025-08-13 20:24:35] Decode batch. #running-req: 82, #token: 229093, token usage: 0.93, cuda graph: True, gen throughput (token/s): 949.17, #queue-req: 15\n",
      "[2025-08-13 20:24:35] INFO:     127.0.0.1:56834 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:35] Prefill batch. #new-seq: 2, #new-token: 4439, #cached-token: 274, token usage: 0.93, #running-req: 81, #queue-req: 16\n",
      "[2025-08-13 20:24:36] INFO:     127.0.0.1:41090 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:36] Prefill batch. #new-seq: 1, #new-token: 2359, #cached-token: 443, token usage: 0.94, #running-req: 82, #queue-req: 15\n",
      "[2025-08-13 20:24:37] INFO:     127.0.0.1:42536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:37] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 448, token usage: 0.94, #running-req: 82, #queue-req: 14\n",
      "[2025-08-13 20:24:38] Decode batch. #running-req: 83, #token: 234843, token usage: 0.96, cuda graph: True, gen throughput (token/s): 890.25, #queue-req: 14\n",
      "[2025-08-13 20:24:41] Decode batch. #running-req: 83, #token: 236379, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1113.81, #queue-req: 17\n",
      "[2025-08-13 20:24:41] INFO:     127.0.0.1:33146 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:42] INFO:     127.0.0.1:46584 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:44] Decode batch. #running-req: 81, #token: 236642, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1038.51, #queue-req: 19\n",
      "[2025-08-13 20:24:46] INFO:     127.0.0.1:40866 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:46] INFO:     127.0.0.1:40882 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:46] INFO:     127.0.0.1:40892 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:47] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.90, #running-req: 78, #queue-req: 21\n",
      "[2025-08-13 20:24:47] INFO:     127.0.0.1:40908 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:47] INFO:     127.0.0.1:40928 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:47] Prefill batch. #new-seq: 3, #new-token: 3996, #cached-token: 251, token usage: 0.93, #running-req: 78, #queue-req: 21\n",
      "[2025-08-13 20:24:48] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 449, token usage: 0.95, #running-req: 79, #queue-req: 20\n",
      "[2025-08-13 20:24:48] INFO:     127.0.0.1:51606 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:49] INFO:     127.0.0.1:44764 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:49] Prefill batch. #new-seq: 1, #new-token: 2220, #cached-token: 412, token usage: 0.93, #running-req: 78, #queue-req: 19\n",
      "[2025-08-13 20:24:49] Decode batch. #running-req: 78, #token: 231756, token usage: 0.94, cuda graph: True, gen throughput (token/s): 712.89, #queue-req: 19\n",
      "[2025-08-13 20:24:51] INFO:     127.0.0.1:36964 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:51] Prefill batch. #new-seq: 1, #new-token: 2173, #cached-token: 461, token usage: 0.92, #running-req: 78, #queue-req: 20\n",
      ".[2025-08-13 20:24:52] Decode batch. #running-req: 79, #token: 230234, token usage: 0.94, cuda graph: True, gen throughput (token/s): 955.00, #queue-req: 20\n",
      "[2025-08-13 20:24:53] INFO:     127.0.0.1:50234 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:53] Prefill batch. #new-seq: 2, #new-token: 4729, #cached-token: 489, token usage: 0.93, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 20:24:55] INFO:     127.0.0.1:46600 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:55] INFO:     127.0.0.1:50246 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:55] INFO:     127.0.0.1:50252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:55] Prefill batch. #new-seq: 1, #new-token: 7180, #cached-token: 626, token usage: 0.92, #running-req: 77, #queue-req: 19\n",
      "[2025-08-13 20:24:56] Decode batch. #running-req: 78, #token: 234610, token usage: 0.95, cuda graph: True, gen throughput (token/s): 791.97, #queue-req: 22\n",
      "[2025-08-13 20:24:56] INFO:     127.0.0.1:46638 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:56] INFO:     127.0.0.1:46648 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:56] Prefill batch. #new-seq: 3, #new-token: 2795, #cached-token: 1072, token usage: 0.93, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:24:59] INFO:     127.0.0.1:33682 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:59] INFO:     127.0.0.1:40860 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:24:59] Prefill batch. #new-seq: 4, #new-token: 5055, #cached-token: 1159, token usage: 0.89, #running-req: 78, #queue-req: 18\n",
      ".[2025-08-13 20:25:00] Prefill batch. #new-seq: 3, #new-token: 5075, #cached-token: 641, token usage: 0.91, #running-req: 81, #queue-req: 15\n",
      "[2025-08-13 20:25:00] Decode batch. #running-req: 84, #token: 229931, token usage: 0.94, cuda graph: True, gen throughput (token/s): 801.06, #queue-req: 16\n",
      "[2025-08-13 20:25:03] Decode batch. #running-req: 84, #token: 230282, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1146.16, #queue-req: 16\n",
      "[2025-08-13 20:25:03] INFO:     127.0.0.1:45800 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:03] Prefill batch. #new-seq: 2, #new-token: 4452, #cached-token: 596, token usage: 0.94, #running-req: 83, #queue-req: 14\n",
      "[2025-08-13 20:25:04] INFO:     127.0.0.1:40866 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:25:06] INFO:     127.0.0.1:35474 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:06] INFO:     127.0.0.1:39866 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:06] Prefill batch. #new-seq: 1, #new-token: 7228, #cached-token: 412, token usage: 0.91, #running-req: 82, #queue-req: 16\n",
      "[2025-08-13 20:25:07] Decode batch. #running-req: 83, #token: 232527, token usage: 0.95, cuda graph: True, gen throughput (token/s): 834.38, #queue-req: 17\n",
      "[2025-08-13 20:25:09] INFO:     127.0.0.1:33130 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:09] Prefill batch. #new-seq: 1, #new-token: 4454, #cached-token: 93, token usage: 0.94, #running-req: 82, #queue-req: 17\n",
      "[2025-08-13 20:25:10] INFO:     127.0.0.1:40928 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:10] Prefill batch. #new-seq: 1, #new-token: 2268, #cached-token: 77, token usage: 0.95, #running-req: 82, #queue-req: 16\n",
      "[2025-08-13 20:25:11] Decode batch. #running-req: 83, #token: 235774, token usage: 0.96, cuda graph: True, gen throughput (token/s): 927.32, #queue-req: 16\n",
      "[2025-08-13 20:25:13] INFO:     127.0.0.1:42512 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:13] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 144, token usage: 0.94, #running-req: 82, #queue-req: 16\n",
      "[2025-08-13 20:25:14] Decode batch. #running-req: 83, #token: 229537, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1106.22, #queue-req: 16\n",
      "[2025-08-13 20:25:14] INFO:     127.0.0.1:45792 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:14] Prefill batch. #new-seq: 2, #new-token: 1877, #cached-token: 539, token usage: 0.93, #running-req: 82, #queue-req: 14\n",
      "[2025-08-13 20:25:14] INFO:     127.0.0.1:56828 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:14] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1023, token usage: 0.92, #running-req: 83, #queue-req: 11\n",
      "[2025-08-13 20:25:15] Prefill batch. #new-seq: 1, #new-token: 1489, #cached-token: 0, token usage: 0.95, #running-req: 85, #queue-req: 11\n",
      "[2025-08-13 20:25:15] INFO:     127.0.0.1:40882 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:15] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 168, token usage: 0.95, #running-req: 85, #queue-req: 12\n",
      "[2025-08-13 20:25:16] INFO:     127.0.0.1:50246 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:16] Prefill batch. #new-seq: 1, #new-token: 2284, #cached-token: 441, token usage: 0.94, #running-req: 85, #queue-req: 11\n",
      "[2025-08-13 20:25:17] INFO:     127.0.0.1:40892 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:17] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 925, token usage: 0.93, #running-req: 85, #queue-req: 9\n",
      "[2025-08-13 20:25:17] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 0, token usage: 0.96, #running-req: 86, #queue-req: 9\n",
      "[2025-08-13 20:25:19] Decode batch. #running-req: 87, #token: 237718, token usage: 0.97, cuda graph: True, gen throughput (token/s): 694.14, #queue-req: 13\n",
      "[2025-08-13 20:25:21] INFO:     127.0.0.1:51558 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:21] INFO:     127.0.0.1:42102 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:22] Decode batch. #running-req: 85, #token: 240052, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1172.19, #queue-req: 13\n",
      "[2025-08-13 20:25:22] INFO:     127.0.0.1:40908 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:24] INFO:     127.0.0.1:46638 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:25] Decode batch. #running-req: 83, #token: 236738, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1126.38, #queue-req: 16\n",
      "[2025-08-13 20:25:26] INFO:     127.0.0.1:50234 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:26] INFO:     127.0.0.1:50252 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:26] Prefill batch. #new-seq: 2, #new-token: 273, #cached-token: 237, token usage: 0.94, #running-req: 81, #queue-req: 15\n",
      "[2025-08-13 20:25:27] INFO:     127.0.0.1:46648 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:27] Prefill batch. #new-seq: 2, #new-token: 4383, #cached-token: 300, token usage: 0.93, #running-req: 82, #queue-req: 13\n",
      "[2025-08-13 20:25:27] INFO:     127.0.0.1:33682 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:28] Decode batch. #running-req: 83, #token: 229996, token usage: 0.94, cuda graph: True, gen throughput (token/s): 992.02, #queue-req: 13\n",
      "[2025-08-13 20:25:28] INFO:     127.0.0.1:51588 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:28] Prefill batch. #new-seq: 1, #new-token: 7535, #cached-token: 464, token usage: 0.93, #running-req: 82, #queue-req: 12\n",
      "[2025-08-13 20:25:29] INFO:     127.0.0.1:47250 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:30] Prefill batch. #new-seq: 1, #new-token: 2348, #cached-token: 437, token usage: 0.95, #running-req: 82, #queue-req: 13\n",
      "[2025-08-13 20:25:31] INFO:     127.0.0.1:45852 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:31] Prefill batch. #new-seq: 1, #new-token: 2275, #cached-token: 126, token usage: 0.94, #running-req: 82, #queue-req: 16\n",
      "[2025-08-13 20:25:31] INFO:     127.0.0.1:42566 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:32] Decode batch. #running-req: 82, #token: 235885, token usage: 0.96, cuda graph: True, gen throughput (token/s): 798.57, #queue-req: 16\n",
      "[2025-08-13 20:25:33] INFO:     127.0.0.1:35474 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:35] Decode batch. #running-req: 81, #token: 236954, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1084.37, #queue-req: 19\n",
      "[2025-08-13 20:25:37] INFO:     127.0.0.1:34626 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:38] Decode batch. #running-req: 80, #token: 235299, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1082.40, #queue-req: 20\n",
      "[2025-08-13 20:25:39] INFO:     127.0.0.1:33130 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:40] INFO:     127.0.0.1:47282 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:40] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 444, token usage: 0.94, #running-req: 78, #queue-req: 19\n",
      "[2025-08-13 20:25:41] Decode batch. #running-req: 79, #token: 233831, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1034.42, #queue-req: 21\n",
      "[2025-08-13 20:25:42] INFO:     127.0.0.1:42532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:42] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 444, token usage: 0.95, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 20:25:44] INFO:     127.0.0.1:56818 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:44] Prefill batch. #new-seq: 1, #new-token: 3268, #cached-token: 467, token usage: 0.95, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 20:25:45] Decode batch. #running-req: 79, #token: 236888, token usage: 0.96, cuda graph: True, gen throughput (token/s): 933.32, #queue-req: 20\n",
      "[2025-08-13 20:25:46] INFO:     127.0.0.1:52258 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:46] INFO:     127.0.0.1:52264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:46] Prefill batch. #new-seq: 2, #new-token: 2360, #cached-token: 537, token usage: 0.94, #running-req: 77, #queue-req: 21\n",
      "[2025-08-13 20:25:47] INFO:     127.0.0.1:55446 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:47] Prefill batch. #new-seq: 2, #new-token: 2546, #cached-token: 922, token usage: 0.94, #running-req: 78, #queue-req: 19\n",
      "[2025-08-13 20:25:48] Decode batch. #running-req: 80, #token: 234149, token usage: 0.95, cuda graph: True, gen throughput (token/s): 955.36, #queue-req: 20\n",
      "[2025-08-13 20:25:48] INFO:     127.0.0.1:42066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:48] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 542, token usage: 0.94, #running-req: 79, #queue-req: 19\n",
      "[2025-08-13 20:25:48] INFO:     127.0.0.1:45776 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:48] Prefill batch. #new-seq: 1, #new-token: 4477, #cached-token: 146, token usage: 0.94, #running-req: 79, #queue-req: 18\n",
      "[2025-08-13 20:25:50] INFO:     127.0.0.1:52270 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:50] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.94, #running-req: 79, #queue-req: 19\n",
      "[2025-08-13 20:25:51] INFO:     127.0.0.1:52278 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:51] INFO:     127.0.0.1:52290 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:51] Prefill batch. #new-seq: 2, #new-token: 6905, #cached-token: 912, token usage: 0.91, #running-req: 78, #queue-req: 17\n",
      "[2025-08-13 20:25:52] Decode batch. #running-req: 80, #token: 232503, token usage: 0.95, cuda graph: True, gen throughput (token/s): 782.56, #queue-req: 20\n",
      "[2025-08-13 20:25:53] INFO:     127.0.0.1:52316 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:53] INFO:     127.0.0.1:52322 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:53] Prefill batch. #new-seq: 1, #new-token: 7552, #cached-token: 413, token usage: 0.92, #running-req: 78, #queue-req: 21\n",
      "[2025-08-13 20:25:55] INFO:     127.0.0.1:60112 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:55] Prefill batch. #new-seq: 1, #new-token: 2217, #cached-token: 469, token usage: 0.95, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 20:25:56] Decode batch. #running-req: 79, #token: 237519, token usage: 0.97, cuda graph: True, gen throughput (token/s): 824.63, #queue-req: 20\n",
      "[2025-08-13 20:25:57] INFO:     127.0.0.1:56836 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:59] Decode batch. #running-req: 78, #token: 229882, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1077.15, #queue-req: 22\n",
      "[2025-08-13 20:25:59] INFO:     127.0.0.1:42514 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:59] INFO:     127.0.0.1:42524 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:59] Prefill batch. #new-seq: 2, #new-token: 2961, #cached-token: 559, token usage: 0.94, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:25:59] INFO:     127.0.0.1:42544 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:25:59] Prefill batch. #new-seq: 1, #new-token: 5190, #cached-token: 625, token usage: 0.93, #running-req: 77, #queue-req: 20\n",
      "[2025-08-13 20:26:02] Decode batch. #running-req: 78, #token: 236797, token usage: 0.96, cuda graph: True, gen throughput (token/s): 860.77, #queue-req: 22\n",
      "[2025-08-13 20:26:03] INFO:     127.0.0.1:41748 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:03] INFO:     127.0.0.1:41752 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:03] Prefill batch. #new-seq: 2, #new-token: 1261, #cached-token: 290, token usage: 0.93, #running-req: 77, #queue-req: 21\n",
      "[2025-08-13 20:26:03] INFO:     127.0.0.1:36172 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:03] INFO:     127.0.0.1:36186 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:03] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 930, token usage: 0.92, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:26:03] Prefill batch. #new-seq: 1, #new-token: 1254, #cached-token: 0, token usage: 0.96, #running-req: 77, #queue-req: 22\n",
      "[2025-08-13 20:26:05] INFO:     127.0.0.1:34626 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:05] INFO:     127.0.0.1:36214 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:05] INFO:     127.0.0.1:34622 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:05] Prefill batch. #new-seq: 3, #new-token: 6183, #cached-token: 1257, token usage: 0.91, #running-req: 75, #queue-req: 19\n",
      "[2025-08-13 20:26:06] INFO:     127.0.0.1:47250 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:06] Prefill batch. #new-seq: 2, #new-token: 6510, #cached-token: 601, token usage: 0.93, #running-req: 77, #queue-req: 20\n",
      "[2025-08-13 20:26:07] INFO:     127.0.0.1:51584 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:07] Decode batch. #running-req: 79, #token: 234784, token usage: 0.95, cuda graph: True, gen throughput (token/s): 631.81, #queue-req: 20\n",
      "[2025-08-13 20:26:10] Decode batch. #running-req: 78, #token: 237904, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1085.30, #queue-req: 22\n",
      "[2025-08-13 20:26:12] INFO:     127.0.0.1:35128 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:13] Decode batch. #running-req: 77, #token: 238215, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1073.06, #queue-req: 23\n",
      "[2025-08-13 20:26:14] INFO:     127.0.0.1:47282 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:15] INFO:     127.0.0.1:34642 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:15] Prefill batch. #new-seq: 1, #new-token: 2856, #cached-token: 480, token usage: 0.95, #running-req: 75, #queue-req: 24\n",
      "[2025-08-13 20:26:16] INFO:     127.0.0.1:34648 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:16] Decode batch. #running-req: 75, #token: 233029, token usage: 0.95, cuda graph: True, gen throughput (token/s): 973.76, #queue-req: 25\n",
      "[2025-08-13 20:26:16] INFO:     127.0.0.1:34658 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:16] INFO:     127.0.0.1:34666 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:16] INFO:     127.0.0.1:44728 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:16] Prefill batch. #new-seq: 2, #new-token: 5630, #cached-token: 674, token usage: 0.91, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:26:17] INFO:     127.0.0.1:52258 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:17] INFO:     127.0.0.1:52264 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:17] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 837, token usage: 0.91, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:26:17] Prefill batch. #new-seq: 2, #new-token: 3583, #cached-token: 449, token usage: 0.94, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 20:26:19] INFO:     127.0.0.1:44744 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:19] INFO:     127.0.0.1:44754 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:19] Prefill batch. #new-seq: 3, #new-token: 7441, #cached-token: 1059, token usage: 0.92, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:26:20] INFO:     127.0.0.1:52278 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:20] Prefill batch. #new-seq: 2, #new-token: 6460, #cached-token: 615, token usage: 0.93, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:26:21] INFO:     127.0.0.1:52322 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:21] Prefill batch. #new-seq: 1, #new-token: 4371, #cached-token: 451, token usage: 0.94, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:26:22] Decode batch. #running-req: 77, #token: 237034, token usage: 0.96, cuda graph: True, gen throughput (token/s): 496.88, #queue-req: 23\n",
      "[2025-08-13 20:26:23] INFO:     127.0.0.1:44762 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:23] Prefill batch. #new-seq: 2, #new-token: 4207, #cached-token: 932, token usage: 0.94, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:26:26] Decode batch. #running-req: 78, #token: 236961, token usage: 0.96, cuda graph: True, gen throughput (token/s): 947.73, #queue-req: 22\n",
      "[2025-08-13 20:26:26] INFO:     127.0.0.1:56836 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:28] INFO:     127.0.0.1:42544 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:28] Prefill batch. #new-seq: 1, #new-token: 4302, #cached-token: 129, token usage: 0.95, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:26:29] Decode batch. #running-req: 77, #token: 237737, token usage: 0.97, cuda graph: True, gen throughput (token/s): 937.25, #queue-req: 22\n",
      "[2025-08-13 20:26:30] INFO:     127.0.0.1:39854 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:30] INFO:     127.0.0.1:52290 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:30] Prefill batch. #new-seq: 2, #new-token: 4700, #cached-token: 902, token usage: 0.94, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:26:31] INFO:     127.0.0.1:52316 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:31] Prefill batch. #new-seq: 1, #new-token: 4301, #cached-token: 126, token usage: 0.95, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:26:32] INFO:     127.0.0.1:42514 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:32] Prefill batch. #new-seq: 1, #new-token: 4358, #cached-token: 464, token usage: 0.95, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:26:32] INFO:     127.0.0.1:36214 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:32] Prefill batch. #new-seq: 1, #new-token: 2359, #cached-token: 443, token usage: 0.95, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:26:33] INFO:     127.0.0.1:41748 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:33] Decode batch. #running-req: 77, #token: 234128, token usage: 0.95, cuda graph: True, gen throughput (token/s): 714.44, #queue-req: 21\n",
      "[2025-08-13 20:26:34] INFO:     127.0.0.1:39874 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:34] INFO:     127.0.0.1:39880 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:34] Prefill batch. #new-seq: 3, #new-token: 3481, #cached-token: 1008, token usage: 0.93, #running-req: 74, #queue-req: 18\n",
      "[2025-08-13 20:26:35] INFO:     127.0.0.1:53274 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:36] INFO:     127.0.0.1:41330 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:36] Prefill batch. #new-seq: 1, #new-token: 4698, #cached-token: 477, token usage: 0.94, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:26:37] Decode batch. #running-req: 76, #token: 236369, token usage: 0.96, cuda graph: True, gen throughput (token/s): 844.41, #queue-req: 22\n",
      "[2025-08-13 20:26:40] Decode batch. #running-req: 76, #token: 239409, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1048.93, #queue-req: 24\n",
      "[2025-08-13 20:26:40] INFO:     127.0.0.1:35122 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:40] INFO:     127.0.0.1:41752 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:40] Prefill batch. #new-seq: 1, #new-token: 2231, #cached-token: 122, token usage: 0.95, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 20:26:41] INFO:     127.0.0.1:36172 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:41] INFO:     127.0.0.1:36186 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:42] Prefill batch. #new-seq: 1, #new-token: 4225, #cached-token: 450, token usage: 0.95, #running-req: 73, #queue-req: 22\n",
      "[2025-08-13 20:26:43] INFO:     127.0.0.1:34622 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:43] Prefill batch. #new-seq: 1, #new-token: 2335, #cached-token: 438, token usage: 0.95, #running-req: 73, #queue-req: 21\n",
      "[2025-08-13 20:26:43] Decode batch. #running-req: 74, #token: 236371, token usage: 0.96, cuda graph: True, gen throughput (token/s): 806.17, #queue-req: 21\n",
      "[2025-08-13 20:26:44] INFO:     127.0.0.1:41294 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:44] Prefill batch. #new-seq: 1, #new-token: 4376, #cached-token: 443, token usage: 0.94, #running-req: 73, #queue-req: 20\n",
      "[2025-08-13 20:26:45] INFO:     127.0.0.1:39886 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:45] Prefill batch. #new-seq: 2, #new-token: 5588, #cached-token: 918, token usage: 0.93, #running-req: 73, #queue-req: 18\n",
      "[2025-08-13 20:26:47] INFO:     127.0.0.1:41298 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:47] Decode batch. #running-req: 75, #token: 232736, token usage: 0.95, cuda graph: True, gen throughput (token/s): 790.42, #queue-req: 25\n",
      "[2025-08-13 20:26:47] Prefill batch. #new-seq: 1, #new-token: 207, #cached-token: 96, token usage: 0.95, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:26:48] INFO:     127.0.0.1:53282 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:48] Prefill batch. #new-seq: 1, #new-token: 4562, #cached-token: 412, token usage: 0.94, #running-req: 74, #queue-req: 23\n",
      ".[2025-08-13 20:26:50] INFO:     127.0.0.1:51566 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:50] Prefill batch. #new-seq: 1, #new-token: 4378, #cached-token: 444, token usage: 0.95, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:26:51] Decode batch. #running-req: 75, #token: 239324, token usage: 0.97, cuda graph: True, gen throughput (token/s): 816.77, #queue-req: 24\n",
      "[2025-08-13 20:26:52] INFO:     127.0.0.1:34642 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:53] INFO:     127.0.0.1:34648 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:54] Decode batch. #running-req: 73, #token: 235572, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1037.06, #queue-req: 26\n",
      "[2025-08-13 20:26:54] INFO:     127.0.0.1:34666 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:54] Prefill batch. #new-seq: 1, #new-token: 3161, #cached-token: 409, token usage: 0.95, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:26:55] INFO:     127.0.0.1:34658 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:55] Prefill batch. #new-seq: 1, #new-token: 3145, #cached-token: 462, token usage: 0.95, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:26:56] INFO:     127.0.0.1:34778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:56] INFO:     127.0.0.1:44728 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:57] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1024, token usage: 0.92, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:26:57] Prefill batch. #new-seq: 1, #new-token: 1557, #cached-token: 0, token usage: 0.95, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:26:58] INFO:     127.0.0.1:45772 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:58] Prefill batch. #new-seq: 1, #new-token: 4369, #cached-token: 452, token usage: 0.95, #running-req: 73, #queue-req: 26\n",
      "[2025-08-13 20:26:58] Decode batch. #running-req: 74, #token: 237643, token usage: 0.97, cuda graph: True, gen throughput (token/s): 619.20, #queue-req: 26\n",
      "[2025-08-13 20:26:59] INFO:     127.0.0.1:44762 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:26:59] Prefill batch. #new-seq: 1, #new-token: 2492, #cached-token: 465, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:27:00] INFO:     127.0.0.1:45812 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:00] INFO:     127.0.0.1:45824 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:00] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1485, token usage: 0.92, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 20:27:00] Prefill batch. #new-seq: 2, #new-token: 3089, #cached-token: 437, token usage: 0.95, #running-req: 74, #queue-req: 22\n",
      "[2025-08-13 20:27:01] INFO:     127.0.0.1:44754 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:01] Prefill batch. #new-seq: 1, #new-token: 2431, #cached-token: 93, token usage: 0.95, #running-req: 75, #queue-req: 23\n",
      "[2025-08-13 20:27:01] INFO:     127.0.0.1:41340 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:02] Prefill batch. #new-seq: 3, #new-token: 1324, #cached-token: 657, token usage: 0.93, #running-req: 75, #queue-req: 20\n",
      "[2025-08-13 20:27:02] INFO:     127.0.0.1:51582 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:02] INFO:     127.0.0.1:51590 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:02] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 225, token usage: 0.90, #running-req: 76, #queue-req: 18\n",
      "[2025-08-13 20:27:02] Prefill batch. #new-seq: 3, #new-token: 2955, #cached-token: 608, token usage: 0.94, #running-req: 77, #queue-req: 16\n",
      "[2025-08-13 20:27:04] Decode batch. #running-req: 80, #token: 234050, token usage: 0.95, cuda graph: True, gen throughput (token/s): 565.39, #queue-req: 20\n",
      "[2025-08-13 20:27:04] INFO:     127.0.0.1:44744 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:04] Prefill batch. #new-seq: 1, #new-token: 3127, #cached-token: 624, token usage: 0.93, #running-req: 79, #queue-req: 19\n",
      "[2025-08-13 20:27:04] INFO:     127.0.0.1:41350 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:04] Prefill batch. #new-seq: 1, #new-token: 2492, #cached-token: 465, token usage: 0.94, #running-req: 79, #queue-req: 18\n",
      "[2025-08-13 20:27:04] INFO:     127.0.0.1:42074 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:05] Prefill batch. #new-seq: 1, #new-token: 3154, #cached-token: 553, token usage: 0.94, #running-req: 79, #queue-req: 17\n",
      "[2025-08-13 20:27:06] INFO:     127.0.0.1:53032 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:07] Decode batch. #running-req: 79, #token: 234412, token usage: 0.95, cuda graph: True, gen throughput (token/s): 868.25, #queue-req: 17\n",
      "[2025-08-13 20:27:08] INFO:     127.0.0.1:51592 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:08] INFO:     127.0.0.1:51604 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:09] Prefill batch. #new-seq: 1, #new-token: 2685, #cached-token: 462, token usage: 0.94, #running-req: 77, #queue-req: 22\n",
      "[2025-08-13 20:27:09] INFO:     127.0.0.1:39880 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:09] Prefill batch. #new-seq: 2, #new-token: 291, #cached-token: 539, token usage: 0.93, #running-req: 77, #queue-req: 20\n",
      "[2025-08-13 20:27:10] Decode batch. #running-req: 79, #token: 231385, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1017.67, #queue-req: 21\n",
      "[2025-08-13 20:27:11] INFO:     127.0.0.1:39854 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:11] Prefill batch. #new-seq: 2, #new-token: 5019, #cached-token: 583, token usage: 0.93, #running-req: 78, #queue-req: 19\n",
      "[2025-08-13 20:27:13] INFO:     127.0.0.1:39874 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:13] Prefill batch. #new-seq: 1, #new-token: 2161, #cached-token: 473, token usage: 0.94, #running-req: 79, #queue-req: 19\n",
      "[2025-08-13 20:27:14] INFO:     127.0.0.1:39886 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:14] Prefill batch. #new-seq: 1, #new-token: 2220, #cached-token: 412, token usage: 0.92, #running-req: 79, #queue-req: 18\n",
      "[2025-08-13 20:27:14] Decode batch. #running-req: 80, #token: 228363, token usage: 0.93, cuda graph: True, gen throughput (token/s): 880.63, #queue-req: 18\n",
      "[2025-08-13 20:27:14] INFO:     127.0.0.1:53284 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:15] INFO:     127.0.0.1:42084 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:15] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 393, token usage: 0.91, #running-req: 78, #queue-req: 17\n",
      "[2025-08-13 20:27:15] Prefill batch. #new-seq: 1, #new-token: 1424, #cached-token: 0, token usage: 0.94, #running-req: 78, #queue-req: 17\n",
      "[2025-08-13 20:27:17] INFO:     127.0.0.1:34778 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:17] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 627, token usage: 0.92, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 20:27:17] Prefill batch. #new-seq: 1, #new-token: 1176, #cached-token: 0, token usage: 0.95, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 20:27:18] INFO:     127.0.0.1:60100 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:18] Prefill batch. #new-seq: 1, #new-token: 2286, #cached-token: 146, token usage: 0.94, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 20:27:19] Decode batch. #running-req: 79, #token: 234637, token usage: 0.95, cuda graph: True, gen throughput (token/s): 629.06, #queue-req: 21\n",
      "[2025-08-13 20:27:21] INFO:     127.0.0.1:42556 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:22] Decode batch. #running-req: 78, #token: 235680, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1077.93, #queue-req: 22\n",
      "[2025-08-13 20:27:24] INFO:     127.0.0.1:45772 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:27:25] Decode batch. #running-req: 77, #token: 236423, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1060.46, #queue-req: 22\n",
      "[2025-08-13 20:27:25] INFO:     127.0.0.1:42522 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:25] INFO:     127.0.0.1:42546 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:26] Prefill batch. #new-seq: 1, #new-token: 4377, #cached-token: 444, token usage: 0.93, #running-req: 75, #queue-req: 24\n",
      "[2025-08-13 20:27:28] Decode batch. #running-req: 76, #token: 234554, token usage: 0.95, cuda graph: True, gen throughput (token/s): 908.37, #queue-req: 24\n",
      "[2025-08-13 20:27:29] INFO:     127.0.0.1:42570 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:31] Decode batch. #running-req: 75, #token: 233273, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1045.34, #queue-req: 25\n",
      "[2025-08-13 20:27:32] INFO:     127.0.0.1:51982 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:32] Prefill batch. #new-seq: 1, #new-token: 5613, #cached-token: 393, token usage: 0.93, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:27:32] INFO:     127.0.0.1:53362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:34] INFO:     127.0.0.1:42560 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:34] Prefill batch. #new-seq: 1, #new-token: 4238, #cached-token: 446, token usage: 0.94, #running-req: 73, #queue-req: 26\n",
      "[2025-08-13 20:27:35] INFO:     127.0.0.1:42568 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:35] Prefill batch. #new-seq: 1, #new-token: 4690, #cached-token: 477, token usage: 0.95, #running-req: 73, #queue-req: 26\n",
      "[2025-08-13 20:27:35] Decode batch. #running-req: 74, #token: 237459, token usage: 0.97, cuda graph: True, gen throughput (token/s): 700.50, #queue-req: 26\n",
      "[2025-08-13 20:27:36] INFO:     127.0.0.1:42574 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:37] INFO:     127.0.0.1:45824 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:37] Prefill batch. #new-seq: 1, #new-token: 4183, #cached-token: 470, token usage: 0.93, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:27:37] INFO:     127.0.0.1:43286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:37] Prefill batch. #new-seq: 1, #new-token: 4374, #cached-token: 452, token usage: 0.94, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:27:38] INFO:     127.0.0.1:43292 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:38] Prefill batch. #new-seq: 2, #new-token: 2478, #cached-token: 911, token usage: 0.94, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 20:27:39] Decode batch. #running-req: 74, #token: 233941, token usage: 0.95, cuda graph: True, gen throughput (token/s): 769.61, #queue-req: 26\n",
      "[2025-08-13 20:27:42] Decode batch. #running-req: 74, #token: 236901, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1039.72, #queue-req: 26\n",
      "[2025-08-13 20:27:45] Decode batch. #running-req: 74, #token: 239861, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1031.23, #queue-req: 26\n",
      "[2025-08-13 20:27:45] INFO:     127.0.0.1:51590 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:46] INFO:     127.0.0.1:46312 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:46] Prefill batch. #new-seq: 1, #new-token: 1218, #cached-token: 119, token usage: 0.95, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:27:46] INFO:     127.0.0.1:51582 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:46] Prefill batch. #new-seq: 2, #new-token: 3436, #cached-token: 900, token usage: 0.94, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 20:27:47] INFO:     127.0.0.1:46358 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:47] Prefill batch. #new-seq: 1, #new-token: 2217, #cached-token: 469, token usage: 0.95, #running-req: 73, #queue-req: 22\n",
      "[2025-08-13 20:27:48] INFO:     127.0.0.1:43296 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:48] INFO:     127.0.0.1:43298 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:48] Prefill batch. #new-seq: 2, #new-token: 4652, #cached-token: 882, token usage: 0.94, #running-req: 72, #queue-req: 20\n",
      "[2025-08-13 20:27:49] Decode batch. #running-req: 74, #token: 235608, token usage: 0.96, cuda graph: True, gen throughput (token/s): 765.34, #queue-req: 22\n",
      "[2025-08-13 20:27:50] INFO:     127.0.0.1:47014 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:51] INFO:     127.0.0.1:41320 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:51] Prefill batch. #new-seq: 1, #new-token: 5227, #cached-token: 553, token usage: 0.94, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:27:52] Decode batch. #running-req: 73, #token: 236488, token usage: 0.96, cuda graph: True, gen throughput (token/s): 881.84, #queue-req: 27\n",
      "[2025-08-13 20:27:53] INFO:     127.0.0.1:42098 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:55] INFO:     127.0.0.1:42116 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:55] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.91, #running-req: 71, #queue-req: 28\n",
      "[2025-08-13 20:27:55] Prefill batch. #new-seq: 1, #new-token: 1168, #cached-token: 0, token usage: 0.94, #running-req: 71, #queue-req: 28\n",
      "[2025-08-13 20:27:56] Decode batch. #running-req: 72, #token: 229847, token usage: 0.93, cuda graph: True, gen throughput (token/s): 759.36, #queue-req: 28\n",
      "[2025-08-13 20:27:56] INFO:     127.0.0.1:45884 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:56] Prefill batch. #new-seq: 2, #new-token: 2409, #cached-token: 293, token usage: 0.94, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:27:56] INFO:     127.0.0.1:51952 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:56] INFO:     127.0.0.1:51964 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:56] INFO:     127.0.0.1:51980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:56] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 843, token usage: 0.91, #running-req: 70, #queue-req: 24\n",
      "[2025-08-13 20:27:56] Prefill batch. #new-seq: 1, #new-token: 1907, #cached-token: 0, token usage: 0.94, #running-req: 71, #queue-req: 24\n",
      "[2025-08-13 20:27:57] INFO:     127.0.0.1:51604 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:27:57] Prefill batch. #new-seq: 1, #new-token: 3069, #cached-token: 392, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:28:00] INFO:     127.0.0.1:47052 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:00] Prefill batch. #new-seq: 2, #new-token: 444, #cached-token: 855, token usage: 0.95, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:28:00] INFO:     127.0.0.1:51592 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:00] INFO:     127.0.0.1:51988 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:00] INFO:     127.0.0.1:53278 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:00] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 843, token usage: 0.91, #running-req: 70, #queue-req: 24\n",
      "[2025-08-13 20:28:00] INFO:     127.0.0.1:53288 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:00] Prefill batch. #new-seq: 2, #new-token: 2252, #cached-token: 624, token usage: 0.94, #running-req: 71, #queue-req: 23\n",
      "[2025-08-13 20:28:01] Prefill batch. #new-seq: 1, #new-token: 2309, #cached-token: 624, token usage: 0.95, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:28:01] Decode batch. #running-req: 73, #token: 235563, token usage: 0.96, cuda graph: True, gen throughput (token/s): 533.18, #queue-req: 27\n",
      "[2025-08-13 20:28:02] INFO:     127.0.0.1:36716 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:02] INFO:     127.0.0.1:42522 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:02] Prefill batch. #new-seq: 2, #new-token: 6447, #cached-token: 860, token usage: 0.93, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:28:05] Decode batch. #running-req: 73, #token: 235715, token usage: 0.96, cuda graph: True, gen throughput (token/s): 836.32, #queue-req: 27\n",
      "[2025-08-13 20:28:05] INFO:     127.0.0.1:49778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:06] INFO:     127.0.0.1:42560 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:06] Prefill batch. #new-seq: 1, #new-token: 2331, #cached-token: 410, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:28:08] Decode batch. #running-req: 72, #token: 236644, token usage: 0.96, cuda graph: True, gen throughput (token/s): 923.50, #queue-req: 28\n",
      "[2025-08-13 20:28:08] INFO:     127.0.0.1:37076 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:08] Prefill batch. #new-seq: 1, #new-token: 4288, #cached-token: 126, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:28:10] INFO:     127.0.0.1:37754 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:10] Prefill batch. #new-seq: 1, #new-token: 4370, #cached-token: 451, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:28:12] Decode batch. #running-req: 72, #token: 239452, token usage: 0.97, cuda graph: True, gen throughput (token/s): 781.13, #queue-req: 28\n",
      "[2025-08-13 20:28:12] INFO:     127.0.0.1:42568 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:12] INFO:     127.0.0.1:42546 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:14] INFO:     127.0.0.1:60086 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:14] Decode batch. #running-req: 69, #token: 235241, token usage: 0.96, cuda graph: True, gen throughput (token/s): 984.63, #queue-req: 31\n",
      "[2025-08-13 20:28:15] INFO:     127.0.0.1:60116 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:15] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 412, token usage: 0.95, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:28:18] Decode batch. #running-req: 69, #token: 238123, token usage: 0.97, cuda graph: True, gen throughput (token/s): 901.64, #queue-req: 31\n",
      "[2025-08-13 20:28:18] INFO:     127.0.0.1:49794 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:18] Prefill batch. #new-seq: 1, #new-token: 2018, #cached-token: 467, token usage: 0.95, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:28:19] INFO:     127.0.0.1:42574 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:19] Prefill batch. #new-seq: 2, #new-token: 6371, #cached-token: 246, token usage: 0.94, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:28:20] INFO:     127.0.0.1:43292 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:21] Decode batch. #running-req: 69, #token: 234518, token usage: 0.95, cuda graph: True, gen throughput (token/s): 779.25, #queue-req: 28\n",
      "[2025-08-13 20:28:24] INFO:     127.0.0.1:46344 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:24] Decode batch. #running-req: 69, #token: 233915, token usage: 0.95, cuda graph: True, gen throughput (token/s): 974.62, #queue-req: 31\n",
      "[2025-08-13 20:28:25] INFO:     127.0.0.1:40866 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:27] INFO:     127.0.0.1:50452 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:27] Decode batch. #running-req: 67, #token: 224643, token usage: 0.91, cuda graph: True, gen throughput (token/s): 954.28, #queue-req: 33\n",
      "[2025-08-13 20:28:27] Prefill batch. #new-seq: 2, #new-token: 7235, #cached-token: 856, token usage: 0.91, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:28:28] INFO:     127.0.0.1:52092 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:28] Prefill batch. #new-seq: 4, #new-token: 5280, #cached-token: 1455, token usage: 0.91, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:28:28] INFO:     127.0.0.1:45900 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:29] Prefill batch. #new-seq: 1, #new-token: 6642, #cached-token: 93, token usage: 0.91, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:28:30] INFO:     127.0.0.1:42098 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:30] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 626, token usage: 0.91, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:28:30] Prefill batch. #new-seq: 2, #new-token: 3368, #cached-token: 462, token usage: 0.95, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:28:31] INFO:     127.0.0.1:43298 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:31] INFO:     127.0.0.1:43296 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:31] INFO:     127.0.0.1:52102 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:31] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1022, token usage: 0.92, #running-req: 70, #queue-req: 25\n",
      "[2025-08-13 20:28:31] Prefill batch. #new-seq: 1, #new-token: 692, #cached-token: 0, token usage: 0.95, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:28:32] Prefill batch. #new-seq: 1, #new-token: 631, #cached-token: 462, token usage: 0.95, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:28:33] INFO:     127.0.0.1:42116 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:33] Prefill batch. #new-seq: 2, #new-token: 6633, #cached-token: 594, token usage: 0.92, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:28:34] Decode batch. #running-req: 74, #token: 233861, token usage: 0.95, cuda graph: True, gen throughput (token/s): 401.88, #queue-req: 25\n",
      "[2025-08-13 20:28:34] INFO:     127.0.0.1:53278 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:34] Prefill batch. #new-seq: 1, #new-token: 4339, #cached-token: 441, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:28:37] Decode batch. #running-req: 74, #token: 238890, token usage: 0.97, cuda graph: True, gen throughput (token/s): 902.62, #queue-req: 26\n",
      "[2025-08-13 20:28:40] INFO:     127.0.0.1:46320 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:40] Decode batch. #running-req: 73, #token: 236073, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1019.66, #queue-req: 26\n",
      "[2025-08-13 20:28:40] INFO:     127.0.0.1:51964 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:40] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 96, token usage: 0.96, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:28:42] INFO:     127.0.0.1:52104 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:42] Prefill batch. #new-seq: 1, #new-token: 2386, #cached-token: 412, token usage: 0.95, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 20:28:42] INFO:     127.0.0.1:51980 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:42] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 159, token usage: 0.95, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:28:43] INFO:     127.0.0.1:51952 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:43] Prefill batch. #new-seq: 1, #new-token: 5100, #cached-token: 392, token usage: 0.93, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:28:44] Decode batch. #running-req: 73, #token: 235417, token usage: 0.96, cuda graph: True, gen throughput (token/s): 810.86, #queue-req: 25\n",
      "[2025-08-13 20:28:44] INFO:     127.0.0.1:51988 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:44] Prefill batch. #new-seq: 2, #new-token: 2973, #cached-token: 1087, token usage: 0.94, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:28:45] INFO:     127.0.0.1:52110 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:45] Prefill batch. #new-seq: 2, #new-token: 2804, #cached-token: 860, token usage: 0.94, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 20:28:45] INFO:     127.0.0.1:53288 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:45] Prefill batch. #new-seq: 2, #new-token: 2618, #cached-token: 903, token usage: 0.93, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 20:28:47] INFO:     127.0.0.1:50458 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:47] Prefill batch. #new-seq: 2, #new-token: 4246, #cached-token: 290, token usage: 0.94, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:28:47] INFO:     127.0.0.1:52122 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:47] Prefill batch. #new-seq: 1, #new-token: 4857, #cached-token: 477, token usage: 0.93, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:28:48] Decode batch. #running-req: 77, #token: 234606, token usage: 0.95, cuda graph: True, gen throughput (token/s): 684.11, #queue-req: 23\n",
      "[2025-08-13 20:28:48] INFO:     127.0.0.1:60086 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:48] Prefill batch. #new-seq: 1, #new-token: 2471, #cached-token: 96, token usage: 0.95, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:28:49] INFO:     127.0.0.1:58270 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:49] INFO:     127.0.0.1:58284 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:49] Prefill batch. #new-seq: 1, #new-token: 2162, #cached-token: 470, token usage: 0.93, #running-req: 75, #queue-req: 24\n",
      "[2025-08-13 20:28:50] INFO:     127.0.0.1:58294 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:50] INFO:     127.0.0.1:58300 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:50] Prefill batch. #new-seq: 3, #new-token: 6740, #cached-token: 720, token usage: 0.92, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 20:28:52] INFO:     127.0.0.1:40866 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:52] Decode batch. #running-req: 77, #token: 231889, token usage: 0.94, cuda graph: True, gen throughput (token/s): 804.76, #queue-req: 23\n",
      "[2025-08-13 20:28:52] INFO:     127.0.0.1:58316 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:52] INFO:     127.0.0.1:58328 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:52] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 393, token usage: 0.91, #running-req: 74, #queue-req: 22\n",
      "[2025-08-13 20:28:53] Prefill batch. #new-seq: 2, #new-token: 1725, #cached-token: 438, token usage: 0.94, #running-req: 74, #queue-req: 21\n",
      "[2025-08-13 20:28:54] INFO:     127.0.0.1:41310 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:54] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 202, token usage: 0.91, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:28:54] Prefill batch. #new-seq: 1, #new-token: 822, #cached-token: 0, token usage: 0.95, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:28:56] INFO:     127.0.0.1:58334 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:56] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 150, token usage: 0.94, #running-req: 76, #queue-req: 23\n",
      "[2025-08-13 20:28:57] Decode batch. #running-req: 77, #token: 233561, token usage: 0.95, cuda graph: True, gen throughput (token/s): 635.48, #queue-req: 23\n",
      "[2025-08-13 20:28:59] INFO:     127.0.0.1:53018 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:59] Prefill batch. #new-seq: 1, #new-token: 2531, #cached-token: 96, token usage: 0.94, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:28:59] INFO:     127.0.0.1:37110 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:28:59] Prefill batch. #new-seq: 1, #new-token: 2354, #cached-token: 447, token usage: 0.94, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:29:00] INFO:     127.0.0.1:50426 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:00] Prefill batch. #new-seq: 1, #new-token: 381, #cached-token: 93, token usage: 0.94, #running-req: 76, #queue-req: 20\n",
      "[2025-08-13 20:29:00] INFO:     127.0.0.1:37054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:00] Decode batch. #running-req: 77, #token: 221753, token usage: 0.90, cuda graph: True, gen throughput (token/s): 935.00, #queue-req: 20\n",
      "[2025-08-13 20:29:00] Prefill batch. #new-seq: 3, #new-token: 6876, #cached-token: 1072, token usage: 0.90, #running-req: 76, #queue-req: 17\n",
      "[2025-08-13 20:29:01] INFO:     127.0.0.1:60116 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:01] Prefill batch. #new-seq: 2, #new-token: 4734, #cached-token: 888, token usage: 0.92, #running-req: 78, #queue-req: 15\n",
      ".[2025-08-13 20:29:01] INFO:     127.0.0.1:47018 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:01] Prefill batch. #new-seq: 1, #new-token: 4374, #cached-token: 441, token usage: 0.91, #running-req: 79, #queue-req: 14\n",
      "[2025-08-13 20:29:02] INFO:     127.0.0.1:50402 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:04] INFO:     127.0.0.1:57420 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:04] Decode batch. #running-req: 78, #token: 228733, token usage: 0.93, cuda graph: True, gen throughput (token/s): 761.93, #queue-req: 15\n",
      "[2025-08-13 20:29:05] INFO:     127.0.0.1:46328 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:05] Prefill batch. #new-seq: 1, #new-token: 7179, #cached-token: 626, token usage: 0.92, #running-req: 77, #queue-req: 15\n",
      "[2025-08-13 20:29:05] INFO:     127.0.0.1:52092 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:06] Prefill batch. #new-seq: 2, #new-token: 7511, #cached-token: 877, token usage: 0.91, #running-req: 77, #queue-req: 13\n",
      "[2025-08-13 20:29:07] INFO:     127.0.0.1:52102 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:07] Prefill batch. #new-seq: 3, #new-token: 4656, #cached-token: 369, token usage: 0.92, #running-req: 78, #queue-req: 13\n",
      "[2025-08-13 20:29:08] INFO:     127.0.0.1:52122 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:08] Prefill batch. #new-seq: 1, #new-token: 4182, #cached-token: 469, token usage: 0.93, #running-req: 80, #queue-req: 12\n",
      "[2025-08-13 20:29:09] Decode batch. #running-req: 81, #token: 232267, token usage: 0.94, cuda graph: True, gen throughput (token/s): 641.53, #queue-req: 15\n",
      "[2025-08-13 20:29:09] INFO:     127.0.0.1:41348 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:09] Prefill batch. #new-seq: 1, #new-token: 4373, #cached-token: 449, token usage: 0.94, #running-req: 80, #queue-req: 14\n",
      "[2025-08-13 20:29:11] INFO:     127.0.0.1:53036 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:11] Prefill batch. #new-seq: 1, #new-token: 2251, #cached-token: 434, token usage: 0.94, #running-req: 80, #queue-req: 19\n",
      "[2025-08-13 20:29:13] Decode batch. #running-req: 81, #token: 235597, token usage: 0.96, cuda graph: True, gen throughput (token/s): 915.66, #queue-req: 19\n",
      "[2025-08-13 20:29:13] INFO:     127.0.0.1:52104 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:13] Prefill batch. #new-seq: 1, #new-token: 2143, #cached-token: 542, token usage: 0.94, #running-req: 80, #queue-req: 18\n",
      "[2025-08-13 20:29:14] INFO:     127.0.0.1:52110 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:16] Decode batch. #running-req: 80, #token: 231951, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1063.99, #queue-req: 20\n",
      "[2025-08-13 20:29:18] INFO:     127.0.0.1:58284 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:18] Decode batch. #running-req: 79, #token: 232848, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1154.10, #queue-req: 20\n",
      "[2025-08-13 20:29:18] INFO:     127.0.0.1:58270 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:18] Prefill batch. #new-seq: 1, #new-token: 6550, #cached-token: 93, token usage: 0.93, #running-req: 78, #queue-req: 19\n",
      "[2025-08-13 20:29:20] INFO:     127.0.0.1:58294 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:20] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 119, token usage: 0.94, #running-req: 78, #queue-req: 18\n",
      "[2025-08-13 20:29:21] INFO:     127.0.0.1:58300 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:21] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 449, token usage: 0.94, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 20:29:22] Decode batch. #running-req: 79, #token: 234109, token usage: 0.95, cuda graph: True, gen throughput (token/s): 859.43, #queue-req: 20\n",
      "[2025-08-13 20:29:22] INFO:     127.0.0.1:47026 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:22] Prefill batch. #new-seq: 2, #new-token: 6722, #cached-token: 900, token usage: 0.93, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 20:29:22] INFO:     127.0.0.1:47042 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:24] INFO:     127.0.0.1:58316 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:25] Decode batch. #running-req: 78, #token: 235026, token usage: 0.96, cuda graph: True, gen throughput (token/s): 914.80, #queue-req: 22\n",
      "[2025-08-13 20:29:28] Decode batch. #running-req: 78, #token: 238146, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1088.89, #queue-req: 22\n",
      "[2025-08-13 20:29:29] INFO:     127.0.0.1:58328 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:29] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 451, token usage: 0.94, #running-req: 77, #queue-req: 21\n",
      "[2025-08-13 20:29:31] Decode batch. #running-req: 78, #token: 236938, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1026.27, #queue-req: 22\n",
      "[2025-08-13 20:29:32] INFO:     127.0.0.1:58334 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:32] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 409, token usage: 0.95, #running-req: 77, #queue-req: 21\n",
      "[2025-08-13 20:29:33] INFO:     127.0.0.1:50462 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:33] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 449, token usage: 0.95, #running-req: 77, #queue-req: 20\n",
      "[2025-08-13 20:29:34] INFO:     127.0.0.1:53366 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:34] Decode batch. #running-req: 77, #token: 232322, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1019.80, #queue-req: 23\n",
      "[2025-08-13 20:29:35] INFO:     127.0.0.1:41816 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:36] INFO:     127.0.0.1:49768 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:36] INFO:     127.0.0.1:49788 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:36] Prefill batch. #new-seq: 3, #new-token: 4912, #cached-token: 702, token usage: 0.92, #running-req: 74, #queue-req: 20\n",
      "[2025-08-13 20:29:38] Decode batch. #running-req: 77, #token: 232208, token usage: 0.94, cuda graph: True, gen throughput (token/s): 948.36, #queue-req: 23\n",
      "[2025-08-13 20:29:38] INFO:     127.0.0.1:50440 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:38] Prefill batch. #new-seq: 2, #new-token: 2771, #cached-token: 555, token usage: 0.93, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:29:41] Decode batch. #running-req: 78, #token: 234761, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1030.82, #queue-req: 22\n",
      "[2025-08-13 20:29:41] INFO:     127.0.0.1:56744 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:41] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.95, #running-req: 77, #queue-req: 21\n",
      "[2025-08-13 20:29:43] INFO:     127.0.0.1:45860 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:44] Decode batch. #running-req: 77, #token: 233318, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1034.94, #queue-req: 22\n",
      "[2025-08-13 20:29:46] INFO:     127.0.0.1:41788 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:46] Decode batch. #running-req: 77, #token: 231141, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1097.92, #queue-req: 23\n",
      "[2025-08-13 20:29:46] INFO:     127.0.0.1:37756 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:48] INFO:     127.0.0.1:41348 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:49] Decode batch. #running-req: 74, #token: 231790, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1073.42, #queue-req: 26\n",
      "[2025-08-13 20:29:52] Decode batch. #running-req: 74, #token: 234750, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1060.43, #queue-req: 26\n",
      "[2025-08-13 20:29:52] INFO:     127.0.0.1:37770 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:53] INFO:     127.0.0.1:37772 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:53] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.92, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 20:29:54] Prefill batch. #new-seq: 1, #new-token: 1529, #cached-token: 0, token usage: 0.95, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 20:29:55] INFO:     127.0.0.1:46302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:56] Decode batch. #running-req: 72, #token: 234933, token usage: 0.96, cuda graph: True, gen throughput (token/s): 763.00, #queue-req: 28\n",
      "[2025-08-13 20:29:56] INFO:     127.0.0.1:52016 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:56] Prefill batch. #new-seq: 1, #new-token: 2454, #cached-token: 149, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:29:57] INFO:     127.0.0.1:46336 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:58] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 440, token usage: 0.95, #running-req: 71, #queue-req: 28\n",
      "[2025-08-13 20:29:58] INFO:     127.0.0.1:46356 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:58] INFO:     127.0.0.1:45844 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:58] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 860, token usage: 0.91, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:29:58] INFO:     127.0.0.1:45870 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:58] INFO:     127.0.0.1:45876 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:29:58] Prefill batch. #new-seq: 1, #new-token: 1708, #cached-token: 0, token usage: 0.95, #running-req: 71, #queue-req: 30\n",
      "[2025-08-13 20:29:59] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 467, token usage: 0.95, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:30:00] Decode batch. #running-req: 71, #token: 237354, token usage: 0.97, cuda graph: True, gen throughput (token/s): 677.06, #queue-req: 29\n",
      "[2025-08-13 20:30:00] INFO:     127.0.0.1:45878 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:00] Prefill batch. #new-seq: 1, #new-token: 2334, #cached-token: 149, token usage: 0.95, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:30:01] INFO:     127.0.0.1:57232 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:01] Prefill batch. #new-seq: 1, #new-token: 4388, #cached-token: 441, token usage: 0.94, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:30:04] Decode batch. #running-req: 71, #token: 238573, token usage: 0.97, cuda graph: True, gen throughput (token/s): 790.22, #queue-req: 29\n",
      "[2025-08-13 20:30:05] INFO:     127.0.0.1:36700 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:05] INFO:     127.0.0.1:36730 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:07] Decode batch. #running-req: 69, #token: 234432, token usage: 0.95, cuda graph: True, gen throughput (token/s): 954.90, #queue-req: 31\n",
      "[2025-08-13 20:30:07] INFO:     127.0.0.1:36740 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:07] INFO:     127.0.0.1:36742 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:07] Prefill batch. #new-seq: 2, #new-token: 7536, #cached-token: 874, token usage: 0.92, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:30:09] INFO:     127.0.0.1:36754 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:09] Prefill batch. #new-seq: 2, #new-token: 6600, #cached-token: 569, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:30:10] INFO:     127.0.0.1:53036 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:10] Prefill batch. #new-seq: 1, #new-token: 2385, #cached-token: 412, token usage: 0.93, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:30:10] INFO:     127.0.0.1:36758 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:11] Decode batch. #running-req: 69, #token: 231870, token usage: 0.94, cuda graph: True, gen throughput (token/s): 637.54, #queue-req: 29\n",
      "[2025-08-13 20:30:14] Decode batch. #running-req: 69, #token: 234630, token usage: 0.95, cuda graph: True, gen throughput (token/s): 959.33, #queue-req: 31\n",
      "[2025-08-13 20:30:17] Decode batch. #running-req: 69, #token: 233307, token usage: 0.95, cuda graph: True, gen throughput (token/s): 954.17, #queue-req: 31\n",
      "[2025-08-13 20:30:17] INFO:     127.0.0.1:53224 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:19] INFO:     127.0.0.1:47026 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:19] INFO:     127.0.0.1:47042 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:19] Decode batch. #running-req: 66, #token: 229166, token usage: 0.93, cuda graph: True, gen throughput (token/s): 966.99, #queue-req: 32\n",
      "[2025-08-13 20:30:21] INFO:     127.0.0.1:34872 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:21] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 145, token usage: 0.93, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:30:21] Prefill batch. #new-seq: 1, #new-token: 573, #cached-token: 0, token usage: 0.96, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:30:23] Decode batch. #running-req: 66, #token: 237259, token usage: 0.97, cuda graph: True, gen throughput (token/s): 721.25, #queue-req: 34\n",
      "[2025-08-13 20:30:26] Decode batch. #running-req: 66, #token: 239899, token usage: 0.98, cuda graph: True, gen throughput (token/s): 912.09, #queue-req: 34\n",
      "[2025-08-13 20:30:26] INFO:     127.0.0.1:37062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:26] Prefill batch. #new-seq: 1, #new-token: 4378, #cached-token: 443, token usage: 0.95, #running-req: 65, #queue-req: 34\n",
      "[2025-08-13 20:30:29] INFO:     127.0.0.1:45474 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:29] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 466, token usage: 0.96, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:30:30] Decode batch. #running-req: 66, #token: 238253, token usage: 0.97, cuda graph: True, gen throughput (token/s): 740.71, #queue-req: 33\n",
      "[2025-08-13 20:30:30] INFO:     127.0.0.1:34868 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:30] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 119, token usage: 0.96, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:30:31] INFO:     127.0.0.1:33960 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:31] Prefill batch. #new-seq: 2, #new-token: 6907, #cached-token: 616, token usage: 0.95, #running-req: 65, #queue-req: 31\n",
      "[2025-08-13 20:30:32] INFO:     127.0.0.1:37092 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:32] Prefill batch. #new-seq: 1, #new-token: 418, #cached-token: 438, token usage: 0.95, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:30:32] INFO:     127.0.0.1:37106 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:32] Prefill batch. #new-seq: 1, #new-token: 2303, #cached-token: 446, token usage: 0.94, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:30:33] INFO:     127.0.0.1:49768 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:33] Prefill batch. #new-seq: 2, #new-token: 4506, #cached-token: 566, token usage: 0.94, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:30:34] Decode batch. #running-req: 68, #token: 235349, token usage: 0.96, cuda graph: True, gen throughput (token/s): 643.25, #queue-req: 31\n",
      "[2025-08-13 20:30:37] Decode batch. #running-req: 68, #token: 238069, token usage: 0.97, cuda graph: True, gen throughput (token/s): 908.57, #queue-req: 32\n",
      "[2025-08-13 20:30:37] INFO:     127.0.0.1:53238 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:37] Prefill batch. #new-seq: 1, #new-token: 2152, #cached-token: 171, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:30:37] INFO:     127.0.0.1:53852 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:38] INFO:     127.0.0.1:53366 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:38] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.94, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:30:39] INFO:     127.0.0.1:50450 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:39] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 528, token usage: 0.93, #running-req: 66, #queue-req: 28\n",
      "[2025-08-13 20:30:39] Prefill batch. #new-seq: 1, #new-token: 1504, #cached-token: 0, token usage: 0.96, #running-req: 67, #queue-req: 28\n",
      "[2025-08-13 20:30:41] Decode batch. #running-req: 68, #token: 238384, token usage: 0.97, cuda graph: True, gen throughput (token/s): 654.34, #queue-req: 32\n",
      "[2025-08-13 20:30:42] INFO:     127.0.0.1:58366 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:42] Prefill batch. #new-seq: 2, #new-token: 7333, #cached-token: 630, token usage: 0.94, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:30:42] INFO:     127.0.0.1:50414 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:43] INFO:     127.0.0.1:46302 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:43] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 434, token usage: 0.96, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:30:43] INFO:     127.0.0.1:49788 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:43] Prefill batch. #new-seq: 1, #new-token: 4179, #cached-token: 472, token usage: 0.95, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:30:44] INFO:     127.0.0.1:37756 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:45] INFO:     127.0.0.1:46336 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:45] Decode batch. #running-req: 67, #token: 233105, token usage: 0.95, cuda graph: True, gen throughput (token/s): 693.27, #queue-req: 30\n",
      "[2025-08-13 20:30:45] Prefill batch. #new-seq: 2, #new-token: 5255, #cached-token: 564, token usage: 0.95, #running-req: 66, #queue-req: 28\n",
      "[2025-08-13 20:30:48] INFO:     127.0.0.1:57224 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:48] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 463, token usage: 0.97, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:30:48] Decode batch. #running-req: 68, #token: 239880, token usage: 0.98, cuda graph: True, gen throughput (token/s): 757.92, #queue-req: 31\n",
      "[2025-08-13 20:30:50] INFO:     127.0.0.1:37772 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:50] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 93, token usage: 0.96, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:30:51] INFO:     127.0.0.1:37770 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:51] Prefill batch. #new-seq: 1, #new-token: 5147, #cached-token: 624, token usage: 0.95, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:30:52] INFO:     127.0.0.1:45844 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:52] Decode batch. #running-req: 67, #token: 236390, token usage: 0.96, cuda graph: True, gen throughput (token/s): 765.68, #queue-req: 30\n",
      "[2025-08-13 20:30:52] INFO:     127.0.0.1:50472 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:52] INFO:     127.0.0.1:51992 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:52] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1465, token usage: 0.90, #running-req: 65, #queue-req: 26\n",
      "[2025-08-13 20:30:52] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 149, token usage: 0.94, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:30:53] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 0, token usage: 0.97, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:30:54] INFO:     127.0.0.1:51996 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:54] Prefill batch. #new-seq: 1, #new-token: 4241, #cached-token: 413, token usage: 0.95, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:30:56] INFO:     127.0.0.1:52008 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:56] INFO:     127.0.0.1:53216 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:56] Prefill batch. #new-seq: 1, #new-token: 4185, #cached-token: 467, token usage: 0.94, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:30:56] INFO:     127.0.0.1:53842 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:57] Prefill batch. #new-seq: 1, #new-token: 2162, #cached-token: 470, token usage: 0.96, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:30:57] Decode batch. #running-req: 69, #token: 238169, token usage: 0.97, cuda graph: True, gen throughput (token/s): 528.19, #queue-req: 30\n",
      "[2025-08-13 20:30:58] INFO:     127.0.0.1:46356 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:58] Prefill batch. #new-seq: 1, #new-token: 308, #cached-token: 443, token usage: 0.96, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:30:58] INFO:     127.0.0.1:36758 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:30:58] Prefill batch. #new-seq: 1, #new-token: 2170, #cached-token: 144, token usage: 0.95, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:31:00] Decode batch. #running-req: 69, #token: 236693, token usage: 0.96, cuda graph: True, gen throughput (token/s): 907.16, #queue-req: 31\n",
      "[2025-08-13 20:31:01] INFO:     127.0.0.1:45876 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:01] INFO:     127.0.0.1:45870 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:01] Prefill batch. #new-seq: 1, #new-token: 3184, #cached-token: 409, token usage: 0.95, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:31:03] INFO:     127.0.0.1:45448 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:03] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 451, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:31:04] Decode batch. #running-req: 68, #token: 231142, token usage: 0.94, cuda graph: True, gen throughput (token/s): 820.42, #queue-req: 31\n",
      "[2025-08-13 20:31:04] INFO:     127.0.0.1:45878 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:04] Prefill batch. #new-seq: 1, #new-token: 7562, #cached-token: 464, token usage: 0.94, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:31:05] INFO:     127.0.0.1:36742 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:05] Prefill batch. #new-seq: 1, #new-token: 2355, #cached-token: 446, token usage: 0.95, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:31:05] INFO:     127.0.0.1:36700 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:05] INFO:     127.0.0.1:36740 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:05] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 590, token usage: 0.93, #running-req: 66, #queue-req: 27\n",
      "[2025-08-13 20:31:05] Prefill batch. #new-seq: 1, #new-token: 480, #cached-token: 0, token usage: 0.96, #running-req: 67, #queue-req: 27\n",
      "[2025-08-13 20:31:06] INFO:     127.0.0.1:36754 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:06] Prefill batch. #new-seq: 2, #new-token: 3446, #cached-token: 534, token usage: 0.94, #running-req: 67, #queue-req: 26\n",
      "[2025-08-13 20:31:08] INFO:     127.0.0.1:41782 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:08] Decode batch. #running-req: 68, #token: 235571, token usage: 0.96, cuda graph: True, gen throughput (token/s): 549.57, #queue-req: 28\n",
      "[2025-08-13 20:31:10] INFO:     127.0.0.1:49468 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:10] Prefill batch. #new-seq: 1, #new-token: 2359, #cached-token: 443, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:31:12] Decode batch. #running-req: 68, #token: 237735, token usage: 0.97, cuda graph: True, gen throughput (token/s): 873.23, #queue-req: 32\n",
      "[2025-08-13 20:31:12] INFO:     127.0.0.1:56730 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:12] Prefill batch. #new-seq: 2, #new-token: 503, #cached-token: 802, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:31:13] INFO:     127.0.0.1:37092 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:13] Prefill batch. #new-seq: 2, #new-token: 5801, #cached-token: 912, token usage: 0.93, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:31:15] Decode batch. #running-req: 70, #token: 236100, token usage: 0.96, cuda graph: True, gen throughput (token/s): 793.64, #queue-req: 30\n",
      "[2025-08-13 20:31:16] INFO:     127.0.0.1:37062 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:16] Prefill batch. #new-seq: 3, #new-token: 4849, #cached-token: 1002, token usage: 0.93, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:31:17] INFO:     127.0.0.1:37106 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:17] Prefill batch. #new-seq: 2, #new-token: 839, #cached-token: 245, token usage: 0.95, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:31:18] INFO:     127.0.0.1:57256 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:18] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 448, token usage: 0.95, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:31:19] Decode batch. #running-req: 73, #token: 234930, token usage: 0.96, cuda graph: True, gen throughput (token/s): 794.53, #queue-req: 26\n",
      "[2025-08-13 20:31:20] INFO:     127.0.0.1:53866 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:20] Prefill batch. #new-seq: 1, #new-token: 2282, #cached-token: 134, token usage: 0.94, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:31:21] INFO:     127.0.0.1:53864 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:21] INFO:     127.0.0.1:49786 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:22] Prefill batch. #new-seq: 1, #new-token: 4371, #cached-token: 450, token usage: 0.93, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:31:22] INFO:     127.0.0.1:33980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:22] Decode batch. #running-req: 72, #token: 230697, token usage: 0.94, cuda graph: True, gen throughput (token/s): 834.94, #queue-req: 26\n",
      "[2025-08-13 20:31:25] Decode batch. #running-req: 71, #token: 226681, token usage: 0.92, cuda graph: True, gen throughput (token/s): 1012.33, #queue-req: 29\n",
      "[2025-08-13 20:31:25] INFO:     127.0.0.1:58356 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:25] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 393, token usage: 0.92, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:31:25] Prefill batch. #new-seq: 1, #new-token: 1575, #cached-token: 0, token usage: 0.96, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:31:26] INFO:     127.0.0.1:57438 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:26] Prefill batch. #new-seq: 1, #new-token: 3357, #cached-token: 410, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:31:27] INFO:     127.0.0.1:58368 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:27] INFO:     127.0.0.1:58384 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:27] INFO:     127.0.0.1:58400 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:27] INFO:     127.0.0.1:58406 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:27] Prefill batch. #new-seq: 2, #new-token: 7407, #cached-token: 614, token usage: 0.91, #running-req: 67, #queue-req: 26\n",
      "[2025-08-13 20:31:28] INFO:     127.0.0.1:51992 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:28] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1497, token usage: 0.90, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:31:28] Prefill batch. #new-seq: 3, #new-token: 4790, #cached-token: 874, token usage: 0.93, #running-req: 70, #queue-req: 26\n",
      ".[2025-08-13 20:31:29] INFO:     127.0.0.1:50414 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:29] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 445, token usage: 0.94, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:31:30] INFO:     127.0.0.1:58422 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:30] INFO:     127.0.0.1:41768 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:30] Prefill batch. #new-seq: 3, #new-token: 3484, #cached-token: 967, token usage: 0.92, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 20:31:30] Prefill batch. #new-seq: 1, #new-token: 4384, #cached-token: 445, token usage: 0.93, #running-req: 74, #queue-req: 22\n",
      "[2025-08-13 20:31:31] INFO:     127.0.0.1:51996 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:31] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 450, token usage: 0.93, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:31:32] INFO:     127.0.0.1:40450 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:32] Prefill batch. #new-seq: 1, #new-token: 2285, #cached-token: 126, token usage: 0.92, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 20:31:32] Decode batch. #running-req: 75, #token: 229235, token usage: 0.93, cuda graph: True, gen throughput (token/s): 398.85, #queue-req: 23\n",
      "[2025-08-13 20:31:33] INFO:     127.0.0.1:39138 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:33] Prefill batch. #new-seq: 1, #new-token: 4872, #cached-token: 462, token usage: 0.92, #running-req: 74, #queue-req: 22\n",
      "[2025-08-13 20:31:34] INFO:     127.0.0.1:44334 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:36] Decode batch. #running-req: 74, #token: 233927, token usage: 0.95, cuda graph: True, gen throughput (token/s): 896.28, #queue-req: 26\n",
      "[2025-08-13 20:31:36] INFO:     127.0.0.1:50472 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:36] Prefill batch. #new-seq: 1, #new-token: 4379, #cached-token: 452, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:31:37] INFO:     127.0.0.1:52008 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:37] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 119, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:31:39] INFO:     127.0.0.1:53216 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:39] Prefill batch. #new-seq: 1, #new-token: 2360, #cached-token: 441, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:31:39] Decode batch. #running-req: 73, #token: 233564, token usage: 0.95, cuda graph: True, gen throughput (token/s): 892.66, #queue-req: 25\n",
      "[2025-08-13 20:31:41] INFO:     127.0.0.1:41794 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:41] INFO:     127.0.0.1:41806 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:41] Prefill batch. #new-seq: 2, #new-token: 6791, #cached-token: 857, token usage: 0.92, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:31:43] Decode batch. #running-req: 74, #token: 234157, token usage: 0.95, cuda graph: True, gen throughput (token/s): 811.54, #queue-req: 26\n",
      "[2025-08-13 20:31:43] INFO:     127.0.0.1:41822 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:43] INFO:     127.0.0.1:57422 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:43] INFO:     127.0.0.1:56730 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:43] Prefill batch. #new-seq: 1, #new-token: 7799, #cached-token: 393, token usage: 0.90, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:31:45] INFO:     127.0.0.1:57430 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:46] INFO:     127.0.0.1:34862 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:46] Prefill batch. #new-seq: 2, #new-token: 8024, #cached-token: 558, token usage: 0.90, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:31:47] Decode batch. #running-req: 72, #token: 230552, token usage: 0.94, cuda graph: True, gen throughput (token/s): 659.85, #queue-req: 28\n",
      "[2025-08-13 20:31:49] INFO:     127.0.0.1:34878 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:49] INFO:     127.0.0.1:57200 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:49] Prefill batch. #new-seq: 2, #new-token: 5096, #cached-token: 261, token usage: 0.91, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:31:50] Decode batch. #running-req: 72, #token: 230006, token usage: 0.94, cuda graph: True, gen throughput (token/s): 879.54, #queue-req: 28\n",
      "[2025-08-13 20:31:51] INFO:     127.0.0.1:57212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:51] INFO:     127.0.0.1:57218 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:51] INFO:     127.0.0.1:39358 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:51] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.86, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:31:51] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1056, token usage: 0.89, #running-req: 69, #queue-req: 26\n",
      "[2025-08-13 20:31:52] Prefill batch. #new-seq: 2, #new-token: 8065, #cached-token: 446, token usage: 0.92, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:31:54] INFO:     127.0.0.1:44342 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:54] Prefill batch. #new-seq: 1, #new-token: 2412, #cached-token: 443, token usage: 0.95, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:31:55] INFO:     127.0.0.1:58356 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:55] Prefill batch. #new-seq: 2, #new-token: 4551, #cached-token: 565, token usage: 0.93, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:31:56] Decode batch. #running-req: 75, #token: 234544, token usage: 0.95, cuda graph: True, gen throughput (token/s): 504.69, #queue-req: 25\n",
      "[2025-08-13 20:31:58] INFO:     127.0.0.1:57246 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:58] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 392, token usage: 0.95, #running-req: 74, #queue-req: 25\n",
      "[2025-08-13 20:31:59] INFO:     127.0.0.1:51008 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:31:59] Decode batch. #running-req: 75, #token: 229985, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1004.42, #queue-req: 25\n",
      "[2025-08-13 20:31:59] Prefill batch. #new-seq: 1, #new-token: 4371, #cached-token: 451, token usage: 0.94, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:31:59] INFO:     127.0.0.1:45456 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:00] INFO:     127.0.0.1:45458 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:00] Prefill batch. #new-seq: 1, #new-token: 2721, #cached-token: 392, token usage: 0.94, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 20:32:00] INFO:     127.0.0.1:50980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:01] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 467, token usage: 0.95, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:32:03] Decode batch. #running-req: 74, #token: 237028, token usage: 0.96, cuda graph: True, gen throughput (token/s): 790.95, #queue-req: 26\n",
      "[2025-08-13 20:32:04] INFO:     127.0.0.1:45484 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:04] INFO:     127.0.0.1:45492 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:04] Prefill batch. #new-seq: 4, #new-token: 2874, #cached-token: 1126, token usage: 0.91, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 20:32:04] Prefill batch. #new-seq: 2, #new-token: 2660, #cached-token: 934, token usage: 0.93, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:32:05] INFO:     127.0.0.1:33968 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:05] INFO:     127.0.0.1:58368 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:05] INFO:     127.0.0.1:58406 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:05] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 962, token usage: 0.89, #running-req: 75, #queue-req: 20\n",
      "[2025-08-13 20:32:05] Prefill batch. #new-seq: 2, #new-token: 5817, #cached-token: 451, token usage: 0.93, #running-req: 77, #queue-req: 19\n",
      "[2025-08-13 20:32:06] INFO:     127.0.0.1:58400 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:06] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 450, token usage: 0.94, #running-req: 78, #queue-req: 20\n",
      "[2025-08-13 20:32:08] INFO:     127.0.0.1:58384 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:08] Decode batch. #running-req: 78, #token: 234419, token usage: 0.95, cuda graph: True, gen throughput (token/s): 607.04, #queue-req: 21\n",
      "[2025-08-13 20:32:09] INFO:     127.0.0.1:41768 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:11] Decode batch. #running-req: 77, #token: 234702, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1065.36, #queue-req: 23\n",
      "[2025-08-13 20:32:11] INFO:     127.0.0.1:58422 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:11] Prefill batch. #new-seq: 1, #new-token: 2354, #cached-token: 448, token usage: 0.94, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:32:14] Decode batch. #running-req: 77, #token: 235631, token usage: 0.96, cuda graph: True, gen throughput (token/s): 987.59, #queue-req: 23\n",
      "[2025-08-13 20:32:14] INFO:     127.0.0.1:41822 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:14] Prefill batch. #new-seq: 1, #new-token: 2471, #cached-token: 437, token usage: 0.94, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:32:15] INFO:     127.0.0.1:58958 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:16] INFO:     127.0.0.1:41794 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:16] INFO:     127.0.0.1:41806 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:16] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 591, token usage: 0.91, #running-req: 74, #queue-req: 22\n",
      "[2025-08-13 20:32:16] Prefill batch. #new-seq: 1, #new-token: 2887, #cached-token: 0, token usage: 0.94, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:32:17] INFO:     127.0.0.1:34862 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:17] Prefill batch. #new-seq: 2, #new-token: 6682, #cached-token: 890, token usage: 0.93, #running-req: 75, #queue-req: 20\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:32:18] INFO:     127.0.0.1:57422 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:18] Prefill batch. #new-seq: 1, #new-token: 6669, #cached-token: 145, token usage: 0.94, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:32:19] Decode batch. #running-req: 77, #token: 236933, token usage: 0.96, cuda graph: True, gen throughput (token/s): 564.05, #queue-req: 23\n",
      "[2025-08-13 20:32:19] INFO:     127.0.0.1:34878 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:20] INFO:     127.0.0.1:57218 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:32:22] INFO:     127.0.0.1:33994 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:22] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.91, #running-req: 74, #queue-req: 25\n",
      "[2025-08-13 20:32:22] Prefill batch. #new-seq: 1, #new-token: 1688, #cached-token: 0, token usage: 0.95, #running-req: 74, #queue-req: 25\n",
      "[2025-08-13 20:32:23] Decode batch. #running-req: 75, #token: 234592, token usage: 0.95, cuda graph: True, gen throughput (token/s): 752.24, #queue-req: 25\n",
      "[2025-08-13 20:32:24] INFO:     127.0.0.1:53834 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:24] Prefill batch. #new-seq: 1, #new-token: 550, #cached-token: 96, token usage: 0.94, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:32:25] INFO:     127.0.0.1:39122 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:26] INFO:     127.0.0.1:49474 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:26] Decode batch. #running-req: 74, #token: 228740, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1008.65, #queue-req: 26\n",
      "[2025-08-13 20:32:26] Prefill batch. #new-seq: 1, #new-token: 5084, #cached-token: 409, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:32:27] INFO:     127.0.0.1:57430 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:28] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 446, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:32:30] Decode batch. #running-req: 74, #token: 238559, token usage: 0.97, cuda graph: True, gen throughput (token/s): 766.62, #queue-req: 26\n",
      "[2025-08-13 20:32:30] INFO:     127.0.0.1:57200 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:30] INFO:     127.0.0.1:57212 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:30] Prefill batch. #new-seq: 1, #new-token: 2268, #cached-token: 77, token usage: 0.94, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:32:31] INFO:     127.0.0.1:45456 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:31] Prefill batch. #new-seq: 1, #new-token: 4547, #cached-token: 462, token usage: 0.95, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:32:34] Decode batch. #running-req: 73, #token: 239077, token usage: 0.97, cuda graph: True, gen throughput (token/s): 805.58, #queue-req: 27\n",
      "[2025-08-13 20:32:35] INFO:     127.0.0.1:42154 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:36] INFO:     127.0.0.1:50246 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:36] Prefill batch. #new-seq: 1, #new-token: 732, #cached-token: 93, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:32:36] INFO:     127.0.0.1:54894 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:36] Prefill batch. #new-seq: 1, #new-token: 396, #cached-token: 437, token usage: 0.92, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:32:37] Decode batch. #running-req: 72, #token: 226895, token usage: 0.92, cuda graph: True, gen throughput (token/s): 952.88, #queue-req: 26\n",
      "[2025-08-13 20:32:38] INFO:     127.0.0.1:53880 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:38] INFO:     127.0.0.1:53886 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:38] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 465, token usage: 0.91, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:32:38] Prefill batch. #new-seq: 2, #new-token: 5353, #cached-token: 467, token usage: 0.94, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:32:39] INFO:     127.0.0.1:57246 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:40] Prefill batch. #new-seq: 1, #new-token: 2234, #cached-token: 119, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:32:40] INFO:     127.0.0.1:45458 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:40] Prefill batch. #new-seq: 1, #new-token: 2173, #cached-token: 461, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:32:40] INFO:     127.0.0.1:45484 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:41] Prefill batch. #new-seq: 2, #new-token: 7213, #cached-token: 880, token usage: 0.91, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:32:41] INFO:     127.0.0.1:45492 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:41] Prefill batch. #new-seq: 2, #new-token: 3011, #cached-token: 558, token usage: 0.93, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 20:32:42] Decode batch. #running-req: 74, #token: 230796, token usage: 0.94, cuda graph: True, gen throughput (token/s): 530.34, #queue-req: 23\n",
      "[2025-08-13 20:32:43] INFO:     127.0.0.1:39344 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:43] Prefill batch. #new-seq: 2, #new-token: 2814, #cached-token: 872, token usage: 0.93, #running-req: 73, #queue-req: 22\n",
      "[2025-08-13 20:32:45] Decode batch. #running-req: 75, #token: 234014, token usage: 0.95, cuda graph: True, gen throughput (token/s): 953.19, #queue-req: 25\n",
      "[2025-08-13 20:32:46] INFO:     127.0.0.1:39348 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:46] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.94, #running-req: 74, #queue-req: 25\n",
      "[2025-08-13 20:32:47] INFO:     127.0.0.1:47504 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:47] INFO:     127.0.0.1:33968 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:47] Prefill batch. #new-seq: 1, #new-token: 4871, #cached-token: 463, token usage: 0.93, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:32:49] Decode batch. #running-req: 74, #token: 234612, token usage: 0.95, cuda graph: True, gen throughput (token/s): 838.49, #queue-req: 26\n",
      "[2025-08-13 20:32:49] INFO:     127.0.0.1:39362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:51] INFO:     127.0.0.1:58946 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:51] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 486, token usage: 0.90, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:32:51] Prefill batch. #new-seq: 1, #new-token: 1397, #cached-token: 0, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:32:52] Decode batch. #running-req: 74, #token: 232407, token usage: 0.95, cuda graph: True, gen throughput (token/s): 784.86, #queue-req: 26\n",
      "[2025-08-13 20:32:53] INFO:     127.0.0.1:39380 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:53] Prefill batch. #new-seq: 1, #new-token: 3431, #cached-token: 481, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:32:55] INFO:     127.0.0.1:54910 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:32:56] Decode batch. #running-req: 73, #token: 233890, token usage: 0.95, cuda graph: True, gen throughput (token/s): 928.36, #queue-req: 27\n",
      "[2025-08-13 20:32:59] Decode batch. #running-req: 73, #token: 236810, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1002.00, #queue-req: 27\n",
      "[2025-08-13 20:33:02] Decode batch. #running-req: 73, #token: 239730, token usage: 0.98, cuda graph: True, gen throughput (token/s): 993.67, #queue-req: 27\n",
      "[2025-08-13 20:33:03] INFO:     127.0.0.1:39368 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:04] INFO:     127.0.0.1:39376 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:04] Prefill batch. #new-seq: 1, #new-token: 2466, #cached-token: 149, token usage: 0.94, #running-req: 71, #queue-req: 28\n",
      "[2025-08-13 20:33:05] Decode batch. #running-req: 72, #token: 235317, token usage: 0.96, cuda graph: True, gen throughput (token/s): 932.54, #queue-req: 28\n",
      "[2025-08-13 20:33:05] INFO:     127.0.0.1:49434 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:05] INFO:     127.0.0.1:39144 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:05] Prefill batch. #new-seq: 2, #new-token: 4478, #cached-token: 523, token usage: 0.92, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:33:05] INFO:     127.0.0.1:49446 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:06] Prefill batch. #new-seq: 2, #new-token: 5338, #cached-token: 1033, token usage: 0.92, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:33:08] Decode batch. #running-req: 73, #token: 232769, token usage: 0.95, cuda graph: True, gen throughput (token/s): 795.12, #queue-req: 27\n",
      "[2025-08-13 20:33:11] Decode batch. #running-req: 73, #token: 235689, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1027.97, #queue-req: 27\n",
      "[2025-08-13 20:33:12] INFO:     127.0.0.1:49456 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:12] Prefill batch. #new-seq: 2, #new-token: 4574, #cached-token: 858, token usage: 0.93, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:33:14] Decode batch. #running-req: 74, #token: 235869, token usage: 0.96, cuda graph: True, gen throughput (token/s): 919.68, #queue-req: 26\n",
      "[2025-08-13 20:33:15] INFO:     127.0.0.1:33994 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:15] INFO:     127.0.0.1:50964 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:17] Decode batch. #running-req: 72, #token: 230601, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1049.83, #queue-req: 28\n",
      "[2025-08-13 20:33:20] Decode batch. #running-req: 72, #token: 227419, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1041.45, #queue-req: 28\n",
      "[2025-08-13 20:33:20] INFO:     127.0.0.1:33916 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:23] Decode batch. #running-req: 71, #token: 230258, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1038.32, #queue-req: 29\n",
      "[2025-08-13 20:33:24] INFO:     127.0.0.1:47492 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:24] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.92, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:33:24] Prefill batch. #new-seq: 1, #new-token: 1327, #cached-token: 0, token usage: 0.96, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:33:26] Decode batch. #running-req: 71, #token: 238016, token usage: 0.97, cuda graph: True, gen throughput (token/s): 754.72, #queue-req: 29\n",
      "[2025-08-13 20:33:29] INFO:     127.0.0.1:33918 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:29] Decode batch. #running-req: 71, #token: 235202, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1007.64, #queue-req: 29\n",
      "[2025-08-13 20:33:32] Decode batch. #running-req: 70, #token: 238002, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1001.70, #queue-req: 30\n",
      "[2025-08-13 20:33:33] INFO:     127.0.0.1:58968 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:34] INFO:     127.0.0.1:58978 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:34] INFO:     127.0.0.1:49762 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:34] Prefill batch. #new-seq: 1, #new-token: 5457, #cached-token: 481, token usage: 0.94, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:33:35] INFO:     127.0.0.1:49774 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:35] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 122, token usage: 0.95, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:33:35] Decode batch. #running-req: 68, #token: 233276, token usage: 0.95, cuda graph: True, gen throughput (token/s): 814.02, #queue-req: 32\n",
      "[2025-08-13 20:33:37] INFO:     127.0.0.1:39158 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:37] Prefill batch. #new-seq: 2, #new-token: 4451, #cached-token: 688, token usage: 0.94, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:33:39] Decode batch. #running-req: 69, #token: 236398, token usage: 0.96, cuda graph: True, gen throughput (token/s): 819.74, #queue-req: 31\n",
      "[2025-08-13 20:33:39] INFO:     127.0.0.1:49968 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:39] Prefill batch. #new-seq: 1, #new-token: 1462, #cached-token: 444, token usage: 0.96, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:33:40] INFO:     127.0.0.1:40442 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:40] Prefill batch. #new-seq: 2, #new-token: 4533, #cached-token: 528, token usage: 0.95, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:33:41] INFO:     127.0.0.1:48918 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:42] Decode batch. #running-req: 69, #token: 239345, token usage: 0.97, cuda graph: True, gen throughput (token/s): 812.21, #queue-req: 31\n",
      "[2025-08-13 20:33:45] Decode batch. #running-req: 69, #token: 242105, token usage: 0.98, cuda graph: True, gen throughput (token/s): 947.73, #queue-req: 31\n",
      "[2025-08-13 20:33:46] INFO:     127.0.0.1:53886 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:46] INFO:     127.0.0.1:54860 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:48] Decode batch. #running-req: 67, #token: 233750, token usage: 0.95, cuda graph: True, gen throughput (token/s): 950.69, #queue-req: 33\n",
      "[2025-08-13 20:33:49] INFO:     127.0.0.1:57016 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:50] Prefill batch. #new-seq: 1, #new-token: 7342, #cached-token: 625, token usage: 0.92, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:33:50] INFO:     127.0.0.1:53880 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:50] Prefill batch. #new-seq: 1, #new-token: 2756, #cached-token: 392, token usage: 0.95, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:33:52] Decode batch. #running-req: 67, #token: 238431, token usage: 0.97, cuda graph: True, gen throughput (token/s): 709.13, #queue-req: 33\n",
      "[2025-08-13 20:33:52] INFO:     127.0.0.1:44350 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:52] Prefill batch. #new-seq: 1, #new-token: 2598, #cached-token: 453, token usage: 0.96, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:33:55] INFO:     127.0.0.1:51070 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:55] Decode batch. #running-req: 66, #token: 237073, token usage: 0.96, cuda graph: True, gen throughput (token/s): 860.26, #queue-req: 34\n",
      "[2025-08-13 20:33:56] INFO:     127.0.0.1:42122 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:33:56] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 449, token usage: 0.95, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:33:58] Decode batch. #running-req: 66, #token: 238025, token usage: 0.97, cuda graph: True, gen throughput (token/s): 884.25, #queue-req: 34\n",
      "[2025-08-13 20:34:01] Decode batch. #running-req: 66, #token: 240665, token usage: 0.98, cuda graph: True, gen throughput (token/s): 944.50, #queue-req: 34\n",
      "[2025-08-13 20:34:01] INFO:     127.0.0.1:50240 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:01] Prefill batch. #new-seq: 1, #new-token: 2361, #cached-token: 441, token usage: 0.96, #running-req: 65, #queue-req: 34\n",
      "[2025-08-13 20:34:02] INFO:     127.0.0.1:50242 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:02] INFO:     127.0.0.1:39344 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:02] Prefill batch. #new-seq: 1, #new-token: 4376, #cached-token: 446, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:34:04] Decode batch. #running-req: 65, #token: 238646, token usage: 0.97, cuda graph: True, gen throughput (token/s): 764.20, #queue-req: 35\n",
      "[2025-08-13 20:34:06] INFO:     127.0.0.1:50258 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:06] Prefill batch. #new-seq: 1, #new-token: 2229, #cached-token: 126, token usage: 0.96, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:34:07] Decode batch. #running-req: 65, #token: 239115, token usage: 0.97, cuda graph: True, gen throughput (token/s): 860.70, #queue-req: 35\n",
      "[2025-08-13 20:34:08] INFO:     127.0.0.1:50950 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:08] INFO:     127.0.0.1:50952 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:08] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 93, token usage: 0.96, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:34:08] INFO:     127.0.0.1:50960 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:08] Prefill batch. #new-seq: 1, #new-token: 2276, #cached-token: 129, token usage: 0.94, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:34:09] INFO:     127.0.0.1:46488 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:10] Decode batch. #running-req: 63, #token: 232531, token usage: 0.95, cuda graph: True, gen throughput (token/s): 860.30, #queue-req: 37\n",
      "[2025-08-13 20:34:11] INFO:     127.0.0.1:50994 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:11] INFO:     127.0.0.1:57216 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:11] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 145, token usage: 0.89, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:34:11] Prefill batch. #new-seq: 4, #new-token: 5559, #cached-token: 1006, token usage: 0.93, #running-req: 61, #queue-req: 34\n",
      ".[2025-08-13 20:34:13] INFO:     127.0.0.1:39348 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:13] Prefill batch. #new-seq: 1, #new-token: 7333, #cached-token: 627, token usage: 0.93, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:34:14] INFO:     127.0.0.1:51018 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:14] Prefill batch. #new-seq: 1, #new-token: 4407, #cached-token: 96, token usage: 0.96, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:34:15] INFO:     127.0.0.1:49434 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:15] INFO:     127.0.0.1:51024 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:15] INFO:     127.0.0.1:39376 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:15] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 911, token usage: 0.91, #running-req: 62, #queue-req: 33\n",
      "[2025-08-13 20:34:15] Prefill batch. #new-seq: 1, #new-token: 548, #cached-token: 0, token usage: 0.95, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 20:34:16] Decode batch. #running-req: 64, #token: 233098, token usage: 0.95, cuda graph: True, gen throughput (token/s): 430.92, #queue-req: 33\n",
      "[2025-08-13 20:34:17] INFO:     127.0.0.1:47478 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:17] Prefill batch. #new-seq: 1, #new-token: 7388, #cached-token: 409, token usage: 0.93, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 20:34:18] INFO:     127.0.0.1:49456 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:19] Prefill batch. #new-seq: 1, #new-token: 7570, #cached-token: 554, token usage: 0.94, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:34:20] INFO:     127.0.0.1:33942 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:20] Prefill batch. #new-seq: 1, #new-token: 3515, #cached-token: 554, token usage: 0.95, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:34:20] Decode batch. #running-req: 63, #token: 238180, token usage: 0.97, cuda graph: True, gen throughput (token/s): 613.71, #queue-req: 35\n",
      "[2025-08-13 20:34:23] Decode batch. #running-req: 64, #token: 240804, token usage: 0.98, cuda graph: True, gen throughput (token/s): 838.45, #queue-req: 36\n",
      "[2025-08-13 20:34:24] INFO:     127.0.0.1:47500 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:24] INFO:     127.0.0.1:42106 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:24] INFO:     127.0.0.1:42116 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:24] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 872, token usage: 0.93, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:34:24] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 0, token usage: 0.96, #running-req: 62, #queue-req: 37\n",
      "[2025-08-13 20:34:25] INFO:     127.0.0.1:39368 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:25] Prefill batch. #new-seq: 2, #new-token: 2348, #cached-token: 580, token usage: 0.95, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:34:26] INFO:     127.0.0.1:42128 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:26] INFO:     127.0.0.1:42134 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:26] INFO:     127.0.0.1:42150 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:26] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1326, token usage: 0.93, #running-req: 61, #queue-req: 32\n",
      "[2025-08-13 20:34:26] Prefill batch. #new-seq: 1, #new-token: 2800, #cached-token: 0, token usage: 0.96, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 20:34:27] INFO:     127.0.0.1:42158 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:27] Prefill batch. #new-seq: 1, #new-token: 1783, #cached-token: 409, token usage: 0.96, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:34:28] INFO:     127.0.0.1:33912 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:28] Prefill batch. #new-seq: 2, #new-token: 4680, #cached-token: 881, token usage: 0.95, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:34:28] Decode batch. #running-req: 65, #token: 237552, token usage: 0.97, cuda graph: True, gen throughput (token/s): 484.00, #queue-req: 35\n",
      "[2025-08-13 20:34:29] INFO:     127.0.0.1:49446 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:29] Prefill batch. #new-seq: 2, #new-token: 331, #cached-token: 241, token usage: 0.94, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:34:30] INFO:     127.0.0.1:48880 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:30] Prefill batch. #new-seq: 2, #new-token: 4710, #cached-token: 893, token usage: 0.93, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:34:32] Decode batch. #running-req: 67, #token: 235226, token usage: 0.96, cuda graph: True, gen throughput (token/s): 801.40, #queue-req: 33\n",
      "[2025-08-13 20:34:33] INFO:     127.0.0.1:33926 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:34] Decode batch. #running-req: 66, #token: 235678, token usage: 0.96, cuda graph: True, gen throughput (token/s): 932.35, #queue-req: 34\n",
      "[2025-08-13 20:34:37] INFO:     127.0.0.1:58968 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:37] INFO:     127.0.0.1:33954 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:37] INFO:     127.0.0.1:58978 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:37] INFO:     127.0.0.1:49762 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:37] INFO:     127.0.0.1:49774 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:37] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 946, token usage: 0.89, #running-req: 61, #queue-req: 32\n",
      "[2025-08-13 20:34:37] Prefill batch. #new-seq: 3, #new-token: 6189, #cached-token: 869, token usage: 0.93, #running-req: 62, #queue-req: 30\n",
      "[2025-08-13 20:34:39] Decode batch. #running-req: 65, #token: 234437, token usage: 0.95, cuda graph: True, gen throughput (token/s): 629.80, #queue-req: 31\n",
      "[2025-08-13 20:34:39] INFO:     127.0.0.1:40442 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:39] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 590, token usage: 0.94, #running-req: 64, #queue-req: 29\n",
      "[2025-08-13 20:34:39] Prefill batch. #new-seq: 1, #new-token: 474, #cached-token: 0, token usage: 0.97, #running-req: 65, #queue-req: 29\n",
      "[2025-08-13 20:34:40] INFO:     127.0.0.1:33970 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:40] Prefill batch. #new-seq: 2, #new-token: 6542, #cached-token: 913, token usage: 0.93, #running-req: 65, #queue-req: 27\n",
      "[2025-08-13 20:34:41] INFO:     127.0.0.1:54892 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:41] Prefill batch. #new-seq: 2, #new-token: 4472, #cached-token: 871, token usage: 0.95, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:34:43] INFO:     127.0.0.1:54872 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:43] INFO:     127.0.0.1:50258 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:43] Prefill batch. #new-seq: 1, #new-token: 5464, #cached-token: 466, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:34:44] Decode batch. #running-req: 67, #token: 238603, token usage: 0.97, cuda graph: True, gen throughput (token/s): 524.63, #queue-req: 32\n",
      "[2025-08-13 20:34:45] INFO:     127.0.0.1:50960 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:45] Prefill batch. #new-seq: 2, #new-token: 2439, #cached-token: 287, token usage: 0.95, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:34:45] INFO:     127.0.0.1:48924 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:45] Prefill batch. #new-seq: 2, #new-token: 2582, #cached-token: 701, token usage: 0.95, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:34:46] INFO:     127.0.0.1:54878 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:46] Prefill batch. #new-seq: 2, #new-token: 6511, #cached-token: 253, token usage: 0.93, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:34:47] INFO:     127.0.0.1:50242 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:47] Prefill batch. #new-seq: 1, #new-token: 2282, #cached-token: 129, token usage: 0.94, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:34:48] Decode batch. #running-req: 70, #token: 234829, token usage: 0.96, cuda graph: True, gen throughput (token/s): 684.69, #queue-req: 29\n",
      "[2025-08-13 20:34:48] INFO:     127.0.0.1:47478 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:48] Prefill batch. #new-seq: 2, #new-token: 4373, #cached-token: 915, token usage: 0.94, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:34:50] INFO:     127.0.0.1:46458 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:50] Prefill batch. #new-seq: 1, #new-token: 2346, #cached-token: 455, token usage: 0.95, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:34:51] INFO:     127.0.0.1:50994 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:51] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 409, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      ".[2025-08-13 20:34:51] Decode batch. #running-req: 71, #token: 233663, token usage: 0.95, cuda graph: True, gen throughput (token/s): 828.66, #queue-req: 28\n",
      "[2025-08-13 20:34:51] INFO:     127.0.0.1:51070 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:51] Prefill batch. #new-seq: 1, #new-token: 7367, #cached-token: 410, token usage: 0.93, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:34:51] INFO:     127.0.0.1:44350 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:53] INFO:     127.0.0.1:50240 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:53] Prefill batch. #new-seq: 2, #new-token: 6384, #cached-token: 932, token usage: 0.94, #running-req: 69, #queue-req: 25\n",
      "[2025-08-13 20:34:54] INFO:     127.0.0.1:50950 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:54] INFO:     127.0.0.1:50952 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:54] Prefill batch. #new-seq: 2, #new-token: 4864, #cached-token: 646, token usage: 0.95, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:34:55] INFO:     127.0.0.1:42116 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:55] Prefill batch. #new-seq: 1, #new-token: 4537, #cached-token: 463, token usage: 0.95, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 20:34:55] INFO:     127.0.0.1:48894 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:56] INFO:     127.0.0.1:46460 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:56] Decode batch. #running-req: 69, #token: 232405, token usage: 0.95, cuda graph: True, gen throughput (token/s): 575.25, #queue-req: 26\n",
      "[2025-08-13 20:34:57] INFO:     127.0.0.1:46474 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:57] Prefill batch. #new-seq: 1, #new-token: 5473, #cached-token: 466, token usage: 0.93, #running-req: 68, #queue-req: 26\n",
      "[2025-08-13 20:34:59] INFO:     127.0.0.1:51018 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:34:59] Prefill batch. #new-seq: 1, #new-token: 4381, #cached-token: 440, token usage: 0.95, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:35:00] Decode batch. #running-req: 69, #token: 238513, token usage: 0.97, cuda graph: True, gen throughput (token/s): 721.12, #queue-req: 30\n",
      "[2025-08-13 20:35:00] INFO:     127.0.0.1:42128 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:00] Prefill batch. #new-seq: 1, #new-token: 4304, #cached-token: 126, token usage: 0.95, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:35:02] INFO:     127.0.0.1:46478 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:02] INFO:     127.0.0.1:46494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:02] INFO:     127.0.0.1:46498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:02] INFO:     127.0.0.1:46514 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:02] Prefill batch. #new-seq: 3, #new-token: 6668, #cached-token: 706, token usage: 0.91, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:35:02] INFO:     127.0.0.1:35264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:02] Prefill batch. #new-seq: 1, #new-token: 4535, #cached-token: 480, token usage: 0.94, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:35:03] INFO:     127.0.0.1:35268 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:03] Prefill batch. #new-seq: 1, #new-token: 2384, #cached-token: 149, token usage: 0.95, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:35:04] INFO:     127.0.0.1:37486 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:04] Decode batch. #running-req: 67, #token: 232856, token usage: 0.95, cuda graph: True, gen throughput (token/s): 614.98, #queue-req: 32\n",
      "[2025-08-13 20:35:05] INFO:     127.0.0.1:47500 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:05] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 393, token usage: 0.92, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:35:05] Prefill batch. #new-seq: 1, #new-token: 1627, #cached-token: 0, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:35:06] INFO:     127.0.0.1:42150 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:06] Prefill batch. #new-seq: 1, #new-token: 2172, #cached-token: 461, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:35:07] INFO:     127.0.0.1:42106 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:07] Prefill batch. #new-seq: 1, #new-token: 2173, #cached-token: 460, token usage: 0.95, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:35:08] INFO:     127.0.0.1:33970 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:08] Prefill batch. #new-seq: 3, #new-token: 5943, #cached-token: 1162, token usage: 0.92, #running-req: 66, #queue-req: 28\n",
      ".[2025-08-13 20:35:08] INFO:     127.0.0.1:42134 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:09] Prefill batch. #new-seq: 2, #new-token: 4491, #cached-token: 617, token usage: 0.94, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:35:09] INFO:     127.0.0.1:57222 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:09] Decode batch. #running-req: 69, #token: 233032, token usage: 0.95, cuda graph: True, gen throughput (token/s): 528.17, #queue-req: 28\n",
      "[2025-08-13 20:35:10] INFO:     127.0.0.1:35282 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:10] Prefill batch. #new-seq: 1, #new-token: 6596, #cached-token: 93, token usage: 0.93, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:35:11] INFO:     127.0.0.1:54872 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:11] INFO:     127.0.0.1:33926 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:35:11] Prefill batch. #new-seq: 1, #new-token: 2354, #cached-token: 447, token usage: 0.94, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:35:12] INFO:     127.0.0.1:54878 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:12] Prefill batch. #new-seq: 2, #new-token: 4734, #cached-token: 519, token usage: 0.93, #running-req: 67, #queue-req: 27\n",
      "[2025-08-13 20:35:13] INFO:     127.0.0.1:33954 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:13] Prefill batch. #new-seq: 2, #new-token: 6477, #cached-token: 540, token usage: 0.93, #running-req: 68, #queue-req: 26\n",
      "[2025-08-13 20:35:14] Decode batch. #running-req: 70, #token: 235602, token usage: 0.96, cuda graph: True, gen throughput (token/s): 593.47, #queue-req: 26\n",
      "[2025-08-13 20:35:14] INFO:     127.0.0.1:42158 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:14] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 93, token usage: 0.94, #running-req: 69, #queue-req: 25\n",
      "[2025-08-13 20:35:15] INFO:     127.0.0.1:49732 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:15] INFO:     127.0.0.1:33912 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:15] Prefill batch. #new-seq: 2, #new-token: 4932, #cached-token: 858, token usage: 0.92, #running-req: 68, #queue-req: 25\n",
      "[2025-08-13 20:35:17] Decode batch. #running-req: 70, #token: 233899, token usage: 0.95, cuda graph: True, gen throughput (token/s): 858.15, #queue-req: 27\n",
      "[2025-08-13 20:35:20] Decode batch. #running-req: 70, #token: 236699, token usage: 0.96, cuda graph: True, gen throughput (token/s): 985.56, #queue-req: 30\n",
      "[2025-08-13 20:35:23] Decode batch. #running-req: 70, #token: 232469, token usage: 0.95, cuda graph: True, gen throughput (token/s): 976.39, #queue-req: 30\n",
      "[2025-08-13 20:35:23] INFO:     127.0.0.1:57236 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:23] Prefill batch. #new-seq: 1, #new-token: 2162, #cached-token: 468, token usage: 0.95, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:35:23] INFO:     127.0.0.1:46458 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:24] Prefill batch. #new-seq: 2, #new-token: 6309, #cached-token: 866, token usage: 0.94, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:35:27] Decode batch. #running-req: 71, #token: 239269, token usage: 0.97, cuda graph: True, gen throughput (token/s): 800.00, #queue-req: 29\n",
      "[2025-08-13 20:35:28] INFO:     127.0.0.1:53248 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:29] INFO:     127.0.0.1:53264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:29] Prefill batch. #new-seq: 2, #new-token: 4842, #cached-token: 844, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:35:29] INFO:     127.0.0.1:57054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:29] INFO:     127.0.0.1:45650 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:29] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 455, token usage: 0.95, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:35:30] Decode batch. #running-req: 70, #token: 235301, token usage: 0.96, cuda graph: True, gen throughput (token/s): 813.28, #queue-req: 27\n",
      "[2025-08-13 20:35:30] INFO:     127.0.0.1:48906 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:30] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 450, token usage: 0.94, #running-req: 69, #queue-req: 26\n",
      "[2025-08-13 20:35:31] INFO:     127.0.0.1:46460 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:31] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 96, token usage: 0.94, #running-req: 69, #queue-req: 25\n",
      "[2025-08-13 20:35:31] INFO:     127.0.0.1:44598 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:31] Prefill batch. #new-seq: 2, #new-token: 4947, #cached-token: 899, token usage: 0.93, #running-req: 69, #queue-req: 23\n",
      "[2025-08-13 20:35:32] INFO:     127.0.0.1:57008 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:32] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 997, token usage: 0.91, #running-req: 70, #queue-req: 21\n",
      "[2025-08-13 20:35:33] Prefill batch. #new-seq: 1, #new-token: 2441, #cached-token: 0, token usage: 0.95, #running-req: 72, #queue-req: 21\n",
      "[2025-08-13 20:35:34] INFO:     127.0.0.1:37466 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:34] Prefill batch. #new-seq: 1, #new-token: 2519, #cached-token: 462, token usage: 0.95, #running-req: 72, #queue-req: 20\n",
      "[2025-08-13 20:35:34] INFO:     127.0.0.1:57002 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:34] Prefill batch. #new-seq: 1, #new-token: 2390, #cached-token: 435, token usage: 0.94, #running-req: 72, #queue-req: 21\n",
      "[2025-08-13 20:35:35] INFO:     127.0.0.1:37470 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:35] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 450, token usage: 0.94, #running-req: 72, #queue-req: 20\n",
      "[2025-08-13 20:35:35] INFO:     127.0.0.1:46498 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:35] Decode batch. #running-req: 72, #token: 232322, token usage: 0.94, cuda graph: True, gen throughput (token/s): 559.11, #queue-req: 20\n",
      "[2025-08-13 20:35:35] INFO:     127.0.0.1:49940 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:35] Prefill batch. #new-seq: 2, #new-token: 7883, #cached-token: 900, token usage: 0.92, #running-req: 71, #queue-req: 20\n",
      "[2025-08-13 20:35:37] INFO:     127.0.0.1:46474 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:37] Prefill batch. #new-seq: 2, #new-token: 2506, #cached-token: 830, token usage: 0.93, #running-req: 72, #queue-req: 22\n",
      "[2025-08-13 20:35:38] INFO:     127.0.0.1:37482 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:38] Prefill batch. #new-seq: 1, #new-token: 4373, #cached-token: 448, token usage: 0.93, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 20:35:39] INFO:     127.0.0.1:49950 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:39] INFO:     127.0.0.1:49954 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:39] Prefill batch. #new-seq: 2, #new-token: 4750, #cached-token: 215, token usage: 0.92, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:35:40] Decode batch. #running-req: 74, #token: 232271, token usage: 0.94, cuda graph: True, gen throughput (token/s): 617.49, #queue-req: 26\n",
      "[2025-08-13 20:35:41] INFO:     127.0.0.1:49956 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:41] Prefill batch. #new-seq: 2, #new-token: 157, #cached-token: 556, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:35:43] INFO:     127.0.0.1:52378 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:43] Prefill batch. #new-seq: 1, #new-token: 4658, #cached-token: 93, token usage: 0.93, #running-req: 74, #queue-req: 24\n",
      ".[2025-08-13 20:35:43] Decode batch. #running-req: 75, #token: 234390, token usage: 0.95, cuda graph: True, gen throughput (token/s): 885.02, #queue-req: 24\n",
      "[2025-08-13 20:35:44] INFO:     127.0.0.1:49976 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:44] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 434, token usage: 0.94, #running-req: 74, #queue-req: 25\n",
      "[2025-08-13 20:35:45] INFO:     127.0.0.1:46478 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:45] Prefill batch. #new-seq: 1, #new-token: 2866, #cached-token: 409, token usage: 0.93, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:35:46] INFO:     127.0.0.1:34862 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:46] Prefill batch. #new-seq: 2, #new-token: 2731, #cached-token: 587, token usage: 0.92, #running-req: 74, #queue-req: 22\n",
      "[2025-08-13 20:35:46] INFO:     127.0.0.1:46494 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:46] INFO:     127.0.0.1:46514 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:46] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 929, token usage: 0.90, #running-req: 74, #queue-req: 22\n",
      "[2025-08-13 20:35:46] Prefill batch. #new-seq: 2, #new-token: 1353, #cached-token: 436, token usage: 0.93, #running-req: 75, #queue-req: 21\n",
      "[2025-08-13 20:35:47] INFO:     127.0.0.1:35264 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:47] Prefill batch. #new-seq: 2, #new-token: 5023, #cached-token: 624, token usage: 0.92, #running-req: 76, #queue-req: 19\n",
      "[2025-08-13 20:35:48] Decode batch. #running-req: 78, #token: 232622, token usage: 0.95, cuda graph: True, gen throughput (token/s): 628.31, #queue-req: 19\n",
      "[2025-08-13 20:35:48] INFO:     127.0.0.1:35268 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:48] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 144, token usage: 0.94, #running-req: 77, #queue-req: 18\n",
      "[2025-08-13 20:35:49] INFO:     127.0.0.1:48932 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:49] Prefill batch. #new-seq: 2, #new-token: 4768, #cached-token: 886, token usage: 0.92, #running-req: 77, #queue-req: 16\n",
      "[2025-08-13 20:35:50] INFO:     127.0.0.1:55396 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:50] Prefill batch. #new-seq: 1, #new-token: 2172, #cached-token: 126, token usage: 0.93, #running-req: 78, #queue-req: 17\n",
      "[2025-08-13 20:35:51] INFO:     127.0.0.1:48866 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:51] Prefill batch. #new-seq: 2, #new-token: 6026, #cached-token: 827, token usage: 0.91, #running-req: 78, #queue-req: 16\n",
      "[2025-08-13 20:35:52] Decode batch. #running-req: 80, #token: 225060, token usage: 0.92, cuda graph: True, gen throughput (token/s): 767.17, #queue-req: 20\n",
      "[2025-08-13 20:35:52] INFO:     127.0.0.1:35282 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:52] Prefill batch. #new-seq: 2, #new-token: 4690, #cached-token: 911, token usage: 0.92, #running-req: 79, #queue-req: 18\n",
      "[2025-08-13 20:35:54] INFO:     127.0.0.1:48290 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:54] Prefill batch. #new-seq: 2, #new-token: 4457, #cached-token: 905, token usage: 0.92, #running-req: 80, #queue-req: 17\n",
      "[2025-08-13 20:35:56] Decode batch. #running-req: 82, #token: 231425, token usage: 0.94, cuda graph: True, gen throughput (token/s): 847.90, #queue-req: 18\n",
      "[2025-08-13 20:35:59] Decode batch. #running-req: 82, #token: 234705, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1080.60, #queue-req: 18\n",
      "[2025-08-13 20:35:59] INFO:     127.0.0.1:57236 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:35:59] Prefill batch. #new-seq: 1, #new-token: 2339, #cached-token: 461, token usage: 0.93, #running-req: 81, #queue-req: 17\n",
      "[2025-08-13 20:36:00] INFO:     127.0.0.1:37466 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:00] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 456, token usage: 0.93, #running-req: 81, #queue-req: 16\n",
      "[2025-08-13 20:36:01] INFO:     127.0.0.1:37470 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:01] Prefill batch. #new-seq: 1, #new-token: 4240, #cached-token: 96, token usage: 0.94, #running-req: 81, #queue-req: 17\n",
      "[2025-08-13 20:36:02] INFO:     127.0.0.1:49962 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:02] Prefill batch. #new-seq: 1, #new-token: 2880, #cached-token: 392, token usage: 0.93, #running-req: 81, #queue-req: 16\n",
      "[2025-08-13 20:36:02] INFO:     127.0.0.1:36866 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:03] Decode batch. #running-req: 81, #token: 233773, token usage: 0.95, cuda graph: True, gen throughput (token/s): 758.73, #queue-req: 17\n",
      "[2025-08-13 20:36:04] INFO:     127.0.0.1:37482 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:04] Prefill batch. #new-seq: 1, #new-token: 4670, #cached-token: 465, token usage: 0.94, #running-req: 80, #queue-req: 18\n",
      "[2025-08-13 20:36:06] INFO:     127.0.0.1:49956 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:06] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 412, token usage: 0.94, #running-req: 80, #queue-req: 18\n",
      "[2025-08-13 20:36:07] Decode batch. #running-req: 81, #token: 232795, token usage: 0.95, cuda graph: True, gen throughput (token/s): 927.01, #queue-req: 19\n",
      "[2025-08-13 20:36:09] INFO:     127.0.0.1:36278 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:10] Decode batch. #running-req: 80, #token: 235644, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1081.43, #queue-req: 19\n",
      "[2025-08-13 20:36:10] INFO:     127.0.0.1:50332 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:10] Prefill batch. #new-seq: 1, #new-token: 4367, #cached-token: 455, token usage: 0.92, #running-req: 79, #queue-req: 19\n",
      "[2025-08-13 20:36:12] INFO:     127.0.0.1:49950 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:12] Prefill batch. #new-seq: 1, #new-token: 6890, #cached-token: 463, token usage: 0.93, #running-req: 79, #queue-req: 19\n",
      "[2025-08-13 20:36:13] INFO:     127.0.0.1:49954 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:14] Decode batch. #running-req: 79, #token: 233981, token usage: 0.95, cuda graph: True, gen throughput (token/s): 817.21, #queue-req: 20\n",
      "[2025-08-13 20:36:14] INFO:     127.0.0.1:56998 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:17] Decode batch. #running-req: 78, #token: 232750, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1106.10, #queue-req: 22\n",
      "[2025-08-13 20:36:19] INFO:     127.0.0.1:52342 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:19] INFO:     127.0.0.1:36252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:19] Decode batch. #running-req: 76, #token: 232118, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1098.23, #queue-req: 22\n",
      "[2025-08-13 20:36:20] INFO:     127.0.0.1:52382 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:20] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 858, token usage: 0.89, #running-req: 75, #queue-req: 20\n",
      "[2025-08-13 20:36:20] INFO:     127.0.0.1:49976 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:20] INFO:     127.0.0.1:34862 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:21] Prefill batch. #new-seq: 2, #new-token: 3618, #cached-token: 96, token usage: 0.92, #running-req: 76, #queue-req: 19\n",
      "[2025-08-13 20:36:22] Prefill batch. #new-seq: 1, #new-token: 2684, #cached-token: 463, token usage: 0.94, #running-req: 76, #queue-req: 19\n",
      "[2025-08-13 20:36:23] INFO:     127.0.0.1:44618 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:23] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 392, token usage: 0.92, #running-req: 76, #queue-req: 18\n",
      "[2025-08-13 20:36:23] Prefill batch. #new-seq: 1, #new-token: 1114, #cached-token: 0, token usage: 0.95, #running-req: 76, #queue-req: 18\n",
      "[2025-08-13 20:36:24] Decode batch. #running-req: 77, #token: 235772, token usage: 0.96, cuda graph: True, gen throughput (token/s): 603.34, #queue-req: 19\n",
      "[2025-08-13 20:36:25] INFO:     127.0.0.1:36140 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:25] INFO:     127.0.0.1:44608 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:25] INFO:     127.0.0.1:48866 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:25] Prefill batch. #new-seq: 3, #new-token: 3781, #cached-token: 1210, token usage: 0.91, #running-req: 74, #queue-req: 20\n",
      "[2025-08-13 20:36:26] INFO:     127.0.0.1:40256 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:26] Prefill batch. #new-seq: 2, #new-token: 4598, #cached-token: 836, token usage: 0.92, #running-req: 76, #queue-req: 18\n",
      "[2025-08-13 20:36:27] INFO:     127.0.0.1:36158 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:28] Decode batch. #running-req: 77, #token: 229021, token usage: 0.93, cuda graph: True, gen throughput (token/s): 871.15, #queue-req: 18\n",
      "[2025-08-13 20:36:31] Decode batch. #running-req: 77, #token: 232101, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1098.28, #queue-req: 23\n",
      "[2025-08-13 20:36:34] Decode batch. #running-req: 77, #token: 235181, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1089.48, #queue-req: 23\n",
      "[2025-08-13 20:36:36] Decode batch. #running-req: 77, #token: 238261, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1081.66, #queue-req: 23\n",
      "[2025-08-13 20:36:39] INFO:     127.0.0.1:57030 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:39] Decode batch. #running-req: 76, #token: 239127, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1073.24, #queue-req: 24\n",
      "[2025-08-13 20:36:41] INFO:     127.0.0.1:57042 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:42] INFO:     127.0.0.1:55440 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:42] Decode batch. #running-req: 74, #token: 235137, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1069.95, #queue-req: 25\n",
      "[2025-08-13 20:36:43] INFO:     127.0.0.1:50326 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:43] INFO:     127.0.0.1:36258 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:43] Prefill batch. #new-seq: 1, #new-token: 7218, #cached-token: 462, token usage: 0.92, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:36:46] Decode batch. #running-req: 73, #token: 236642, token usage: 0.96, cuda graph: True, gen throughput (token/s): 821.83, #queue-req: 27\n",
      "[2025-08-13 20:36:49] Decode batch. #running-req: 73, #token: 239562, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1007.50, #queue-req: 27\n",
      "[2025-08-13 20:36:49] INFO:     127.0.0.1:52346 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:51] Decode batch. #running-req: 72, #token: 239131, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1005.57, #queue-req: 28\n",
      "[2025-08-13 20:36:52] INFO:     127.0.0.1:46502 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:53] INFO:     127.0.0.1:50340 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:53] Prefill batch. #new-seq: 1, #new-token: 4799, #cached-token: 134, token usage: 0.94, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:36:55] Decode batch. #running-req: 71, #token: 237074, token usage: 0.96, cuda graph: True, gen throughput (token/s): 867.72, #queue-req: 29\n",
      "[2025-08-13 20:36:55] INFO:     127.0.0.1:47448 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:55] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 413, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:36:58] Decode batch. #running-req: 71, #token: 238058, token usage: 0.97, cuda graph: True, gen throughput (token/s): 957.46, #queue-req: 29\n",
      "[2025-08-13 20:36:58] INFO:     127.0.0.1:53456 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:59] INFO:     127.0.0.1:50348 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:36:59] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 455, token usage: 0.94, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:37:00] INFO:     127.0.0.1:48256 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:00] Prefill batch. #new-seq: 1, #new-token: 1910, #cached-token: 451, token usage: 0.94, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:37:01] Decode batch. #running-req: 70, #token: 233848, token usage: 0.95, cuda graph: True, gen throughput (token/s): 870.66, #queue-req: 29\n",
      "[2025-08-13 20:37:02] INFO:     127.0.0.1:36242 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:02] Prefill batch. #new-seq: 1, #new-token: 2348, #cached-token: 454, token usage: 0.94, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:37:04] Decode batch. #running-req: 70, #token: 235592, token usage: 0.96, cuda graph: True, gen throughput (token/s): 928.70, #queue-req: 30\n",
      "[2025-08-13 20:37:04] INFO:     127.0.0.1:50358 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:04] Prefill batch. #new-seq: 2, #new-token: 2668, #cached-token: 573, token usage: 0.94, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:37:07] Decode batch. #running-req: 71, #token: 236732, token usage: 0.96, cuda graph: True, gen throughput (token/s): 924.61, #queue-req: 29\n",
      "[2025-08-13 20:37:10] Decode batch. #running-req: 71, #token: 239572, token usage: 0.97, cuda graph: True, gen throughput (token/s): 991.42, #queue-req: 29\n",
      "[2025-08-13 20:37:11] INFO:     127.0.0.1:55400 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:11] INFO:     127.0.0.1:55410 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:11] INFO:     127.0.0.1:56082 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:11] Prefill batch. #new-seq: 1, #new-token: 2355, #cached-token: 447, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:37:13] Decode batch. #running-req: 69, #token: 234943, token usage: 0.96, cuda graph: True, gen throughput (token/s): 907.74, #queue-req: 31\n",
      "[2025-08-13 20:37:14] INFO:     127.0.0.1:55416 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:14] INFO:     127.0.0.1:55430 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:14] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 603, token usage: 0.90, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:37:14] Prefill batch. #new-seq: 2, #new-token: 5704, #cached-token: 441, token usage: 0.93, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:37:15] INFO:     127.0.0.1:56126 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:16] Prefill batch. #new-seq: 2, #new-token: 2497, #cached-token: 581, token usage: 0.94, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:37:16] INFO:     127.0.0.1:56066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:16] Prefill batch. #new-seq: 1, #new-token: 2246, #cached-token: 450, token usage: 0.94, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:37:17] Decode batch. #running-req: 71, #token: 234364, token usage: 0.95, cuda graph: True, gen throughput (token/s): 630.30, #queue-req: 29\n",
      "[2025-08-13 20:37:20] INFO:     127.0.0.1:45654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:20] Decode batch. #running-req: 71, #token: 231615, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1033.90, #queue-req: 29\n",
      "[2025-08-13 20:37:20] Prefill batch. #new-seq: 1, #new-token: 2163, #cached-token: 471, token usage: 0.94, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:37:23] INFO:     127.0.0.1:36274 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:23] Decode batch. #running-req: 70, #token: 235314, token usage: 0.96, cuda graph: True, gen throughput (token/s): 960.09, #queue-req: 29\n",
      "[2025-08-13 20:37:24] INFO:     127.0.0.1:35180 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:24] INFO:     127.0.0.1:35184 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:24] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 915, token usage: 0.91, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:37:24] Prefill batch. #new-seq: 2, #new-token: 1309, #cached-token: 147, token usage: 0.94, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:37:26] INFO:     127.0.0.1:56998 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:26] Prefill batch. #new-seq: 1, #new-token: 3657, #cached-token: 413, token usage: 0.93, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:37:27] INFO:     127.0.0.1:48232 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:27] INFO:     127.0.0.1:36880 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:27] Prefill batch. #new-seq: 1, #new-token: 7429, #cached-token: 410, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:37:28] Decode batch. #running-req: 70, #token: 235333, token usage: 0.96, cuda graph: True, gen throughput (token/s): 601.98, #queue-req: 30\n",
      "[2025-08-13 20:37:28] INFO:     127.0.0.1:36888 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:28] INFO:     127.0.0.1:44590 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:28] Prefill batch. #new-seq: 2, #new-token: 2822, #cached-token: 539, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:37:31] Decode batch. #running-req: 70, #token: 236651, token usage: 0.96, cuda graph: True, gen throughput (token/s): 936.97, #queue-req: 30\n",
      "[2025-08-13 20:37:33] INFO:     127.0.0.1:46138 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:33] Prefill batch. #new-seq: 1, #new-token: 2230, #cached-token: 122, token usage: 0.96, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:37:33] INFO:     127.0.0.1:52388 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:33] Prefill batch. #new-seq: 1, #new-token: 5239, #cached-token: 625, token usage: 0.95, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:37:34] Decode batch. #running-req: 70, #token: 239819, token usage: 0.98, cuda graph: True, gen throughput (token/s): 812.51, #queue-req: 30\n",
      "[2025-08-13 20:37:34] INFO:     127.0.0.1:57042 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:35] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 144, token usage: 0.96, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:37:37] INFO:     127.0.0.1:36126 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:37] Prefill batch. #new-seq: 1, #new-token: 3470, #cached-token: 455, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:37:37] Decode batch. #running-req: 70, #token: 237249, token usage: 0.96, cuda graph: True, gen throughput (token/s): 899.08, #queue-req: 29\n",
      "[2025-08-13 20:37:40] INFO:     127.0.0.1:46136 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:40] Decode batch. #running-req: 69, #token: 234689, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1006.01, #queue-req: 30\n",
      "[2025-08-13 20:37:41] INFO:     127.0.0.1:40250 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:41] Prefill batch. #new-seq: 1, #new-token: 4557, #cached-token: 146, token usage: 0.93, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:37:41] INFO:     127.0.0.1:40268 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:42] Prefill batch. #new-seq: 1, #new-token: 2359, #cached-token: 442, token usage: 0.95, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:37:42] INFO:     127.0.0.1:36124 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:43] Prefill batch. #new-seq: 2, #new-token: 4828, #cached-token: 876, token usage: 0.95, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:37:44] INFO:     127.0.0.1:52350 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:44] INFO:     127.0.0.1:57030 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:44] Prefill batch. #new-seq: 1, #new-token: 1386, #cached-token: 409, token usage: 0.94, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:37:44] Decode batch. #running-req: 69, #token: 233208, token usage: 0.95, cuda graph: True, gen throughput (token/s): 698.55, #queue-req: 29\n",
      "[2025-08-13 20:37:44] INFO:     127.0.0.1:48240 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:44] Prefill batch. #new-seq: 2, #new-token: 6948, #cached-token: 858, token usage: 0.93, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:37:45] INFO:     127.0.0.1:53482 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:45] Prefill batch. #new-seq: 1, #new-token: 2193, #cached-token: 461, token usage: 0.94, #running-req: 69, #queue-req: 26\n",
      "[2025-08-13 20:37:47] INFO:     127.0.0.1:48272 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:47] Prefill batch. #new-seq: 1, #new-token: 1020, #cached-token: 467, token usage: 0.94, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:37:47] INFO:     127.0.0.1:48286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:47] Prefill batch. #new-seq: 2, #new-token: 6530, #cached-token: 541, token usage: 0.94, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:37:48] Decode batch. #running-req: 71, #token: 237786, token usage: 0.97, cuda graph: True, gen throughput (token/s): 653.77, #queue-req: 29\n",
      "[2025-08-13 20:37:49] INFO:     127.0.0.1:55400 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:49] Prefill batch. #new-seq: 1, #new-token: 4300, #cached-token: 125, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:37:49] INFO:     127.0.0.1:50326 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:49] INFO:     127.0.0.1:55410 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:37:52] Decode batch. #running-req: 69, #token: 234796, token usage: 0.96, cuda graph: True, gen throughput (token/s): 867.18, #queue-req: 31\n",
      "[2025-08-13 20:37:52] INFO:     127.0.0.1:52418 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:52] Prefill batch. #new-seq: 1, #new-token: 5691, #cached-token: 625, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:37:53] INFO:     127.0.0.1:46506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:53] Prefill batch. #new-seq: 1, #new-token: 4366, #cached-token: 456, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:37:54] INFO:     127.0.0.1:56098 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:55] INFO:     127.0.0.1:50340 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:55] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 93, token usage: 0.92, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:37:55] INFO:     127.0.0.1:46142 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:55] Prefill batch. #new-seq: 3, #new-token: 3210, #cached-token: 805, token usage: 0.93, #running-req: 67, #queue-req: 28\n",
      "[2025-08-13 20:37:56] Prefill batch. #new-seq: 1, #new-token: 5607, #cached-token: 481, token usage: 0.94, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:37:57] Decode batch. #running-req: 70, #token: 237917, token usage: 0.97, cuda graph: True, gen throughput (token/s): 504.27, #queue-req: 30\n",
      "[2025-08-13 20:37:58] INFO:     127.0.0.1:50348 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:58] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 392, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:37:58] INFO:     127.0.0.1:49966 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:37:58] Prefill batch. #new-seq: 1, #new-token: 7050, #cached-token: 462, token usage: 0.94, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:38:01] Decode batch. #running-req: 70, #token: 239260, token usage: 0.97, cuda graph: True, gen throughput (token/s): 792.88, #queue-req: 30\n",
      "[2025-08-13 20:38:01] INFO:     127.0.0.1:50358 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:02] INFO:     127.0.0.1:52362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:02] INFO:     127.0.0.1:52374 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:03] Prefill batch. #new-seq: 2, #new-token: 7960, #cached-token: 943, token usage: 0.92, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:38:04] Decode batch. #running-req: 69, #token: 236048, token usage: 0.96, cuda graph: True, gen throughput (token/s): 776.19, #queue-req: 31\n",
      "[2025-08-13 20:38:04] INFO:     127.0.0.1:55416 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:04] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 800, token usage: 0.92, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:38:04] Prefill batch. #new-seq: 2, #new-token: 2868, #cached-token: 134, token usage: 0.95, #running-req: 71, #queue-req: 26\n",
      ".[2025-08-13 20:38:06] INFO:     127.0.0.1:52404 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:06] Prefill batch. #new-seq: 1, #new-token: 1705, #cached-token: 466, token usage: 0.95, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 20:38:07] INFO:     127.0.0.1:55430 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:07] Prefill batch. #new-seq: 2, #new-token: 2417, #cached-token: 586, token usage: 0.94, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:38:08] Decode batch. #running-req: 74, #token: 234437, token usage: 0.95, cuda graph: True, gen throughput (token/s): 715.15, #queue-req: 26\n",
      "[2025-08-13 20:38:08] INFO:     127.0.0.1:45654 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:09] Prefill batch. #new-seq: 3, #new-token: 7068, #cached-token: 989, token usage: 0.93, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 20:38:10] INFO:     127.0.0.1:36156 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:10] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 136, token usage: 0.95, #running-req: 75, #queue-req: 24\n",
      "[2025-08-13 20:38:10] INFO:     127.0.0.1:35184 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:10] Prefill batch. #new-seq: 2, #new-token: 6721, #cached-token: 903, token usage: 0.93, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:38:11] INFO:     127.0.0.1:35180 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:12] Prefill batch. #new-seq: 2, #new-token: 4000, #cached-token: 652, token usage: 0.93, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:38:13] Decode batch. #running-req: 78, #token: 234622, token usage: 0.95, cuda graph: True, gen throughput (token/s): 666.25, #queue-req: 21\n",
      "[2025-08-13 20:38:14] INFO:     127.0.0.1:36888 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:15] INFO:     127.0.0.1:36636 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:15] INFO:     127.0.0.1:40268 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:15] Prefill batch. #new-seq: 2, #new-token: 6686, #cached-token: 867, token usage: 0.93, #running-req: 75, #queue-req: 21\n",
      "[2025-08-13 20:38:16] INFO:     127.0.0.1:56088 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:16] Prefill batch. #new-seq: 1, #new-token: 2280, #cached-token: 125, token usage: 0.94, #running-req: 76, #queue-req: 20\n",
      "[2025-08-13 20:38:16] Decode batch. #running-req: 77, #token: 230377, token usage: 0.94, cuda graph: True, gen throughput (token/s): 848.01, #queue-req: 20\n",
      "[2025-08-13 20:38:16] INFO:     127.0.0.1:36170 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:16] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 122, token usage: 0.94, #running-req: 76, #queue-req: 19\n",
      ".[2025-08-13 20:38:17] INFO:     127.0.0.1:36880 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:17] INFO:     127.0.0.1:44590 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:18] INFO:     127.0.0.1:40250 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:18] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.91, #running-req: 74, #queue-req: 19\n",
      "[2025-08-13 20:38:18] Prefill batch. #new-seq: 1, #new-token: 1566, #cached-token: 0, token usage: 0.95, #running-req: 74, #queue-req: 19\n",
      "[2025-08-13 20:38:20] Decode batch. #running-req: 75, #token: 236244, token usage: 0.96, cuda graph: True, gen throughput (token/s): 768.29, #queue-req: 20\n",
      "[2025-08-13 20:38:20] INFO:     127.0.0.1:36166 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:20] Prefill batch. #new-seq: 1, #new-token: 2286, #cached-token: 126, token usage: 0.94, #running-req: 74, #queue-req: 19\n",
      "[2025-08-13 20:38:22] INFO:     127.0.0.1:45684 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:22] INFO:     127.0.0.1:48240 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:22] Prefill batch. #new-seq: 2, #new-token: 2724, #cached-token: 886, token usage: 0.94, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 20:38:24] Decode batch. #running-req: 75, #token: 235066, token usage: 0.96, cuda graph: True, gen throughput (token/s): 900.58, #queue-req: 23\n",
      "[2025-08-13 20:38:26] INFO:     127.0.0.1:59752 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:26] INFO:     127.0.0.1:53472 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:27] Decode batch. #running-req: 73, #token: 232223, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1037.83, #queue-req: 25\n",
      "[2025-08-13 20:38:27] INFO:     127.0.0.1:48272 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:27] INFO:     127.0.0.1:48286 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:27] Prefill batch. #new-seq: 2, #new-token: 7271, #cached-token: 866, token usage: 0.92, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:38:27] INFO:     127.0.0.1:53496 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:28] Prefill batch. #new-seq: 1, #new-token: 4278, #cached-token: 141, token usage: 0.94, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:38:28] INFO:     127.0.0.1:52424 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:28] INFO:     127.0.0.1:53500 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:29] Prefill batch. #new-seq: 1, #new-token: 7553, #cached-token: 413, token usage: 0.92, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:38:31] INFO:     127.0.0.1:53506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:31] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 412, token usage: 0.94, #running-req: 71, #queue-req: 28\n",
      "[2025-08-13 20:38:31] Decode batch. #running-req: 71, #token: 234218, token usage: 0.95, cuda graph: True, gen throughput (token/s): 614.90, #queue-req: 28\n",
      "[2025-08-13 20:38:32] INFO:     127.0.0.1:53518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:32] INFO:     127.0.0.1:36232 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:32] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 923, token usage: 0.91, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:38:32] Prefill batch. #new-seq: 2, #new-token: 647, #cached-token: 77, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:38:34] INFO:     127.0.0.1:52374 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:34] Prefill batch. #new-seq: 2, #new-token: 6456, #cached-token: 851, token usage: 0.93, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:38:35] INFO:     127.0.0.1:36260 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:36] Decode batch. #running-req: 73, #token: 233843, token usage: 0.95, cuda graph: True, gen throughput (token/s): 655.71, #queue-req: 27\n",
      "[2025-08-13 20:38:36] INFO:     127.0.0.1:36794 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:36] Prefill batch. #new-seq: 1, #new-token: 2525, #cached-token: 434, token usage: 0.94, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:38:37] INFO:     127.0.0.1:36712 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:37] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 449, token usage: 0.93, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:38:38] INFO:     127.0.0.1:36786 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:38] Prefill batch. #new-seq: 1, #new-token: 3675, #cached-token: 410, token usage: 0.94, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:38:39] INFO:     127.0.0.1:36286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:40] Decode batch. #running-req: 72, #token: 230506, token usage: 0.94, cuda graph: True, gen throughput (token/s): 754.22, #queue-req: 25\n",
      "[2025-08-13 20:38:40] INFO:     127.0.0.1:36298 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:40] INFO:     127.0.0.1:49966 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:41] Prefill batch. #new-seq: 2, #new-token: 7367, #cached-token: 555, token usage: 0.91, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:38:42] INFO:     127.0.0.1:36302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:42] Prefill batch. #new-seq: 2, #new-token: 3158, #cached-token: 596, token usage: 0.93, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:38:43] INFO:     127.0.0.1:52416 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:43] Prefill batch. #new-seq: 2, #new-token: 4492, #cached-token: 875, token usage: 0.93, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:38:43] INFO:     127.0.0.1:56062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:43] Prefill batch. #new-seq: 3, #new-token: 2268, #cached-token: 703, token usage: 0.93, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:38:43] INFO:     127.0.0.1:36714 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:44] Prefill batch. #new-seq: 1, #new-token: 2164, #cached-token: 151, token usage: 0.94, #running-req: 75, #queue-req: 23\n",
      "[2025-08-13 20:38:44] Decode batch. #running-req: 76, #token: 233398, token usage: 0.95, cuda graph: True, gen throughput (token/s): 629.48, #queue-req: 23\n",
      "[2025-08-13 20:38:44] INFO:     127.0.0.1:56120 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:44] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 439, token usage: 0.93, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:38:45] INFO:     127.0.0.1:56072 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:45] INFO:     127.0.0.1:36166 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:45] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1000, token usage: 0.91, #running-req: 74, #queue-req: 20\n",
      "[2025-08-13 20:38:45] Prefill batch. #new-seq: 1, #new-token: 1727, #cached-token: 0, token usage: 0.94, #running-req: 75, #queue-req: 20\n",
      "[2025-08-13 20:38:47] INFO:     127.0.0.1:36716 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:47] INFO:     127.0.0.1:52404 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:47] Prefill batch. #new-seq: 2, #new-token: 3370, #cached-token: 620, token usage: 0.92, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:38:48] Prefill batch. #new-seq: 1, #new-token: 4582, #cached-token: 463, token usage: 0.94, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:38:48] INFO:     127.0.0.1:56108 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:49] Decode batch. #running-req: 76, #token: 233755, token usage: 0.95, cuda graph: True, gen throughput (token/s): 668.61, #queue-req: 21\n",
      "[2025-08-13 20:38:49] INFO:     127.0.0.1:53500 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:50] INFO:     127.0.0.1:56138 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:50] Prefill batch. #new-seq: 1, #new-token: 5473, #cached-token: 466, token usage: 0.93, #running-req: 74, #queue-req: 25\n",
      "[2025-08-13 20:38:50] INFO:     127.0.0.1:36156 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:51] Prefill batch. #new-seq: 1, #new-token: 2473, #cached-token: 437, token usage: 0.93, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:38:52] Decode batch. #running-req: 75, #token: 233333, token usage: 0.95, cuda graph: True, gen throughput (token/s): 823.00, #queue-req: 25\n",
      "[2025-08-13 20:38:53] INFO:     127.0.0.1:39064 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:54] INFO:     127.0.0.1:46194 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:54] Prefill batch. #new-seq: 1, #new-token: 2354, #cached-token: 447, token usage: 0.94, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:38:56] Decode batch. #running-req: 74, #token: 233783, token usage: 0.95, cuda graph: True, gen throughput (token/s): 944.74, #queue-req: 26\n",
      "[2025-08-13 20:38:56] INFO:     127.0.0.1:46498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:56] Prefill batch. #new-seq: 1, #new-token: 4370, #cached-token: 451, token usage: 0.93, #running-req: 73, #queue-req: 26\n",
      "[2025-08-13 20:38:57] INFO:     127.0.0.1:50640 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:57] INFO:     127.0.0.1:53472 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:59] INFO:     127.0.0.1:53496 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:38:59] Decode batch. #running-req: 71, #token: 228845, token usage: 0.93, cuda graph: True, gen throughput (token/s): 867.09, #queue-req: 28\n",
      "[2025-08-13 20:39:01] INFO:     127.0.0.1:46504 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:02] Decode batch. #running-req: 70, #token: 229560, token usage: 0.93, cuda graph: True, gen throughput (token/s): 983.71, #queue-req: 30\n",
      "[2025-08-13 20:39:05] Decode batch. #running-req: 70, #token: 232360, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1013.28, #queue-req: 30\n",
      "[2025-08-13 20:39:05] INFO:     127.0.0.1:53506 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:07] INFO:     127.0.0.1:58998 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:07] Decode batch. #running-req: 68, #token: 230148, token usage: 0.94, cuda graph: True, gen throughput (token/s): 998.02, #queue-req: 31\n",
      "[2025-08-13 20:39:10] Decode batch. #running-req: 68, #token: 232868, token usage: 0.95, cuda graph: True, gen throughput (token/s): 966.76, #queue-req: 32\n",
      "[2025-08-13 20:39:12] INFO:     127.0.0.1:40598 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:13] Decode batch. #running-req: 67, #token: 234517, token usage: 0.95, cuda graph: True, gen throughput (token/s): 958.92, #queue-req: 32\n",
      "[2025-08-13 20:39:14] INFO:     127.0.0.1:46140 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:15] INFO:     127.0.0.1:36120 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:16] Decode batch. #running-req: 65, #token: 231582, token usage: 0.94, cuda graph: True, gen throughput (token/s): 948.51, #queue-req: 34\n",
      "[2025-08-13 20:39:17] INFO:     127.0.0.1:46156 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:17] INFO:     127.0.0.1:46172 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:17] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.93, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:39:17] Prefill batch. #new-seq: 1, #new-token: 1361, #cached-token: 0, token usage: 0.96, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:39:18] INFO:     127.0.0.1:46188 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:18] Prefill batch. #new-seq: 1, #new-token: 2423, #cached-token: 437, token usage: 0.95, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:39:20] Decode batch. #running-req: 64, #token: 237467, token usage: 0.97, cuda graph: True, gen throughput (token/s): 647.50, #queue-req: 36\n",
      "[2025-08-13 20:39:22] Decode batch. #running-req: 64, #token: 240027, token usage: 0.98, cuda graph: True, gen throughput (token/s): 915.61, #queue-req: 36\n",
      "[2025-08-13 20:39:24] INFO:     127.0.0.1:53422 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:25] Decode batch. #running-req: 63, #token: 241827, token usage: 0.98, cuda graph: True, gen throughput (token/s): 904.29, #queue-req: 37\n",
      "[2025-08-13 20:39:27] INFO:     127.0.0.1:53518 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:27] Prefill batch. #new-seq: 1, #new-token: 2349, #cached-token: 451, token usage: 0.95, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:39:27] INFO:     127.0.0.1:36232 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:27] Prefill batch. #new-seq: 1, #new-token: 2245, #cached-token: 122, token usage: 0.95, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:39:29] Decode batch. #running-req: 63, #token: 236707, token usage: 0.96, cuda graph: True, gen throughput (token/s): 787.42, #queue-req: 35\n",
      "[2025-08-13 20:39:31] INFO:     127.0.0.1:53440 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:31] Decode batch. #running-req: 63, #token: 237571, token usage: 0.97, cuda graph: True, gen throughput (token/s): 916.91, #queue-req: 37\n",
      "[2025-08-13 20:39:34] Decode batch. #running-req: 62, #token: 240051, token usage: 0.98, cuda graph: True, gen throughput (token/s): 899.80, #queue-req: 38\n",
      "[2025-08-13 20:39:35] INFO:     127.0.0.1:36706 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:35] Prefill batch. #new-seq: 1, #new-token: 2843, #cached-token: 464, token usage: 0.94, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 20:39:37] INFO:     127.0.0.1:36260 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:39:37] Decode batch. #running-req: 61, #token: 233777, token usage: 0.95, cuda graph: True, gen throughput (token/s): 825.53, #queue-req: 38\n",
      "[2025-08-13 20:39:40] Decode batch. #running-req: 61, #token: 236217, token usage: 0.96, cuda graph: True, gen throughput (token/s): 886.82, #queue-req: 39\n",
      "[2025-08-13 20:39:41] INFO:     127.0.0.1:50612 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:41] Prefill batch. #new-seq: 1, #new-token: 6625, #cached-token: 146, token usage: 0.95, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:39:42] INFO:     127.0.0.1:36286 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:39:43] Decode batch. #running-req: 60, #token: 235300, token usage: 0.96, cuda graph: True, gen throughput (token/s): 714.04, #queue-req: 40\n",
      "[2025-08-13 20:39:44] INFO:     127.0.0.1:36726 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:45] Prefill batch. #new-seq: 1, #new-token: 5802, #cached-token: 93, token usage: 0.95, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:39:46] Decode batch. #running-req: 60, #token: 239685, token usage: 0.97, cuda graph: True, gen throughput (token/s): 727.04, #queue-req: 40\n",
      "[2025-08-13 20:39:49] INFO:     127.0.0.1:53436 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:49] Prefill batch. #new-seq: 2, #new-token: 2437, #cached-token: 527, token usage: 0.96, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:39:49] Decode batch. #running-req: 61, #token: 238159, token usage: 0.97, cuda graph: True, gen throughput (token/s): 805.27, #queue-req: 38\n",
      "[2025-08-13 20:39:50] INFO:     127.0.0.1:43664 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:52] Decode batch. #running-req: 60, #token: 239071, token usage: 0.97, cuda graph: True, gen throughput (token/s): 884.20, #queue-req: 40\n",
      "[2025-08-13 20:39:53] INFO:     127.0.0.1:36736 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:53] Prefill batch. #new-seq: 1, #new-token: 2297, #cached-token: 171, token usage: 0.96, #running-req: 59, #queue-req: 40\n",
      "[2025-08-13 20:39:55] Decode batch. #running-req: 60, #token: 239414, token usage: 0.97, cuda graph: True, gen throughput (token/s): 813.60, #queue-req: 40\n",
      "[2025-08-13 20:39:56] INFO:     127.0.0.1:36744 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:56] Prefill batch. #new-seq: 1, #new-token: 4882, #cached-token: 412, token usage: 0.96, #running-req: 59, #queue-req: 40\n",
      "[2025-08-13 20:39:57] INFO:     127.0.0.1:46368 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:57] Prefill batch. #new-seq: 2, #new-token: 4673, #cached-token: 879, token usage: 0.96, #running-req: 59, #queue-req: 38\n",
      ".[2025-08-13 20:39:58] INFO:     127.0.0.1:36302 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:58] Prefill batch. #new-seq: 2, #new-token: 4374, #cached-token: 594, token usage: 0.96, #running-req: 60, #queue-req: 36\n",
      "[2025-08-13 20:39:59] INFO:     127.0.0.1:56072 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:39:59] Decode batch. #running-req: 61, #token: 235805, token usage: 0.96, cuda graph: True, gen throughput (token/s): 611.38, #queue-req: 36\n",
      "[2025-08-13 20:39:59] INFO:     127.0.0.1:36298 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:00] INFO:     127.0.0.1:36646 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:00] Prefill batch. #new-seq: 1, #new-token: 7735, #cached-token: 554, token usage: 0.93, #running-req: 59, #queue-req: 36\n",
      "[2025-08-13 20:40:03] Decode batch. #running-req: 60, #token: 237471, token usage: 0.97, cuda graph: True, gen throughput (token/s): 684.59, #queue-req: 40\n",
      "[2025-08-13 20:40:04] INFO:     127.0.0.1:59942 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:04] Prefill batch. #new-seq: 3, #new-token: 4736, #cached-token: 1361, token usage: 0.93, #running-req: 59, #queue-req: 37\n",
      "[2025-08-13 20:40:05] INFO:     127.0.0.1:36644 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:05] Prefill batch. #new-seq: 2, #new-token: 5905, #cached-token: 871, token usage: 0.94, #running-req: 61, #queue-req: 35\n",
      "[2025-08-13 20:40:06] Decode batch. #running-req: 63, #token: 237342, token usage: 0.97, cuda graph: True, gen throughput (token/s): 673.49, #queue-req: 37\n",
      "[2025-08-13 20:40:07] INFO:     127.0.0.1:36658 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:07] Prefill batch. #new-seq: 2, #new-token: 4456, #cached-token: 905, token usage: 0.95, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:40:08] INFO:     127.0.0.1:59890 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:08] INFO:     127.0.0.1:59904 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:08] Prefill batch. #new-seq: 2, #new-token: 3838, #cached-token: 907, token usage: 0.94, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:40:09] INFO:     127.0.0.1:53416 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:09] Prefill batch. #new-seq: 2, #new-token: 5273, #cached-token: 595, token usage: 0.95, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:40:09] INFO:     127.0.0.1:59912 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:09] Prefill batch. #new-seq: 1, #new-token: 2172, #cached-token: 461, token usage: 0.95, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:40:10] INFO:     127.0.0.1:52416 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:10] INFO:     127.0.0.1:56062 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:10] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 924, token usage: 0.92, #running-req: 63, #queue-req: 30\n",
      "[2025-08-13 20:40:10] INFO:     127.0.0.1:36766 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:10] Prefill batch. #new-seq: 2, #new-token: 776, #cached-token: 136, token usage: 0.95, #running-req: 65, #queue-req: 29\n",
      "[2025-08-13 20:40:11] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 435, token usage: 0.95, #running-req: 66, #queue-req: 28\n",
      "[2025-08-13 20:40:11] Decode batch. #running-req: 67, #token: 233785, token usage: 0.95, cuda graph: True, gen throughput (token/s): 525.34, #queue-req: 28\n",
      "[2025-08-13 20:40:11] INFO:     127.0.0.1:40610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:11] Prefill batch. #new-seq: 1, #new-token: 4757, #cached-token: 409, token usage: 0.95, #running-req: 66, #queue-req: 27\n",
      "[2025-08-13 20:40:13] INFO:     127.0.0.1:46140 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:13] Prefill batch. #new-seq: 2, #new-token: 2618, #cached-token: 873, token usage: 0.96, #running-req: 66, #queue-req: 25\n",
      "[2025-08-13 20:40:14] INFO:     127.0.0.1:53410 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:14] Prefill batch. #new-seq: 1, #new-token: 2212, #cached-token: 144, token usage: 0.96, #running-req: 67, #queue-req: 25\n",
      "[2025-08-13 20:40:14] INFO:     127.0.0.1:46504 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:15] Decode batch. #running-req: 67, #token: 233820, token usage: 0.95, cuda graph: True, gen throughput (token/s): 734.65, #queue-req: 25\n",
      "[2025-08-13 20:40:15] INFO:     127.0.0.1:59926 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:15] Prefill batch. #new-seq: 1, #new-token: 4186, #cached-token: 466, token usage: 0.95, #running-req: 66, #queue-req: 24\n",
      "[2025-08-13 20:40:16] INFO:     127.0.0.1:46188 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:16] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 460, token usage: 0.96, #running-req: 66, #queue-req: 25\n",
      "[2025-08-13 20:40:17] INFO:     127.0.0.1:56108 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:18] Decode batch. #running-req: 66, #token: 234166, token usage: 0.95, cuda graph: True, gen throughput (token/s): 832.39, #queue-req: 28\n",
      "[2025-08-13 20:40:19] INFO:     127.0.0.1:59950 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:19] INFO:     127.0.0.1:36760 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:20] INFO:     127.0.0.1:56138 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:20] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.92, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:40:20] Prefill batch. #new-seq: 1, #new-token: 1474, #cached-token: 0, token usage: 0.96, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:40:21] INFO:     127.0.0.1:46172 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:21] Prefill batch. #new-seq: 1, #new-token: 2863, #cached-token: 412, token usage: 0.95, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:40:22] INFO:     127.0.0.1:46498 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:22] INFO:     127.0.0.1:46156 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:22] Prefill batch. #new-seq: 1, #new-token: 589, #cached-token: 467, token usage: 0.94, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 20:40:22] INFO:     127.0.0.1:36774 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:22] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 462, token usage: 0.90, #running-req: 62, #queue-req: 33\n",
      "[2025-08-13 20:40:22] Prefill batch. #new-seq: 2, #new-token: 1140, #cached-token: 93, token usage: 0.94, #running-req: 62, #queue-req: 32\n",
      "[2025-08-13 20:40:23] Decode batch. #running-req: 64, #token: 231602, token usage: 0.94, cuda graph: True, gen throughput (token/s): 516.46, #queue-req: 33\n",
      "[2025-08-13 20:40:24] INFO:     127.0.0.1:36706 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:24] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 647, token usage: 0.91, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:40:24] Prefill batch. #new-seq: 1, #new-token: 1937, #cached-token: 0, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:40:27] Decode batch. #running-req: 65, #token: 235063, token usage: 0.96, cuda graph: True, gen throughput (token/s): 696.32, #queue-req: 35\n",
      "[2025-08-13 20:40:27] INFO:     127.0.0.1:34864 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:27] Prefill batch. #new-seq: 1, #new-token: 1978, #cached-token: 412, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:40:29] INFO:     127.0.0.1:43642 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:29] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 450, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:40:29] INFO:     127.0.0.1:43644 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:29] Prefill batch. #new-seq: 1, #new-token: 3553, #cached-token: 481, token usage: 0.94, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:40:30] Decode batch. #running-req: 65, #token: 234011, token usage: 0.95, cuda graph: True, gen throughput (token/s): 730.86, #queue-req: 35\n",
      "[2025-08-13 20:40:31] INFO:     127.0.0.1:46352 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:31] Prefill batch. #new-seq: 1, #new-token: 4373, #cached-token: 449, token usage: 0.94, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:40:33] Decode batch. #running-req: 65, #token: 238813, token usage: 0.97, cuda graph: True, gen throughput (token/s): 806.63, #queue-req: 35\n",
      "[2025-08-13 20:40:34] INFO:     127.0.0.1:53388 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:36] INFO:     127.0.0.1:45676 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:36] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 450, token usage: 0.96, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:40:36] INFO:     127.0.0.1:60832 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:40:37] Decode batch. #running-req: 63, #token: 239465, token usage: 0.97, cuda graph: True, gen throughput (token/s): 812.63, #queue-req: 36\n",
      "[2025-08-13 20:40:39] INFO:     127.0.0.1:45690 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:39] Decode batch. #running-req: 62, #token: 238598, token usage: 0.97, cuda graph: True, gen throughput (token/s): 914.02, #queue-req: 38\n",
      "[2025-08-13 20:40:40] INFO:     127.0.0.1:59734 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:40] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 392, token usage: 0.95, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 20:40:40] INFO:     127.0.0.1:59744 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:40] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 136, token usage: 0.94, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 20:40:40] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 0, token usage: 0.97, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 20:40:41] INFO:     127.0.0.1:36736 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:41] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.95, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:40:43] INFO:     127.0.0.1:48850 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:43] Decode batch. #running-req: 61, #token: 238349, token usage: 0.97, cuda graph: True, gen throughput (token/s): 652.12, #queue-req: 38\n",
      "[2025-08-13 20:40:46] INFO:     127.0.0.1:58988 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:46] Prefill batch. #new-seq: 1, #new-token: 256, #cached-token: 123, token usage: 0.95, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:40:46] INFO:     127.0.0.1:47682 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:46] Decode batch. #running-req: 60, #token: 234345, token usage: 0.95, cuda graph: True, gen throughput (token/s): 884.87, #queue-req: 38\n",
      "[2025-08-13 20:40:46] INFO:     127.0.0.1:36744 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:46] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 908, token usage: 0.90, #running-req: 59, #queue-req: 36\n",
      "[2025-08-13 20:40:46] INFO:     127.0.0.1:39060 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:46] Prefill batch. #new-seq: 1, #new-token: 1022, #cached-token: 0, token usage: 0.94, #running-req: 60, #queue-req: 36\n",
      "[2025-08-13 20:40:48] INFO:     127.0.0.1:40626 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:48] Prefill batch. #new-seq: 1, #new-token: 7196, #cached-token: 462, token usage: 0.93, #running-req: 59, #queue-req: 36\n",
      "[2025-08-13 20:40:49] INFO:     127.0.0.1:36646 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:49] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 986, token usage: 0.92, #running-req: 59, #queue-req: 33\n",
      "[2025-08-13 20:40:49] Prefill batch. #new-seq: 1, #new-token: 3403, #cached-token: 0, token usage: 0.95, #running-req: 61, #queue-req: 33\n",
      "[2025-08-13 20:40:51] Decode batch. #running-req: 62, #token: 239483, token usage: 0.97, cuda graph: True, gen throughput (token/s): 466.56, #queue-req: 38\n",
      "[2025-08-13 20:40:53] INFO:     127.0.0.1:36658 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:54] Decode batch. #running-req: 61, #token: 236852, token usage: 0.96, cuda graph: True, gen throughput (token/s): 918.41, #queue-req: 38\n",
      "[2025-08-13 20:40:54] INFO:     127.0.0.1:53398 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:54] Prefill batch. #new-seq: 1, #new-token: 2249, #cached-token: 126, token usage: 0.95, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:40:55] INFO:     127.0.0.1:36644 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:55] Prefill batch. #new-seq: 2, #new-token: 6203, #cached-token: 937, token usage: 0.94, #running-req: 60, #queue-req: 35\n",
      "[2025-08-13 20:40:57] Decode batch. #running-req: 62, #token: 239511, token usage: 0.97, cuda graph: True, gen throughput (token/s): 722.36, #queue-req: 38\n",
      "[2025-08-13 20:40:57] INFO:     127.0.0.1:41978 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:59] INFO:     127.0.0.1:43648 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:59] Prefill batch. #new-seq: 2, #new-token: 2497, #cached-token: 909, token usage: 0.95, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:40:59] INFO:     127.0.0.1:36118 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:59] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 467, token usage: 0.96, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 20:40:59] INFO:     127.0.0.1:59904 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:59] INFO:     127.0.0.1:59890 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:40:59] Prefill batch. #new-seq: 2, #new-token: 3253, #cached-token: 855, token usage: 0.94, #running-req: 60, #queue-req: 36\n",
      "[2025-08-13 20:41:01] Decode batch. #running-req: 62, #token: 234703, token usage: 0.95, cuda graph: True, gen throughput (token/s): 725.31, #queue-req: 36\n",
      "[2025-08-13 20:41:02] INFO:     127.0.0.1:59926 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:02] Prefill batch. #new-seq: 2, #new-token: 6515, #cached-token: 588, token usage: 0.94, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 20:41:02] INFO:     127.0.0.1:36130 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:02] INFO:     127.0.0.1:36144 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:02] Prefill batch. #new-seq: 3, #new-token: 2692, #cached-token: 1003, token usage: 0.93, #running-req: 62, #queue-req: 33\n",
      "[2025-08-13 20:41:03] Prefill batch. #new-seq: 1, #new-token: 2406, #cached-token: 392, token usage: 0.94, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:41:03] INFO:     127.0.0.1:39336 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:03] Prefill batch. #new-seq: 1, #new-token: 2224, #cached-token: 409, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      ".[2025-08-13 20:41:04] INFO:     127.0.0.1:36158 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:04] INFO:     127.0.0.1:36168 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:04] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.92, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 20:41:04] Prefill batch. #new-seq: 2, #new-token: 1562, #cached-token: 122, token usage: 0.96, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 20:41:06] Decode batch. #running-req: 65, #token: 237132, token usage: 0.96, cuda graph: True, gen throughput (token/s): 509.37, #queue-req: 35\n",
      "[2025-08-13 20:41:06] INFO:     127.0.0.1:36774 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:06] Prefill batch. #new-seq: 1, #new-token: 5139, #cached-token: 480, token usage: 0.93, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:41:09] INFO:     127.0.0.1:55410 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:09] Prefill batch. #new-seq: 1, #new-token: 2685, #cached-token: 553, token usage: 0.94, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:41:09] Decode batch. #running-req: 64, #token: 233745, token usage: 0.95, cuda graph: True, gen throughput (token/s): 788.76, #queue-req: 35\n",
      "[2025-08-13 20:41:09] INFO:     127.0.0.1:34836 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:10] INFO:     127.0.0.1:34850 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:10] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 875, token usage: 0.90, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:41:10] Prefill batch. #new-seq: 1, #new-token: 3862, #cached-token: 0, token usage: 0.93, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:41:13] INFO:     127.0.0.1:58956 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:13] Prefill batch. #new-seq: 2, #new-token: 2284, #cached-token: 220, token usage: 0.94, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:41:13] Decode batch. #running-req: 66, #token: 232569, token usage: 0.95, cuda graph: True, gen throughput (token/s): 594.57, #queue-req: 33\n",
      "[2025-08-13 20:41:13] INFO:     127.0.0.1:34860 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:13] Prefill batch. #new-seq: 3, #new-token: 6667, #cached-token: 611, token usage: 0.93, #running-req: 65, #queue-req: 30\n",
      "[2025-08-13 20:41:14] INFO:     127.0.0.1:44914 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:14] Prefill batch. #new-seq: 2, #new-token: 3409, #cached-token: 889, token usage: 0.94, #running-req: 67, #queue-req: 28\n",
      "[2025-08-13 20:41:14] INFO:     127.0.0.1:45676 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:41:16] INFO:     127.0.0.1:36760 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:16] INFO:     127.0.0.1:59950 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:16] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 852, token usage: 0.93, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:41:16] Prefill batch. #new-seq: 1, #new-token: 636, #cached-token: 0, token usage: 0.96, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:41:17] INFO:     127.0.0.1:34878 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:17] INFO:     127.0.0.1:33770 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:17] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 468, token usage: 0.95, #running-req: 66, #queue-req: 29\n",
      "[2025-08-13 20:41:18] INFO:     127.0.0.1:59734 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:18] Decode batch. #running-req: 67, #token: 230597, token usage: 0.94, cuda graph: True, gen throughput (token/s): 577.67, #queue-req: 30\n",
      "[2025-08-13 20:41:18] Prefill batch. #new-seq: 1, #new-token: 268, #cached-token: 441, token usage: 0.94, #running-req: 66, #queue-req: 29\n",
      "[2025-08-13 20:41:21] Decode batch. #running-req: 67, #token: 233545, token usage: 0.95, cuda graph: True, gen throughput (token/s): 955.35, #queue-req: 33\n",
      "[2025-08-13 20:41:21] INFO:     127.0.0.1:58948 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:21] Prefill batch. #new-seq: 1, #new-token: 7782, #cached-token: 554, token usage: 0.92, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:41:22] INFO:     127.0.0.1:58966 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:23] Prefill batch. #new-seq: 2, #new-token: 3872, #cached-token: 1077, token usage: 0.92, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:41:23] INFO:     127.0.0.1:39060 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:23] Prefill batch. #new-seq: 3, #new-token: 7201, #cached-token: 1074, token usage: 0.90, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:41:25] INFO:     127.0.0.1:58982 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:25] Decode batch. #running-req: 70, #token: 226810, token usage: 0.92, cuda graph: True, gen throughput (token/s): 611.39, #queue-req: 30\n",
      "[2025-08-13 20:41:25] Prefill batch. #new-seq: 2, #new-token: 5374, #cached-token: 912, token usage: 0.92, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:41:26] INFO:     127.0.0.1:46352 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:27] Prefill batch. #new-seq: 1, #new-token: 7457, #cached-token: 625, token usage: 0.92, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:41:27] INFO:     127.0.0.1:45690 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:28] INFO:     127.0.0.1:50606 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:28] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 136, token usage: 0.94, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:41:29] INFO:     127.0.0.1:52372 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:29] INFO:     127.0.0.1:59744 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:29] Prefill batch. #new-seq: 2, #new-token: 7905, #cached-token: 602, token usage: 0.92, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:41:30] INFO:     127.0.0.1:36118 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:30] Prefill batch. #new-seq: 1, #new-token: 2220, #cached-token: 412, token usage: 0.93, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:41:30] Decode batch. #running-req: 70, #token: 231588, token usage: 0.94, cuda graph: True, gen throughput (token/s): 560.34, #queue-req: 27\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:41:31] INFO:     127.0.0.1:42472 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:32] Prefill batch. #new-seq: 1, #new-token: 2476, #cached-token: 149, token usage: 0.93, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:41:32] INFO:     127.0.0.1:50624 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:32] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 574, token usage: 0.91, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:41:32] INFO:     127.0.0.1:60816 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:32] Prefill batch. #new-seq: 2, #new-token: 2785, #cached-token: 449, token usage: 0.94, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 20:41:33] INFO:     127.0.0.1:47364 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:34] Prefill batch. #new-seq: 1, #new-token: 4327, #cached-token: 171, token usage: 0.94, #running-req: 70, #queue-req: 25\n",
      "[2025-08-13 20:41:35] INFO:     127.0.0.1:36158 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:35] Decode batch. #running-req: 71, #token: 230683, token usage: 0.94, cuda graph: True, gen throughput (token/s): 623.26, #queue-req: 26\n",
      "[2025-08-13 20:41:35] Prefill batch. #new-seq: 2, #new-token: 3734, #cached-token: 963, token usage: 0.94, #running-req: 70, #queue-req: 24\n",
      "[2025-08-13 20:41:36] INFO:     127.0.0.1:48408 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:36] INFO:     127.0.0.1:50630 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:36] INFO:     127.0.0.1:50632 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:36] Prefill batch. #new-seq: 1, #new-token: 7588, #cached-token: 410, token usage: 0.91, #running-req: 69, #queue-req: 23\n",
      "[2025-08-13 20:41:38] INFO:     127.0.0.1:50648 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:38] Prefill batch. #new-seq: 2, #new-token: 6518, #cached-token: 248, token usage: 0.93, #running-req: 69, #queue-req: 21\n",
      "[2025-08-13 20:41:39] INFO:     127.0.0.1:53374 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:39] Decode batch. #running-req: 70, #token: 233028, token usage: 0.95, cuda graph: True, gen throughput (token/s): 617.94, #queue-req: 30\n",
      "[2025-08-13 20:41:40] INFO:     127.0.0.1:36130 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:40] INFO:     127.0.0.1:60780 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:42] Decode batch. #running-req: 68, #token: 230301, token usage: 0.94, cuda graph: True, gen throughput (token/s): 937.89, #queue-req: 30\n",
      "[2025-08-13 20:41:42] INFO:     127.0.0.1:43648 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:43] INFO:     127.0.0.1:60846 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:43] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.91, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:41:43] INFO:     127.0.0.1:60798 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:43] Prefill batch. #new-seq: 2, #new-token: 5945, #cached-token: 441, token usage: 0.92, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:41:45] Prefill batch. #new-seq: 1, #new-token: 1590, #cached-token: 627, token usage: 0.95, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:41:45] INFO:     127.0.0.1:42458 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:45] Prefill batch. #new-seq: 3, #new-token: 4725, #cached-token: 1271, token usage: 0.92, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:41:46] INFO:     127.0.0.1:36144 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:47] Prefill batch. #new-seq: 1, #new-token: 2317, #cached-token: 77, token usage: 0.93, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:41:47] Decode batch. #running-req: 70, #token: 231194, token usage: 0.94, cuda graph: True, gen throughput (token/s): 532.77, #queue-req: 29\n",
      "[2025-08-13 20:41:48] INFO:     127.0.0.1:36168 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:49] INFO:     127.0.0.1:42482 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:49] Prefill batch. #new-seq: 1, #new-token: 7658, #cached-token: 627, token usage: 0.91, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:41:50] INFO:     127.0.0.1:34836 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:50] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 454, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:41:50] INFO:     127.0.0.1:55410 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:51] Prefill batch. #new-seq: 1, #new-token: 2737, #cached-token: 409, token usage: 0.93, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:41:51] Decode batch. #running-req: 69, #token: 231807, token usage: 0.94, cuda graph: True, gen throughput (token/s): 678.33, #queue-req: 29\n",
      "[2025-08-13 20:41:54] Decode batch. #running-req: 69, #token: 234567, token usage: 0.95, cuda graph: True, gen throughput (token/s): 960.51, #queue-req: 31\n",
      "[2025-08-13 20:41:56] INFO:     127.0.0.1:34850 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:56] Prefill batch. #new-seq: 1, #new-token: 6891, #cached-token: 464, token usage: 0.91, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:41:57] INFO:     127.0.0.1:34878 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:58] INFO:     127.0.0.1:58948 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:41:58] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.91, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:41:58] Prefill batch. #new-seq: 2, #new-token: 1781, #cached-token: 437, token usage: 0.94, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:41:59] Decode batch. #running-req: 69, #token: 232921, token usage: 0.95, cuda graph: True, gen throughput (token/s): 606.58, #queue-req: 29\n",
      "[2025-08-13 20:42:00] INFO:     127.0.0.1:58966 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:00] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 938, token usage: 0.91, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:42:00] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 0, token usage: 0.95, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:42:02] INFO:     127.0.0.1:50606 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:02] Prefill batch. #new-seq: 1, #new-token: 4489, #cached-token: 120, token usage: 0.93, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:42:03] Decode batch. #running-req: 70, #token: 234772, token usage: 0.95, cuda graph: True, gen throughput (token/s): 697.66, #queue-req: 30\n",
      "[2025-08-13 20:42:05] INFO:     127.0.0.1:47676 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:05] Prefill batch. #new-seq: 2, #new-token: 4597, #cached-token: 571, token usage: 0.92, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:42:06] INFO:     127.0.0.1:47678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:06] Prefill batch. #new-seq: 2, #new-token: 4526, #cached-token: 910, token usage: 0.92, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 20:42:07] Decode batch. #running-req: 72, #token: 232083, token usage: 0.94, cuda graph: True, gen throughput (token/s): 772.92, #queue-req: 26\n",
      "[2025-08-13 20:42:09] Decode batch. #running-req: 72, #token: 234963, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1039.82, #queue-req: 28\n",
      "[2025-08-13 20:42:11] INFO:     127.0.0.1:58982 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:11] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 460, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:42:12] Decode batch. #running-req: 72, #token: 233674, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1027.71, #queue-req: 28\n",
      "[2025-08-13 20:42:13] INFO:     127.0.0.1:52070 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:13] Prefill batch. #new-seq: 1, #new-token: 5731, #cached-token: 393, token usage: 0.92, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:42:15] Decode batch. #running-req: 72, #token: 234344, token usage: 0.95, cuda graph: True, gen throughput (token/s): 860.31, #queue-req: 28\n",
      "[2025-08-13 20:42:16] INFO:     127.0.0.1:46312 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:16] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 450, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:42:17] INFO:     127.0.0.1:44360 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:17] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 96, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:42:19] Decode batch. #running-req: 72, #token: 238329, token usage: 0.97, cuda graph: True, gen throughput (token/s): 877.74, #queue-req: 28\n",
      "[2025-08-13 20:42:20] INFO:     127.0.0.1:52048 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:21] INFO:     127.0.0.1:44950 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:22] Decode batch. #running-req: 70, #token: 232721, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1006.48, #queue-req: 28\n",
      "[2025-08-13 20:42:24] Decode batch. #running-req: 70, #token: 235521, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1011.46, #queue-req: 30\n",
      "[2025-08-13 20:42:26] INFO:     127.0.0.1:42490 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:26] INFO:     127.0.0.1:50632 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:27] Decode batch. #running-req: 68, #token: 231645, token usage: 0.94, cuda graph: True, gen throughput (token/s): 981.83, #queue-req: 32\n",
      "[2025-08-13 20:42:28] INFO:     127.0.0.1:44330 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:30] Decode batch. #running-req: 67, #token: 231440, token usage: 0.94, cuda graph: True, gen throughput (token/s): 922.61, #queue-req: 33\n",
      "[2025-08-13 20:42:31] INFO:     127.0.0.1:33782 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:31] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 462, token usage: 0.92, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:42:31] Prefill batch. #new-seq: 1, #new-token: 1044, #cached-token: 0, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:42:33] INFO:     127.0.0.1:50630 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:33] Prefill batch. #new-seq: 3, #new-token: 6948, #cached-token: 1349, token usage: 0.93, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:42:34] Decode batch. #running-req: 69, #token: 235034, token usage: 0.96, cuda graph: True, gen throughput (token/s): 605.25, #queue-req: 30\n",
      "[2025-08-13 20:42:35] INFO:     127.0.0.1:53374 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:35] Prefill batch. #new-seq: 1, #new-token: 2206, #cached-token: 129, token usage: 0.95, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:42:35] INFO:     127.0.0.1:39316 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:36] Prefill batch. #new-seq: 2, #new-token: 2700, #cached-token: 279, token usage: 0.94, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:42:37] INFO:     127.0.0.1:39332 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:37] Prefill batch. #new-seq: 2, #new-token: 2840, #cached-token: 873, token usage: 0.94, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:42:38] INFO:     127.0.0.1:44604 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:38] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 439, token usage: 0.95, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:42:38] Decode batch. #running-req: 71, #token: 234079, token usage: 0.95, cuda graph: True, gen throughput (token/s): 802.97, #queue-req: 27\n",
      "[2025-08-13 20:42:41] Decode batch. #running-req: 71, #token: 236919, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1025.94, #queue-req: 29\n",
      "[2025-08-13 20:42:43] INFO:     127.0.0.1:50648 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:44] Decode batch. #running-req: 71, #token: 235255, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1019.04, #queue-req: 29\n",
      "[2025-08-13 20:42:44] INFO:     127.0.0.1:52016 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:44] Prefill batch. #new-seq: 1, #new-token: 2346, #cached-token: 455, token usage: 0.95, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:42:44] INFO:     127.0.0.1:44554 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:45] INFO:     127.0.0.1:39322 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:45] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 877, token usage: 0.91, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:42:45] Prefill batch. #new-seq: 1, #new-token: 1520, #cached-token: 0, token usage: 0.95, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:42:47] INFO:     127.0.0.1:52412 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:47] Prefill batch. #new-seq: 2, #new-token: 6873, #cached-token: 882, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:42:48] INFO:     127.0.0.1:42458 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:48] Prefill batch. #new-seq: 2, #new-token: 2709, #cached-token: 248, token usage: 0.93, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 20:42:48] Decode batch. #running-req: 72, #token: 231359, token usage: 0.94, cuda graph: True, gen throughput (token/s): 584.62, #queue-req: 26\n",
      "[2025-08-13 20:42:49] INFO:     127.0.0.1:48378 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:49] Prefill batch. #new-seq: 1, #new-token: 4381, #cached-token: 448, token usage: 0.92, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:42:51] INFO:     127.0.0.1:39330 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:51] Decode batch. #running-req: 71, #token: 230769, token usage: 0.94, cuda graph: True, gen throughput (token/s): 904.43, #queue-req: 29\n",
      "[2025-08-13 20:42:54] INFO:     127.0.0.1:48394 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:54] INFO:     127.0.0.1:52000 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:54] Prefill batch. #new-seq: 1, #new-token: 7928, #cached-token: 410, token usage: 0.92, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:42:55] Decode batch. #running-req: 70, #token: 234344, token usage: 0.95, cuda graph: True, gen throughput (token/s): 785.06, #queue-req: 28\n",
      "[2025-08-13 20:42:58] Decode batch. #running-req: 70, #token: 232642, token usage: 0.95, cuda graph: True, gen throughput (token/s): 990.84, #queue-req: 30\n",
      "[2025-08-13 20:42:58] INFO:     127.0.0.1:42482 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:59] INFO:     127.0.0.1:41994 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:42:59] Prefill batch. #new-seq: 1, #new-token: 5102, #cached-token: 392, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:43:01] Decode batch. #running-req: 69, #token: 236832, token usage: 0.96, cuda graph: True, gen throughput (token/s): 838.89, #queue-req: 31\n",
      "[2025-08-13 20:43:02] INFO:     127.0.0.1:44960 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:02] Prefill batch. #new-seq: 2, #new-token: 4686, #cached-token: 916, token usage: 0.93, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:43:03] INFO:     127.0.0.1:39338 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:03] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.91, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:43:03] Prefill batch. #new-seq: 1, #new-token: 1624, #cached-token: 0, token usage: 0.95, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:43:05] Decode batch. #running-req: 70, #token: 235712, token usage: 0.96, cuda graph: True, gen throughput (token/s): 650.26, #queue-req: 30\n",
      "[2025-08-13 20:43:07] INFO:     127.0.0.1:39354 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:07] Prefill batch. #new-seq: 1, #new-token: 2349, #cached-token: 453, token usage: 0.95, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:43:07] INFO:     127.0.0.1:60810 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:07] Prefill batch. #new-seq: 1, #new-token: 4377, #cached-token: 454, token usage: 0.94, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:43:09] Decode batch. #running-req: 70, #token: 236166, token usage: 0.96, cuda graph: True, gen throughput (token/s): 812.74, #queue-req: 30\n",
      "[2025-08-13 20:43:11] INFO:     127.0.0.1:33760 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:11] INFO:     127.0.0.1:44616 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:11] Prefill batch. #new-seq: 2, #new-token: 4515, #cached-token: 898, token usage: 0.93, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:43:11] INFO:     127.0.0.1:33788 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:11] INFO:     127.0.0.1:48938 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:43:11] Prefill batch. #new-seq: 3, #new-token: 4700, #cached-token: 1058, token usage: 0.92, #running-req: 68, #queue-req: 26\n",
      "[2025-08-13 20:43:12] INFO:     127.0.0.1:48946 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:12] Prefill batch. #new-seq: 1, #new-token: 4365, #cached-token: 455, token usage: 0.93, #running-req: 70, #queue-req: 25\n",
      "[2025-08-13 20:43:13] Decode batch. #running-req: 71, #token: 234622, token usage: 0.95, cuda graph: True, gen throughput (token/s): 704.44, #queue-req: 29\n",
      "[2025-08-13 20:43:14] INFO:     127.0.0.1:48958 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:15] INFO:     127.0.0.1:33940 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:15] Prefill batch. #new-seq: 2, #new-token: 6843, #cached-token: 561, token usage: 0.92, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:43:16] Decode batch. #running-req: 71, #token: 233104, token usage: 0.95, cuda graph: True, gen throughput (token/s): 830.04, #queue-req: 28\n",
      "[2025-08-13 20:43:18] INFO:     127.0.0.1:52644 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:43:19] Decode batch. #running-req: 70, #token: 233226, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1012.32, #queue-req: 30\n",
      "[2025-08-13 20:43:22] INFO:     127.0.0.1:41988 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:22] Prefill batch. #new-seq: 1, #new-token: 4653, #cached-token: 96, token usage: 0.93, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:43:22] Decode batch. #running-req: 70, #token: 228660, token usage: 0.93, cuda graph: True, gen throughput (token/s): 878.53, #queue-req: 29\n",
      "[2025-08-13 20:43:22] INFO:     127.0.0.1:42490 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:22] Prefill batch. #new-seq: 1, #new-token: 7376, #cached-token: 463, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:43:24] INFO:     127.0.0.1:36286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:24] Prefill batch. #new-seq: 2, #new-token: 5313, #cached-token: 899, token usage: 0.94, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:43:26] Decode batch. #running-req: 71, #token: 237513, token usage: 0.97, cuda graph: True, gen throughput (token/s): 705.60, #queue-req: 29\n",
      "[2025-08-13 20:43:28] INFO:     127.0.0.1:47362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:29] Decode batch. #running-req: 70, #token: 235987, token usage: 0.96, cuda graph: True, gen throughput (token/s): 991.67, #queue-req: 30\n",
      "[2025-08-13 20:43:31] INFO:     127.0.0.1:52358 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:43:32] Decode batch. #running-req: 69, #token: 237016, token usage: 0.96, cuda graph: True, gen throughput (token/s): 980.26, #queue-req: 30\n",
      "[2025-08-13 20:43:34] INFO:     127.0.0.1:39316 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:34] Prefill batch. #new-seq: 1, #new-token: 2277, #cached-token: 125, token usage: 0.95, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:43:35] INFO:     127.0.0.1:51998 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:35] Decode batch. #running-req: 69, #token: 233994, token usage: 0.95, cuda graph: True, gen throughput (token/s): 891.81, #queue-req: 31\n",
      "[2025-08-13 20:43:35] Prefill batch. #new-seq: 1, #new-token: 331, #cached-token: 439, token usage: 0.95, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:43:36] INFO:     127.0.0.1:52030 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:36] Prefill batch. #new-seq: 1, #new-token: 7744, #cached-token: 171, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:43:39] Decode batch. #running-req: 69, #token: 238855, token usage: 0.97, cuda graph: True, gen throughput (token/s): 754.72, #queue-req: 31\n",
      "[2025-08-13 20:43:39] INFO:     127.0.0.1:44322 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:40] INFO:     127.0.0.1:39322 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:40] Prefill batch. #new-seq: 2, #new-token: 3630, #cached-token: 1037, token usage: 0.94, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:43:40] INFO:     127.0.0.1:44930 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:40] Prefill batch. #new-seq: 2, #new-token: 2922, #cached-token: 587, token usage: 0.94, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:43:42] Decode batch. #running-req: 70, #token: 236046, token usage: 0.96, cuda graph: True, gen throughput (token/s): 805.70, #queue-req: 30\n",
      "[2025-08-13 20:43:45] INFO:     127.0.0.1:44934 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:45] Decode batch. #running-req: 69, #token: 236585, token usage: 0.96, cuda graph: True, gen throughput (token/s): 968.34, #queue-req: 31\n",
      "[2025-08-13 20:43:48] Decode batch. #running-req: 69, #token: 239345, token usage: 0.97, cuda graph: True, gen throughput (token/s): 978.42, #queue-req: 31\n",
      "[2025-08-13 20:43:51] Decode batch. #running-req: 69, #token: 242105, token usage: 0.98, cuda graph: True, gen throughput (token/s): 969.11, #queue-req: 31\n",
      "[2025-08-13 20:43:51] INFO:     127.0.0.1:46296 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:52] INFO:     127.0.0.1:52426 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:52] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:43:54] Decode batch. #running-req: 68, #token: 238465, token usage: 0.97, cuda graph: True, gen throughput (token/s): 895.47, #queue-req: 32\n",
      "[2025-08-13 20:43:55] INFO:     127.0.0.1:46318 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:55] INFO:     127.0.0.1:46332 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:55] INFO:     127.0.0.1:46336 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:55] Prefill batch. #new-seq: 3, #new-token: 4234, #cached-token: 823, token usage: 0.93, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:43:56] Prefill batch. #new-seq: 1, #new-token: 697, #cached-token: 436, token usage: 0.95, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:43:56] INFO:     127.0.0.1:52338 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:56] INFO:     127.0.0.1:52350 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:56] Prefill batch. #new-seq: 2, #new-token: 4272, #cached-token: 920, token usage: 0.92, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:43:57] Decode batch. #running-req: 69, #token: 232354, token usage: 0.95, cuda graph: True, gen throughput (token/s): 752.96, #queue-req: 31\n",
      "[2025-08-13 20:43:58] INFO:     127.0.0.1:43016 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:59] INFO:     127.0.0.1:52364 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:59] INFO:     127.0.0.1:52370 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:43:59] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 413, token usage: 0.92, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:43:59] Prefill batch. #new-seq: 1, #new-token: 1703, #cached-token: 0, token usage: 0.95, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:44:00] INFO:     127.0.0.1:52380 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:00] INFO:     127.0.0.1:52396 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:01] Prefill batch. #new-seq: 1, #new-token: 7340, #cached-token: 478, token usage: 0.93, #running-req: 65, #queue-req: 34\n",
      "[2025-08-13 20:44:01] INFO:     127.0.0.1:44570 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:01] Prefill batch. #new-seq: 1, #new-token: 4368, #cached-token: 449, token usage: 0.95, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:44:02] INFO:     127.0.0.1:39338 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:02] Prefill batch. #new-seq: 2, #new-token: 7746, #cached-token: 526, token usage: 0.93, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:44:03] Decode batch. #running-req: 67, #token: 235798, token usage: 0.96, cuda graph: True, gen throughput (token/s): 479.03, #queue-req: 32\n",
      "[2025-08-13 20:44:05] INFO:     127.0.0.1:33926 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:05] Prefill batch. #new-seq: 1, #new-token: 4182, #cached-token: 469, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:44:06] Decode batch. #running-req: 67, #token: 238703, token usage: 0.97, cuda graph: True, gen throughput (token/s): 844.71, #queue-req: 32\n",
      "[2025-08-13 20:44:06] INFO:     127.0.0.1:36752 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:07] INFO:     127.0.0.1:52678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:07] Prefill batch. #new-seq: 3, #new-token: 4660, #cached-token: 631, token usage: 0.94, #running-req: 65, #queue-req: 30\n",
      "[2025-08-13 20:44:07] INFO:     127.0.0.1:33788 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:07] Prefill batch. #new-seq: 1, #new-token: 2020, #cached-token: 467, token usage: 0.96, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:44:08] INFO:     127.0.0.1:52442 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:08] Prefill batch. #new-seq: 3, #new-token: 2686, #cached-token: 984, token usage: 0.93, #running-req: 67, #queue-req: 26\n",
      "[2025-08-13 20:44:09] INFO:     127.0.0.1:39330 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:09] Prefill batch. #new-seq: 1, #new-token: 2724, #cached-token: 392, token usage: 0.93, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:44:09] INFO:     127.0.0.1:33760 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:10] Prefill batch. #new-seq: 1, #new-token: 6673, #cached-token: 93, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:44:10] INFO:     127.0.0.1:48400 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:10] Prefill batch. #new-seq: 1, #new-token: 4368, #cached-token: 452, token usage: 0.95, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:44:11] Decode batch. #running-req: 70, #token: 238688, token usage: 0.97, cuda graph: True, gen throughput (token/s): 561.49, #queue-req: 28\n",
      "[2025-08-13 20:44:13] INFO:     127.0.0.1:43018 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:13] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 96, token usage: 0.96, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:44:14] INFO:     127.0.0.1:39354 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:14] Decode batch. #running-req: 70, #token: 230649, token usage: 0.94, cuda graph: True, gen throughput (token/s): 981.39, #queue-req: 30\n",
      "[2025-08-13 20:44:14] Prefill batch. #new-seq: 1, #new-token: 5029, #cached-token: 464, token usage: 0.94, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:44:14] INFO:     127.0.0.1:43028 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:15] INFO:     127.0.0.1:60810 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:15] Prefill batch. #new-seq: 1, #new-token: 3904, #cached-token: 393, token usage: 0.94, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:44:17] INFO:     127.0.0.1:36764 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:18] Decode batch. #running-req: 68, #token: 231068, token usage: 0.94, cuda graph: True, gen throughput (token/s): 751.76, #queue-req: 31\n",
      "[2025-08-13 20:44:18] INFO:     127.0.0.1:49504 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:18] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 450, token usage: 0.94, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:44:19] INFO:     127.0.0.1:48938 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:19] INFO:     127.0.0.1:48946 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:19] Prefill batch. #new-seq: 2, #new-token: 4620, #cached-token: 525, token usage: 0.93, #running-req: 66, #queue-req: 28\n",
      "[2025-08-13 20:44:20] INFO:     127.0.0.1:52046 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:20] INFO:     127.0.0.1:47362 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:20] Prefill batch. #new-seq: 4, #new-token: 8108, #cached-token: 828, token usage: 0.92, #running-req: 66, #queue-req: 24\n",
      "[2025-08-13 20:44:21] INFO:     127.0.0.1:44344 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:21] Prefill batch. #new-seq: 2, #new-token: 6536, #cached-token: 910, token usage: 0.94, #running-req: 69, #queue-req: 22\n",
      "[2025-08-13 20:44:22] INFO:     127.0.0.1:41542 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:22] Decode batch. #running-req: 70, #token: 227745, token usage: 0.93, cuda graph: True, gen throughput (token/s): 580.25, #queue-req: 24\n",
      "[2025-08-13 20:44:22] INFO:     127.0.0.1:52054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:22] INFO:     127.0.0.1:52068 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:22] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1197, token usage: 0.90, #running-req: 68, #queue-req: 21\n",
      "[2025-08-13 20:44:22] INFO:     127.0.0.1:36286 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:23] Prefill batch. #new-seq: 2, #new-token: 7766, #cached-token: 468, token usage: 0.93, #running-req: 70, #queue-req: 20\n",
      "[2025-08-13 20:44:27] Decode batch. #running-req: 71, #token: 239737, token usage: 0.98, cuda graph: True, gen throughput (token/s): 663.71, #queue-req: 29\n",
      "[2025-08-13 20:44:27] INFO:     127.0.0.1:52660 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:27] Prefill batch. #new-seq: 1, #new-token: 2020, #cached-token: 666, token usage: 0.96, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:44:28] INFO:     127.0.0.1:44348 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:28] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 392, token usage: 0.96, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:44:30] Decode batch. #running-req: 71, #token: 236707, token usage: 0.96, cuda graph: True, gen throughput (token/s): 914.92, #queue-req: 29\n",
      "[2025-08-13 20:44:31] INFO:     127.0.0.1:47268 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:31] Prefill batch. #new-seq: 2, #new-token: 6569, #cached-token: 531, token usage: 0.93, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:44:32] INFO:     127.0.0.1:44930 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:32] INFO:     127.0.0.1:41750 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:32] Prefill batch. #new-seq: 3, #new-token: 6198, #cached-token: 970, token usage: 0.92, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:44:33] INFO:     127.0.0.1:44934 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:33] INFO:     127.0.0.1:46296 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:33] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 478, token usage: 0.91, #running-req: 71, #queue-req: 24\n",
      "[2025-08-13 20:44:33] INFO:     127.0.0.1:52338 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:33] Prefill batch. #new-seq: 2, #new-token: 2246, #cached-token: 455, token usage: 0.94, #running-req: 71, #queue-req: 23\n",
      ".[2025-08-13 20:44:34] INFO:     127.0.0.1:46332 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:34] INFO:     127.0.0.1:46318 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:34] Prefill batch. #new-seq: 2, #new-token: 6057, #cached-token: 910, token usage: 0.92, #running-req: 70, #queue-req: 21\n",
      "[2025-08-13 20:44:35] Decode batch. #running-req: 72, #token: 233075, token usage: 0.95, cuda graph: True, gen throughput (token/s): 521.32, #queue-req: 21\n",
      "[2025-08-13 20:44:36] INFO:     127.0.0.1:52442 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:36] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 285, token usage: 0.91, #running-req: 71, #queue-req: 19\n",
      "[2025-08-13 20:44:36] Prefill batch. #new-seq: 1, #new-token: 884, #cached-token: 0, token usage: 0.95, #running-req: 73, #queue-req: 19\n",
      "[2025-08-13 20:44:37] INFO:     127.0.0.1:46336 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:37] INFO:     127.0.0.1:52350 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:37] INFO:     127.0.0.1:52370 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:37] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1377, token usage: 0.89, #running-req: 71, #queue-req: 17\n",
      "[2025-08-13 20:44:37] Prefill batch. #new-seq: 2, #new-token: 5355, #cached-token: 462, token usage: 0.93, #running-req: 73, #queue-req: 16\n",
      "[2025-08-13 20:44:39] INFO:     127.0.0.1:47288 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:39] Prefill batch. #new-seq: 2, #new-token: 5032, #cached-token: 588, token usage: 0.93, #running-req: 74, #queue-req: 14\n",
      "[2025-08-13 20:44:40] Decode batch. #running-req: 76, #token: 236103, token usage: 0.96, cuda graph: True, gen throughput (token/s): 573.61, #queue-req: 17\n",
      "[2025-08-13 20:44:41] INFO:     127.0.0.1:45676 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:41] Prefill batch. #new-seq: 2, #new-token: 5340, #cached-token: 511, token usage: 0.93, #running-req: 75, #queue-req: 15\n",
      "[2025-08-13 20:44:41] INFO:     127.0.0.1:47276 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:42] INFO:     127.0.0.1:52364 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:42] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 450, token usage: 0.95, #running-req: 75, #queue-req: 14\n",
      "[2025-08-13 20:44:43] INFO:     127.0.0.1:47304 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:44] Decode batch. #running-req: 75, #token: 236329, token usage: 0.96, cuda graph: True, gen throughput (token/s): 814.81, #queue-req: 25\n",
      "[2025-08-13 20:44:45] INFO:     127.0.0.1:48400 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:46] INFO:     127.0.0.1:52380 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:46] INFO:     127.0.0.1:52396 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:44:46] Prefill batch. #new-seq: 2, #new-token: 4442, #cached-token: 509, token usage: 0.93, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:44:47] INFO:     127.0.0.1:33944 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:47] Prefill batch. #new-seq: 2, #new-token: 8030, #cached-token: 621, token usage: 0.91, #running-req: 73, #queue-req: 22\n",
      "[2025-08-13 20:44:47] INFO:     127.0.0.1:33954 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:48] Prefill batch. #new-seq: 1, #new-token: 342, #cached-token: 119, token usage: 0.95, #running-req: 74, #queue-req: 21\n",
      "[2025-08-13 20:44:48] Decode batch. #running-req: 75, #token: 233782, token usage: 0.95, cuda graph: True, gen throughput (token/s): 757.57, #queue-req: 25\n",
      "[2025-08-13 20:44:49] INFO:     127.0.0.1:52054 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:49] INFO:     127.0.0.1:43018 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:49] INFO:     127.0.0.1:43028 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:49] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 93, token usage: 0.91, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:44:49] Prefill batch. #new-seq: 1, #new-token: 804, #cached-token: 0, token usage: 0.94, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:44:51] INFO:     127.0.0.1:52046 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:51] Prefill batch. #new-seq: 1, #new-token: 2231, #cached-token: 126, token usage: 0.93, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 20:44:52] Decode batch. #running-req: 73, #token: 231537, token usage: 0.94, cuda graph: True, gen throughput (token/s): 744.89, #queue-req: 24\n",
      "[2025-08-13 20:44:54] INFO:     127.0.0.1:52068 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:54] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 449, token usage: 0.93, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:44:55] INFO:     127.0.0.1:33958 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:55] Decode batch. #running-req: 72, #token: 231930, token usage: 0.94, cuda graph: True, gen throughput (token/s): 874.83, #queue-req: 28\n",
      "[2025-08-13 20:44:57] INFO:     127.0.0.1:36982 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:57] INFO:     127.0.0.1:46762 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:44:58] Decode batch. #running-req: 70, #token: 229086, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1040.62, #queue-req: 28\n",
      "[2025-08-13 20:45:00] INFO:     127.0.0.1:36118 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:01] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.92, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:45:01] Prefill batch. #new-seq: 1, #new-token: 1416, #cached-token: 0, token usage: 0.96, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:45:02] INFO:     127.0.0.1:44578 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:02] INFO:     127.0.0.1:44588 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:02] Prefill batch. #new-seq: 1, #new-token: 3041, #cached-token: 392, token usage: 0.93, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:45:02] Decode batch. #running-req: 68, #token: 231778, token usage: 0.94, cuda graph: True, gen throughput (token/s): 735.27, #queue-req: 31\n",
      "[2025-08-13 20:45:03] INFO:     127.0.0.1:47268 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:03] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.91, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:45:03] Prefill batch. #new-seq: 1, #new-token: 1747, #cached-token: 0, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:45:06] INFO:     127.0.0.1:44348 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:06] Prefill batch. #new-seq: 2, #new-token: 2773, #cached-token: 505, token usage: 0.94, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:45:06] Decode batch. #running-req: 70, #token: 233200, token usage: 0.95, cuda graph: True, gen throughput (token/s): 631.97, #queue-req: 29\n",
      "[2025-08-13 20:45:08] INFO:     127.0.0.1:54566 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:08] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 392, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:45:09] Decode batch. #running-req: 70, #token: 235417, token usage: 0.96, cuda graph: True, gen throughput (token/s): 965.81, #queue-req: 29\n",
      "[2025-08-13 20:45:10] INFO:     127.0.0.1:52702 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:10] Prefill batch. #new-seq: 1, #new-token: 4377, #cached-token: 444, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:45:11] INFO:     127.0.0.1:34152 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:11] INFO:     127.0.0.1:41556 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:12] Decode batch. #running-req: 68, #token: 235172, token usage: 0.96, cuda graph: True, gen throughput (token/s): 830.86, #queue-req: 29\n",
      "[2025-08-13 20:45:13] INFO:     127.0.0.1:44632 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:13] Prefill batch. #new-seq: 1, #new-token: 3824, #cached-token: 413, token usage: 0.94, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:45:16] Decode batch. #running-req: 68, #token: 237368, token usage: 0.97, cuda graph: True, gen throughput (token/s): 861.20, #queue-req: 32\n",
      "[2025-08-13 20:45:16] INFO:     127.0.0.1:36944 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:45:18] INFO:     127.0.0.1:48452 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:18] Decode batch. #running-req: 66, #token: 237833, token usage: 0.97, cuda graph: True, gen throughput (token/s): 944.56, #queue-req: 33\n",
      "[2025-08-13 20:45:20] INFO:     127.0.0.1:45676 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:21] Decode batch. #running-req: 65, #token: 235951, token usage: 0.96, cuda graph: True, gen throughput (token/s): 920.18, #queue-req: 35\n",
      "[2025-08-13 20:45:22] INFO:     127.0.0.1:47276 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:24] INFO:     127.0.0.1:41764 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:24] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1000, token usage: 0.91, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:45:24] Prefill batch. #new-seq: 1, #new-token: 1895, #cached-token: 0, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:45:25] Decode batch. #running-req: 65, #token: 235205, token usage: 0.96, cuda graph: True, gen throughput (token/s): 700.57, #queue-req: 35\n",
      "[2025-08-13 20:45:28] Decode batch. #running-req: 65, #token: 237805, token usage: 0.97, cuda graph: True, gen throughput (token/s): 897.25, #queue-req: 35\n",
      "[2025-08-13 20:45:28] INFO:     127.0.0.1:49484 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:30] INFO:     127.0.0.1:52642 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:31] Decode batch. #running-req: 63, #token: 232092, token usage: 0.94, cuda graph: True, gen throughput (token/s): 937.62, #queue-req: 37\n",
      "[2025-08-13 20:45:31] INFO:     127.0.0.1:52656 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:33] INFO:     127.0.0.1:52666 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:33] Prefill batch. #new-seq: 1, #new-token: 7589, #cached-token: 410, token usage: 0.93, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 20:45:34] INFO:     127.0.0.1:52686 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:34] Prefill batch. #new-seq: 1, #new-token: 2223, #cached-token: 409, token usage: 0.96, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 20:45:34] Decode batch. #running-req: 61, #token: 237438, token usage: 0.97, cuda graph: True, gen throughput (token/s): 724.25, #queue-req: 38\n",
      "[2025-08-13 20:45:36] INFO:     127.0.0.1:52010 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:37] INFO:     127.0.0.1:48428 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:37] Decode batch. #running-req: 61, #token: 232630, token usage: 0.95, cuda graph: True, gen throughput (token/s): 860.80, #queue-req: 38\n",
      "[2025-08-13 20:45:37] Prefill batch. #new-seq: 1, #new-token: 4384, #cached-token: 446, token usage: 0.95, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:45:39] INFO:     127.0.0.1:54332 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:40] Prefill batch. #new-seq: 2, #new-token: 7246, #cached-token: 932, token usage: 0.94, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:45:41] Decode batch. #running-req: 62, #token: 238271, token usage: 0.97, cuda graph: True, gen throughput (token/s): 650.89, #queue-req: 38\n",
      "[2025-08-13 20:45:42] INFO:     127.0.0.1:51984 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:42] Prefill batch. #new-seq: 1, #new-token: 2114, #cached-token: 143, token usage: 0.96, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 20:45:43] INFO:     127.0.0.1:52002 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:44] Decode batch. #running-req: 61, #token: 236463, token usage: 0.96, cuda graph: True, gen throughput (token/s): 850.06, #queue-req: 39\n",
      "[2025-08-13 20:45:45] INFO:     127.0.0.1:42032 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:45] Prefill batch. #new-seq: 1, #new-token: 2389, #cached-token: 409, token usage: 0.96, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:45:47] Decode batch. #running-req: 61, #token: 239058, token usage: 0.97, cuda graph: True, gen throughput (token/s): 825.58, #queue-req: 39\n",
      "[2025-08-13 20:45:49] INFO:     127.0.0.1:56840 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:49] Prefill batch. #new-seq: 1, #new-token: 415, #cached-token: 119, token usage: 0.96, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:45:49] Decode batch. #running-req: 61, #token: 233340, token usage: 0.95, cuda graph: True, gen throughput (token/s): 871.27, #queue-req: 38\n",
      "[2025-08-13 20:45:49] INFO:     127.0.0.1:47304 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:49] Prefill batch. #new-seq: 1, #new-token: 4371, #cached-token: 449, token usage: 0.95, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:45:50] INFO:     127.0.0.1:36750 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:50] Prefill batch. #new-seq: 1, #new-token: 4756, #cached-token: 409, token usage: 0.95, #running-req: 60, #queue-req: 36\n",
      "[2025-08-13 20:45:51] INFO:     127.0.0.1:33944 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:51] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 409, token usage: 0.96, #running-req: 60, #queue-req: 36\n",
      "[2025-08-13 20:45:53] Decode batch. #running-req: 61, #token: 236252, token usage: 0.96, cuda graph: True, gen throughput (token/s): 673.82, #queue-req: 39\n",
      "[2025-08-13 20:45:54] INFO:     127.0.0.1:41776 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:54] Prefill batch. #new-seq: 1, #new-token: 4390, #cached-token: 441, token usage: 0.94, #running-req: 60, #queue-req: 39\n",
      "[2025-08-13 20:45:55] INFO:     127.0.0.1:48412 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:55] Prefill batch. #new-seq: 1, #new-token: 5159, #cached-token: 463, token usage: 0.94, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:45:56] INFO:     127.0.0.1:49704 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:57] Decode batch. #running-req: 60, #token: 235284, token usage: 0.96, cuda graph: True, gen throughput (token/s): 667.83, #queue-req: 39\n",
      "[2025-08-13 20:45:58] INFO:     127.0.0.1:41786 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:58] INFO:     127.0.0.1:41794 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:58] Prefill batch. #new-seq: 2, #new-token: 6545, #cached-token: 919, token usage: 0.93, #running-req: 58, #queue-req: 40\n",
      "[2025-08-13 20:45:59] INFO:     127.0.0.1:41796 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:45:59] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1524, token usage: 0.90, #running-req: 59, #queue-req: 37\n",
      "[2025-08-13 20:45:59] Prefill batch. #new-seq: 2, #new-token: 1447, #cached-token: 93, token usage: 0.94, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:46:01] Decode batch. #running-req: 64, #token: 233371, token usage: 0.95, cuda graph: True, gen throughput (token/s): 595.33, #queue-req: 36\n",
      "[2025-08-13 20:46:02] INFO:     127.0.0.1:33954 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:02] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 569, token usage: 0.93, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:46:02] INFO:     127.0.0.1:56826 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:02] Prefill batch. #new-seq: 2, #new-token: 4563, #cached-token: 467, token usage: 0.95, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:46:03] INFO:     127.0.0.1:36118 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:46:04] INFO:     127.0.0.1:44578 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:05] Decode batch. #running-req: 63, #token: 231034, token usage: 0.94, cuda graph: True, gen throughput (token/s): 665.65, #queue-req: 36\n",
      "[2025-08-13 20:46:07] INFO:     127.0.0.1:56852 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:07] INFO:     127.0.0.1:56858 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:07] INFO:     127.0.0.1:46756 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:07] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 878, token usage: 0.89, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:46:07] INFO:     127.0.0.1:46772 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:07] Prefill batch. #new-seq: 4, #new-token: 3397, #cached-token: 604, token usage: 0.92, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:46:08] Prefill batch. #new-seq: 2, #new-token: 6577, #cached-token: 899, token usage: 0.93, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:46:09] Decode batch. #running-req: 66, #token: 236642, token usage: 0.96, cuda graph: True, gen throughput (token/s): 580.79, #queue-req: 34\n",
      "[2025-08-13 20:46:10] INFO:     127.0.0.1:44684 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:10] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 412, token usage: 0.96, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:46:10] INFO:     127.0.0.1:54312 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:10] Prefill batch. #new-seq: 2, #new-token: 2307, #cached-token: 567, token usage: 0.93, #running-req: 65, #queue-req: 31\n",
      "[2025-08-13 20:46:10] INFO:     127.0.0.1:46482 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:11] Prefill batch. #new-seq: 1, #new-token: 2540, #cached-token: 436, token usage: 0.94, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:46:11] INFO:     127.0.0.1:33958 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:12] Prefill batch. #new-seq: 1, #new-token: 2354, #cached-token: 448, token usage: 0.94, #running-req: 66, #queue-req: 29\n",
      "[2025-08-13 20:46:12] INFO:     127.0.0.1:49492 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:12] Prefill batch. #new-seq: 2, #new-token: 3898, #cached-token: 518, token usage: 0.94, #running-req: 66, #queue-req: 27\n",
      "[2025-08-13 20:46:13] Decode batch. #running-req: 68, #token: 234520, token usage: 0.95, cuda graph: True, gen throughput (token/s): 689.40, #queue-req: 27\n",
      "[2025-08-13 20:46:14] INFO:     127.0.0.1:36954 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:14] Prefill batch. #new-seq: 3, #new-token: 6936, #cached-token: 971, token usage: 0.94, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:46:15] INFO:     127.0.0.1:44588 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:15] Prefill batch. #new-seq: 1, #new-token: 2274, #cached-token: 133, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:46:16] Decode batch. #running-req: 70, #token: 237151, token usage: 0.96, cuda graph: True, gen throughput (token/s): 765.65, #queue-req: 30\n",
      "[2025-08-13 20:46:19] Decode batch. #running-req: 70, #token: 235453, token usage: 0.96, cuda graph: True, gen throughput (token/s): 986.17, #queue-req: 30\n",
      "[2025-08-13 20:46:19] INFO:     127.0.0.1:44632 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:19] Prefill batch. #new-seq: 1, #new-token: 2275, #cached-token: 129, token usage: 0.92, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:46:19] INFO:     127.0.0.1:49506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:20] Prefill batch. #new-seq: 1, #new-token: 7499, #cached-token: 478, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:46:21] INFO:     127.0.0.1:48446 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:21] Prefill batch. #new-seq: 1, #new-token: 4257, #cached-token: 392, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:46:22] INFO:     127.0.0.1:49510 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:22] INFO:     127.0.0.1:48460 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:22] Prefill batch. #new-seq: 3, #new-token: 7102, #cached-token: 601, token usage: 0.92, #running-req: 69, #queue-req: 28\n",
      ".[2025-08-13 20:46:22] Prefill batch. #new-seq: 1, #new-token: 2219, #cached-token: 412, token usage: 0.95, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:46:23] INFO:     127.0.0.1:51984 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:23] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 449, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:46:24] Decode batch. #running-req: 72, #token: 234456, token usage: 0.95, cuda graph: True, gen throughput (token/s): 548.12, #queue-req: 28\n",
      "[2025-08-13 20:46:25] INFO:     127.0.0.1:52656 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:25] Prefill batch. #new-seq: 1, #new-token: 2106, #cached-token: 413, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:46:25] INFO:     127.0.0.1:52642 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:26] INFO:     127.0.0.1:52666 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:26] INFO:     127.0.0.1:52686 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:26] Prefill batch. #new-seq: 1, #new-token: 7050, #cached-token: 464, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:46:28] Decode batch. #running-req: 70, #token: 229632, token usage: 0.93, cuda graph: True, gen throughput (token/s): 759.93, #queue-req: 30\n",
      "[2025-08-13 20:46:28] INFO:     127.0.0.1:41776 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:28] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 449, token usage: 0.93, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:46:30] INFO:     127.0.0.1:38342 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:31] Prefill batch. #new-seq: 1, #new-token: 2286, #cached-token: 126, token usage: 0.94, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:46:31] Decode batch. #running-req: 70, #token: 233720, token usage: 0.95, cuda graph: True, gen throughput (token/s): 860.44, #queue-req: 30\n",
      "[2025-08-13 20:46:33] INFO:     127.0.0.1:36734 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:33] INFO:     127.0.0.1:52002 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:33] Prefill batch. #new-seq: 1, #new-token: 4374, #cached-token: 446, token usage: 0.93, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:46:35] Decode batch. #running-req: 69, #token: 231955, token usage: 0.94, cuda graph: True, gen throughput (token/s): 837.26, #queue-req: 31\n",
      "[2025-08-13 20:46:35] INFO:     127.0.0.1:36740 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:35] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 446, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:46:38] INFO:     127.0.0.1:48432 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:38] Decode batch. #running-req: 69, #token: 232121, token usage: 0.94, cuda graph: True, gen throughput (token/s): 851.40, #queue-req: 31\n",
      "[2025-08-13 20:46:39] INFO:     127.0.0.1:38314 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:41] Decode batch. #running-req: 67, #token: 230467, token usage: 0.94, cuda graph: True, gen throughput (token/s): 934.27, #queue-req: 33\n",
      "[2025-08-13 20:46:43] INFO:     127.0.0.1:38122 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:43] INFO:     127.0.0.1:41794 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:43] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.92, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:46:43] Prefill batch. #new-seq: 1, #new-token: 3696, #cached-token: 0, token usage: 0.95, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:46:45] Decode batch. #running-req: 66, #token: 238589, token usage: 0.97, cuda graph: True, gen throughput (token/s): 630.60, #queue-req: 34\n",
      "[2025-08-13 20:46:46] INFO:     127.0.0.1:41786 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:48] INFO:     127.0.0.1:44762 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:48] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 450, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:46:48] Decode batch. #running-req: 65, #token: 237417, token usage: 0.97, cuda graph: True, gen throughput (token/s): 799.42, #queue-req: 34\n",
      "[2025-08-13 20:46:48] INFO:     127.0.0.1:54294 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:50] INFO:     127.0.0.1:42024 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:50] Prefill batch. #new-seq: 1, #new-token: 2162, #cached-token: 134, token usage: 0.96, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:46:51] Decode batch. #running-req: 64, #token: 238084, token usage: 0.97, cuda graph: True, gen throughput (token/s): 882.01, #queue-req: 36\n",
      "[2025-08-13 20:46:52] INFO:     127.0.0.1:38326 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:54] Decode batch. #running-req: 63, #token: 236265, token usage: 0.96, cuda graph: True, gen throughput (token/s): 914.44, #queue-req: 37\n",
      "[2025-08-13 20:46:54] INFO:     127.0.0.1:41796 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:54] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1304, token usage: 0.89, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 20:46:54] INFO:     127.0.0.1:34182 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:54] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 883, token usage: 0.92, #running-req: 64, #queue-req: 32\n",
      ".[2025-08-13 20:46:55] Prefill batch. #new-seq: 1, #new-token: 1701, #cached-token: 0, token usage: 0.96, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:46:57] INFO:     127.0.0.1:38346 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:57] INFO:     127.0.0.1:38356 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:58] INFO:     127.0.0.1:54320 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:58] Prefill batch. #new-seq: 2, #new-token: 5043, #cached-token: 934, token usage: 0.93, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:46:59] Decode batch. #running-req: 65, #token: 234997, token usage: 0.96, cuda graph: True, gen throughput (token/s): 529.78, #queue-req: 35\n",
      "[2025-08-13 20:46:59] INFO:     127.0.0.1:56826 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:46:59] Prefill batch. #new-seq: 1, #new-token: 4380, #cached-token: 441, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:47:02] Decode batch. #running-req: 65, #token: 237476, token usage: 0.97, cuda graph: True, gen throughput (token/s): 803.74, #queue-req: 35\n",
      "[2025-08-13 20:47:04] INFO:     127.0.0.1:36976 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:04] Prefill batch. #new-seq: 2, #new-token: 2677, #cached-token: 890, token usage: 0.95, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:47:05] Decode batch. #running-req: 66, #token: 236518, token usage: 0.96, cuda graph: True, gen throughput (token/s): 851.88, #queue-req: 34\n",
      "[2025-08-13 20:47:06] INFO:     127.0.0.1:56852 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:06] INFO:     127.0.0.1:56858 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:06] INFO:     127.0.0.1:46756 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:06] Prefill batch. #new-seq: 2, #new-token: 8162, #cached-token: 992, token usage: 0.92, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 20:47:07] INFO:     127.0.0.1:42026 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:07] Prefill batch. #new-seq: 1, #new-token: 2563, #cached-token: 392, token usage: 0.95, #running-req: 64, #queue-req: 31\n",
      "[2025-08-13 20:47:08] INFO:     127.0.0.1:41570 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:08] INFO:     127.0.0.1:54576 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:08] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.93, #running-req: 63, #queue-req: 30\n",
      "[2025-08-13 20:47:08] Prefill batch. #new-seq: 1, #new-token: 1204, #cached-token: 0, token usage: 0.96, #running-req: 63, #queue-req: 30\n",
      "[2025-08-13 20:47:10] INFO:     127.0.0.1:54590 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:10] Prefill batch. #new-seq: 1, #new-token: 2165, #cached-token: 468, token usage: 0.95, #running-req: 63, #queue-req: 30\n",
      "[2025-08-13 20:47:10] Decode batch. #running-req: 64, #token: 236883, token usage: 0.96, cuda graph: True, gen throughput (token/s): 515.63, #queue-req: 30\n",
      "[2025-08-13 20:47:10] INFO:     127.0.0.1:44738 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:10] Prefill batch. #new-seq: 2, #new-token: 3973, #cached-token: 585, token usage: 0.94, #running-req: 63, #queue-req: 28\n",
      "[2025-08-13 20:47:12] INFO:     127.0.0.1:49492 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:12] Prefill batch. #new-seq: 2, #new-token: 2452, #cached-token: 528, token usage: 0.94, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:47:14] Decode batch. #running-req: 66, #token: 228966, token usage: 0.93, cuda graph: True, gen throughput (token/s): 755.56, #queue-req: 34\n",
      "[2025-08-13 20:47:14] INFO:     127.0.0.1:34168 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:14] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 77, token usage: 0.93, #running-req: 65, #queue-req: 34\n",
      "[2025-08-13 20:47:16] INFO:     127.0.0.1:44712 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:16] INFO:     127.0.0.1:59046 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:16] Prefill batch. #new-seq: 1, #new-token: 5702, #cached-token: 554, token usage: 0.91, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:47:17] Decode batch. #running-req: 65, #token: 231065, token usage: 0.94, cuda graph: True, gen throughput (token/s): 770.67, #queue-req: 33\n",
      "[2025-08-13 20:47:19] INFO:     127.0.0.1:40704 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:19] Prefill batch. #new-seq: 1, #new-token: 5791, #cached-token: 466, token usage: 0.94, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:47:20] INFO:     127.0.0.1:49506 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:20] Prefill batch. #new-seq: 2, #new-token: 7485, #cached-token: 801, token usage: 0.92, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:47:21] Decode batch. #running-req: 66, #token: 235131, token usage: 0.96, cuda graph: True, gen throughput (token/s): 635.28, #queue-req: 34\n",
      "[2025-08-13 20:47:22] INFO:     127.0.0.1:49510 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:23] INFO:     127.0.0.1:54572 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:23] Prefill batch. #new-seq: 2, #new-token: 7857, #cached-token: 548, token usage: 0.93, #running-req: 64, #queue-req: 32\n",
      "[2025-08-13 20:47:24] INFO:     127.0.0.1:53520 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:25] Decode batch. #running-req: 65, #token: 234744, token usage: 0.95, cuda graph: True, gen throughput (token/s): 747.79, #queue-req: 35\n",
      "[2025-08-13 20:47:25] INFO:     127.0.0.1:53512 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:26] INFO:     127.0.0.1:54584 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:26] Prefill batch. #new-seq: 1, #new-token: 4486, #cached-token: 120, token usage: 0.93, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:47:27] INFO:     127.0.0.1:46476 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:27] INFO:     127.0.0.1:49678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:27] Prefill batch. #new-seq: 2, #new-token: 4333, #cached-token: 930, token usage: 0.93, #running-req: 62, #queue-req: 32\n",
      ".[2025-08-13 20:47:28] Decode batch. #running-req: 64, #token: 232773, token usage: 0.95, cuda graph: True, gen throughput (token/s): 738.87, #queue-req: 36\n",
      "[2025-08-13 20:47:30] INFO:     127.0.0.1:46498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:30] INFO:     127.0.0.1:46506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:30] Prefill batch. #new-seq: 2, #new-token: 5997, #cached-token: 572, token usage: 0.93, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:47:31] INFO:     127.0.0.1:36970 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:31] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 466, token usage: 0.94, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:47:32] Decode batch. #running-req: 64, #token: 232439, token usage: 0.95, cuda graph: True, gen throughput (token/s): 755.98, #queue-req: 36\n",
      "[2025-08-13 20:47:32] INFO:     127.0.0.1:36998 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:32] INFO:     127.0.0.1:37008 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:32] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 859, token usage: 0.90, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:47:32] Prefill batch. #new-seq: 2, #new-token: 2071, #cached-token: 122, token usage: 0.94, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:47:34] INFO:     127.0.0.1:48390 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:34] Prefill batch. #new-seq: 1, #new-token: 898, #cached-token: 480, token usage: 0.94, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:47:35] INFO:     127.0.0.1:36734 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:35] Prefill batch. #new-seq: 3, #new-token: 4854, #cached-token: 977, token usage: 0.92, #running-req: 64, #queue-req: 32\n",
      "[2025-08-13 20:47:36] Decode batch. #running-req: 67, #token: 232927, token usage: 0.95, cuda graph: True, gen throughput (token/s): 606.44, #queue-req: 33\n",
      "[2025-08-13 20:47:37] INFO:     127.0.0.1:48396 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:37] Prefill batch. #new-seq: 2, #new-token: 5296, #cached-token: 513, token usage: 0.94, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:47:39] Decode batch. #running-req: 68, #token: 238700, token usage: 0.97, cuda graph: True, gen throughput (token/s): 789.10, #queue-req: 32\n",
      "[2025-08-13 20:47:42] INFO:     127.0.0.1:38314 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:42] INFO:     127.0.0.1:38346 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:42] Decode batch. #running-req: 66, #token: 234263, token usage: 0.95, cuda graph: True, gen throughput (token/s): 902.57, #queue-req: 32\n",
      "[2025-08-13 20:47:45] INFO:     127.0.0.1:38326 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:45] Prefill batch. #new-seq: 1, #new-token: 4126, #cached-token: 453, token usage: 0.94, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:47:46] Decode batch. #running-req: 66, #token: 236534, token usage: 0.96, cuda graph: True, gen throughput (token/s): 779.22, #queue-req: 33\n",
      "[2025-08-13 20:47:47] INFO:     127.0.0.1:38356 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:49] Decode batch. #running-req: 65, #token: 236311, token usage: 0.96, cuda graph: True, gen throughput (token/s): 870.21, #queue-req: 35\n",
      "[2025-08-13 20:47:51] INFO:     127.0.0.1:56392 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:52] Decode batch. #running-req: 64, #token: 238358, token usage: 0.97, cuda graph: True, gen throughput (token/s): 865.55, #queue-req: 35\n",
      "[2025-08-13 20:47:53] INFO:     127.0.0.1:54564 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:54] INFO:     127.0.0.1:49692 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:54] Decode batch. #running-req: 63, #token: 234475, token usage: 0.95, cuda graph: True, gen throughput (token/s): 927.81, #queue-req: 37\n",
      "[2025-08-13 20:47:55] INFO:     127.0.0.1:54320 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:55] Prefill batch. #new-seq: 1, #new-token: 2954, #cached-token: 480, token usage: 0.94, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:47:56] INFO:     127.0.0.1:49698 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:56] Prefill batch. #new-seq: 2, #new-token: 6917, #cached-token: 521, token usage: 0.90, #running-req: 61, #queue-req: 35\n",
      "[2025-08-13 20:47:57] INFO:     127.0.0.1:56376 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:57] Prefill batch. #new-seq: 1, #new-token: 7659, #cached-token: 625, token usage: 0.93, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:47:58] INFO:     127.0.0.1:44680 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:47:58] Prefill batch. #new-seq: 1, #new-token: 4656, #cached-token: 480, token usage: 0.95, #running-req: 62, #queue-req: 37\n",
      "[2025-08-13 20:47:59] Decode batch. #running-req: 63, #token: 238380, token usage: 0.97, cuda graph: True, gen throughput (token/s): 527.21, #queue-req: 37\n",
      "[2025-08-13 20:48:00] INFO:     127.0.0.1:54590 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:00] Prefill batch. #new-seq: 1, #new-token: 2405, #cached-token: 392, token usage: 0.95, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:48:02] Decode batch. #running-req: 63, #token: 238632, token usage: 0.97, cuda graph: True, gen throughput (token/s): 858.48, #queue-req: 37\n",
      "[2025-08-13 20:48:03] INFO:     127.0.0.1:56366 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:04] INFO:     127.0.0.1:54300 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:05] Prefill batch. #new-seq: 1, #new-token: 2158, #cached-token: 475, token usage: 0.95, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:48:05] Decode batch. #running-req: 62, #token: 236982, token usage: 0.96, cuda graph: True, gen throughput (token/s): 858.71, #queue-req: 37\n",
      "[2025-08-13 20:48:06] INFO:     127.0.0.1:54614 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:06] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 122, token usage: 0.95, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:48:06] INFO:     127.0.0.1:54576 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:08] INFO:     127.0.0.1:38140 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:08] Decode batch. #running-req: 60, #token: 229971, token usage: 0.94, cuda graph: True, gen throughput (token/s): 905.95, #queue-req: 37\n",
      "[2025-08-13 20:48:10] Decode batch. #running-req: 60, #token: 232371, token usage: 0.95, cuda graph: True, gen throughput (token/s): 906.76, #queue-req: 40\n",
      "[2025-08-13 20:48:11] INFO:     127.0.0.1:47946 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:11] Prefill batch. #new-seq: 1, #new-token: 7744, #cached-token: 554, token usage: 0.94, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:48:13] INFO:     127.0.0.1:54598 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:13] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 461, token usage: 0.95, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:48:14] INFO:     127.0.0.1:51252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:14] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 412, token usage: 0.96, #running-req: 59, #queue-req: 39\n",
      "[2025-08-13 20:48:14] Decode batch. #running-req: 59, #token: 237182, token usage: 0.96, cuda graph: True, gen throughput (token/s): 673.77, #queue-req: 39\n",
      "[2025-08-13 20:48:17] INFO:     127.0.0.1:44700 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:17] Prefill batch. #new-seq: 1, #new-token: 7051, #cached-token: 462, token usage: 0.94, #running-req: 59, #queue-req: 40\n",
      "[2025-08-13 20:48:18] Decode batch. #running-req: 60, #token: 238989, token usage: 0.97, cuda graph: True, gen throughput (token/s): 666.41, #queue-req: 40\n",
      "[2025-08-13 20:48:18] INFO:     127.0.0.1:47342 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:18] Prefill batch. #new-seq: 2, #new-token: 146, #cached-token: 1077, token usage: 0.95, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:48:20] INFO:     127.0.0.1:54592 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:20] Prefill batch. #new-seq: 1, #new-token: 2316, #cached-token: 442, token usage: 0.93, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:48:21] Decode batch. #running-req: 61, #token: 232105, token usage: 0.94, cuda graph: True, gen throughput (token/s): 822.82, #queue-req: 38\n",
      "[2025-08-13 20:48:23] Decode batch. #running-req: 61, #token: 234545, token usage: 0.95, cuda graph: True, gen throughput (token/s): 900.69, #queue-req: 39\n",
      "[2025-08-13 20:48:25] INFO:     127.0.0.1:44716 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:25] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.92, #running-req: 60, #queue-req: 39\n",
      "[2025-08-13 20:48:26] Prefill batch. #new-seq: 1, #new-token: 1371, #cached-token: 0, token usage: 0.96, #running-req: 60, #queue-req: 39\n",
      "[2025-08-13 20:48:27] INFO:     127.0.0.1:34168 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:27] Prefill batch. #new-seq: 2, #new-token: 2375, #cached-token: 859, token usage: 0.93, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:48:27] INFO:     127.0.0.1:44732 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:27] Decode batch. #running-req: 62, #token: 228072, token usage: 0.93, cuda graph: True, gen throughput (token/s): 621.47, #queue-req: 37\n",
      "[2025-08-13 20:48:27] Prefill batch. #new-seq: 3, #new-token: 4928, #cached-token: 1286, token usage: 0.93, #running-req: 61, #queue-req: 34\n",
      "[2025-08-13 20:48:30] Decode batch. #running-req: 64, #token: 235560, token usage: 0.96, cuda graph: True, gen throughput (token/s): 811.22, #queue-req: 36\n",
      "[2025-08-13 20:48:31] INFO:     127.0.0.1:40704 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:33] INFO:     127.0.0.1:44744 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:33] Prefill batch. #new-seq: 2, #new-token: 5427, #cached-token: 541, token usage: 0.93, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:48:34] Decode batch. #running-req: 64, #token: 233988, token usage: 0.95, cuda graph: True, gen throughput (token/s): 777.46, #queue-req: 36\n",
      "[2025-08-13 20:48:34] INFO:     127.0.0.1:46476 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:34] Prefill batch. #new-seq: 2, #new-token: 6746, #cached-token: 560, token usage: 0.94, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:48:35] INFO:     127.0.0.1:46506 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:36] INFO:     127.0.0.1:44748 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:36] Prefill batch. #new-seq: 1, #new-token: 4368, #cached-token: 451, token usage: 0.94, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:48:37] Decode batch. #running-req: 64, #token: 236894, token usage: 0.96, cuda graph: True, gen throughput (token/s): 689.82, #queue-req: 36\n",
      "[2025-08-13 20:48:38] INFO:     127.0.0.1:47412 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:40] Decode batch. #running-req: 63, #token: 235806, token usage: 0.96, cuda graph: True, gen throughput (token/s): 929.18, #queue-req: 37\n",
      "[2025-08-13 20:48:43] INFO:     127.0.0.1:44776 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:43] Decode batch. #running-req: 62, #token: 235910, token usage: 0.96, cuda graph: True, gen throughput (token/s): 908.58, #queue-req: 38\n",
      "[2025-08-13 20:48:44] INFO:     127.0.0.1:46498 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:45] INFO:     127.0.0.1:36970 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:45] Prefill batch. #new-seq: 1, #new-token: 6927, #cached-token: 463, token usage: 0.94, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:48:46] Decode batch. #running-req: 61, #token: 238273, token usage: 0.97, cuda graph: True, gen throughput (token/s): 728.86, #queue-req: 39\n",
      "[2025-08-13 20:48:46] INFO:     127.0.0.1:47964 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:47] Prefill batch. #new-seq: 2, #new-token: 6929, #cached-token: 542, token usage: 0.95, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:48:47] INFO:     127.0.0.1:52728 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:47] Prefill batch. #new-seq: 1, #new-token: 2451, #cached-token: 93, token usage: 0.96, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 20:48:48] INFO:     127.0.0.1:37008 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:48] Prefill batch. #new-seq: 1, #new-token: 2248, #cached-token: 119, token usage: 0.94, #running-req: 61, #queue-req: 35\n",
      ".[2025-08-13 20:48:49] INFO:     127.0.0.1:36998 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:49] Prefill batch. #new-seq: 2, #new-token: 5572, #cached-token: 602, token usage: 0.94, #running-req: 61, #queue-req: 33\n",
      "[2025-08-13 20:48:50] Decode batch. #running-req: 63, #token: 237183, token usage: 0.96, cuda graph: True, gen throughput (token/s): 585.82, #queue-req: 33\n",
      "[2025-08-13 20:48:51] INFO:     127.0.0.1:54596 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:52] INFO:     127.0.0.1:38148 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:52] Prefill batch. #new-seq: 1, #new-token: 5632, #cached-token: 466, token usage: 0.94, #running-req: 61, #queue-req: 38\n",
      "[2025-08-13 20:48:53] INFO:     127.0.0.1:48390 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:54] Decode batch. #running-req: 61, #token: 236105, token usage: 0.96, cuda graph: True, gen throughput (token/s): 759.16, #queue-req: 38\n",
      "[2025-08-13 20:48:56] Decode batch. #running-req: 61, #token: 238545, token usage: 0.97, cuda graph: True, gen throughput (token/s): 885.82, #queue-req: 39\n",
      "[2025-08-13 20:48:58] INFO:     127.0.0.1:48396 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:58] INFO:     127.0.0.1:33984 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:59] INFO:     127.0.0.1:38158 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:59] INFO:     127.0.0.1:38174 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:59] INFO:     127.0.0.1:59008 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:59] INFO:     127.0.0.1:59018 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:59] INFO:     127.0.0.1:59024 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:59] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1578, token usage: 0.86, #running-req: 54, #queue-req: 35\n",
      "[2025-08-13 20:48:59] INFO:     127.0.0.1:59032 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:48:59] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 627, token usage: 0.89, #running-req: 57, #queue-req: 34\n",
      "[2025-08-13 20:48:59] Prefill batch. #new-seq: 2, #new-token: 8069, #cached-token: 413, token usage: 0.93, #running-req: 58, #queue-req: 39\n",
      "[2025-08-13 20:49:01] Prefill batch. #new-seq: 1, #new-token: 1155, #cached-token: 126, token usage: 0.96, #running-req: 59, #queue-req: 40\n",
      "[2025-08-13 20:49:02] Decode batch. #running-req: 60, #token: 237780, token usage: 0.97, cuda graph: True, gen throughput (token/s): 456.89, #queue-req: 40\n",
      "[2025-08-13 20:49:02] INFO:     127.0.0.1:49698 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:02] INFO:     127.0.0.1:49692 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:02] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1754, token usage: 0.90, #running-req: 59, #queue-req: 36\n",
      "[2025-08-13 20:49:02] Prefill batch. #new-seq: 2, #new-token: 3773, #cached-token: 468, token usage: 0.93, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:49:04] INFO:     127.0.0.1:54316 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:05] INFO:     127.0.0.1:54328 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:05] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 577, token usage: 0.92, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:49:05] Prefill batch. #new-seq: 1, #new-token: 1140, #cached-token: 0, token usage: 0.95, #running-req: 62, #queue-req: 37\n",
      "[2025-08-13 20:49:06] Decode batch. #running-req: 63, #token: 235787, token usage: 0.96, cuda graph: True, gen throughput (token/s): 538.28, #queue-req: 37\n",
      "[2025-08-13 20:49:08] INFO:     127.0.0.1:47370 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:09] Decode batch. #running-req: 62, #token: 236522, token usage: 0.96, cuda graph: True, gen throughput (token/s): 914.45, #queue-req: 38\n",
      "[2025-08-13 20:49:12] Decode batch. #running-req: 62, #token: 239002, token usage: 0.97, cuda graph: True, gen throughput (token/s): 894.63, #queue-req: 38\n",
      "[2025-08-13 20:49:12] INFO:     127.0.0.1:52734 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:12] INFO:     127.0.0.1:52736 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:12] Prefill batch. #new-seq: 3, #new-token: 4870, #cached-token: 976, token usage: 0.92, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 20:49:12] Prefill batch. #new-seq: 1, #new-token: 7723, #cached-token: 554, token usage: 0.94, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:49:13] INFO:     127.0.0.1:55352 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:14] INFO:     127.0.0.1:44680 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:14] INFO:     127.0.0.1:52740 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:14] Prefill batch. #new-seq: 2, #new-token: 2386, #cached-token: 860, token usage: 0.93, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:49:15] INFO:     127.0.0.1:53534 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:15] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 478, token usage: 0.92, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 20:49:15] Prefill batch. #new-seq: 1, #new-token: 1348, #cached-token: 0, token usage: 0.96, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 20:49:17] INFO:     127.0.0.1:44716 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:17] Prefill batch. #new-seq: 1, #new-token: 4259, #cached-token: 392, token usage: 0.93, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:49:17] Decode batch. #running-req: 62, #token: 232297, token usage: 0.94, cuda graph: True, gen throughput (token/s): 488.63, #queue-req: 36\n",
      "[2025-08-13 20:49:17] INFO:     127.0.0.1:53538 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:18] Prefill batch. #new-seq: 1, #new-token: 5188, #cached-token: 464, token usage: 0.93, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:49:19] INFO:     127.0.0.1:44732 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:19] Prefill batch. #new-seq: 1, #new-token: 4837, #cached-token: 624, token usage: 0.94, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:49:21] Decode batch. #running-req: 63, #token: 236576, token usage: 0.96, cuda graph: True, gen throughput (token/s): 630.76, #queue-req: 37\n",
      "[2025-08-13 20:49:21] INFO:     127.0.0.1:53554 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:22] INFO:     127.0.0.1:56420 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:22] Prefill batch. #new-seq: 2, #new-token: 7496, #cached-token: 818, token usage: 0.92, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 20:49:24] INFO:     127.0.0.1:55792 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:24] Prefill batch. #new-seq: 1, #new-token: 2278, #cached-token: 77, token usage: 0.94, #running-req: 62, #queue-req: 37\n",
      "[2025-08-13 20:49:25] Decode batch. #running-req: 63, #token: 233171, token usage: 0.95, cuda graph: True, gen throughput (token/s): 697.76, #queue-req: 37\n",
      "[2025-08-13 20:49:25] INFO:     127.0.0.1:44700 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:25] Prefill batch. #new-seq: 3, #new-token: 7286, #cached-token: 663, token usage: 0.92, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 20:49:26] INFO:     127.0.0.1:47364 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:27] INFO:     127.0.0.1:47972 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:27] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.92, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 20:49:27] Prefill batch. #new-seq: 1, #new-token: 1645, #cached-token: 0, token usage: 0.96, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 20:49:29] Decode batch. #running-req: 64, #token: 237591, token usage: 0.97, cuda graph: True, gen throughput (token/s): 591.27, #queue-req: 36\n",
      "[2025-08-13 20:49:29] INFO:     127.0.0.1:54094 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:32] Decode batch. #running-req: 63, #token: 236583, token usage: 0.96, cuda graph: True, gen throughput (token/s): 903.26, #queue-req: 37\n",
      "[2025-08-13 20:49:33] INFO:     127.0.0.1:44744 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:33] Prefill batch. #new-seq: 2, #new-token: 3232, #cached-token: 554, token usage: 0.94, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:49:35] Decode batch. #running-req: 64, #token: 235106, token usage: 0.96, cuda graph: True, gen throughput (token/s): 824.99, #queue-req: 36\n",
      "[2025-08-13 20:49:36] INFO:     127.0.0.1:44776 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:38] Decode batch. #running-req: 63, #token: 235086, token usage: 0.96, cuda graph: True, gen throughput (token/s): 914.10, #queue-req: 37\n",
      "[2025-08-13 20:49:40] INFO:     127.0.0.1:54798 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:40] Decode batch. #running-req: 62, #token: 235668, token usage: 0.96, cuda graph: True, gen throughput (token/s): 898.84, #queue-req: 37\n",
      "[2025-08-13 20:49:42] INFO:     127.0.0.1:36118 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:43] Decode batch. #running-req: 61, #token: 233964, token usage: 0.95, cuda graph: True, gen throughput (token/s): 883.60, #queue-req: 39\n",
      "[2025-08-13 20:49:43] INFO:     127.0.0.1:51236 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:46] Decode batch. #running-req: 60, #token: 234619, token usage: 0.95, cuda graph: True, gen throughput (token/s): 870.02, #queue-req: 40\n",
      "[2025-08-13 20:49:46] INFO:     127.0.0.1:55794 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:46] INFO:     127.0.0.1:55796 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:46] Prefill batch. #new-seq: 3, #new-token: 7524, #cached-token: 1303, token usage: 0.91, #running-req: 58, #queue-req: 39\n",
      "[2025-08-13 20:49:49] INFO:     127.0.0.1:47356 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:49] Prefill batch. #new-seq: 2, #new-token: 6461, #cached-token: 505, token usage: 0.94, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:49:50] Decode batch. #running-req: 62, #token: 235559, token usage: 0.96, cuda graph: True, gen throughput (token/s): 613.66, #queue-req: 38\n",
      "[2025-08-13 20:49:50] INFO:     127.0.0.1:38148 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:50] INFO:     127.0.0.1:54596 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:50] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1037, token usage: 0.91, #running-req: 60, #queue-req: 35\n",
      "[2025-08-13 20:49:50] INFO:     127.0.0.1:55340 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:50] Prefill batch. #new-seq: 3, #new-token: 5738, #cached-token: 282, token usage: 0.94, #running-req: 62, #queue-req: 33\n",
      "[2025-08-13 20:49:52] INFO:     127.0.0.1:43648 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:52] INFO:     127.0.0.1:34990 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:52] INFO:     127.0.0.1:59008 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:54] INFO:     127.0.0.1:52226 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:54] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.93, #running-req: 60, #queue-req: 33\n",
      "[2025-08-13 20:49:54] Prefill batch. #new-seq: 1, #new-token: 1575, #cached-token: 0, token usage: 0.96, #running-req: 60, #queue-req: 33\n",
      ".[2025-08-13 20:49:55] Decode batch. #running-req: 61, #token: 236462, token usage: 0.96, cuda graph: True, gen throughput (token/s): 496.37, #queue-req: 33\n",
      "[2025-08-13 20:49:55] INFO:     127.0.0.1:34024 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:56] INFO:     127.0.0.1:38158 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:56] Prefill batch. #new-seq: 1, #new-token: 4219, #cached-token: 456, token usage: 0.93, #running-req: 59, #queue-req: 33\n",
      "[2025-08-13 20:49:58] INFO:     127.0.0.1:55328 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:58] Decode batch. #running-req: 59, #token: 231774, token usage: 0.94, cuda graph: True, gen throughput (token/s): 757.95, #queue-req: 33\n",
      "[2025-08-13 20:49:59] INFO:     127.0.0.1:47384 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:59] INFO:     127.0.0.1:47398 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:49:59] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 967, token usage: 0.90, #running-req: 57, #queue-req: 31\n",
      "[2025-08-13 20:49:59] Prefill batch. #new-seq: 3, #new-token: 6172, #cached-token: 889, token usage: 0.93, #running-req: 59, #queue-req: 29\n",
      "[2025-08-13 20:50:01] INFO:     127.0.0.1:43826 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:01] Prefill batch. #new-seq: 1, #new-token: 4370, #cached-token: 452, token usage: 0.95, #running-req: 61, #queue-req: 37\n",
      "[2025-08-13 20:50:02] INFO:     127.0.0.1:54316 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:02] Decode batch. #running-req: 61, #token: 234815, token usage: 0.96, cuda graph: True, gen throughput (token/s): 541.84, #queue-req: 37\n",
      "[2025-08-13 20:50:03] INFO:     127.0.0.1:59018 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:03] INFO:     127.0.0.1:38174 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:03] INFO:     127.0.0.1:59024 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:03] Prefill batch. #new-seq: 2, #new-token: 7871, #cached-token: 752, token usage: 0.90, #running-req: 58, #queue-req: 37\n",
      "[2025-08-13 20:50:03] INFO:     127.0.0.1:56406 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:04] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.93, #running-req: 59, #queue-req: 36\n",
      "[2025-08-13 20:50:04] Prefill batch. #new-seq: 1, #new-token: 1341, #cached-token: 0, token usage: 0.97, #running-req: 59, #queue-req: 36\n",
      "[2025-08-13 20:50:06] INFO:     127.0.0.1:52734 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:06] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 438, token usage: 0.96, #running-req: 59, #queue-req: 35\n",
      "[2025-08-13 20:50:07] Decode batch. #running-req: 60, #token: 236111, token usage: 0.96, cuda graph: True, gen throughput (token/s): 539.74, #queue-req: 35\n",
      "[2025-08-13 20:50:07] INFO:     127.0.0.1:56414 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:08] INFO:     127.0.0.1:59032 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:09] Prefill batch. #new-seq: 1, #new-token: 6678, #cached-token: 171, token usage: 0.94, #running-req: 58, #queue-req: 40\n",
      ".[2025-08-13 20:50:09] INFO:     127.0.0.1:54070 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:09] Prefill batch. #new-seq: 1, #new-token: 4371, #cached-token: 449, token usage: 0.95, #running-req: 58, #queue-req: 39\n",
      "[2025-08-13 20:50:10] INFO:     127.0.0.1:52740 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:10] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 409, token usage: 0.94, #running-req: 58, #queue-req: 38\n",
      "[2025-08-13 20:50:11] Decode batch. #running-req: 59, #token: 234770, token usage: 0.95, cuda graph: True, gen throughput (token/s): 582.29, #queue-req: 38\n",
      "[2025-08-13 20:50:13] INFO:     127.0.0.1:47934 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:13] Prefill batch. #new-seq: 1, #new-token: 4072, #cached-token: 467, token usage: 0.93, #running-req: 58, #queue-req: 41\n",
      "[2025-08-13 20:50:13] INFO:     127.0.0.1:47952 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:13] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 862, token usage: 0.92, #running-req: 58, #queue-req: 40\n",
      "[2025-08-13 20:50:13] Prefill batch. #new-seq: 1, #new-token: 1905, #cached-token: 0, token usage: 0.95, #running-req: 59, #queue-req: 40\n",
      "[2025-08-13 20:50:15] INFO:     127.0.0.1:58488 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:15] Prefill batch. #new-seq: 2, #new-token: 6706, #cached-token: 917, token usage: 0.93, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 20:50:15] INFO:     127.0.0.1:54328 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:16] Decode batch. #running-req: 60, #token: 231425, token usage: 0.94, cuda graph: True, gen throughput (token/s): 509.47, #queue-req: 38\n",
      "[2025-08-13 20:50:16] INFO:     127.0.0.1:53538 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:16] Prefill batch. #new-seq: 1, #new-token: 4303, #cached-token: 129, token usage: 0.94, #running-req: 59, #queue-req: 37\n",
      ".[2025-08-13 20:50:17] INFO:     127.0.0.1:47956 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:17] Prefill batch. #new-seq: 1, #new-token: 4384, #cached-token: 446, token usage: 0.94, #running-req: 59, #queue-req: 36\n",
      "[2025-08-13 20:50:18] INFO:     127.0.0.1:52736 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:18] Prefill batch. #new-seq: 3, #new-token: 4823, #cached-token: 1358, token usage: 0.92, #running-req: 59, #queue-req: 37\n",
      "[2025-08-13 20:50:19] INFO:     127.0.0.1:34518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:19] INFO:     127.0.0.1:43634 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:19] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 613, token usage: 0.90, #running-req: 60, #queue-req: 35\n",
      "[2025-08-13 20:50:19] Prefill batch. #new-seq: 2, #new-token: 2775, #cached-token: 137, token usage: 0.93, #running-req: 61, #queue-req: 34\n",
      "[2025-08-13 20:50:21] Decode batch. #running-req: 63, #token: 232113, token usage: 0.94, cuda graph: True, gen throughput (token/s): 498.98, #queue-req: 34\n",
      "[2025-08-13 20:50:23] INFO:     127.0.0.1:53534 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:23] Prefill batch. #new-seq: 2, #new-token: 4342, #cached-token: 230, token usage: 0.93, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 20:50:24] Decode batch. #running-req: 64, #token: 234482, token usage: 0.95, cuda graph: True, gen throughput (token/s): 809.28, #queue-req: 36\n",
      "[2025-08-13 20:50:25] INFO:     127.0.0.1:34528 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:25] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 447, token usage: 0.93, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:50:26] INFO:     127.0.0.1:54084 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:26] Prefill batch. #new-seq: 1, #new-token: 6942, #cached-token: 409, token usage: 0.94, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:50:27] Decode batch. #running-req: 64, #token: 238432, token usage: 0.97, cuda graph: True, gen throughput (token/s): 663.09, #queue-req: 36\n",
      "[2025-08-13 20:50:28] INFO:     127.0.0.1:53554 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:28] Prefill batch. #new-seq: 2, #new-token: 2289, #cached-token: 788, token usage: 0.95, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 20:50:28] INFO:     127.0.0.1:55792 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:28] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 455, token usage: 0.95, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:50:28] INFO:     127.0.0.1:54100 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:29] INFO:     127.0.0.1:51226 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:29] Prefill batch. #new-seq: 3, #new-token: 2579, #cached-token: 679, token usage: 0.90, #running-req: 63, #queue-req: 30\n",
      "[2025-08-13 20:50:30] INFO:     127.0.0.1:51242 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:30] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.90, #running-req: 65, #queue-req: 34\n",
      "[2025-08-13 20:50:30] Prefill batch. #new-seq: 3, #new-token: 4085, #cached-token: 847, token usage: 0.93, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:50:31] INFO:     127.0.0.1:51264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:31] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.94, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:50:32] Decode batch. #running-req: 68, #token: 234858, token usage: 0.96, cuda graph: True, gen throughput (token/s): 538.75, #queue-req: 32\n",
      "[2025-08-13 20:50:32] INFO:     127.0.0.1:47384 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:33] Prefill batch. #new-seq: 2, #new-token: 8123, #cached-token: 847, token usage: 0.92, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:50:35] INFO:     127.0.0.1:55794 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:35] Prefill batch. #new-seq: 2, #new-token: 1290, #cached-token: 305, token usage: 0.93, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:50:36] INFO:     127.0.0.1:34020 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:36] Prefill batch. #new-seq: 1, #new-token: 5516, #cached-token: 627, token usage: 0.92, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:50:37] Decode batch. #running-req: 70, #token: 231998, token usage: 0.94, cuda graph: True, gen throughput (token/s): 641.37, #queue-req: 28\n",
      "[2025-08-13 20:50:37] INFO:     127.0.0.1:36118 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:37] Prefill batch. #new-seq: 2, #new-token: 6642, #cached-token: 535, token usage: 0.93, #running-req: 69, #queue-req: 26\n",
      ".[2025-08-13 20:50:39] INFO:     127.0.0.1:55796 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:39] Prefill batch. #new-seq: 1, #new-token: 2307, #cached-token: 93, token usage: 0.94, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:50:40] Decode batch. #running-req: 71, #token: 234982, token usage: 0.96, cuda graph: True, gen throughput (token/s): 766.49, #queue-req: 29\n",
      "[2025-08-13 20:50:41] INFO:     127.0.0.1:60052 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:41] INFO:     127.0.0.1:60060 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:41] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 449, token usage: 0.94, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:50:41] INFO:     127.0.0.1:47356 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:42] Prefill batch. #new-seq: 1, #new-token: 2404, #cached-token: 439, token usage: 0.94, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:50:43] INFO:     127.0.0.1:56414 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:43] INFO:     127.0.0.1:47398 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:43] Prefill batch. #new-seq: 1, #new-token: 2049, #cached-token: 144, token usage: 0.94, #running-req: 68, #queue-req: 26\n",
      "[2025-08-13 20:50:44] Decode batch. #running-req: 69, #token: 233520, token usage: 0.95, cuda graph: True, gen throughput (token/s): 798.03, #queue-req: 27\n",
      "[2025-08-13 20:50:47] Decode batch. #running-req: 69, #token: 236280, token usage: 0.96, cuda graph: True, gen throughput (token/s): 981.03, #queue-req: 31\n",
      "[2025-08-13 20:50:47] INFO:     127.0.0.1:56406 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:48] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 412, token usage: 0.95, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:50:50] Decode batch. #running-req: 69, #token: 234625, token usage: 0.95, cuda graph: True, gen throughput (token/s): 970.57, #queue-req: 31\n",
      "[2025-08-13 20:50:52] Decode batch. #running-req: 69, #token: 237385, token usage: 0.97, cuda graph: True, gen throughput (token/s): 975.51, #queue-req: 31\n",
      "[2025-08-13 20:50:54] INFO:     127.0.0.1:55304 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:54] Prefill batch. #new-seq: 2, #new-token: 3971, #cached-token: 673, token usage: 0.93, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:50:56] Decode batch. #running-req: 70, #token: 234472, token usage: 0.95, cuda graph: True, gen throughput (token/s): 858.71, #queue-req: 30\n",
      "[2025-08-13 20:50:56] INFO:     127.0.0.1:46828 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:57] INFO:     127.0.0.1:55310 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:50:57] Prefill batch. #new-seq: 1, #new-token: 7811, #cached-token: 466, token usage: 0.93, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:50:59] Decode batch. #running-req: 69, #token: 237311, token usage: 0.97, cuda graph: True, gen throughput (token/s): 743.72, #queue-req: 31\n",
      "[2025-08-13 20:51:00] INFO:     127.0.0.1:47934 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:00] Prefill batch. #new-seq: 1, #new-token: 7208, #cached-token: 464, token usage: 0.93, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:51:01] INFO:     127.0.0.1:47952 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:02] Prefill batch. #new-seq: 1, #new-token: 5609, #cached-token: 393, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:51:03] INFO:     127.0.0.1:55320 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:03] INFO:     127.0.0.1:47956 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:03] Prefill batch. #new-seq: 2, #new-token: 4593, #cached-token: 896, token usage: 0.93, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:51:04] Decode batch. #running-req: 69, #token: 232565, token usage: 0.95, cuda graph: True, gen throughput (token/s): 604.13, #queue-req: 30\n",
      "[2025-08-13 20:51:05] INFO:     127.0.0.1:43762 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:05] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 77, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:51:07] Decode batch. #running-req: 69, #token: 232757, token usage: 0.95, cuda graph: True, gen throughput (token/s): 957.65, #queue-req: 31\n",
      "[2025-08-13 20:51:09] INFO:     127.0.0.1:46968 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:10] Decode batch. #running-req: 68, #token: 232834, token usage: 0.95, cuda graph: True, gen throughput (token/s): 949.82, #queue-req: 32\n",
      "[2025-08-13 20:51:11] INFO:     127.0.0.1:43844 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:12] INFO:     127.0.0.1:55362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:13] Decode batch. #running-req: 67, #token: 230328, token usage: 0.94, cuda graph: True, gen throughput (token/s): 937.28, #queue-req: 33\n",
      "[2025-08-13 20:51:16] Decode batch. #running-req: 66, #token: 232968, token usage: 0.95, cuda graph: True, gen throughput (token/s): 899.00, #queue-req: 34\n",
      "[2025-08-13 20:51:16] INFO:     127.0.0.1:33990 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:17] INFO:     127.0.0.1:52248 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:17] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 478, token usage: 0.91, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:51:17] Prefill batch. #new-seq: 1, #new-token: 1493, #cached-token: 0, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:51:19] INFO:     127.0.0.1:44866 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:19] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:51:20] Decode batch. #running-req: 65, #token: 235271, token usage: 0.96, cuda graph: True, gen throughput (token/s): 619.09, #queue-req: 34\n",
      "[2025-08-13 20:51:21] INFO:     127.0.0.1:42704 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:51:23] Decode batch. #running-req: 64, #token: 236255, token usage: 0.96, cuda graph: True, gen throughput (token/s): 896.31, #queue-req: 36\n",
      "[2025-08-13 20:51:25] INFO:     127.0.0.1:34004 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:25] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1088, token usage: 0.92, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:51:25] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 0, token usage: 0.96, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:51:26] Decode batch. #running-req: 65, #token: 228818, token usage: 0.93, cuda graph: True, gen throughput (token/s): 723.60, #queue-req: 35\n",
      "[2025-08-13 20:51:26] INFO:     127.0.0.1:34030 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:26] INFO:     127.0.0.1:43630 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:26] Prefill batch. #new-seq: 1, #new-token: 4706, #cached-token: 93, token usage: 0.93, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 20:51:28] INFO:     127.0.0.1:56600 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:28] Prefill batch. #new-seq: 1, #new-token: 3639, #cached-token: 129, token usage: 0.94, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:51:30] Decode batch. #running-req: 64, #token: 235851, token usage: 0.96, cuda graph: True, gen throughput (token/s): 745.51, #queue-req: 36\n",
      "[2025-08-13 20:51:32] Decode batch. #running-req: 64, #token: 238411, token usage: 0.97, cuda graph: True, gen throughput (token/s): 935.44, #queue-req: 36\n",
      "[2025-08-13 20:51:35] INFO:     127.0.0.1:44884 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:35] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 446, token usage: 0.95, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:51:35] Decode batch. #running-req: 63, #token: 237176, token usage: 0.96, cuda graph: True, gen throughput (token/s): 921.54, #queue-req: 35\n",
      "[2025-08-13 20:51:37] INFO:     127.0.0.1:56584 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:37] INFO:     127.0.0.1:54084 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:38] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 627, token usage: 0.93, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:51:38] Prefill batch. #new-seq: 1, #new-token: 1325, #cached-token: 0, token usage: 0.96, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 20:51:39] Decode batch. #running-req: 63, #token: 239128, token usage: 0.97, cuda graph: True, gen throughput (token/s): 621.97, #queue-req: 37\n",
      "[2025-08-13 20:51:39] INFO:     127.0.0.1:46986 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:41] INFO:     127.0.0.1:52678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:42] Decode batch. #running-req: 61, #token: 237925, token usage: 0.97, cuda graph: True, gen throughput (token/s): 907.03, #queue-req: 39\n",
      "[2025-08-13 20:51:43] INFO:     127.0.0.1:50658 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:44] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 413, token usage: 0.96, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:51:45] Decode batch. #running-req: 61, #token: 239345, token usage: 0.97, cuda graph: True, gen throughput (token/s): 829.89, #queue-req: 39\n",
      "[2025-08-13 20:51:45] INFO:     127.0.0.1:43652 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:45] INFO:     127.0.0.1:51226 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:45] Prefill batch. #new-seq: 3, #new-token: 7519, #cached-token: 1056, token usage: 0.94, #running-req: 60, #queue-req: 37\n",
      "[2025-08-13 20:51:47] INFO:     127.0.0.1:52232 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:48] INFO:     127.0.0.1:54100 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:48] Decode batch. #running-req: 61, #token: 228428, token usage: 0.93, cuda graph: True, gen throughput (token/s): 721.72, #queue-req: 39\n",
      "[2025-08-13 20:51:48] Prefill batch. #new-seq: 1, #new-token: 2346, #cached-token: 455, token usage: 0.93, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:51:51] Decode batch. #running-req: 61, #token: 233214, token usage: 0.95, cuda graph: True, gen throughput (token/s): 843.69, #queue-req: 39\n",
      "[2025-08-13 20:51:54] Decode batch. #running-req: 61, #token: 235654, token usage: 0.96, cuda graph: True, gen throughput (token/s): 904.81, #queue-req: 39\n",
      "[2025-08-13 20:51:54] INFO:     127.0.0.1:38006 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:54] Prefill batch. #new-seq: 1, #new-token: 7072, #cached-token: 392, token usage: 0.94, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:51:54] INFO:     127.0.0.1:51242 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:55] Prefill batch. #new-seq: 2, #new-token: 2445, #cached-token: 525, token usage: 0.95, #running-req: 60, #queue-req: 36\n",
      "[2025-08-13 20:51:56] INFO:     127.0.0.1:51264 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:56] Prefill batch. #new-seq: 1, #new-token: 2163, #cached-token: 471, token usage: 0.96, #running-req: 61, #queue-req: 35\n",
      "[2025-08-13 20:51:56] INFO:     127.0.0.1:44852 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:56] Prefill batch. #new-seq: 1, #new-token: 323, #cached-token: 438, token usage: 0.96, #running-req: 61, #queue-req: 34\n",
      "[2025-08-13 20:51:57] INFO:     127.0.0.1:58464 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:57] INFO:     127.0.0.1:58472 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:57] INFO:     127.0.0.1:58474 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:57] Prefill batch. #new-seq: 3, #new-token: 5786, #cached-token: 911, token usage: 0.92, #running-req: 59, #queue-req: 32\n",
      "[2025-08-13 20:51:58] Decode batch. #running-req: 62, #token: 232057, token usage: 0.94, cuda graph: True, gen throughput (token/s): 566.10, #queue-req: 38\n",
      "[2025-08-13 20:51:59] INFO:     127.0.0.1:35004 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:59] INFO:     127.0.0.1:35010 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:59] INFO:     127.0.0.1:35016 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:59] INFO:     127.0.0.1:54778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:51:59] Prefill batch. #new-seq: 2, #new-token: 8172, #cached-token: 878, token usage: 0.88, #running-req: 58, #queue-req: 40\n",
      "[2025-08-13 20:51:59] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 627, token usage: 0.91, #running-req: 60, #queue-req: 39\n",
      "[2025-08-13 20:52:00] Prefill batch. #new-seq: 2, #new-token: 5889, #cached-token: 412, token usage: 0.94, #running-req: 60, #queue-req: 38\n",
      "[2025-08-13 20:52:02] INFO:     127.0.0.1:55304 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:02] Prefill batch. #new-seq: 2, #new-token: 5035, #cached-token: 839, token usage: 0.93, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 20:52:03] INFO:     127.0.0.1:54786 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:03] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 802, token usage: 0.91, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 20:52:03] Prefill batch. #new-seq: 2, #new-token: 1880, #cached-token: 436, token usage: 0.95, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 20:52:04] Decode batch. #running-req: 65, #token: 235023, token usage: 0.96, cuda graph: True, gen throughput (token/s): 401.02, #queue-req: 35\n",
      "[2025-08-13 20:52:05] INFO:     127.0.0.1:55320 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:05] Prefill batch. #new-seq: 1, #new-token: 2283, #cached-token: 125, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:52:07] Decode batch. #running-req: 65, #token: 235647, token usage: 0.96, cuda graph: True, gen throughput (token/s): 839.96, #queue-req: 35\n",
      "[2025-08-13 20:52:09] INFO:     127.0.0.1:47026 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:09] Prefill batch. #new-seq: 1, #new-token: 2281, #cached-token: 126, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:52:10] INFO:     127.0.0.1:55310 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:10] Prefill batch. #new-seq: 2, #new-token: 4476, #cached-token: 843, token usage: 0.94, #running-req: 64, #queue-req: 32\n",
      "[2025-08-13 20:52:11] Decode batch. #running-req: 66, #token: 237373, token usage: 0.97, cuda graph: True, gen throughput (token/s): 748.34, #queue-req: 32\n",
      "[2025-08-13 20:52:11] INFO:     127.0.0.1:54806 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:11] INFO:     127.0.0.1:54812 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:11] INFO:     127.0.0.1:54822 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:11] INFO:     127.0.0.1:55362 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:11] Prefill batch. #new-seq: 4, #new-token: 4853, #cached-token: 1472, token usage: 0.90, #running-req: 62, #queue-req: 30\n",
      "[2025-08-13 20:52:13] INFO:     127.0.0.1:42690 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:14] INFO:     127.0.0.1:43862 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:14] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.91, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:52:14] Prefill batch. #new-seq: 1, #new-token: 3443, #cached-token: 0, token usage: 0.94, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:52:15] INFO:     127.0.0.1:34004 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:52:15] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1012, token usage: 0.91, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:52:15] Prefill batch. #new-seq: 1, #new-token: 653, #cached-token: 0, token usage: 0.95, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:52:16] Decode batch. #running-req: 67, #token: 233459, token usage: 0.95, cuda graph: True, gen throughput (token/s): 495.07, #queue-req: 33\n",
      "[2025-08-13 20:52:17] INFO:     127.0.0.1:56572 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:17] Prefill batch. #new-seq: 1, #new-token: 7375, #cached-token: 463, token usage: 0.92, #running-req: 66, #queue-req: 33\n",
      "[2025-08-13 20:52:19] INFO:     127.0.0.1:47020 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:52:20] Decode batch. #running-req: 66, #token: 235238, token usage: 0.96, cuda graph: True, gen throughput (token/s): 747.39, #queue-req: 34\n",
      "[2025-08-13 20:52:21] INFO:     127.0.0.1:43854 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:21] Prefill batch. #new-seq: 2, #new-token: 2440, #cached-token: 532, token usage: 0.94, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:52:21] INFO:     127.0.0.1:56594 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:21] Prefill batch. #new-seq: 1, #new-token: 3437, #cached-token: 410, token usage: 0.94, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:52:22] INFO:     127.0.0.1:42662 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:22] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 159, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:52:23] INFO:     127.0.0.1:56596 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:23] Prefill batch. #new-seq: 2, #new-token: 4663, #cached-token: 505, token usage: 0.94, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:52:24] INFO:     127.0.0.1:35070 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:24] Decode batch. #running-req: 68, #token: 230204, token usage: 0.94, cuda graph: True, gen throughput (token/s): 677.13, #queue-req: 32\n",
      "[2025-08-13 20:52:24] Prefill batch. #new-seq: 2, #new-token: 4839, #cached-token: 531, token usage: 0.94, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:52:24] INFO:     127.0.0.1:43652 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:24] Prefill batch. #new-seq: 1, #new-token: 4373, #cached-token: 453, token usage: 0.94, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:52:25] INFO:     127.0.0.1:33990 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:26] INFO:     127.0.0.1:46830 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:26] Prefill batch. #new-seq: 2, #new-token: 6084, #cached-token: 1063, token usage: 0.90, #running-req: 67, #queue-req: 27\n",
      "[2025-08-13 20:52:27] INFO:     127.0.0.1:45358 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:27] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 760, token usage: 0.90, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:52:27] Prefill batch. #new-seq: 2, #new-token: 3169, #cached-token: 409, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:52:29] INFO:     127.0.0.1:58472 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:29] Decode batch. #running-req: 70, #token: 230480, token usage: 0.94, cuda graph: True, gen throughput (token/s): 519.23, #queue-req: 29\n",
      "[2025-08-13 20:52:29] INFO:     127.0.0.1:34030 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:29] INFO:     127.0.0.1:43630 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:29] Prefill batch. #new-seq: 2, #new-token: 6391, #cached-token: 918, token usage: 0.91, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:52:30] INFO:     127.0.0.1:43764 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:31] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 907, token usage: 0.93, #running-req: 69, #queue-req: 25\n",
      "[2025-08-13 20:52:31] Prefill batch. #new-seq: 1, #new-token: 542, #cached-token: 0, token usage: 0.96, #running-req: 70, #queue-req: 25\n",
      ".[2025-08-13 20:52:32] INFO:     127.0.0.1:42710 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:32] Prefill batch. #new-seq: 1, #new-token: 4380, #cached-token: 441, token usage: 0.93, #running-req: 70, #queue-req: 25\n",
      "[2025-08-13 20:52:33] INFO:     127.0.0.1:58474 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:33] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 449, token usage: 0.95, #running-req: 70, #queue-req: 24\n",
      "[2025-08-13 20:52:34] Decode batch. #running-req: 71, #token: 237848, token usage: 0.97, cuda graph: True, gen throughput (token/s): 562.06, #queue-req: 26\n",
      "[2025-08-13 20:52:35] INFO:     127.0.0.1:43830 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:36] INFO:     127.0.0.1:46836 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:37] Decode batch. #running-req: 69, #token: 229549, token usage: 0.93, cuda graph: True, gen throughput (token/s): 974.83, #queue-req: 31\n",
      "[2025-08-13 20:52:38] INFO:     127.0.0.1:52232 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:38] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 481, token usage: 0.93, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:52:38] Prefill batch. #new-seq: 1, #new-token: 1631, #cached-token: 0, token usage: 0.96, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:52:40] INFO:     127.0.0.1:54786 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:40] Prefill batch. #new-seq: 2, #new-token: 4696, #cached-token: 907, token usage: 0.93, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:52:41] INFO:     127.0.0.1:58464 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:41] Prefill batch. #new-seq: 2, #new-token: 6556, #cached-token: 527, token usage: 0.92, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:52:42] Decode batch. #running-req: 71, #token: 234057, token usage: 0.95, cuda graph: True, gen throughput (token/s): 565.69, #queue-req: 29\n",
      "[2025-08-13 20:52:42] INFO:     127.0.0.1:54822 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:42] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 449, token usage: 0.94, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:52:44] INFO:     127.0.0.1:35016 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:44] INFO:     127.0.0.1:35004 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:44] Prefill batch. #new-seq: 2, #new-token: 2500, #cached-token: 916, token usage: 0.93, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:52:44] INFO:     127.0.0.1:35010 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:44] Prefill batch. #new-seq: 3, #new-token: 4802, #cached-token: 693, token usage: 0.92, #running-req: 70, #queue-req: 24\n",
      "[2025-08-13 20:52:45] INFO:     127.0.0.1:50664 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:46] INFO:     127.0.0.1:54778 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:46] Decode batch. #running-req: 72, #token: 224701, token usage: 0.91, cuda graph: True, gen throughput (token/s): 737.30, #queue-req: 24\n",
      "[2025-08-13 20:52:46] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.91, #running-req: 71, #queue-req: 23\n",
      "[2025-08-13 20:52:46] Prefill batch. #new-seq: 1, #new-token: 1424, #cached-token: 0, token usage: 0.95, #running-req: 71, #queue-req: 23\n",
      ".[2025-08-13 20:52:50] Decode batch. #running-req: 72, #token: 237197, token usage: 0.96, cuda graph: True, gen throughput (token/s): 740.83, #queue-req: 28\n",
      "[2025-08-13 20:52:50] INFO:     127.0.0.1:42660 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:53] Decode batch. #running-req: 71, #token: 236154, token usage: 0.96, cuda graph: True, gen throughput (token/s): 989.22, #queue-req: 29\n",
      "[2025-08-13 20:52:53] INFO:     127.0.0.1:54812 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:53] INFO:     127.0.0.1:40258 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:54] INFO:     127.0.0.1:54806 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:54] Prefill batch. #new-seq: 2, #new-token: 7347, #cached-token: 821, token usage: 0.93, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:52:55] INFO:     127.0.0.1:35792 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:55] Prefill batch. #new-seq: 2, #new-token: 2791, #cached-token: 822, token usage: 0.93, #running-req: 69, #queue-req: 25\n",
      "[2025-08-13 20:52:56] Decode batch. #running-req: 71, #token: 233470, token usage: 0.95, cuda graph: True, gen throughput (token/s): 731.34, #queue-req: 25\n",
      "[2025-08-13 20:52:57] INFO:     127.0.0.1:35050 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:57] Prefill batch. #new-seq: 2, #new-token: 4440, #cached-token: 505, token usage: 0.94, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:52:58] INFO:     127.0.0.1:56596 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:52:58] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.94, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:52:59] INFO:     127.0.0.1:50702 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:00] Decode batch. #running-req: 71, #token: 233124, token usage: 0.95, cuda graph: True, gen throughput (token/s): 809.77, #queue-req: 28\n",
      "[2025-08-13 20:53:03] INFO:     127.0.0.1:43778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:03] Decode batch. #running-req: 70, #token: 234085, token usage: 0.95, cuda graph: True, gen throughput (token/s): 970.80, #queue-req: 29\n",
      "[2025-08-13 20:53:04] INFO:     127.0.0.1:45362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:04] INFO:     127.0.0.1:45368 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:04] INFO:     127.0.0.1:45384 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:04] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 627, token usage: 0.92, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:53:04] Prefill batch. #new-seq: 1, #new-token: 3592, #cached-token: 0, token usage: 0.95, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:53:06] INFO:     127.0.0.1:56572 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:06] Prefill batch. #new-seq: 1, #new-token: 2274, #cached-token: 129, token usage: 0.94, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:53:07] INFO:     127.0.0.1:56594 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:07] Prefill batch. #new-seq: 1, #new-token: 2406, #cached-token: 392, token usage: 0.94, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:53:07] Decode batch. #running-req: 68, #token: 234416, token usage: 0.95, cuda graph: True, gen throughput (token/s): 597.12, #queue-req: 31\n",
      "[2025-08-13 20:53:09] INFO:     127.0.0.1:45286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:09] Prefill batch. #new-seq: 2, #new-token: 4403, #cached-token: 206, token usage: 0.93, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:53:10] INFO:     127.0.0.1:46830 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:10] Prefill batch. #new-seq: 4, #new-token: 6683, #cached-token: 1753, token usage: 0.91, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 20:53:10] INFO:     127.0.0.1:45296 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:10] Prefill batch. #new-seq: 2, #new-token: 4523, #cached-token: 933, token usage: 0.92, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:53:12] Decode batch. #running-req: 73, #token: 232902, token usage: 0.95, cuda graph: True, gen throughput (token/s): 662.06, #queue-req: 27\n",
      "[2025-08-13 20:53:12] INFO:     127.0.0.1:35024 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:12] INFO:     127.0.0.1:46836 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:12] Prefill batch. #new-seq: 1, #new-token: 5225, #cached-token: 464, token usage: 0.93, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:53:14] INFO:     127.0.0.1:47000 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:15] INFO:     127.0.0.1:45308 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:15] Prefill batch. #new-seq: 1, #new-token: 2643, #cached-token: 96, token usage: 0.93, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:53:15] Decode batch. #running-req: 71, #token: 232147, token usage: 0.94, cuda graph: True, gen throughput (token/s): 795.22, #queue-req: 27\n",
      "[2025-08-13 20:53:17] INFO:     127.0.0.1:37974 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:17] INFO:     127.0.0.1:37988 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:17] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1507, token usage: 0.90, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:53:18] Prefill batch. #new-seq: 2, #new-token: 3759, #cached-token: 412, token usage: 0.93, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:53:19] INFO:     127.0.0.1:37994 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:19] Prefill batch. #new-seq: 2, #new-token: 2245, #cached-token: 888, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:53:19] Decode batch. #running-req: 75, #token: 230834, token usage: 0.94, cuda graph: True, gen throughput (token/s): 686.15, #queue-req: 25\n",
      "[2025-08-13 20:53:21] INFO:     127.0.0.1:44878 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:21] Prefill batch. #new-seq: 1, #new-token: 2172, #cached-token: 460, token usage: 0.93, #running-req: 74, #queue-req: 25\n",
      "[2025-08-13 20:53:23] Decode batch. #running-req: 75, #token: 231647, token usage: 0.94, cuda graph: True, gen throughput (token/s): 955.28, #queue-req: 25\n",
      "[2025-08-13 20:53:25] INFO:     127.0.0.1:42054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:25] Prefill batch. #new-seq: 1, #new-token: 4842, #cached-token: 481, token usage: 0.93, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:53:26] Decode batch. #running-req: 75, #token: 234354, token usage: 0.95, cuda graph: True, gen throughput (token/s): 888.80, #queue-req: 25\n",
      "[2025-08-13 20:53:29] Decode batch. #running-req: 75, #token: 237354, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1001.12, #queue-req: 25\n",
      "[2025-08-13 20:53:29] INFO:     127.0.0.1:50648 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:30] INFO:     127.0.0.1:50666 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:30] INFO:     127.0.0.1:50682 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:30] Prefill batch. #new-seq: 1, #new-token: 2794, #cached-token: 480, token usage: 0.94, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 20:53:31] INFO:     127.0.0.1:42654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:31] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 176, token usage: 0.95, #running-req: 72, #queue-req: 27\n",
      "[2025-08-13 20:53:32] Decode batch. #running-req: 73, #token: 234605, token usage: 0.95, cuda graph: True, gen throughput (token/s): 902.88, #queue-req: 27\n",
      "[2025-08-13 20:53:32] INFO:     127.0.0.1:42678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:32] Prefill batch. #new-seq: 3, #new-token: 4737, #cached-token: 1364, token usage: 0.91, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:53:33] INFO:     127.0.0.1:46362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:34] Prefill batch. #new-seq: 1, #new-token: 2152, #cached-token: 138, token usage: 0.93, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:53:36] Decode batch. #running-req: 75, #token: 234019, token usage: 0.95, cuda graph: True, gen throughput (token/s): 862.88, #queue-req: 25\n",
      "[2025-08-13 20:53:37] INFO:     127.0.0.1:52682 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:37] Prefill batch. #new-seq: 3, #new-token: 4963, #cached-token: 998, token usage: 0.91, #running-req: 74, #queue-req: 22\n",
      "[2025-08-13 20:53:38] INFO:     127.0.0.1:46342 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:38] Prefill batch. #new-seq: 1, #new-token: 4373, #cached-token: 448, token usage: 0.93, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:53:39] INFO:     127.0.0.1:48242 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:39] Prefill batch. #new-seq: 1, #new-token: 2308, #cached-token: 438, token usage: 0.94, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:53:40] Decode batch. #running-req: 77, #token: 234445, token usage: 0.95, cuda graph: True, gen throughput (token/s): 782.04, #queue-req: 21\n",
      "[2025-08-13 20:53:40] INFO:     127.0.0.1:45384 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:40] Prefill batch. #new-seq: 1, #new-token: 7374, #cached-token: 465, token usage: 0.92, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:53:40] INFO:     127.0.0.1:46978 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:43] INFO:     127.0.0.1:46996 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:43] Prefill batch. #new-seq: 1, #new-token: 2578, #cached-token: 409, token usage: 0.94, #running-req: 75, #queue-req: 24\n",
      "[2025-08-13 20:53:43] Decode batch. #running-req: 76, #token: 234609, token usage: 0.95, cuda graph: True, gen throughput (token/s): 808.39, #queue-req: 24\n",
      "[2025-08-13 20:53:45] INFO:     127.0.0.1:47010 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:46] Decode batch. #running-req: 75, #token: 231822, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1058.98, #queue-req: 25\n",
      "[2025-08-13 20:53:46] INFO:     127.0.0.1:55026 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:47] Prefill batch. #new-seq: 1, #new-token: 5810, #cached-token: 413, token usage: 0.93, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:53:48] INFO:     127.0.0.1:45286 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:48] Prefill batch. #new-seq: 1, #new-token: 2315, #cached-token: 438, token usage: 0.94, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:53:49] INFO:     127.0.0.1:45368 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:49] Prefill batch. #new-seq: 1, #new-token: 4303, #cached-token: 449, token usage: 0.94, #running-req: 74, #queue-req: 23\n",
      ".[2025-08-13 20:53:50] Decode batch. #running-req: 75, #token: 235417, token usage: 0.96, cuda graph: True, gen throughput (token/s): 739.62, #queue-req: 23\n",
      "[2025-08-13 20:53:50] INFO:     127.0.0.1:60738 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:50] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 450, token usage: 0.94, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:53:51] INFO:     127.0.0.1:45362 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:51] Prefill batch. #new-seq: 1, #new-token: 1315, #cached-token: 77, token usage: 0.94, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 20:53:53] Decode batch. #running-req: 75, #token: 234517, token usage: 0.95, cuda graph: True, gen throughput (token/s): 930.03, #queue-req: 25\n",
      "[2025-08-13 20:53:56] Decode batch. #running-req: 75, #token: 237517, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1029.98, #queue-req: 25\n",
      "[2025-08-13 20:53:57] INFO:     127.0.0.1:35784 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:58] INFO:     127.0.0.1:48236 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:58] Prefill batch. #new-seq: 1, #new-token: 4759, #cached-token: 409, token usage: 0.94, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:53:59] INFO:     127.0.0.1:45296 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:53:59] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 452, token usage: 0.95, #running-req: 73, #queue-req: 25\n",
      ".[2025-08-13 20:54:00] Decode batch. #running-req: 74, #token: 234783, token usage: 0.95, cuda graph: True, gen throughput (token/s): 881.66, #queue-req: 25\n",
      "[2025-08-13 20:54:02] INFO:     127.0.0.1:52666 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:02] Prefill batch. #new-seq: 1, #new-token: 4368, #cached-token: 453, token usage: 0.95, #running-req: 73, #queue-req: 26\n",
      "[2025-08-13 20:54:03] INFO:     127.0.0.1:45308 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:03] Decode batch. #running-req: 74, #token: 233054, token usage: 0.95, cuda graph: True, gen throughput (token/s): 893.76, #queue-req: 26\n",
      "[2025-08-13 20:54:06] Decode batch. #running-req: 73, #token: 235974, token usage: 0.96, cuda graph: True, gen throughput (token/s): 998.14, #queue-req: 27\n",
      "[2025-08-13 20:54:06] INFO:     127.0.0.1:50700 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:07] INFO:     127.0.0.1:48246 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:09] Decode batch. #running-req: 71, #token: 234665, token usage: 0.95, cuda graph: True, gen throughput (token/s): 997.88, #queue-req: 29\n",
      "[2025-08-13 20:54:10] INFO:     127.0.0.1:46392 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:10] INFO:     127.0.0.1:60694 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:11] INFO:     127.0.0.1:35032 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:11] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.92, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:54:11] Prefill batch. #new-seq: 1, #new-token: 1521, #cached-token: 0, token usage: 0.96, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:54:13] Decode batch. #running-req: 69, #token: 237570, token usage: 0.97, cuda graph: True, gen throughput (token/s): 723.87, #queue-req: 28\n",
      "[2025-08-13 20:54:13] INFO:     127.0.0.1:37988 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:13] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 449, token usage: 0.95, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:54:14] INFO:     127.0.0.1:37974 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:14] Prefill batch. #new-seq: 1, #new-token: 4378, #cached-token: 443, token usage: 0.93, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:54:16] Decode batch. #running-req: 69, #token: 234853, token usage: 0.96, cuda graph: True, gen throughput (token/s): 754.60, #queue-req: 31\n",
      "[2025-08-13 20:54:16] INFO:     127.0.0.1:35250 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:54:19] INFO:     127.0.0.1:52698 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:19] Prefill batch. #new-seq: 1, #new-token: 6580, #cached-token: 466, token usage: 0.93, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:54:20] Decode batch. #running-req: 68, #token: 236332, token usage: 0.96, cuda graph: True, gen throughput (token/s): 790.18, #queue-req: 32\n",
      "[2025-08-13 20:54:21] INFO:     127.0.0.1:50684 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:21] Prefill batch. #new-seq: 1, #new-token: 2290, #cached-token: 122, token usage: 0.96, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:54:23] Decode batch. #running-req: 68, #token: 239917, token usage: 0.98, cuda graph: True, gen throughput (token/s): 883.28, #queue-req: 32\n",
      "[2025-08-13 20:54:24] INFO:     127.0.0.1:37994 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:24] Prefill batch. #new-seq: 1, #new-token: 2133, #cached-token: 159, token usage: 0.96, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:54:24] INFO:     127.0.0.1:44878 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:24] Prefill batch. #new-seq: 2, #new-token: 4225, #cached-token: 630, token usage: 0.95, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:54:26] INFO:     127.0.0.1:52706 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:26] INFO:     127.0.0.1:52722 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:26] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.92, #running-req: 67, #queue-req: 28\n",
      "[2025-08-13 20:54:26] Prefill batch. #new-seq: 2, #new-token: 2036, #cached-token: 437, token usage: 0.96, #running-req: 67, #queue-req: 27\n",
      "[2025-08-13 20:54:27] INFO:     127.0.0.1:48620 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:27] Decode batch. #running-req: 68, #token: 235920, token usage: 0.96, cuda graph: True, gen throughput (token/s): 612.04, #queue-req: 31\n",
      "[2025-08-13 20:54:27] INFO:     127.0.0.1:52726 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:28] INFO:     127.0.0.1:42678 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:28] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.89, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:54:28] Prefill batch. #new-seq: 3, #new-token: 4008, #cached-token: 611, token usage: 0.93, #running-req: 66, #queue-req: 29\n",
      ".[2025-08-13 20:54:31] INFO:     127.0.0.1:42654 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:31] Prefill batch. #new-seq: 1, #new-token: 4367, #cached-token: 454, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:54:32] Decode batch. #running-req: 69, #token: 236556, token usage: 0.96, cuda graph: True, gen throughput (token/s): 624.31, #queue-req: 30\n",
      "[2025-08-13 20:54:34] INFO:     127.0.0.1:50648 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:54:35] Decode batch. #running-req: 68, #token: 236888, token usage: 0.96, cuda graph: True, gen throughput (token/s): 959.14, #queue-req: 31\n",
      "[2025-08-13 20:54:36] INFO:     127.0.0.1:50666 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:36] INFO:     127.0.0.1:50682 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:37] Prefill batch. #new-seq: 1, #new-token: 3013, #cached-token: 465, token usage: 0.95, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:54:37] INFO:     127.0.0.1:48670 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:37] Prefill batch. #new-seq: 1, #new-token: 4119, #cached-token: 93, token usage: 0.95, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:54:38] Decode batch. #running-req: 67, #token: 238494, token usage: 0.97, cuda graph: True, gen throughput (token/s): 789.46, #queue-req: 30\n",
      "[2025-08-13 20:54:38] INFO:     127.0.0.1:46996 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:38] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 436, token usage: 0.95, #running-req: 66, #queue-req: 29\n",
      "[2025-08-13 20:54:41] Decode batch. #running-req: 67, #token: 237263, token usage: 0.97, cuda graph: True, gen throughput (token/s): 935.30, #queue-req: 33\n",
      "[2025-08-13 20:54:41] INFO:     127.0.0.1:46978 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:41] Prefill batch. #new-seq: 2, #new-token: 2739, #cached-token: 580, token usage: 0.95, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:54:42] INFO:     127.0.0.1:48702 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:42] INFO:     127.0.0.1:60562 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:42] Prefill batch. #new-seq: 3, #new-token: 4001, #cached-token: 999, token usage: 0.91, #running-req: 66, #queue-req: 29\n",
      ".[2025-08-13 20:54:44] Decode batch. #running-req: 69, #token: 230578, token usage: 0.94, cuda graph: True, gen throughput (token/s): 793.41, #queue-req: 31\n",
      "[2025-08-13 20:54:45] INFO:     127.0.0.1:35062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:45] Prefill batch. #new-seq: 1, #new-token: 7897, #cached-token: 393, token usage: 0.93, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:54:47] INFO:     127.0.0.1:55018 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:48] Decode batch. #running-req: 68, #token: 234893, token usage: 0.96, cuda graph: True, gen throughput (token/s): 752.58, #queue-req: 32\n",
      "[2025-08-13 20:54:50] INFO:     127.0.0.1:60536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:51] Decode batch. #running-req: 67, #token: 230096, token usage: 0.94, cuda graph: True, gen throughput (token/s): 947.02, #queue-req: 32\n",
      "[2025-08-13 20:54:51] INFO:     127.0.0.1:55040 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:51] Prefill batch. #new-seq: 2, #new-token: 5330, #cached-token: 242, token usage: 0.94, #running-req: 66, #queue-req: 30\n",
      "[2025-08-13 20:54:52] INFO:     127.0.0.1:48256 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:52] Prefill batch. #new-seq: 1, #new-token: 4261, #cached-token: 446, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:54:54] INFO:     127.0.0.1:47162 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:54] Prefill batch. #new-seq: 1, #new-token: 2784, #cached-token: 409, token usage: 0.96, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:54:55] Decode batch. #running-req: 68, #token: 238428, token usage: 0.97, cuda graph: True, gen throughput (token/s): 689.42, #queue-req: 31\n",
      "[2025-08-13 20:54:56] INFO:     127.0.0.1:42096 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:54:56] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 437, token usage: 0.96, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:54:58] Decode batch. #running-req: 68, #token: 237316, token usage: 0.97, cuda graph: True, gen throughput (token/s): 907.24, #queue-req: 32\n",
      "[2025-08-13 20:54:58] INFO:     127.0.0.1:55042 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:58] INFO:     127.0.0.1:35014 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:54:58] Prefill batch. #new-seq: 3, #new-token: 7033, #cached-token: 1367, token usage: 0.91, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:54:59] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 449, token usage: 0.94, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:55:00] INFO:     127.0.0.1:35036 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:00] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 466, token usage: 0.95, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:55:01] INFO:     127.0.0.1:35048 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:02] Decode batch. #running-req: 69, #token: 230729, token usage: 0.94, cuda graph: True, gen throughput (token/s): 722.41, #queue-req: 31\n",
      "[2025-08-13 20:55:02] INFO:     127.0.0.1:43500 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:02] INFO:     127.0.0.1:48218 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:02] Prefill batch. #new-seq: 2, #new-token: 7930, #cached-token: 574, token usage: 0.92, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:55:03] INFO:     127.0.0.1:52666 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:55:03] Prefill batch. #new-seq: 2, #new-token: 4485, #cached-token: 568, token usage: 0.94, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:55:05] INFO:     127.0.0.1:42048 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:05] Prefill batch. #new-seq: 1, #new-token: 5040, #cached-token: 412, token usage: 0.95, #running-req: 69, #queue-req: 30\n",
      "[2025-08-13 20:55:06] INFO:     127.0.0.1:42066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:06] INFO:     127.0.0.1:42082 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:06] Prefill batch. #new-seq: 1, #new-token: 7550, #cached-token: 410, token usage: 0.93, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:55:07] Decode batch. #running-req: 69, #token: 237146, token usage: 0.96, cuda graph: True, gen throughput (token/s): 527.14, #queue-req: 31\n",
      "[2025-08-13 20:55:07] INFO:     127.0.0.1:52722 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:09] INFO:     127.0.0.1:48254 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:09] Prefill batch. #new-seq: 1, #new-token: 5935, #cached-token: 481, token usage: 0.94, #running-req: 67, #queue-req: 32\n",
      "[2025-08-13 20:55:10] INFO:     127.0.0.1:52706 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:10] Prefill batch. #new-seq: 1, #new-token: 2163, #cached-token: 470, token usage: 0.93, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:55:11] Decode batch. #running-req: 68, #token: 231789, token usage: 0.94, cuda graph: True, gen throughput (token/s): 754.40, #queue-req: 31\n",
      "[2025-08-13 20:55:12] INFO:     127.0.0.1:60590 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:12] Prefill batch. #new-seq: 2, #new-token: 8016, #cached-token: 239, token usage: 0.93, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:55:13] INFO:     127.0.0.1:60592 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:13] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 412, token usage: 0.96, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:55:14] Decode batch. #running-req: 69, #token: 236162, token usage: 0.96, cuda graph: True, gen throughput (token/s): 763.76, #queue-req: 31\n",
      "[2025-08-13 20:55:14] INFO:     127.0.0.1:40248 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:14] INFO:     127.0.0.1:40250 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:14] Prefill batch. #new-seq: 3, #new-token: 2540, #cached-token: 878, token usage: 0.94, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:55:16] INFO:     127.0.0.1:52698 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:16] Prefill batch. #new-seq: 2, #new-token: 5305, #cached-token: 486, token usage: 0.93, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:55:18] Decode batch. #running-req: 71, #token: 235771, token usage: 0.96, cuda graph: True, gen throughput (token/s): 796.36, #queue-req: 29\n",
      "[2025-08-13 20:55:18] INFO:     127.0.0.1:35258 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:18] Prefill batch. #new-seq: 3, #new-token: 4372, #cached-token: 1041, token usage: 0.92, #running-req: 70, #queue-req: 27\n",
      "[2025-08-13 20:55:20] INFO:     127.0.0.1:60708 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:20] INFO:     127.0.0.1:52726 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:20] Prefill batch. #new-seq: 2, #new-token: 7798, #cached-token: 665, token usage: 0.92, #running-req: 71, #queue-req: 25\n",
      ".[2025-08-13 20:55:22] Decode batch. #running-req: 73, #token: 233371, token usage: 0.95, cuda graph: True, gen throughput (token/s): 729.79, #queue-req: 26\n",
      "[2025-08-13 20:55:22] INFO:     127.0.0.1:50668 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:22] INFO:     127.0.0.1:50694 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:22] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 916, token usage: 0.91, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:55:22] Prefill batch. #new-seq: 3, #new-token: 761, #cached-token: 874, token usage: 0.95, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:55:24] INFO:     127.0.0.1:50696 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:25] Decode batch. #running-req: 74, #token: 233387, token usage: 0.95, cuda graph: True, gen throughput (token/s): 802.08, #queue-req: 26\n",
      "[2025-08-13 20:55:26] INFO:     127.0.0.1:55018 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:26] Prefill batch. #new-seq: 1, #new-token: 5302, #cached-token: 480, token usage: 0.93, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:55:27] INFO:     127.0.0.1:49898 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:27] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 96, token usage: 0.95, #running-req: 73, #queue-req: 26\n",
      "[2025-08-13 20:55:28] INFO:     127.0.0.1:37786 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:55:29] INFO:     127.0.0.1:38636 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:29] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 409, token usage: 0.92, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:55:29] Decode batch. #running-req: 72, #token: 235190, token usage: 0.96, cuda graph: True, gen throughput (token/s): 855.58, #queue-req: 26\n",
      "[2025-08-13 20:55:29] Prefill batch. #new-seq: 1, #new-token: 883, #cached-token: 0, token usage: 0.96, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:55:30] INFO:     127.0.0.1:49914 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:30] INFO:     127.0.0.1:49924 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:30] Prefill batch. #new-seq: 2, #new-token: 6716, #cached-token: 885, token usage: 0.92, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:55:31] INFO:     127.0.0.1:55042 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:31] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 937, token usage: 0.91, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:55:31] Prefill batch. #new-seq: 2, #new-token: 1302, #cached-token: 159, token usage: 0.95, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:55:34] Decode batch. #running-req: 75, #token: 235854, token usage: 0.96, cuda graph: True, gen throughput (token/s): 566.64, #queue-req: 25\n",
      "[2025-08-13 20:55:35] INFO:     127.0.0.1:55040 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:35] Prefill batch. #new-seq: 2, #new-token: 2754, #cached-token: 576, token usage: 0.95, #running-req: 74, #queue-req: 23\n",
      ".[2025-08-13 20:55:37] Decode batch. #running-req: 76, #token: 237133, token usage: 0.96, cuda graph: True, gen throughput (token/s): 951.64, #queue-req: 24\n",
      "[2025-08-13 20:55:39] INFO:     127.0.0.1:49926 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:39] INFO:     127.0.0.1:49940 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:39] Prefill batch. #new-seq: 1, #new-token: 2428, #cached-token: 436, token usage: 0.94, #running-req: 74, #queue-req: 25\n",
      "[2025-08-13 20:55:40] INFO:     127.0.0.1:48218 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:40] Prefill batch. #new-seq: 1, #new-token: 7369, #cached-token: 463, token usage: 0.93, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:55:41] Decode batch. #running-req: 75, #token: 236974, token usage: 0.96, cuda graph: True, gen throughput (token/s): 786.82, #queue-req: 25\n",
      "[2025-08-13 20:55:42] INFO:     127.0.0.1:35014 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:42] INFO:     127.0.0.1:35036 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:42] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 450, token usage: 0.94, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:55:43] INFO:     127.0.0.1:35048 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:43] Prefill batch. #new-seq: 1, #new-token: 3543, #cached-token: 467, token usage: 0.93, #running-req: 73, #queue-req: 23\n",
      ".[2025-08-13 20:55:43] INFO:     127.0.0.1:48666 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:43] INFO:     127.0.0.1:48680 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:43] INFO:     127.0.0.1:48690 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:43] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 606, token usage: 0.91, #running-req: 71, #queue-req: 21\n",
      "[2025-08-13 20:55:43] Prefill batch. #new-seq: 2, #new-token: 5887, #cached-token: 469, token usage: 0.94, #running-req: 72, #queue-req: 20\n",
      "[2025-08-13 20:55:46] Decode batch. #running-req: 74, #token: 227260, token usage: 0.92, cuda graph: True, gen throughput (token/s): 631.88, #queue-req: 26\n",
      "[2025-08-13 20:55:46] INFO:     127.0.0.1:34004 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:46] Prefill batch. #new-seq: 2, #new-token: 6584, #cached-token: 906, token usage: 0.92, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:55:48] INFO:     127.0.0.1:42048 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:48] Prefill batch. #new-seq: 1, #new-token: 3040, #cached-token: 553, token usage: 0.95, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:55:49] Decode batch. #running-req: 75, #token: 236999, token usage: 0.96, cuda graph: True, gen throughput (token/s): 796.32, #queue-req: 25\n",
      "[2025-08-13 20:55:50] INFO:     127.0.0.1:35696 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:52] INFO:     127.0.0.1:42082 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:52] INFO:     127.0.0.1:42066 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:52] Decode batch. #running-req: 73, #token: 229598, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1001.65, #queue-req: 26\n",
      "[2025-08-13 20:55:52] INFO:     127.0.0.1:48594 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:53] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.91, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:55:53] Prefill batch. #new-seq: 3, #new-token: 1400, #cached-token: 655, token usage: 0.94, #running-req: 71, #queue-req: 23\n",
      ".[2025-08-13 20:55:54] INFO:     127.0.0.1:54320 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:54] Prefill batch. #new-seq: 1, #new-token: 4381, #cached-token: 441, token usage: 0.95, #running-req: 73, #queue-req: 22\n",
      "[2025-08-13 20:55:55] INFO:     127.0.0.1:35258 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:55] Prefill batch. #new-seq: 2, #new-token: 7571, #cached-token: 586, token usage: 0.93, #running-req: 73, #queue-req: 21\n",
      "[2025-08-13 20:55:56] INFO:     127.0.0.1:46350 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:56] INFO:     127.0.0.1:48254 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:57] Prefill batch. #new-seq: 2, #new-token: 4685, #cached-token: 883, token usage: 0.94, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:55:57] INFO:     127.0.0.1:60590 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:57] INFO:     127.0.0.1:60592 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:57] INFO:     127.0.0.1:40250 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:57] Prefill batch. #new-seq: 3, #new-token: 4261, #cached-token: 1298, token usage: 0.93, #running-req: 73, #queue-req: 21\n",
      "[2025-08-13 20:55:58] Decode batch. #running-req: 75, #token: 232386, token usage: 0.95, cuda graph: True, gen throughput (token/s): 521.64, #queue-req: 21\n",
      "[2025-08-13 20:55:59] INFO:     127.0.0.1:40248 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:55:59] Prefill batch. #new-seq: 1, #new-token: 7955, #cached-token: 481, token usage: 0.93, #running-req: 74, #queue-req: 20\n",
      "[2025-08-13 20:56:00] INFO:     127.0.0.1:46378 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:01] INFO:     127.0.0.1:50694 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:02] Decode batch. #running-req: 73, #token: 228943, token usage: 0.93, cuda graph: True, gen throughput (token/s): 820.72, #queue-req: 26\n",
      "[2025-08-13 20:56:05] Decode batch. #running-req: 73, #token: 231863, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1024.64, #queue-req: 27\n",
      "[2025-08-13 20:56:06] INFO:     127.0.0.1:50668 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:06] INFO:     127.0.0.1:46382 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:06] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 409, token usage: 0.91, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:56:06] Prefill batch. #new-seq: 2, #new-token: 933, #cached-token: 483, token usage: 0.95, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:56:07] INFO:     127.0.0.1:50696 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:07] Prefill batch. #new-seq: 1, #new-token: 4368, #cached-token: 454, token usage: 0.94, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:56:09] INFO:     127.0.0.1:49898 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:09] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1305, token usage: 0.92, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:56:09] INFO:     127.0.0.1:49914 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:09] Prefill batch. #new-seq: 2, #new-token: 3007, #cached-token: 120, token usage: 0.95, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 20:56:10] Decode batch. #running-req: 75, #token: 235330, token usage: 0.96, cuda graph: True, gen throughput (token/s): 565.71, #queue-req: 23\n",
      "[2025-08-13 20:56:10] INFO:     127.0.0.1:49924 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:12] INFO:     127.0.0.1:48264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:12] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 450, token usage: 0.94, #running-req: 73, #queue-req: 26\n",
      "[2025-08-13 20:56:12] INFO:     127.0.0.1:48266 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:13] Decode batch. #running-req: 73, #token: 236014, token usage: 0.96, cuda graph: True, gen throughput (token/s): 870.34, #queue-req: 27\n",
      "[2025-08-13 20:56:13] INFO:     127.0.0.1:48278 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:13] Prefill batch. #new-seq: 2, #new-token: 2167, #cached-token: 969, token usage: 0.93, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:56:14] INFO:     127.0.0.1:39004 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:14] Prefill batch. #new-seq: 1, #new-token: 2420, #cached-token: 438, token usage: 0.94, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 20:56:16] INFO:     127.0.0.1:47136 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:16] Decode batch. #running-req: 73, #token: 231096, token usage: 0.94, cuda graph: True, gen throughput (token/s): 880.75, #queue-req: 27\n",
      "[2025-08-13 20:56:17] INFO:     127.0.0.1:48690 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:18] INFO:     127.0.0.1:40734 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:19] INFO:     127.0.0.1:47146 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:19] INFO:     127.0.0.1:47166 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:19] INFO:     127.0.0.1:47170 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:19] INFO:     127.0.0.1:47180 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:19] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.86, #running-req: 67, #queue-req: 27\n",
      "[2025-08-13 20:56:19] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 995, token usage: 0.90, #running-req: 67, #queue-req: 24\n",
      "[2025-08-13 20:56:20] Prefill batch. #new-seq: 1, #new-token: 3430, #cached-token: 0, token usage: 0.93, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:56:21] INFO:     127.0.0.1:49940 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:21] Prefill batch. #new-seq: 1, #new-token: 7534, #cached-token: 465, token usage: 0.93, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:56:22] Decode batch. #running-req: 71, #token: 233766, token usage: 0.95, cuda graph: True, gen throughput (token/s): 520.49, #queue-req: 29\n",
      "[2025-08-13 20:56:22] INFO:     127.0.0.1:48666 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:22] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 96, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:56:22] INFO:     127.0.0.1:34004 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:22] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1380, token usage: 0.90, #running-req: 70, #queue-req: 25\n",
      "[2025-08-13 20:56:22] Prefill batch. #new-seq: 2, #new-token: 4259, #cached-token: 446, token usage: 0.94, #running-req: 72, #queue-req: 24\n",
      "[2025-08-13 20:56:24] INFO:     127.0.0.1:49926 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:24] Prefill batch. #new-seq: 1, #new-token: 4374, #cached-token: 448, token usage: 0.94, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 20:56:25] INFO:     127.0.0.1:53296 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:25] INFO:     127.0.0.1:60722 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:26] Prefill batch. #new-seq: 1, #new-token: 2224, #cached-token: 409, token usage: 0.94, #running-req: 72, #queue-req: 23\n",
      "[2025-08-13 20:56:26] INFO:     127.0.0.1:54308 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:26] INFO:     127.0.0.1:48680 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:26] Prefill batch. #new-seq: 2, #new-token: 623, #cached-token: 531, token usage: 0.93, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:56:27] Decode batch. #running-req: 73, #token: 229322, token usage: 0.93, cuda graph: True, gen throughput (token/s): 612.09, #queue-req: 25\n",
      "[2025-08-13 20:56:29] INFO:     127.0.0.1:40720 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:30] Decode batch. #running-req: 72, #token: 231263, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1004.39, #queue-req: 27\n",
      "[2025-08-13 20:56:30] INFO:     127.0.0.1:54814 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:32] Decode batch. #running-req: 71, #token: 233104, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1037.04, #queue-req: 29\n",
      "[2025-08-13 20:56:33] INFO:     127.0.0.1:46350 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:33] INFO:     127.0.0.1:60752 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:33] Prefill batch. #new-seq: 2, #new-token: 5948, #cached-token: 904, token usage: 0.92, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:56:34] INFO:     127.0.0.1:46378 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:56:34] Prefill batch. #new-seq: 1, #new-token: 4284, #cached-token: 138, token usage: 0.93, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:56:35] INFO:     127.0.0.1:40716 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:35] INFO:     127.0.0.1:60764 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:35] Prefill batch. #new-seq: 1, #new-token: 4995, #cached-token: 624, token usage: 0.94, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:56:37] Decode batch. #running-req: 70, #token: 236149, token usage: 0.96, cuda graph: True, gen throughput (token/s): 659.49, #queue-req: 30\n",
      "[2025-08-13 20:56:37] INFO:     127.0.0.1:60766 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:37] INFO:     127.0.0.1:60772 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:37] Prefill batch. #new-seq: 1, #new-token: 2220, #cached-token: 96, token usage: 0.94, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:56:38] INFO:     127.0.0.1:60538 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:38] Prefill batch. #new-seq: 1, #new-token: 3128, #cached-token: 465, token usage: 0.93, #running-req: 68, #queue-req: 31\n",
      "[2025-08-13 20:56:40] Decode batch. #running-req: 69, #token: 233564, token usage: 0.95, cuda graph: True, gen throughput (token/s): 827.72, #queue-req: 31\n",
      "[2025-08-13 20:56:41] INFO:     127.0.0.1:60542 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:41] INFO:     127.0.0.1:60556 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:41] Prefill batch. #new-seq: 2, #new-token: 4516, #cached-token: 917, token usage: 0.93, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:56:43] Decode batch. #running-req: 69, #token: 234283, token usage: 0.95, cuda graph: True, gen throughput (token/s): 854.54, #queue-req: 31\n",
      "[2025-08-13 20:56:44] INFO:     127.0.0.1:37750 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:44] Prefill batch. #new-seq: 2, #new-token: 6672, #cached-token: 858, token usage: 0.91, #running-req: 68, #queue-req: 29\n",
      ".[2025-08-13 20:56:46] INFO:     127.0.0.1:46382 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:46] Prefill batch. #new-seq: 2, #new-token: 7439, #cached-token: 935, token usage: 0.92, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:56:46] INFO:     127.0.0.1:56504 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:47] INFO:     127.0.0.1:48590 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:47] Prefill batch. #new-seq: 2, #new-token: 5007, #cached-token: 242, token usage: 0.93, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:56:48] Decode batch. #running-req: 71, #token: 235091, token usage: 0.96, cuda graph: True, gen throughput (token/s): 604.05, #queue-req: 27\n",
      "[2025-08-13 20:56:51] Decode batch. #running-req: 71, #token: 237931, token usage: 0.97, cuda graph: True, gen throughput (token/s): 982.36, #queue-req: 29\n",
      "[2025-08-13 20:56:54] Decode batch. #running-req: 71, #token: 240771, token usage: 0.98, cuda graph: True, gen throughput (token/s): 973.85, #queue-req: 29\n",
      "[2025-08-13 20:56:54] INFO:     127.0.0.1:48606 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:54] Prefill batch. #new-seq: 1, #new-token: 4186, #cached-token: 467, token usage: 0.94, #running-req: 70, #queue-req: 29\n",
      "[2025-08-13 20:56:54] INFO:     127.0.0.1:47136 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:56] INFO:     127.0.0.1:54272 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:56] INFO:     127.0.0.1:48264 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:56] INFO:     127.0.0.1:48266 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:56] Prefill batch. #new-seq: 1, #new-token: 4376, #cached-token: 446, token usage: 0.94, #running-req: 67, #queue-req: 29\n",
      "[2025-08-13 20:56:57] INFO:     127.0.0.1:48278 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:57] Prefill batch. #new-seq: 2, #new-token: 7159, #cached-token: 485, token usage: 0.93, #running-req: 67, #queue-req: 27\n",
      "[2025-08-13 20:56:58] INFO:     127.0.0.1:39018 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:58] Prefill batch. #new-seq: 3, #new-token: 4774, #cached-token: 1300, token usage: 0.92, #running-req: 68, #queue-req: 24\n",
      "[2025-08-13 20:56:58] Decode batch. #running-req: 68, #token: 231525, token usage: 0.94, cuda graph: True, gen throughput (token/s): 618.50, #queue-req: 24\n",
      "[2025-08-13 20:56:59] INFO:     127.0.0.1:47166 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:56:59] INFO:     127.0.0.1:47180 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:01] INFO:     127.0.0.1:43054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:01] Decode batch. #running-req: 69, #token: 223563, token usage: 0.91, cuda graph: True, gen throughput (token/s): 869.92, #queue-req: 25\n",
      "[2025-08-13 20:57:01] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.91, #running-req: 68, #queue-req: 24\n",
      "[2025-08-13 20:57:01] Prefill batch. #new-seq: 1, #new-token: 3492, #cached-token: 0, token usage: 0.94, #running-req: 68, #queue-req: 24\n",
      "[2025-08-13 20:57:03] INFO:     127.0.0.1:54338 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:05] INFO:     127.0.0.1:52476 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:05] INFO:     127.0.0.1:48626 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:05] Prefill batch. #new-seq: 1, #new-token: 4186, #cached-token: 466, token usage: 0.95, #running-req: 66, #queue-req: 25\n",
      "[2025-08-13 20:57:06] Decode batch. #running-req: 67, #token: 238011, token usage: 0.97, cuda graph: True, gen throughput (token/s): 600.12, #queue-req: 28\n",
      "[2025-08-13 20:57:07] INFO:     127.0.0.1:47170 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:07] INFO:     127.0.0.1:54330 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:08] INFO:     127.0.0.1:47146 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:09] INFO:     127.0.0.1:52486 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:09] Decode batch. #running-req: 64, #token: 228109, token usage: 0.93, cuda graph: True, gen throughput (token/s): 923.17, #queue-req: 33\n",
      "[2025-08-13 20:57:09] Prefill batch. #new-seq: 1, #new-token: 7818, #cached-token: 625, token usage: 0.93, #running-req: 63, #queue-req: 32\n",
      ".[2025-08-13 20:57:12] INFO:     127.0.0.1:35688 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:12] Prefill batch. #new-seq: 3, #new-token: 3719, #cached-token: 685, token usage: 0.93, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 20:57:12] INFO:     127.0.0.1:43518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:12] Prefill batch. #new-seq: 2, #new-token: 733, #cached-token: 170, token usage: 0.94, #running-req: 65, #queue-req: 31\n",
      "[2025-08-13 20:57:13] Decode batch. #running-req: 67, #token: 232883, token usage: 0.95, cuda graph: True, gen throughput (token/s): 659.17, #queue-req: 31\n",
      "[2025-08-13 20:57:14] INFO:     127.0.0.1:40058 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:14] Prefill batch. #new-seq: 3, #new-token: 7546, #cached-token: 905, token usage: 0.92, #running-req: 66, #queue-req: 30\n",
      ".[2025-08-13 20:57:16] INFO:     127.0.0.1:60752 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:16] Prefill batch. #new-seq: 3, #new-token: 4598, #cached-token: 730, token usage: 0.93, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:57:16] INFO:     127.0.0.1:60772 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:16] Prefill batch. #new-seq: 1, #new-token: 4185, #cached-token: 466, token usage: 0.94, #running-req: 70, #queue-req: 27\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:57:17] Decode batch. #running-req: 71, #token: 236145, token usage: 0.96, cuda graph: True, gen throughput (token/s): 637.47, #queue-req: 29\n",
      "[2025-08-13 20:57:17] INFO:     127.0.0.1:60722 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:17] Prefill batch. #new-seq: 1, #new-token: 4167, #cached-token: 143, token usage: 0.94, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:57:18] INFO:     127.0.0.1:60766 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:18] Prefill batch. #new-seq: 1, #new-token: 4349, #cached-token: 472, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:57:20] INFO:     127.0.0.1:60542 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:20] Prefill batch. #new-seq: 1, #new-token: 2246, #cached-token: 119, token usage: 0.95, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 20:57:21] Decode batch. #running-req: 71, #token: 236865, token usage: 0.96, cuda graph: True, gen throughput (token/s): 741.24, #queue-req: 28\n",
      "[2025-08-13 20:57:24] Decode batch. #running-req: 71, #token: 239705, token usage: 0.97, cuda graph: True, gen throughput (token/s): 988.04, #queue-req: 29\n",
      "[2025-08-13 20:57:25] INFO:     127.0.0.1:40060 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:26] INFO:     127.0.0.1:49066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:27] Decode batch. #running-req: 69, #token: 237563, token usage: 0.97, cuda graph: True, gen throughput (token/s): 950.04, #queue-req: 30\n",
      "[2025-08-13 20:57:27] INFO:     127.0.0.1:53706 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:27] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 93, token usage: 0.95, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:57:27] INFO:     127.0.0.1:60764 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:27] INFO:     127.0.0.1:35674 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:27] Prefill batch. #new-seq: 2, #new-token: 2618, #cached-token: 242, token usage: 0.93, #running-req: 67, #queue-req: 27\n",
      "[2025-08-13 20:57:27] INFO:     127.0.0.1:60538 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:29] INFO:     127.0.0.1:39002 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:29] Prefill batch. #new-seq: 1, #new-token: 4634, #cached-token: 392, token usage: 0.94, #running-req: 67, #queue-req: 26\n",
      "[2025-08-13 20:57:30] INFO:     127.0.0.1:60556 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:30] Prefill batch. #new-seq: 1, #new-token: 4374, #cached-token: 448, token usage: 0.95, #running-req: 67, #queue-req: 25\n",
      "[2025-08-13 20:57:30] Decode batch. #running-req: 67, #token: 237102, token usage: 0.96, cuda graph: True, gen throughput (token/s): 760.77, #queue-req: 25\n",
      "[2025-08-13 20:57:33] INFO:     127.0.0.1:34650 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:33] Decode batch. #running-req: 67, #token: 237581, token usage: 0.97, cuda graph: True, gen throughput (token/s): 810.55, #queue-req: 33\n",
      "[2025-08-13 20:57:34] INFO:     127.0.0.1:37762 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:34] INFO:     127.0.0.1:37768 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:34] Prefill batch. #new-seq: 2, #new-token: 2416, #cached-token: 262, token usage: 0.94, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:57:36] INFO:     127.0.0.1:45498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:36] INFO:     127.0.0.1:38962 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:36] Prefill batch. #new-seq: 1, #new-token: 5789, #cached-token: 627, token usage: 0.93, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:57:37] Decode batch. #running-req: 66, #token: 235578, token usage: 0.96, cuda graph: True, gen throughput (token/s): 732.02, #queue-req: 32\n",
      "[2025-08-13 20:57:40] INFO:     127.0.0.1:48268 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:57:40] Decode batch. #running-req: 65, #token: 235525, token usage: 0.96, cuda graph: True, gen throughput (token/s): 909.05, #queue-req: 34\n",
      "[2025-08-13 20:57:41] INFO:     127.0.0.1:48606 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:41] Prefill batch. #new-seq: 2, #new-token: 4812, #cached-token: 863, token usage: 0.94, #running-req: 64, #queue-req: 32\n",
      "[2025-08-13 20:57:42] INFO:     127.0.0.1:37778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:42] INFO:     127.0.0.1:52502 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:43] INFO:     127.0.0.1:43472 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:43] Prefill batch. #new-seq: 1, #new-token: 7411, #cached-token: 464, token usage: 0.93, #running-req: 63, #queue-req: 34\n",
      ".[2025-08-13 20:57:44] Decode batch. #running-req: 64, #token: 235480, token usage: 0.96, cuda graph: True, gen throughput (token/s): 651.18, #queue-req: 34\n",
      "[2025-08-13 20:57:47] Decode batch. #running-req: 64, #token: 228263, token usage: 0.93, cuda graph: True, gen throughput (token/s): 930.14, #queue-req: 36\n",
      "[2025-08-13 20:57:47] INFO:     127.0.0.1:54792 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:47] Prefill batch. #new-seq: 1, #new-token: 7694, #cached-token: 463, token usage: 0.93, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 20:57:48] INFO:     127.0.0.1:37658 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:48] Prefill batch. #new-seq: 2, #new-token: 2618, #cached-token: 601, token usage: 0.95, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 20:57:48] INFO:     127.0.0.1:43486 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:48] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 461, token usage: 0.96, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 20:57:49] INFO:     127.0.0.1:43514 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:49] Prefill batch. #new-seq: 2, #new-token: 363, #cached-token: 946, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:57:49] INFO:     127.0.0.1:49054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:49] Prefill batch. #new-seq: 2, #new-token: 4661, #cached-token: 857, token usage: 0.93, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:57:51] Decode batch. #running-req: 67, #token: 235972, token usage: 0.96, cuda graph: True, gen throughput (token/s): 601.77, #queue-req: 33\n",
      "[2025-08-13 20:57:52] INFO:     127.0.0.1:48626 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:54] INFO:     127.0.0.1:40726 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:54] Prefill batch. #new-seq: 1, #new-token: 7962, #cached-token: 481, token usage: 0.93, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:57:55] Decode batch. #running-req: 66, #token: 236669, token usage: 0.96, cuda graph: True, gen throughput (token/s): 714.86, #queue-req: 33\n",
      "[2025-08-13 20:57:58] Decode batch. #running-req: 66, #token: 239309, token usage: 0.97, cuda graph: True, gen throughput (token/s): 846.05, #queue-req: 34\n",
      "[2025-08-13 20:57:58] INFO:     127.0.0.1:54806 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:57:58] Prefill batch. #new-seq: 2, #new-token: 1495, #cached-token: 826, token usage: 0.94, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 20:58:00] INFO:     127.0.0.1:45478 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:00] Prefill batch. #new-seq: 2, #new-token: 2436, #cached-token: 850, token usage: 0.94, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 20:58:01] INFO:     127.0.0.1:54816 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:01] Prefill batch. #new-seq: 2, #new-token: 2678, #cached-token: 883, token usage: 0.94, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 20:58:02] Decode batch. #running-req: 69, #token: 233366, token usage: 0.95, cuda graph: True, gen throughput (token/s): 755.14, #queue-req: 30\n",
      "[2025-08-13 20:58:03] INFO:     127.0.0.1:43034 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:03] INFO:     127.0.0.1:53734 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:03] Prefill batch. #new-seq: 1, #new-token: 4382, #cached-token: 447, token usage: 0.94, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:58:05] INFO:     127.0.0.1:48280 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:05] Decode batch. #running-req: 67, #token: 234510, token usage: 0.95, cuda graph: True, gen throughput (token/s): 802.26, #queue-req: 32\n",
      "[2025-08-13 20:58:05] INFO:     127.0.0.1:43046 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:05] INFO:     127.0.0.1:43048 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:05] INFO:     127.0.0.1:52488 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:06] INFO:     127.0.0.1:43066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:06] Prefill batch. #new-seq: 6, #new-token: 8192, #cached-token: 2064, token usage: 0.86, #running-req: 64, #queue-req: 26\n",
      "[2025-08-13 20:58:06] Prefill batch. #new-seq: 4, #new-token: 7054, #cached-token: 697, token usage: 0.89, #running-req: 69, #queue-req: 25\n",
      "[2025-08-13 20:58:07] Prefill batch. #new-seq: 3, #new-token: 6823, #cached-token: 1424, token usage: 0.92, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:58:08] INFO:     127.0.0.1:43078 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:08] Prefill batch. #new-seq: 1, #new-token: 4180, #cached-token: 126, token usage: 0.94, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:58:10] INFO:     127.0.0.1:37768 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:10] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 450, token usage: 0.94, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 20:58:10] Decode batch. #running-req: 75, #token: 234107, token usage: 0.95, cuda graph: True, gen throughput (token/s): 554.51, #queue-req: 24\n",
      "[2025-08-13 20:58:11] INFO:     127.0.0.1:43080 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:11] Prefill batch. #new-seq: 3, #new-token: 4532, #cached-token: 1015, token usage: 0.92, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 20:58:14] Decode batch. #running-req: 77, #token: 231807, token usage: 0.94, cuda graph: True, gen throughput (token/s): 921.01, #queue-req: 23\n",
      "[2025-08-13 20:58:17] Decode batch. #running-req: 77, #token: 234887, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1032.55, #queue-req: 23\n",
      "[2025-08-13 20:58:18] INFO:     127.0.0.1:34650 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:18] INFO:     127.0.0.1:37762 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:19] Decode batch. #running-req: 75, #token: 233198, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1018.45, #queue-req: 25\n",
      "[2025-08-13 20:58:21] INFO:     127.0.0.1:38970 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:21] INFO:     127.0.0.1:38980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:21] Prefill batch. #new-seq: 3, #new-token: 5274, #cached-token: 1039, token usage: 0.92, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 20:58:22] INFO:     127.0.0.1:39034 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:22] Prefill batch. #new-seq: 2, #new-token: 2833, #cached-token: 876, token usage: 0.93, #running-req: 75, #queue-req: 22\n",
      ".[2025-08-13 20:58:23] INFO:     127.0.0.1:37778 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:23] Prefill batch. #new-seq: 1, #new-token: 3410, #cached-token: 481, token usage: 0.93, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:58:23] Decode batch. #running-req: 76, #token: 231049, token usage: 0.94, cuda graph: True, gen throughput (token/s): 815.74, #queue-req: 21\n",
      "[2025-08-13 20:58:24] INFO:     127.0.0.1:38986 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:24] Prefill batch. #new-seq: 2, #new-token: 6104, #cached-token: 903, token usage: 0.93, #running-req: 76, #queue-req: 19\n",
      "[2025-08-13 20:58:26] INFO:     127.0.0.1:54238 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:26] Prefill batch. #new-seq: 1, #new-token: 2384, #cached-token: 412, token usage: 0.94, #running-req: 77, #queue-req: 21\n",
      "[2025-08-13 20:58:27] INFO:     127.0.0.1:37644 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:27] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 449, token usage: 0.94, #running-req: 77, #queue-req: 20\n",
      "[2025-08-13 20:58:27] Decode batch. #running-req: 78, #token: 233522, token usage: 0.95, cuda graph: True, gen throughput (token/s): 741.78, #queue-req: 20\n",
      "[2025-08-13 20:58:28] INFO:     127.0.0.1:35676 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:30] Decode batch. #running-req: 77, #token: 234447, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1046.74, #queue-req: 23\n",
      "[2025-08-13 20:58:32] INFO:     127.0.0.1:37466 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:33] INFO:     127.0.0.1:43486 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:33] Decode batch. #running-req: 75, #token: 234425, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1048.79, #queue-req: 23\n",
      "[2025-08-13 20:58:34] INFO:     127.0.0.1:56492 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:34] INFO:     127.0.0.1:43514 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:36] Decode batch. #running-req: 73, #token: 231368, token usage: 0.94, cuda graph: True, gen throughput (token/s): 983.88, #queue-req: 27\n",
      "[2025-08-13 20:58:37] INFO:     127.0.0.1:40662 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:37] Prefill batch. #new-seq: 1, #new-token: 7347, #cached-token: 77, token usage: 0.93, #running-req: 72, #queue-req: 26\n",
      ".[2025-08-13 20:58:40] Decode batch. #running-req: 73, #token: 238625, token usage: 0.97, cuda graph: True, gen throughput (token/s): 786.76, #queue-req: 27\n",
      "[2025-08-13 20:58:41] INFO:     127.0.0.1:43624 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:41] INFO:     127.0.0.1:53710 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:43] Decode batch. #running-req: 71, #token: 239950, token usage: 0.98, cuda graph: True, gen throughput (token/s): 960.24, #queue-req: 27\n",
      "[2025-08-13 20:58:43] INFO:     127.0.0.1:45706 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:44] INFO:     127.0.0.1:40046 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:44] Prefill batch. #new-seq: 1, #new-token: 2247, #cached-token: 161, token usage: 0.95, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:58:44] INFO:     127.0.0.1:53650 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:45] INFO:     127.0.0.1:54806 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:45] Prefill batch. #new-seq: 2, #new-token: 7179, #cached-token: 847, token usage: 0.92, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 20:58:47] Decode batch. #running-req: 70, #token: 233305, token usage: 0.95, cuda graph: True, gen throughput (token/s): 739.04, #queue-req: 30\n",
      "[2025-08-13 20:58:47] INFO:     127.0.0.1:53680 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:47] Prefill batch. #new-seq: 1, #new-token: 56, #cached-token: 180, token usage: 0.95, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:58:47] INFO:     127.0.0.1:48256 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:48] Prefill batch. #new-seq: 1, #new-token: 4380, #cached-token: 441, token usage: 0.95, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:58:49] INFO:     127.0.0.1:40646 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:49] Prefill batch. #new-seq: 1, #new-token: 4379, #cached-token: 441, token usage: 0.94, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 20:58:50] Decode batch. #running-req: 70, #token: 237669, token usage: 0.97, cuda graph: True, gen throughput (token/s): 752.89, #queue-req: 30\n",
      "[2025-08-13 20:58:51] INFO:     127.0.0.1:51966 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:51] INFO:     127.0.0.1:43046 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:52] Prefill batch. #new-seq: 1, #new-token: 4373, #cached-token: 449, token usage: 0.95, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 20:58:54] Decode batch. #running-req: 69, #token: 239533, token usage: 0.97, cuda graph: True, gen throughput (token/s): 853.48, #queue-req: 31\n",
      "[2025-08-13 20:58:54] INFO:     127.0.0.1:53292 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:56] INFO:     127.0.0.1:53302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:56] INFO:     127.0.0.1:43034 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:56] Prefill batch. #new-seq: 1, #new-token: 2348, #cached-token: 454, token usage: 0.95, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:58:57] Decode batch. #running-req: 67, #token: 235557, token usage: 0.96, cuda graph: True, gen throughput (token/s): 867.70, #queue-req: 33\n",
      "[2025-08-13 20:58:58] INFO:     127.0.0.1:43654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:58:58] INFO:     127.0.0.1:43048 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:00] Decode batch. #running-req: 65, #token: 233146, token usage: 0.95, cuda graph: True, gen throughput (token/s): 945.82, #queue-req: 35\n",
      "[2025-08-13 20:59:00] INFO:     127.0.0.1:48296 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:00] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 393, token usage: 0.91, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:59:00] Prefill batch. #new-seq: 1, #new-token: 1108, #cached-token: 0, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:59:02] INFO:     127.0.0.1:43066 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:02] Prefill batch. #new-seq: 1, #new-token: 4234, #cached-token: 449, token usage: 0.94, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:59:04] Decode batch. #running-req: 65, #token: 235672, token usage: 0.96, cuda graph: True, gen throughput (token/s): 626.62, #queue-req: 35\n",
      "[2025-08-13 20:59:06] INFO:     127.0.0.1:49044 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:07] Prefill batch. #new-seq: 1, #new-token: 2101, #cached-token: 96, token usage: 0.95, #running-req: 64, #queue-req: 35\n",
      "[2025-08-13 20:59:07] Decode batch. #running-req: 64, #token: 235951, token usage: 0.96, cuda graph: True, gen throughput (token/s): 910.71, #queue-req: 35\n",
      "[2025-08-13 20:59:09] INFO:     127.0.0.1:37464 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:09] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.93, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:59:09] Prefill batch. #new-seq: 1, #new-token: 1735, #cached-token: 0, token usage: 0.97, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:59:10] INFO:     127.0.0.1:43080 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 20:59:10] Prefill batch. #new-seq: 2, #new-token: 4461, #cached-token: 804, token usage: 0.93, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 20:59:11] Decode batch. #running-req: 66, #token: 234248, token usage: 0.95, cuda graph: True, gen throughput (token/s): 582.74, #queue-req: 34\n",
      "[2025-08-13 20:59:12] INFO:     127.0.0.1:43606 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:59:12] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 555, token usage: 0.92, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:59:12] INFO:     127.0.0.1:45484 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:12] Prefill batch. #new-seq: 1, #new-token: 1084, #cached-token: 0, token usage: 0.96, #running-req: 66, #queue-req: 32\n",
      "[2025-08-13 20:59:13] INFO:     127.0.0.1:49072 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:13] Prefill batch. #new-seq: 2, #new-token: 4261, #cached-token: 203, token usage: 0.94, #running-req: 65, #queue-req: 30\n",
      "[2025-08-13 20:59:13] INFO:     127.0.0.1:38980 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:14] Prefill batch. #new-seq: 1, #new-token: 2239, #cached-token: 448, token usage: 0.94, #running-req: 66, #queue-req: 29\n",
      "[2025-08-13 20:59:15] Decode batch. #running-req: 67, #token: 233740, token usage: 0.95, cuda graph: True, gen throughput (token/s): 618.55, #queue-req: 33\n",
      "[2025-08-13 20:59:18] INFO:     127.0.0.1:54242 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:18] INFO:     127.0.0.1:54246 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:18] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1312, token usage: 0.92, #running-req: 65, #queue-req: 32\n",
      "[2025-08-13 20:59:18] Prefill batch. #new-seq: 2, #new-token: 510, #cached-token: 665, token usage: 0.95, #running-req: 67, #queue-req: 31\n",
      "[2025-08-13 20:59:19] INFO:     127.0.0.1:54256 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:19] Prefill batch. #new-seq: 2, #new-token: 7931, #cached-token: 614, token usage: 0.92, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 20:59:20] INFO:     127.0.0.1:38970 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:20] Decode batch. #running-req: 70, #token: 230924, token usage: 0.94, cuda graph: True, gen throughput (token/s): 623.91, #queue-req: 30\n",
      "[2025-08-13 20:59:20] Prefill batch. #new-seq: 1, #new-token: 5617, #cached-token: 481, token usage: 0.94, #running-req: 69, #queue-req: 29\n",
      "[2025-08-13 20:59:20] INFO:     127.0.0.1:54276 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:20] INFO:     127.0.0.1:54284 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:20] INFO:     127.0.0.1:37628 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:20] Prefill batch. #new-seq: 6, #new-token: 5182, #cached-token: 1763, token usage: 0.90, #running-req: 67, #queue-req: 23\n",
      "[2025-08-13 20:59:23] INFO:     127.0.0.1:37650 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:23] INFO:     127.0.0.1:37652 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:23] Prefill batch. #new-seq: 3, #new-token: 2412, #cached-token: 338, token usage: 0.91, #running-req: 71, #queue-req: 26\n",
      "[2025-08-13 20:59:24] Decode batch. #running-req: 74, #token: 226399, token usage: 0.92, cuda graph: True, gen throughput (token/s): 724.09, #queue-req: 26\n",
      "[2025-08-13 20:59:25] INFO:     127.0.0.1:34164 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:25] Prefill batch. #new-seq: 3, #new-token: 7174, #cached-token: 1317, token usage: 0.91, #running-req: 73, #queue-req: 23\n",
      "[2025-08-13 20:59:26] INFO:     127.0.0.1:37496 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:26] Prefill batch. #new-seq: 1, #new-token: 2216, #cached-token: 469, token usage: 0.94, #running-req: 75, #queue-req: 23\n",
      "[2025-08-13 20:59:26] INFO:     127.0.0.1:38986 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:26] Prefill batch. #new-seq: 1, #new-token: 4373, #cached-token: 448, token usage: 0.93, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:59:27] INFO:     127.0.0.1:34144 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:27] Prefill batch. #new-seq: 2, #new-token: 2290, #cached-token: 615, token usage: 0.94, #running-req: 75, #queue-req: 20\n",
      "[2025-08-13 20:59:28] Decode batch. #running-req: 77, #token: 233556, token usage: 0.95, cuda graph: True, gen throughput (token/s): 702.49, #queue-req: 20\n",
      "[2025-08-13 20:59:29] INFO:     127.0.0.1:37670 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:29] Prefill batch. #new-seq: 2, #new-token: 4900, #cached-token: 856, token usage: 0.92, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:59:31] Decode batch. #running-req: 78, #token: 232099, token usage: 0.94, cuda graph: True, gen throughput (token/s): 939.67, #queue-req: 22\n",
      "[2025-08-13 20:59:31] INFO:     127.0.0.1:35676 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:31] Prefill batch. #new-seq: 1, #new-token: 2157, #cached-token: 476, token usage: 0.94, #running-req: 77, #queue-req: 21\n",
      "[2025-08-13 20:59:32] INFO:     127.0.0.1:56492 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:32] INFO:     127.0.0.1:40046 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:32] Prefill batch. #new-seq: 1, #new-token: 4376, #cached-token: 446, token usage: 0.93, #running-req: 76, #queue-req: 20\n",
      "[2025-08-13 20:59:32] INFO:     127.0.0.1:37654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:33] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 449, token usage: 0.92, #running-req: 76, #queue-req: 20\n",
      "[2025-08-13 20:59:35] INFO:     127.0.0.1:43638 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:35] Prefill batch. #new-seq: 1, #new-token: 7907, #cached-token: 410, token usage: 0.92, #running-req: 76, #queue-req: 22\n",
      "[2025-08-13 20:59:36] Decode batch. #running-req: 77, #token: 234307, token usage: 0.95, cuda graph: True, gen throughput (token/s): 693.07, #queue-req: 22\n",
      "[2025-08-13 20:59:38] INFO:     127.0.0.1:53292 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:38] Prefill batch. #new-seq: 2, #new-token: 4546, #cached-token: 829, token usage: 0.94, #running-req: 76, #queue-req: 21\n",
      "[2025-08-13 20:59:38] INFO:     127.0.0.1:53302 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:39] Decode batch. #running-req: 77, #token: 235087, token usage: 0.96, cuda graph: True, gen throughput (token/s): 892.35, #queue-req: 21\n",
      "[2025-08-13 20:59:40] INFO:     127.0.0.1:45516 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:41] INFO:     127.0.0.1:45492 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:41] Prefill batch. #new-seq: 1, #new-token: 2348, #cached-token: 454, token usage: 0.94, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 20:59:42] Decode batch. #running-req: 76, #token: 235832, token usage: 0.96, cuda graph: True, gen throughput (token/s): 970.87, #queue-req: 24\n",
      "[2025-08-13 20:59:42] INFO:     127.0.0.1:51890 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:44] INFO:     127.0.0.1:49044 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:44] INFO:     127.0.0.1:45512 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:45] Decode batch. #running-req: 73, #token: 228237, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1013.21, #queue-req: 27\n",
      "[2025-08-13 20:59:46] INFO:     127.0.0.1:33258 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:46] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 146, token usage: 0.91, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:59:46] Prefill batch. #new-seq: 2, #new-token: 2593, #cached-token: 147, token usage: 0.95, #running-req: 72, #queue-req: 25\n",
      "[2025-08-13 20:59:49] Decode batch. #running-req: 74, #token: 232950, token usage: 0.95, cuda graph: True, gen throughput (token/s): 736.54, #queue-req: 26\n",
      "[2025-08-13 20:59:49] INFO:     127.0.0.1:49072 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:51] INFO:     127.0.0.1:40864 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:51] Prefill batch. #new-seq: 1, #new-token: 7636, #cached-token: 481, token usage: 0.93, #running-req: 72, #queue-req: 26\n",
      "[2025-08-13 20:59:52] INFO:     127.0.0.1:37444 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 20:59:53] Decode batch. #running-req: 72, #token: 232156, token usage: 0.94, cuda graph: True, gen throughput (token/s): 790.67, #queue-req: 26\n",
      "[2025-08-13 20:59:53] INFO:     127.0.0.1:53722 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:53] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.93, #running-req: 71, #queue-req: 25\n",
      "[2025-08-13 20:59:53] Prefill batch. #new-seq: 1, #new-token: 1363, #cached-token: 0, token usage: 0.96, #running-req: 71, #queue-req: 26\n",
      ".[2025-08-13 20:59:55] INFO:     127.0.0.1:54256 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:56] Prefill batch. #new-seq: 1, #new-token: 2234, #cached-token: 452, token usage: 0.93, #running-req: 71, #queue-req: 27\n",
      "[2025-08-13 20:59:57] INFO:     127.0.0.1:48282 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:57] Decode batch. #running-req: 72, #token: 230567, token usage: 0.94, cuda graph: True, gen throughput (token/s): 717.83, #queue-req: 28\n",
      "[2025-08-13 20:59:58] INFO:     127.0.0.1:54242 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:59] INFO:     127.0.0.1:47152 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 20:59:59] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.91, #running-req: 69, #queue-req: 28\n",
      "[2025-08-13 20:59:59] Prefill batch. #new-seq: 2, #new-token: 5734, #cached-token: 448, token usage: 0.95, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 21:00:01] Decode batch. #running-req: 71, #token: 225785, token usage: 0.92, cuda graph: True, gen throughput (token/s): 657.72, #queue-req: 29\n",
      "[2025-08-13 21:00:01] INFO:     127.0.0.1:48286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:01] Prefill batch. #new-seq: 4, #new-token: 7462, #cached-token: 1099, token usage: 0.92, #running-req: 70, #queue-req: 26\n",
      "[2025-08-13 21:00:03] INFO:     127.0.0.1:34168 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:03] Prefill batch. #new-seq: 2, #new-token: 119, #cached-token: 694, token usage: 0.94, #running-req: 73, #queue-req: 24\n",
      "[2025-08-13 21:00:05] INFO:     127.0.0.1:54246 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:05] Prefill batch. #new-seq: 2, #new-token: 4624, #cached-token: 588, token usage: 0.92, #running-req: 74, #queue-req: 23\n",
      "[2025-08-13 21:00:05] Decode batch. #running-req: 76, #token: 229740, token usage: 0.93, cuda graph: True, gen throughput (token/s): 745.50, #queue-req: 23\n",
      "[2025-08-13 21:00:06] INFO:     127.0.0.1:43616 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:06] Prefill batch. #new-seq: 1, #new-token: 7810, #cached-token: 466, token usage: 0.92, #running-req: 75, #queue-req: 22\n",
      "[2025-08-13 21:00:07] INFO:     127.0.0.1:37876 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:07] Prefill batch. #new-seq: 1, #new-token: 2368, #cached-token: 462, token usage: 0.95, #running-req: 75, #queue-req: 21\n",
      "[2025-08-13 21:00:08] INFO:     127.0.0.1:37654 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:08] Prefill batch. #new-seq: 2, #new-token: 5421, #cached-token: 485, token usage: 0.93, #running-req: 75, #queue-req: 19\n",
      "[2025-08-13 21:00:09] INFO:     127.0.0.1:54276 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:09] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 449, token usage: 0.94, #running-req: 76, #queue-req: 20\n",
      "[2025-08-13 21:00:10] INFO:     127.0.0.1:51878 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:10] Decode batch. #running-req: 77, #token: 226536, token usage: 0.92, cuda graph: True, gen throughput (token/s): 661.63, #queue-req: 21\n",
      "[2025-08-13 21:00:10] Prefill batch. #new-seq: 2, #new-token: 4551, #cached-token: 878, token usage: 0.92, #running-req: 76, #queue-req: 19\n",
      "[2025-08-13 21:00:13] INFO:     127.0.0.1:54284 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:13] INFO:     127.0.0.1:37628 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:13] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1525, token usage: 0.89, #running-req: 76, #queue-req: 18\n",
      "[2025-08-13 21:00:13] Prefill batch. #new-seq: 3, #new-token: 5027, #cached-token: 861, token usage: 0.93, #running-req: 79, #queue-req: 16\n",
      "[2025-08-13 21:00:14] INFO:     127.0.0.1:48304 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:14] INFO:     127.0.0.1:53690 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:14] Prefill batch. #new-seq: 1, #new-token: 7411, #cached-token: 392, token usage: 0.92, #running-req: 80, #queue-req: 15\n",
      "[2025-08-13 21:00:15] Decode batch. #running-req: 81, #token: 234401, token usage: 0.95, cuda graph: True, gen throughput (token/s): 601.54, #queue-req: 19\n",
      "[2025-08-13 21:00:16] INFO:     127.0.0.1:37650 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:16] INFO:     127.0.0.1:37652 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:16] Prefill batch. #new-seq: 3, #new-token: 282, #cached-token: 1282, token usage: 0.94, #running-req: 79, #queue-req: 16\n",
      "[2025-08-13 21:00:18] INFO:     127.0.0.1:53740 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:18] Decode batch. #running-req: 81, #token: 230915, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1045.11, #queue-req: 16\n",
      "[2025-08-13 21:00:19] INFO:     127.0.0.1:45578 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:00:21] Decode batch. #running-req: 80, #token: 232842, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1091.64, #queue-req: 20\n",
      "[2025-08-13 21:00:24] INFO:     127.0.0.1:45492 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:24] INFO:     127.0.0.1:45512 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:24] Decode batch. #running-req: 80, #token: 229264, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1082.97, #queue-req: 20\n",
      ".[2025-08-13 21:00:25] INFO:     127.0.0.1:47158 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:27] Decode batch. #running-req: 77, #token: 231249, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1067.77, #queue-req: 20\n",
      "[2025-08-13 21:00:28] INFO:     127.0.0.1:53662 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:28] INFO:     127.0.0.1:40640 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:28] Prefill batch. #new-seq: 1, #new-token: 7693, #cached-token: 465, token usage: 0.92, #running-req: 75, #queue-req: 24\n",
      "[2025-08-13 21:00:31] Decode batch. #running-req: 76, #token: 235318, token usage: 0.96, cuda graph: True, gen throughput (token/s): 836.43, #queue-req: 24\n",
      "[2025-08-13 21:00:34] Decode batch. #running-req: 76, #token: 238358, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1047.24, #queue-req: 24\n",
      "[2025-08-13 21:00:34] INFO:     127.0.0.1:40676 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:37] Decode batch. #running-req: 75, #token: 239307, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1015.14, #queue-req: 25\n",
      "[2025-08-13 21:00:40] Decode batch. #running-req: 75, #token: 242307, token usage: 0.99, cuda graph: True, gen throughput (token/s): 996.16, #queue-req: 25\n",
      "[2025-08-13 21:00:42] INFO:     127.0.0.1:51906 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:42] Prefill batch. #new-seq: 1, #new-token: 2365, #cached-token: 438, token usage: 0.96, #running-req: 74, #queue-req: 25\n",
      "[2025-08-13 21:00:43] Decode batch. #running-req: 75, #token: 238206, token usage: 0.97, cuda graph: True, gen throughput (token/s): 925.34, #queue-req: 25\n",
      "[2025-08-13 21:00:45] INFO:     127.0.0.1:51922 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:45] Prefill batch. #new-seq: 1, #new-token: 2150, #cached-token: 167, token usage: 0.94, #running-req: 74, #queue-req: 24\n",
      "[2025-08-13 21:00:46] Decode batch. #running-req: 75, #token: 233674, token usage: 0.95, cuda graph: True, gen throughput (token/s): 948.42, #queue-req: 24\n",
      "[2025-08-13 21:00:46] INFO:     127.0.0.1:51938 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:46] INFO:     127.0.0.1:51950 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:46] Prefill batch. #new-seq: 1, #new-token: 5661, #cached-token: 409, token usage: 0.92, #running-req: 73, #queue-req: 25\n",
      "[2025-08-13 21:00:48] INFO:     127.0.0.1:51970 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:48] INFO:     127.0.0.1:51974 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:48] INFO:     127.0.0.1:37450 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:49] Decode batch. #running-req: 71, #token: 229227, token usage: 0.93, cuda graph: True, gen throughput (token/s): 865.17, #queue-req: 29\n",
      "[2025-08-13 21:00:50] INFO:     127.0.0.1:37870 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:51] INFO:     127.0.0.1:37886 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:52] Decode batch. #running-req: 69, #token: 227522, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1025.04, #queue-req: 29\n",
      "[2025-08-13 21:00:52] INFO:     127.0.0.1:50542 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:52] INFO:     127.0.0.1:48282 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:52] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.90, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 21:00:53] Prefill batch. #new-seq: 1, #new-token: 5458, #cached-token: 0, token usage: 0.94, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 21:00:55] INFO:     127.0.0.1:48286 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:55] Prefill batch. #new-seq: 3, #new-token: 8181, #cached-token: 671, token usage: 0.91, #running-req: 67, #queue-req: 27\n",
      "[2025-08-13 21:00:56] INFO:     127.0.0.1:40612 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:56] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 451, token usage: 0.94, #running-req: 69, #queue-req: 26\n",
      "[2025-08-13 21:00:57] INFO:     127.0.0.1:56664 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:57] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 449, token usage: 0.94, #running-req: 69, #queue-req: 27\n",
      "[2025-08-13 21:00:57] Decode batch. #running-req: 70, #token: 232926, token usage: 0.95, cuda graph: True, gen throughput (token/s): 503.67, #queue-req: 27\n",
      "[2025-08-13 21:00:57] INFO:     127.0.0.1:40600 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:58] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 412, token usage: 0.95, #running-req: 69, #queue-req: 26\n",
      "[2025-08-13 21:00:58] INFO:     127.0.0.1:37478 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:58] Prefill batch. #new-seq: 1, #new-token: 2359, #cached-token: 443, token usage: 0.94, #running-req: 69, #queue-req: 26\n",
      "[2025-08-13 21:00:59] INFO:     127.0.0.1:37494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:00:59] Prefill batch. #new-seq: 2, #new-token: 6321, #cached-token: 617, token usage: 0.94, #running-req: 69, #queue-req: 24\n",
      "[2025-08-13 21:01:01] INFO:     127.0.0.1:60772 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:01] INFO:     127.0.0.1:37512 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:01] Decode batch. #running-req: 69, #token: 232211, token usage: 0.94, cuda graph: True, gen throughput (token/s): 741.35, #queue-req: 25\n",
      "[2025-08-13 21:01:04] Decode batch. #running-req: 69, #token: 234971, token usage: 0.96, cuda graph: True, gen throughput (token/s): 973.30, #queue-req: 31\n",
      "[2025-08-13 21:01:05] INFO:     127.0.0.1:40880 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:05] INFO:     127.0.0.1:40884 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:05] INFO:     127.0.0.1:40896 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:05] INFO:     127.0.0.1:34128 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:05] INFO:     127.0.0.1:34132 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:05] INFO:     127.0.0.1:34154 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:05] INFO:     127.0.0.1:34174 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:05] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.86, #running-req: 63, #queue-req: 36\n",
      "[2025-08-13 21:01:05] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 667, token usage: 0.89, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 21:01:06] Prefill batch. #new-seq: 3, #new-token: 4357, #cached-token: 543, token usage: 0.92, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 21:01:07] Prefill batch. #new-seq: 2, #new-token: 2392, #cached-token: 573, token usage: 0.94, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 21:01:09] Decode batch. #running-req: 70, #token: 236138, token usage: 0.96, cuda graph: True, gen throughput (token/s): 567.56, #queue-req: 30\n",
      "[2025-08-13 21:01:11] INFO:     127.0.0.1:53690 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:11] INFO:     127.0.0.1:48304 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:11] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 146, token usage: 0.94, #running-req: 68, #queue-req: 29\n",
      "[2025-08-13 21:01:12] Decode batch. #running-req: 69, #token: 232505, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1000.72, #queue-req: 29\n",
      "[2025-08-13 21:01:13] INFO:     127.0.0.1:46186 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:13] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 391, token usage: 0.93, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 21:01:13] Prefill batch. #new-seq: 1, #new-token: 602, #cached-token: 0, token usage: 0.96, #running-req: 70, #queue-req: 28\n",
      "[2025-08-13 21:01:14] INFO:     127.0.0.1:53106 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:15] INFO:     127.0.0.1:53662 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:15] Decode batch. #running-req: 69, #token: 227942, token usage: 0.93, cuda graph: True, gen throughput (token/s): 789.15, #queue-req: 29\n",
      "[2025-08-13 21:01:15] INFO:     127.0.0.1:57738 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:15] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.93, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 21:01:15] Prefill batch. #new-seq: 1, #new-token: 1292, #cached-token: 0, token usage: 0.96, #running-req: 68, #queue-req: 28\n",
      "[2025-08-13 21:01:17] INFO:     127.0.0.1:53740 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:17] INFO:     127.0.0.1:51906 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:17] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 874, token usage: 0.92, #running-req: 67, #queue-req: 27\n",
      "[2025-08-13 21:01:18] Prefill batch. #new-seq: 1, #new-token: 1688, #cached-token: 0, token usage: 0.96, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 21:01:20] Decode batch. #running-req: 69, #token: 238294, token usage: 0.97, cuda graph: True, gen throughput (token/s): 583.29, #queue-req: 31\n",
      "[2025-08-13 21:01:22] INFO:     127.0.0.1:43648 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:22] INFO:     127.0.0.1:56680 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:01:22] INFO:     127.0.0.1:45692 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:22] Prefill batch. #new-seq: 1, #new-token: 2877, #cached-token: 409, token usage: 0.94, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 21:01:23] Decode batch. #running-req: 67, #token: 235775, token usage: 0.96, cuda graph: True, gen throughput (token/s): 888.89, #queue-req: 31\n",
      "[2025-08-13 21:01:24] INFO:     127.0.0.1:45722 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:24] Prefill batch. #new-seq: 3, #new-token: 6448, #cached-token: 1608, token usage: 0.94, #running-req: 66, #queue-req: 31\n",
      "[2025-08-13 21:01:25] INFO:     127.0.0.1:51970 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:26] INFO:     127.0.0.1:45730 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:26] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.95, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 21:01:26] INFO:     127.0.0.1:40640 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:26] INFO:     127.0.0.1:40676 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:26] Prefill batch. #new-seq: 2, #new-token: 2647, #cached-token: 555, token usage: 0.94, #running-req: 66, #queue-req: 28\n",
      "[2025-08-13 21:01:27] INFO:     127.0.0.1:45742 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:27] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 467, token usage: 0.94, #running-req: 67, #queue-req: 28\n",
      "[2025-08-13 21:01:27] Decode batch. #running-req: 68, #token: 232501, token usage: 0.95, cuda graph: True, gen throughput (token/s): 668.44, #queue-req: 28\n",
      "[2025-08-13 21:01:27] INFO:     127.0.0.1:57722 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:29] INFO:     127.0.0.1:51950 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:30] Decode batch. #running-req: 66, #token: 225584, token usage: 0.92, cuda graph: True, gen throughput (token/s): 923.85, #queue-req: 32\n",
      "[2025-08-13 21:01:30] INFO:     127.0.0.1:47506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:31] INFO:     127.0.0.1:50530 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:33] Decode batch. #running-req: 64, #token: 227069, token usage: 0.92, cuda graph: True, gen throughput (token/s): 940.53, #queue-req: 36\n",
      "[2025-08-13 21:01:34] INFO:     127.0.0.1:51974 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:34] INFO:     127.0.0.1:37450 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:34] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.91, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 21:01:34] Prefill batch. #new-seq: 1, #new-token: 3598, #cached-token: 0, token usage: 0.94, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 21:01:37] Decode batch. #running-req: 63, #token: 236802, token usage: 0.96, cuda graph: True, gen throughput (token/s): 636.96, #queue-req: 37\n",
      "[2025-08-13 21:01:39] INFO:     127.0.0.1:47166 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:39] Prefill batch. #new-seq: 3, #new-token: 5968, #cached-token: 1321, token usage: 0.93, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 21:01:40] Decode batch. #running-req: 65, #token: 234273, token usage: 0.95, cuda graph: True, gen throughput (token/s): 783.98, #queue-req: 35\n",
      "[2025-08-13 21:01:41] INFO:     127.0.0.1:38558 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:41] Prefill batch. #new-seq: 1, #new-token: 4370, #cached-token: 450, token usage: 0.95, #running-req: 64, #queue-req: 34\n",
      "[2025-08-13 21:01:43] Decode batch. #running-req: 65, #token: 238664, token usage: 0.97, cuda graph: True, gen throughput (token/s): 802.91, #queue-req: 35\n",
      "[2025-08-13 21:01:44] INFO:     127.0.0.1:53642 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:44] INFO:     127.0.0.1:47146 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:44] Prefill batch. #new-seq: 2, #new-token: 2659, #cached-token: 886, token usage: 0.95, #running-req: 63, #queue-req: 33\n",
      "[2025-08-13 21:01:46] Decode batch. #running-req: 65, #token: 237584, token usage: 0.97, cuda graph: True, gen throughput (token/s): 856.57, #queue-req: 35\n",
      "[2025-08-13 21:01:49] INFO:     127.0.0.1:34606 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:49] INFO:     127.0.0.1:37478 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:49] INFO:     127.0.0.1:60772 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:49] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1496, token usage: 0.91, #running-req: 62, #queue-req: 31\n",
      "[2025-08-13 21:01:49] INFO:     127.0.0.1:53112 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:49] Prefill batch. #new-seq: 2, #new-token: 5596, #cached-token: 409, token usage: 0.95, #running-req: 65, #queue-req: 30\n",
      ".[2025-08-13 21:01:50] Prefill batch. #new-seq: 1, #new-token: 4372, #cached-token: 449, token usage: 0.95, #running-req: 66, #queue-req: 29\n",
      "[2025-08-13 21:01:50] INFO:     127.0.0.1:40884 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:50] Decode batch. #running-req: 66, #token: 237762, token usage: 0.97, cuda graph: True, gen throughput (token/s): 647.16, #queue-req: 29\n",
      "[2025-08-13 21:01:53] INFO:     127.0.0.1:35992 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:53] INFO:     127.0.0.1:40590 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:53] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1371, token usage: 0.90, #running-req: 64, #queue-req: 26\n",
      "[2025-08-13 21:01:53] INFO:     127.0.0.1:37512 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:53] Prefill batch. #new-seq: 4, #new-token: 7300, #cached-token: 631, token usage: 0.91, #running-req: 66, #queue-req: 23\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 21:01:54] Prefill batch. #new-seq: 1, #new-token: 2276, #cached-token: 126, token usage: 0.94, #running-req: 69, #queue-req: 24\n",
      "[2025-08-13 21:01:55] Decode batch. #running-req: 70, #token: 235186, token usage: 0.96, cuda graph: True, gen throughput (token/s): 563.82, #queue-req: 24\n",
      "[2025-08-13 21:01:57] INFO:     127.0.0.1:47160 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:01:57] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 452, token usage: 0.95, #running-req: 69, #queue-req: 23\n",
      "[2025-08-13 21:01:58] Decode batch. #running-req: 70, #token: 235982, token usage: 0.96, cuda graph: True, gen throughput (token/s): 922.26, #queue-req: 30\n",
      "[2025-08-13 21:02:01] Decode batch. #running-req: 70, #token: 238782, token usage: 0.97, cuda graph: True, gen throughput (token/s): 998.84, #queue-req: 30\n",
      "[2025-08-13 21:02:01] INFO:     127.0.0.1:34132 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:01] INFO:     127.0.0.1:34154 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:01] INFO:     127.0.0.1:34128 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:01] Prefill batch. #new-seq: 2, #new-token: 7665, #cached-token: 612, token usage: 0.92, #running-req: 67, #queue-req: 28\n",
      "[2025-08-13 21:02:01] INFO:     127.0.0.1:40896 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:02] Prefill batch. #new-seq: 1, #new-token: 2191, #cached-token: 463, token usage: 0.96, #running-req: 68, #queue-req: 27\n",
      "[2025-08-13 21:02:04] INFO:     127.0.0.1:40880 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:04] Prefill batch. #new-seq: 2, #new-token: 2455, #cached-token: 534, token usage: 0.95, #running-req: 68, #queue-req: 25\n",
      "[2025-08-13 21:02:05] Decode batch. #running-req: 70, #token: 237315, token usage: 0.97, cuda graph: True, gen throughput (token/s): 684.22, #queue-req: 25\n",
      "[2025-08-13 21:02:08] INFO:     127.0.0.1:46190 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:08] Decode batch. #running-req: 70, #token: 236010, token usage: 0.96, cuda graph: True, gen throughput (token/s): 970.29, #queue-req: 30\n",
      "[2025-08-13 21:02:10] INFO:     127.0.0.1:50546 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:10] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 446, token usage: 0.96, #running-req: 68, #queue-req: 30\n",
      "[2025-08-13 21:02:11] Decode batch. #running-req: 69, #token: 239515, token usage: 0.97, cuda graph: True, gen throughput (token/s): 861.18, #queue-req: 30\n",
      "[2025-08-13 21:02:11] INFO:     127.0.0.1:43648 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:12] INFO:     127.0.0.1:37894 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:12] Prefill batch. #new-seq: 1, #new-token: 4351, #cached-token: 465, token usage: 0.95, #running-req: 67, #queue-req: 30\n",
      "[2025-08-13 21:02:14] Decode batch. #running-req: 68, #token: 240041, token usage: 0.98, cuda graph: True, gen throughput (token/s): 836.24, #queue-req: 32\n",
      "[2025-08-13 21:02:15] INFO:     127.0.0.1:52760 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:15] INFO:     127.0.0.1:45692 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:15] INFO:     127.0.0.1:37788 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:17] INFO:     127.0.0.1:33272 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:17] INFO:     127.0.0.1:33278 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:17] Prefill batch. #new-seq: 2, #new-token: 4781, #cached-token: 843, token usage: 0.94, #running-req: 63, #queue-req: 30\n",
      "[2025-08-13 21:02:17] INFO:     127.0.0.1:33292 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:17] Prefill batch. #new-seq: 2, #new-token: 6634, #cached-token: 276, token usage: 0.93, #running-req: 64, #queue-req: 28\n",
      "[2025-08-13 21:02:18] Decode batch. #running-req: 66, #token: 228264, token usage: 0.93, cuda graph: True, gen throughput (token/s): 678.77, #queue-req: 34\n",
      "[2025-08-13 21:02:18] INFO:     127.0.0.1:33294 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:18] Prefill batch. #new-seq: 2, #new-token: 6870, #cached-token: 592, token usage: 0.93, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 21:02:19] INFO:     127.0.0.1:45532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:19] INFO:     127.0.0.1:45536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:19] INFO:     127.0.0.1:45548 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:19] INFO:     127.0.0.1:45562 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:19] Prefill batch. #new-seq: 3, #new-token: 5114, #cached-token: 1054, token usage: 0.92, #running-req: 63, #queue-req: 34\n",
      "[2025-08-13 21:02:21] INFO:     127.0.0.1:38570 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:21] Prefill batch. #new-seq: 1, #new-token: 2412, #cached-token: 462, token usage: 0.95, #running-req: 65, #queue-req: 33\n",
      "[2025-08-13 21:02:22] INFO:     127.0.0.1:57694 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:22] INFO:     127.0.0.1:57702 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:22] Decode batch. #running-req: 64, #token: 229936, token usage: 0.94, cuda graph: True, gen throughput (token/s): 650.97, #queue-req: 33\n",
      "[2025-08-13 21:02:22] INFO:     127.0.0.1:45722 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:23] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.92, #running-req: 63, #queue-req: 35\n",
      ".[2025-08-13 21:02:23] Prefill batch. #new-seq: 1, #new-token: 1250, #cached-token: 0, token usage: 0.95, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 21:02:24] INFO:     127.0.0.1:53694 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:24] Prefill batch. #new-seq: 1, #new-token: 2333, #cached-token: 469, token usage: 0.95, #running-req: 63, #queue-req: 35\n",
      "[2025-08-13 21:02:25] INFO:     127.0.0.1:57708 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:25] INFO:     127.0.0.1:57718 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:25] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 693, token usage: 0.92, #running-req: 62, #queue-req: 32\n",
      "[2025-08-13 21:02:25] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 0, token usage: 0.95, #running-req: 64, #queue-req: 32\n",
      "[2025-08-13 21:02:26] INFO:     127.0.0.1:45730 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:26] Prefill batch. #new-seq: 2, #new-token: 4932, #cached-token: 542, token usage: 0.94, #running-req: 64, #queue-req: 33\n",
      "[2025-08-13 21:02:26] INFO:     127.0.0.1:56662 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:27] Decode batch. #running-req: 65, #token: 234273, token usage: 0.95, cuda graph: True, gen throughput (token/s): 505.51, #queue-req: 35\n",
      "[2025-08-13 21:02:28] INFO:     127.0.0.1:47146 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:29] INFO:     127.0.0.1:59302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:29] INFO:     127.0.0.1:47518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:29] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 412, token usage: 0.93, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 21:02:29] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 0, token usage: 0.96, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 21:02:31] Decode batch. #running-req: 63, #token: 236857, token usage: 0.96, cuda graph: True, gen throughput (token/s): 710.58, #queue-req: 37\n",
      "[2025-08-13 21:02:31] INFO:     127.0.0.1:56688 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:31] INFO:     127.0.0.1:45742 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:31] Prefill batch. #new-seq: 2, #new-token: 6431, #cached-token: 889, token usage: 0.93, #running-req: 61, #queue-req: 36\n",
      ".[2025-08-13 21:02:32] INFO:     127.0.0.1:35968 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:32] Prefill batch. #new-seq: 1, #new-token: 2349, #cached-token: 452, token usage: 0.94, #running-req: 62, #queue-req: 36\n",
      ".[2025-08-13 21:02:34] INFO:     127.0.0.1:43080 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:34] Prefill batch. #new-seq: 1, #new-token: 2951, #cached-token: 480, token usage: 0.92, #running-req: 62, #queue-req: 36\n",
      "[2025-08-13 21:02:34] Decode batch. #running-req: 62, #token: 228496, token usage: 0.93, cuda graph: True, gen throughput (token/s): 699.70, #queue-req: 36\n",
      "[2025-08-13 21:02:37] INFO:     127.0.0.1:35972 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:37] INFO:     127.0.0.1:47160 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:37] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 77, token usage: 0.91, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 21:02:37] Prefill batch. #new-seq: 1, #new-token: 599, #cached-token: 0, token usage: 0.95, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 21:02:38] Decode batch. #running-req: 62, #token: 233360, token usage: 0.95, cuda graph: True, gen throughput (token/s): 655.21, #queue-req: 37\n",
      "[2025-08-13 21:02:39] INFO:     127.0.0.1:37794 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:39] Prefill batch. #new-seq: 1, #new-token: 2245, #cached-token: 553, token usage: 0.94, #running-req: 61, #queue-req: 36\n",
      "[2025-08-13 21:02:40] INFO:     127.0.0.1:50536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:40] Prefill batch. #new-seq: 2, #new-token: 4444, #cached-token: 505, token usage: 0.92, #running-req: 61, #queue-req: 35\n",
      "[2025-08-13 21:02:40] INFO:     127.0.0.1:35984 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:40] Prefill batch. #new-seq: 1, #new-token: 3198, #cached-token: 553, token usage: 0.94, #running-req: 62, #queue-req: 34\n",
      "[2025-08-13 21:02:42] Decode batch. #running-req: 63, #token: 234551, token usage: 0.95, cuda graph: True, gen throughput (token/s): 690.34, #queue-req: 36\n",
      "[2025-08-13 21:02:43] INFO:     127.0.0.1:47472 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:43] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 412, token usage: 0.94, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 21:02:44] INFO:     127.0.0.1:51404 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:44] Prefill batch. #new-seq: 1, #new-token: 4124, #cached-token: 93, token usage: 0.95, #running-req: 62, #queue-req: 35\n",
      "[2025-08-13 21:02:45] Decode batch. #running-req: 63, #token: 238411, token usage: 0.97, cuda graph: True, gen throughput (token/s): 758.99, #queue-req: 36\n",
      "[2025-08-13 21:02:45] INFO:     127.0.0.1:46190 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:48] INFO:     127.0.0.1:40606 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:48] Decode batch. #running-req: 61, #token: 234934, token usage: 0.96, cuda graph: True, gen throughput (token/s): 890.20, #queue-req: 37\n",
      "[2025-08-13 21:02:48] INFO:     127.0.0.1:38542 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:48] Prefill batch. #new-seq: 2, #new-token: 6526, #cached-token: 591, token usage: 0.93, #running-req: 60, #queue-req: 35\n",
      "[2025-08-13 21:02:50] INFO:     127.0.0.1:37894 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:50] Prefill batch. #new-seq: 2, #new-token: 2573, #cached-token: 897, token usage: 0.95, #running-req: 61, #queue-req: 35\n",
      "[2025-08-13 21:02:52] Decode batch. #running-req: 63, #token: 236717, token usage: 0.96, cuda graph: True, gen throughput (token/s): 712.26, #queue-req: 36\n",
      "[2025-08-13 21:02:52] INFO:     127.0.0.1:59570 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:54] Decode batch. #running-req: 62, #token: 238854, token usage: 0.97, cuda graph: True, gen throughput (token/s): 920.51, #queue-req: 37\n",
      "[2025-08-13 21:02:57] Decode batch. #running-req: 62, #token: 241334, token usage: 0.98, cuda graph: True, gen throughput (token/s): 911.14, #queue-req: 37\n",
      "[2025-08-13 21:02:57] INFO:     127.0.0.1:34594 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:58] INFO:     127.0.0.1:51426 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:58] INFO:     127.0.0.1:50514 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:59] INFO:     127.0.0.1:33278 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:02:59] Prefill batch. #new-seq: 1, #new-token: 4381, #cached-token: 441, token usage: 0.95, #running-req: 58, #queue-req: 39\n",
      "[2025-08-13 21:02:59] INFO:     127.0.0.1:51548 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:00] INFO:     127.0.0.1:50534 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:00] Prefill batch. #new-seq: 1, #new-token: 7860, #cached-token: 413, token usage: 0.94, #running-req: 57, #queue-req: 38\n",
      "[2025-08-13 21:03:00] Decode batch. #running-req: 57, #token: 238792, token usage: 0.97, cuda graph: True, gen throughput (token/s): 750.01, #queue-req: 38\n",
      "[2025-08-13 21:03:02] INFO:     127.0.0.1:33292 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:03] INFO:     127.0.0.1:50554 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:03] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 413, token usage: 0.92, #running-req: 56, #queue-req: 40\n",
      "[2025-08-13 21:03:03] Prefill batch. #new-seq: 1, #new-token: 1863, #cached-token: 0, token usage: 0.96, #running-req: 56, #queue-req: 40\n",
      "[2025-08-13 21:03:04] INFO:     127.0.0.1:50558 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:04] Prefill batch. #new-seq: 2, #new-token: 458, #cached-token: 581, token usage: 0.95, #running-req: 56, #queue-req: 41\n",
      "[2025-08-13 21:03:05] Decode batch. #running-req: 58, #token: 230092, token usage: 0.94, cuda graph: True, gen throughput (token/s): 503.90, #queue-req: 41\n",
      "[2025-08-13 21:03:05] INFO:     127.0.0.1:47480 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:05] Prefill batch. #new-seq: 1, #new-token: 7708, #cached-token: 410, token usage: 0.94, #running-req: 57, #queue-req: 41\n",
      "[2025-08-13 21:03:07] INFO:     127.0.0.1:33294 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:07] Prefill batch. #new-seq: 3, #new-token: 6710, #cached-token: 1018, token usage: 0.94, #running-req: 57, #queue-req: 38\n",
      "[2025-08-13 21:03:08] INFO:     127.0.0.1:45536 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:08] Prefill batch. #new-seq: 1, #new-token: 2155, #cached-token: 136, token usage: 0.96, #running-req: 59, #queue-req: 38\n",
      "[2025-08-13 21:03:08] INFO:     127.0.0.1:47492 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:08] INFO:     127.0.0.1:40582 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:08] Prefill batch. #new-seq: 2, #new-token: 5689, #cached-token: 265, token usage: 0.95, #running-req: 58, #queue-req: 36\n",
      "[2025-08-13 21:03:09] Decode batch. #running-req: 60, #token: 239079, token usage: 0.97, cuda graph: True, gen throughput (token/s): 494.67, #queue-req: 39\n",
      "[2025-08-13 21:03:11] INFO:     127.0.0.1:54160 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:12] INFO:     127.0.0.1:33272 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:12] Prefill batch. #new-seq: 1, #new-token: 1444, #cached-token: 136, token usage: 0.95, #running-req: 58, #queue-req: 38\n",
      "[2025-08-13 21:03:12] Decode batch. #running-req: 59, #token: 235812, token usage: 0.96, cuda graph: True, gen throughput (token/s): 816.98, #queue-req: 38\n",
      "[2025-08-13 21:03:13] INFO:     127.0.0.1:54150 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:13] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 392, token usage: 0.95, #running-req: 58, #queue-req: 37\n",
      "[2025-08-13 21:03:14] INFO:     127.0.0.1:59286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:14] Prefill batch. #new-seq: 1, #new-token: 6743, #cached-token: 462, token usage: 0.94, #running-req: 58, #queue-req: 38\n",
      "[2025-08-13 21:03:16] Decode batch. #running-req: 59, #token: 239176, token usage: 0.97, cuda graph: True, gen throughput (token/s): 695.59, #queue-req: 40\n",
      "[2025-08-13 21:03:17] INFO:     127.0.0.1:57694 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:17] Prefill batch. #new-seq: 1, #new-token: 2358, #cached-token: 437, token usage: 0.96, #running-req: 58, #queue-req: 39\n",
      "[2025-08-13 21:03:18] INFO:     127.0.0.1:45532 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:18] INFO:     127.0.0.1:45548 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:18] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 449, token usage: 0.95, #running-req: 57, #queue-req: 38\n",
      "[2025-08-13 21:03:19] INFO:     127.0.0.1:45562 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:19] Prefill batch. #new-seq: 1, #new-token: 2143, #cached-token: 148, token usage: 0.96, #running-req: 57, #queue-req: 37\n",
      "[2025-08-13 21:03:19] Decode batch. #running-req: 58, #token: 235380, token usage: 0.96, cuda graph: True, gen throughput (token/s): 694.66, #queue-req: 37\n",
      "[2025-08-13 21:03:19] INFO:     127.0.0.1:57702 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:19] Prefill batch. #new-seq: 1, #new-token: 2359, #cached-token: 441, token usage: 0.96, #running-req: 57, #queue-req: 36\n",
      "[2025-08-13 21:03:22] INFO:     127.0.0.1:59562 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:22] Prefill batch. #new-seq: 2, #new-token: 2252, #cached-token: 229, token usage: 0.94, #running-req: 57, #queue-req: 34\n",
      "[2025-08-13 21:03:22] Decode batch. #running-req: 59, #token: 233369, token usage: 0.95, cuda graph: True, gen throughput (token/s): 739.37, #queue-req: 34\n",
      "[2025-08-13 21:03:23] INFO:     127.0.0.1:57708 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:23] Prefill batch. #new-seq: 3, #new-token: 6626, #cached-token: 1332, token usage: 0.92, #running-req: 58, #queue-req: 31\n",
      "[2025-08-13 21:03:24] INFO:     127.0.0.1:40616 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:24] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 781, token usage: 0.91, #running-req: 60, #queue-req: 31\n",
      "[2025-08-13 21:03:24] Prefill batch. #new-seq: 2, #new-token: 3469, #cached-token: 412, token usage: 0.95, #running-req: 60, #queue-req: 30\n",
      "[2025-08-13 21:03:27] Decode batch. #running-req: 62, #token: 237555, token usage: 0.97, cuda graph: True, gen throughput (token/s): 541.39, #queue-req: 37\n",
      "[2025-08-13 21:03:28] INFO:     127.0.0.1:53226 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:28] INFO:     127.0.0.1:54190 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:28] Prefill batch. #new-seq: 2, #new-token: 2244, #cached-token: 610, token usage: 0.95, #running-req: 60, #queue-req: 35\n",
      "[2025-08-13 21:03:29] INFO:     127.0.0.1:57718 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:29] Prefill batch. #new-seq: 1, #new-token: 4353, #cached-token: 469, token usage: 0.95, #running-req: 61, #queue-req: 34\n",
      ".[2025-08-13 21:03:30] Decode batch. #running-req: 62, #token: 238774, token usage: 0.97, cuda graph: True, gen throughput (token/s): 737.98, #queue-req: 36\n",
      "[2025-08-13 21:03:30] INFO:     127.0.0.1:56662 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:31] INFO:     127.0.0.1:53238 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:31] INFO:     127.0.0.1:43080 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:31] INFO:     127.0.0.1:35972 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:31] Prefill batch. #new-seq: 3, #new-token: 7431, #cached-token: 1475, token usage: 0.90, #running-req: 59, #queue-req: 33\n",
      "[2025-08-13 21:03:32] Prefill batch. #new-seq: 2, #new-token: 2261, #cached-token: 563, token usage: 0.93, #running-req: 61, #queue-req: 31\n",
      ".[2025-08-13 21:03:33] INFO:     127.0.0.1:51546 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:33] Prefill batch. #new-seq: 1, #new-token: 5735, #cached-token: 77, token usage: 0.93, #running-req: 62, #queue-req: 30\n",
      "[2025-08-13 21:03:34] Decode batch. #running-req: 63, #token: 236109, token usage: 0.96, cuda graph: True, gen throughput (token/s): 605.83, #queue-req: 31\n",
      "[2025-08-13 21:03:35] INFO:     127.0.0.1:56688 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:36] Prefill batch. #new-seq: 1, #new-token: 3157, #cached-token: 480, token usage: 0.95, #running-req: 62, #queue-req: 33\n",
      "[2025-08-13 21:03:37] Decode batch. #running-req: 63, #token: 237480, token usage: 0.97, cuda graph: True, gen throughput (token/s): 839.92, #queue-req: 34\n",
      "[2025-08-13 21:03:39] INFO:     127.0.0.1:53222 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:39] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 434, token usage: 0.96, #running-req: 62, #queue-req: 33\n",
      "[2025-08-13 21:03:40] INFO:     127.0.0.1:35984 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:40] Prefill batch. #new-seq: 2, #new-token: 4746, #cached-token: 897, token usage: 0.94, #running-req: 62, #queue-req: 31\n",
      "[2025-08-13 21:03:40] INFO:     127.0.0.1:60194 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:40] Decode batch. #running-req: 63, #token: 235913, token usage: 0.96, cuda graph: True, gen throughput (token/s): 794.71, #queue-req: 31\n",
      "[2025-08-13 21:03:41] INFO:     127.0.0.1:59564 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:41] Prefill batch. #new-seq: 2, #new-token: 6491, #cached-token: 593, token usage: 0.93, #running-req: 62, #queue-req: 30\n",
      "[2025-08-13 21:03:43] INFO:     127.0.0.1:51434 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:43] Prefill batch. #new-seq: 1, #new-token: 2165, #cached-token: 467, token usage: 0.95, #running-req: 63, #queue-req: 32\n",
      "[2025-08-13 21:03:44] Decode batch. #running-req: 64, #token: 236551, token usage: 0.96, cuda graph: True, gen throughput (token/s): 726.26, #queue-req: 32\n",
      "[2025-08-13 21:03:46] INFO:     127.0.0.1:50514 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:46] INFO:     127.0.0.1:54108 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:46] Prefill batch. #new-seq: 1, #new-token: 2641, #cached-token: 392, token usage: 0.95, #running-req: 62, #queue-req: 32\n",
      "[2025-08-13 21:03:46] INFO:     127.0.0.1:51522 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:46] Prefill batch. #new-seq: 1, #new-token: 5198, #cached-token: 412, token usage: 0.94, #running-req: 62, #queue-req: 31\n",
      "[2025-08-13 21:03:47] Decode batch. #running-req: 63, #token: 235797, token usage: 0.96, cuda graph: True, gen throughput (token/s): 733.46, #queue-req: 31\n",
      ".[2025-08-13 21:03:48] INFO:     127.0.0.1:50554 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:48] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 448, token usage: 0.94, #running-req: 62, #queue-req: 32\n",
      "[2025-08-13 21:03:49] INFO:     127.0.0.1:54138 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:49] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 859, token usage: 0.92, #running-req: 62, #queue-req: 31\n",
      "[2025-08-13 21:03:49] Prefill batch. #new-seq: 2, #new-token: 2778, #cached-token: 446, token usage: 0.95, #running-req: 63, #queue-req: 30\n",
      ".[2025-08-13 21:03:51] Decode batch. #running-req: 65, #token: 236848, token usage: 0.96, cuda graph: True, gen throughput (token/s): 639.57, #queue-req: 30\n",
      "[2025-08-13 21:03:51] INFO:     127.0.0.1:47480 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:52] Prefill batch. #new-seq: 2, #new-token: 5764, #cached-token: 594, token usage: 0.95, #running-req: 64, #queue-req: 28\n",
      "[2025-08-13 21:03:52] INFO:     127.0.0.1:34594 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:52] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 93, token usage: 0.96, #running-req: 65, #queue-req: 27\n",
      "[2025-08-13 21:03:53] INFO:     127.0.0.1:53114 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:53] INFO:     127.0.0.1:53638 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:54] Prefill batch. #new-seq: 2, #new-token: 4580, #cached-token: 854, token usage: 0.92, #running-req: 64, #queue-req: 25\n",
      "[2025-08-13 21:03:54] INFO:     127.0.0.1:50534 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:54] Prefill batch. #new-seq: 3, #new-token: 5291, #cached-token: 636, token usage: 0.92, #running-req: 65, #queue-req: 23\n",
      "[2025-08-13 21:03:54] INFO:     127.0.0.1:53644 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:55] Prefill batch. #new-seq: 1, #new-token: 5733, #cached-token: 410, token usage: 0.93, #running-req: 67, #queue-req: 23\n",
      "[2025-08-13 21:03:55] INFO:     127.0.0.1:46592 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:55] Prefill batch. #new-seq: 1, #new-token: 2316, #cached-token: 480, token usage: 0.91, #running-req: 67, #queue-req: 22\n",
      "[2025-08-13 21:03:56] INFO:     127.0.0.1:51516 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:56] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.90, #running-req: 67, #queue-req: 21\n",
      "[2025-08-13 21:03:56] Prefill batch. #new-seq: 2, #new-token: 3776, #cached-token: 149, token usage: 0.93, #running-req: 67, #queue-req: 20\n",
      ".[2025-08-13 21:03:57] INFO:     127.0.0.1:53654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:57] Prefill batch. #new-seq: 1, #new-token: 2491, #cached-token: 159, token usage: 0.93, #running-req: 68, #queue-req: 21\n",
      "[2025-08-13 21:03:58] Decode batch. #running-req: 69, #token: 232127, token usage: 0.94, cuda graph: True, gen throughput (token/s): 417.87, #queue-req: 23\n",
      "[2025-08-13 21:03:58] INFO:     127.0.0.1:53666 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:58] Prefill batch. #new-seq: 2, #new-token: 7290, #cached-token: 855, token usage: 0.91, #running-req: 68, #queue-req: 21\n",
      "[2025-08-13 21:03:58] INFO:     127.0.0.1:53680 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:03:59] Prefill batch. #new-seq: 1, #new-token: 916, #cached-token: 146, token usage: 0.94, #running-req: 69, #queue-req: 20\n",
      "[2025-08-13 21:04:01] INFO:     127.0.0.1:60208 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:01] Prefill batch. #new-seq: 1, #new-token: 2348, #cached-token: 453, token usage: 0.95, #running-req: 69, #queue-req: 23\n",
      "[2025-08-13 21:04:02] Decode batch. #running-req: 70, #token: 234993, token usage: 0.96, cuda graph: True, gen throughput (token/s): 732.07, #queue-req: 23\n",
      "[2025-08-13 21:04:03] INFO:     127.0.0.1:57308 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:03] Prefill batch. #new-seq: 1, #new-token: 2132, #cached-token: 185, token usage: 0.94, #running-req: 69, #queue-req: 23\n",
      "[2025-08-13 21:04:04] INFO:     127.0.0.1:50558 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:04] Prefill batch. #new-seq: 2, #new-token: 2557, #cached-token: 911, token usage: 0.93, #running-req: 69, #queue-req: 21\n",
      ".[2025-08-13 21:04:05] Decode batch. #running-req: 71, #token: 231960, token usage: 0.94, cuda graph: True, gen throughput (token/s): 840.13, #queue-req: 22\n",
      "[2025-08-13 21:04:05] INFO:     127.0.0.1:53234 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:05] Prefill batch. #new-seq: 1, #new-token: 2359, #cached-token: 443, token usage: 0.93, #running-req: 70, #queue-req: 21\n",
      "[2025-08-13 21:04:06] INFO:     127.0.0.1:47492 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:06] Prefill batch. #new-seq: 1, #new-token: 4381, #cached-token: 449, token usage: 0.93, #running-req: 70, #queue-req: 20\n",
      "[2025-08-13 21:04:06] INFO:     127.0.0.1:53688 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:06] Prefill batch. #new-seq: 3, #new-token: 3985, #cached-token: 1071, token usage: 0.90, #running-req: 70, #queue-req: 17\n",
      "[2025-08-13 21:04:06] INFO:     127.0.0.1:52776 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:06] INFO:     127.0.0.1:40582 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:07] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1000, token usage: 0.88, #running-req: 71, #queue-req: 15\n",
      "[2025-08-13 21:04:07] Prefill batch. #new-seq: 2, #new-token: 1390, #cached-token: 550, token usage: 0.92, #running-req: 72, #queue-req: 14\n",
      "[2025-08-13 21:04:09] INFO:     127.0.0.1:54174 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:09] Prefill batch. #new-seq: 1, #new-token: 5503, #cached-token: 393, token usage: 0.91, #running-req: 73, #queue-req: 15\n",
      "[2025-08-13 21:04:10] INFO:     127.0.0.1:60198 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:10] Decode batch. #running-req: 74, #token: 220378, token usage: 0.90, cuda graph: True, gen throughput (token/s): 547.67, #queue-req: 15\n",
      "[2025-08-13 21:04:10] INFO:     127.0.0.1:40616 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:10] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1035, token usage: 0.90, #running-req: 73, #queue-req: 12\n",
      "[2025-08-13 21:04:10] Prefill batch. #new-seq: 1, #new-token: 799, #cached-token: 0, token usage: 0.93, #running-req: 75, #queue-req: 12\n",
      "[2025-08-13 21:04:11] Prefill batch. #new-seq: 1, #new-token: 2636, #cached-token: 480, token usage: 0.93, #running-req: 75, #queue-req: 12\n",
      "[2025-08-13 21:04:12] INFO:     127.0.0.1:51506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:13] INFO:     127.0.0.1:52790 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:14] Decode batch. #running-req: 74, #token: 229502, token usage: 0.93, cuda graph: True, gen throughput (token/s): 766.83, #queue-req: 15\n",
      "[2025-08-13 21:04:14] INFO:     127.0.0.1:37766 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:14] Prefill batch. #new-seq: 1, #new-token: 7658, #cached-token: 481, token usage: 0.91, #running-req: 73, #queue-req: 18\n",
      "[2025-08-13 21:04:18] Decode batch. #running-req: 74, #token: 234201, token usage: 0.95, cuda graph: True, gen throughput (token/s): 797.42, #queue-req: 19\n",
      "[2025-08-13 21:04:21] Decode batch. #running-req: 74, #token: 237161, token usage: 0.96, cuda graph: True, gen throughput (token/s): 989.38, #queue-req: 19\n",
      "[2025-08-13 21:04:21] INFO:     127.0.0.1:52006 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:21] INFO:     127.0.0.1:53114 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:22] Prefill batch. #new-seq: 1, #new-token: 2391, #cached-token: 96, token usage: 0.93, #running-req: 72, #queue-req: 18\n",
      "[2025-08-13 21:04:23] INFO:     127.0.0.1:53216 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:23] Prefill batch. #new-seq: 1, #new-token: 2011, #cached-token: 475, token usage: 0.93, #running-req: 72, #queue-req: 17\n",
      "[2025-08-13 21:04:24] Decode batch. #running-req: 73, #token: 231630, token usage: 0.94, cuda graph: True, gen throughput (token/s): 875.82, #queue-req: 20\n",
      "[2025-08-13 21:04:27] Decode batch. #running-req: 73, #token: 234550, token usage: 0.95, cuda graph: True, gen throughput (token/s): 988.26, #queue-req: 20\n",
      "[2025-08-13 21:04:30] Decode batch. #running-req: 73, #token: 237470, token usage: 0.97, cuda graph: True, gen throughput (token/s): 976.81, #queue-req: 20\n",
      "[2025-08-13 21:04:31] INFO:     127.0.0.1:37776 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:33] INFO:     127.0.0.1:42888 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:33] Decode batch. #running-req: 71, #token: 233530, token usage: 0.95, cuda graph: True, gen throughput (token/s): 952.56, #queue-req: 21\n",
      "[2025-08-13 21:04:34] INFO:     127.0.0.1:53244 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:34] INFO:     127.0.0.1:57304 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:34] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 914, token usage: 0.90, #running-req: 70, #queue-req: 21\n",
      "[2025-08-13 21:04:35] Prefill batch. #new-seq: 2, #new-token: 4898, #cached-token: 146, token usage: 0.93, #running-req: 71, #queue-req: 20\n",
      "[2025-08-13 21:04:37] Decode batch. #running-req: 72, #token: 234838, token usage: 0.96, cuda graph: True, gen throughput (token/s): 693.30, #queue-req: 21\n",
      "[2025-08-13 21:04:40] INFO:     127.0.0.1:58390 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:40] Prefill batch. #new-seq: 1, #new-token: 5803, #cached-token: 466, token usage: 0.93, #running-req: 71, #queue-req: 20\n",
      "[2025-08-13 21:04:41] Decode batch. #running-req: 72, #token: 235551, token usage: 0.96, cuda graph: True, gen throughput (token/s): 835.58, #queue-req: 20\n",
      "[2025-08-13 21:04:42] INFO:     127.0.0.1:59290 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:42] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 144, token usage: 0.96, #running-req: 71, #queue-req: 20\n",
      "[2025-08-13 21:04:43] INFO:     127.0.0.1:53666 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:43] Prefill batch. #new-seq: 1, #new-token: 1295, #cached-token: 126, token usage: 0.94, #running-req: 71, #queue-req: 20\n",
      "[2025-08-13 21:04:44] Decode batch. #running-req: 72, #token: 233683, token usage: 0.95, cuda graph: True, gen throughput (token/s): 960.02, #queue-req: 20\n",
      "[2025-08-13 21:04:45] INFO:     127.0.0.1:51410 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:45] INFO:     127.0.0.1:51416 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:45] INFO:     127.0.0.1:53680 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:46] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.91, #running-req: 69, #queue-req: 22\n",
      ".[2025-08-13 21:04:46] Prefill batch. #new-seq: 1, #new-token: 3547, #cached-token: 0, token usage: 0.95, #running-req: 69, #queue-req: 22\n",
      "[2025-08-13 21:04:48] Decode batch. #running-req: 70, #token: 237084, token usage: 0.96, cuda graph: True, gen throughput (token/s): 677.90, #queue-req: 22\n",
      "[2025-08-13 21:04:48] INFO:     127.0.0.1:53688 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:48] Prefill batch. #new-seq: 2, #new-token: 7023, #cached-token: 942, token usage: 0.92, #running-req: 69, #queue-req: 20\n",
      "[2025-08-13 21:04:50] INFO:     127.0.0.1:52776 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:50] Prefill batch. #new-seq: 1, #new-token: 2250, #cached-token: 149, token usage: 0.93, #running-req: 70, #queue-req: 20\n",
      "[2025-08-13 21:04:52] Decode batch. #running-req: 71, #token: 231574, token usage: 0.94, cuda graph: True, gen throughput (token/s): 772.00, #queue-req: 21\n",
      "[2025-08-13 21:04:52] INFO:     127.0.0.1:39650 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:54] INFO:     127.0.0.1:40884 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:54] Prefill batch. #new-seq: 1, #new-token: 4997, #cached-token: 465, token usage: 0.93, #running-req: 69, #queue-req: 21\n",
      "[2025-08-13 21:04:55] Decode batch. #running-req: 70, #token: 235197, token usage: 0.96, cuda graph: True, gen throughput (token/s): 833.36, #queue-req: 22\n",
      "[2025-08-13 21:04:55] INFO:     127.0.0.1:52012 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:55] Prefill batch. #new-seq: 1, #new-token: 2284, #cached-token: 126, token usage: 0.95, #running-req: 69, #queue-req: 21\n",
      "[2025-08-13 21:04:58] INFO:     127.0.0.1:59288 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:58] Prefill batch. #new-seq: 2, #new-token: 2939, #cached-token: 556, token usage: 0.92, #running-req: 69, #queue-req: 21\n",
      "[2025-08-13 21:04:58] INFO:     127.0.0.1:46732 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:58] INFO:     127.0.0.1:43188 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:04:58] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.91, #running-req: 69, #queue-req: 20\n",
      "[2025-08-13 21:04:58] Prefill batch. #new-seq: 1, #new-token: 1742, #cached-token: 0, token usage: 0.94, #running-req: 69, #queue-req: 20\n",
      "[2025-08-13 21:04:59] Decode batch. #running-req: 70, #token: 233479, token usage: 0.95, cuda graph: True, gen throughput (token/s): 638.22, #queue-req: 20\n",
      "[2025-08-13 21:05:00] INFO:     127.0.0.1:47624 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:00] Prefill batch. #new-seq: 2, #new-token: 2491, #cached-token: 568, token usage: 0.94, #running-req: 69, #queue-req: 20\n",
      "[2025-08-13 21:05:01] INFO:     127.0.0.1:42872 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:01] Prefill batch. #new-seq: 1, #new-token: 4826, #cached-token: 480, token usage: 0.94, #running-req: 70, #queue-req: 20\n",
      "[2025-08-13 21:05:02] INFO:     127.0.0.1:46718 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:02] Prefill batch. #new-seq: 1, #new-token: 228, #cached-token: 412, token usage: 0.95, #running-req: 70, #queue-req: 19\n",
      "[2025-08-13 21:05:03] Decode batch. #running-req: 71, #token: 230398, token usage: 0.94, cuda graph: True, gen throughput (token/s): 782.23, #queue-req: 19\n",
      "[2025-08-13 21:05:03] INFO:     127.0.0.1:53216 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:03] Prefill batch. #new-seq: 1, #new-token: 2220, #cached-token: 96, token usage: 0.94, #running-req: 70, #queue-req: 18\n",
      ".[2025-08-13 21:05:04] INFO:     127.0.0.1:59294 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:04] Prefill batch. #new-seq: 2, #new-token: 6165, #cached-token: 301, token usage: 0.91, #running-req: 70, #queue-req: 16\n",
      "[2025-08-13 21:05:05] INFO:     127.0.0.1:37776 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:07] Decode batch. #running-req: 71, #token: 227982, token usage: 0.93, cuda graph: True, gen throughput (token/s): 789.31, #queue-req: 19\n",
      "[2025-08-13 21:05:07] INFO:     127.0.0.1:60212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:08] INFO:     127.0.0.1:48134 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:09] Decode batch. #running-req: 69, #token: 226323, token usage: 0.92, cuda graph: True, gen throughput (token/s): 976.23, #queue-req: 19\n",
      "[2025-08-13 21:05:10] INFO:     127.0.0.1:52790 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:10] INFO:     127.0.0.1:43174 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:10] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.86, #running-req: 67, #queue-req: 18\n",
      "[2025-08-13 21:05:10] INFO:     127.0.0.1:51998 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:10] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1026, token usage: 0.90, #running-req: 67, #queue-req: 15\n",
      "[2025-08-13 21:05:11] Prefill batch. #new-seq: 2, #new-token: 4692, #cached-token: 875, token usage: 0.93, #running-req: 71, #queue-req: 14\n",
      "[2025-08-13 21:05:13] INFO:     127.0.0.1:53244 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:13] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 913, token usage: 0.90, #running-req: 71, #queue-req: 12\n",
      "[2025-08-13 21:05:13] Prefill batch. #new-seq: 1, #new-token: 6058, #cached-token: 0, token usage: 0.93, #running-req: 72, #queue-req: 12\n",
      "[2025-08-13 21:05:15] INFO:     127.0.0.1:52578 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:05:15] Prefill batch. #new-seq: 1, #new-token: 2344, #cached-token: 457, token usage: 0.94, #running-req: 72, #queue-req: 12\n",
      "[2025-08-13 21:05:16] Decode batch. #running-req: 73, #token: 234304, token usage: 0.95, cuda graph: True, gen throughput (token/s): 426.52, #queue-req: 13\n",
      "[2025-08-13 21:05:18] INFO:     127.0.0.1:42598 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:19] Decode batch. #running-req: 72, #token: 236256, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1002.54, #queue-req: 17\n",
      "[2025-08-13 21:05:21] INFO:     127.0.0.1:51496 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:22] Decode batch. #running-req: 71, #token: 236877, token usage: 0.96, cuda graph: True, gen throughput (token/s): 968.48, #queue-req: 19\n",
      "[2025-08-13 21:05:22] INFO:     127.0.0.1:51520 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:22] Prefill batch. #new-seq: 1, #new-token: 947, #cached-token: 191, token usage: 0.95, #running-req: 70, #queue-req: 19\n",
      "[2025-08-13 21:05:22] INFO:     127.0.0.1:51524 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:22] INFO:     127.0.0.1:51530 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:22] Prefill batch. #new-seq: 2, #new-token: 2755, #cached-token: 543, token usage: 0.92, #running-req: 69, #queue-req: 19\n",
      "[2025-08-13 21:05:24] INFO:     127.0.0.1:51416 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:24] Prefill batch. #new-seq: 2, #new-token: 6729, #cached-token: 895, token usage: 0.93, #running-req: 70, #queue-req: 17\n",
      "[2025-08-13 21:05:25] INFO:     127.0.0.1:51410 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:25] Prefill batch. #new-seq: 1, #new-token: 1948, #cached-token: 446, token usage: 0.94, #running-req: 71, #queue-req: 17\n",
      "[2025-08-13 21:05:25] INFO:     127.0.0.1:52596 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:26] Prefill batch. #new-seq: 1, #new-token: 2346, #cached-token: 455, token usage: 0.92, #running-req: 71, #queue-req: 16\n",
      "[2025-08-13 21:05:26] Decode batch. #running-req: 72, #token: 228113, token usage: 0.93, cuda graph: True, gen throughput (token/s): 670.95, #queue-req: 16\n",
      "[2025-08-13 21:05:28] INFO:     127.0.0.1:59552 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:28] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 393, token usage: 0.93, #running-req: 71, #queue-req: 18\n",
      "[2025-08-13 21:05:28] Prefill batch. #new-seq: 1, #new-token: 1469, #cached-token: 0, token usage: 0.96, #running-req: 71, #queue-req: 18\n",
      "[2025-08-13 21:05:30] Decode batch. #running-req: 72, #token: 238160, token usage: 0.97, cuda graph: True, gen throughput (token/s): 741.34, #queue-req: 18\n",
      "[2025-08-13 21:05:30] INFO:     127.0.0.1:59294 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:30] Prefill batch. #new-seq: 2, #new-token: 3698, #cached-token: 867, token usage: 0.93, #running-req: 71, #queue-req: 16\n",
      "[2025-08-13 21:05:32] INFO:     127.0.0.1:58422 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:32] Prefill batch. #new-seq: 2, #new-token: 2359, #cached-token: 572, token usage: 0.94, #running-req: 72, #queue-req: 15\n",
      "[2025-08-13 21:05:33] Decode batch. #running-req: 74, #token: 234713, token usage: 0.95, cuda graph: True, gen throughput (token/s): 861.19, #queue-req: 16\n",
      "[2025-08-13 21:05:36] INFO:     127.0.0.1:59288 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:36] Prefill batch. #new-seq: 1, #new-token: 2346, #cached-token: 455, token usage: 0.95, #running-req: 73, #queue-req: 15\n",
      "[2025-08-13 21:05:36] INFO:     127.0.0.1:54122 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:37] Decode batch. #running-req: 74, #token: 230547, token usage: 0.94, cuda graph: True, gen throughput (token/s): 961.33, #queue-req: 15\n",
      "[2025-08-13 21:05:37] Prefill batch. #new-seq: 1, #new-token: 4480, #cached-token: 180, token usage: 0.94, #running-req: 73, #queue-req: 16\n",
      "[2025-08-13 21:05:37] INFO:     127.0.0.1:47648 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:38] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 119, token usage: 0.95, #running-req: 73, #queue-req: 15\n",
      "[2025-08-13 21:05:38] INFO:     127.0.0.1:47526 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:38] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 393, token usage: 0.90, #running-req: 73, #queue-req: 14\n",
      "[2025-08-13 21:05:38] Prefill batch. #new-seq: 1, #new-token: 1426, #cached-token: 0, token usage: 0.94, #running-req: 73, #queue-req: 14\n",
      "[2025-08-13 21:05:41] Decode batch. #running-req: 74, #token: 233637, token usage: 0.95, cuda graph: True, gen throughput (token/s): 697.07, #queue-req: 16\n",
      "[2025-08-13 21:05:41] INFO:     127.0.0.1:42910 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:41] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 448, token usage: 0.95, #running-req: 73, #queue-req: 15\n",
      "[2025-08-13 21:05:44] Decode batch. #running-req: 74, #token: 237364, token usage: 0.97, cuda graph: True, gen throughput (token/s): 961.93, #queue-req: 16\n",
      "[2025-08-13 21:05:45] INFO:     127.0.0.1:54202 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:45] Prefill batch. #new-seq: 1, #new-token: 901, #cached-token: 439, token usage: 0.95, #running-req: 73, #queue-req: 16\n",
      "[2025-08-13 21:05:47] Decode batch. #running-req: 74, #token: 237057, token usage: 0.96, cuda graph: True, gen throughput (token/s): 989.90, #queue-req: 16\n",
      "[2025-08-13 21:05:50] Decode batch. #running-req: 74, #token: 240017, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1008.82, #queue-req: 16\n",
      "[2025-08-13 21:05:50] INFO:     127.0.0.1:47514 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:51] INFO:     127.0.0.1:57310 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:51] Prefill batch. #new-seq: 1, #new-token: 2272, #cached-token: 550, token usage: 0.94, #running-req: 72, #queue-req: 16\n",
      "[2025-08-13 21:05:51] INFO:     127.0.0.1:47520 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:51] Prefill batch. #new-seq: 1, #new-token: 4263, #cached-token: 456, token usage: 0.95, #running-req: 72, #queue-req: 15\n",
      "[2025-08-13 21:05:53] Decode batch. #running-req: 73, #token: 238196, token usage: 0.97, cuda graph: True, gen throughput (token/s): 847.19, #queue-req: 17\n",
      "[2025-08-13 21:05:56] Decode batch. #running-req: 73, #token: 241116, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1023.87, #queue-req: 17\n",
      "[2025-08-13 21:05:56] INFO:     127.0.0.1:51496 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:05:59] Decode batch. #running-req: 72, #token: 241660, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1025.82, #queue-req: 18\n",
      "[2025-08-13 21:06:00] INFO:     127.0.0.1:43210 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:01] INFO:     127.0.0.1:51520 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:02] Decode batch. #running-req: 70, #token: 238205, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1012.19, #queue-req: 18\n",
      "[2025-08-13 21:06:05] Decode batch. #running-req: 70, #token: 241005, token usage: 0.98, cuda graph: True, gen throughput (token/s): 998.77, #queue-req: 20\n",
      "[2025-08-13 21:06:05] INFO:     127.0.0.1:51766 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:07] Decode batch. #running-req: 69, #token: 238925, token usage: 0.97, cuda graph: True, gen throughput (token/s): 988.52, #queue-req: 21\n",
      "[2025-08-13 21:06:10] INFO:     127.0.0.1:42302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:10] Decode batch. #running-req: 68, #token: 239670, token usage: 0.97, cuda graph: True, gen throughput (token/s): 980.80, #queue-req: 21\n",
      "[2025-08-13 21:06:13] Decode batch. #running-req: 68, #token: 242390, token usage: 0.99, cuda graph: True, gen throughput (token/s): 973.37, #queue-req: 22\n",
      "[2025-08-13 21:06:14] INFO:     127.0.0.1:52594 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:14] INFO:     127.0.0.1:42278 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:15] INFO:     127.0.0.1:42624 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:15] Prefill batch. #new-seq: 1, #new-token: 4917, #cached-token: 409, token usage: 0.95, #running-req: 65, #queue-req: 21\n",
      "[2025-08-13 21:06:15] INFO:     127.0.0.1:60218 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:16] Decode batch. #running-req: 65, #token: 240040, token usage: 0.98, cuda graph: True, gen throughput (token/s): 810.10, #queue-req: 22\n",
      "[2025-08-13 21:06:17] INFO:     127.0.0.1:46756 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:17] Prefill batch. #new-seq: 1, #new-token: 2123, #cached-token: 125, token usage: 0.96, #running-req: 64, #queue-req: 24\n",
      "[2025-08-13 21:06:19] INFO:     127.0.0.1:42892 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:19] Decode batch. #running-req: 64, #token: 238438, token usage: 0.97, cuda graph: True, gen throughput (token/s): 842.73, #queue-req: 26\n",
      "[2025-08-13 21:06:20] INFO:     127.0.0.1:42902 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:20] Prefill batch. #new-seq: 1, #new-token: 2240, #cached-token: 393, token usage: 0.95, #running-req: 63, #queue-req: 26\n",
      "[2025-08-13 21:06:22] Decode batch. #running-req: 64, #token: 238882, token usage: 0.97, cuda graph: True, gen throughput (token/s): 870.25, #queue-req: 26\n",
      "[2025-08-13 21:06:23] INFO:     127.0.0.1:51530 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:24] INFO:     127.0.0.1:43166 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:24] Prefill batch. #new-seq: 1, #new-token: 2636, #cached-token: 480, token usage: 0.95, #running-req: 62, #queue-req: 25\n",
      "[2025-08-13 21:06:24] INFO:     127.0.0.1:56228 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:25] INFO:     127.0.0.1:51524 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:25] Prefill batch. #new-seq: 1, #new-token: 8027, #cached-token: 551, token usage: 0.94, #running-req: 61, #queue-req: 26\n",
      "[2025-08-13 21:06:26] Decode batch. #running-req: 62, #token: 239159, token usage: 0.97, cuda graph: True, gen throughput (token/s): 663.84, #queue-req: 26\n",
      "[2025-08-13 21:06:27] INFO:     127.0.0.1:43202 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:27] INFO:     127.0.0.1:43216 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:27] Prefill batch. #new-seq: 1, #new-token: 2576, #cached-token: 96, token usage: 0.94, #running-req: 61, #queue-req: 28\n",
      "[2025-08-13 21:06:28] INFO:     127.0.0.1:58384 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:28] Prefill batch. #new-seq: 1, #new-token: 7729, #cached-token: 464, token usage: 0.94, #running-req: 60, #queue-req: 28\n",
      "[2025-08-13 21:06:29] INFO:     127.0.0.1:46750 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:29] Prefill batch. #new-seq: 1, #new-token: 2200, #cached-token: 455, token usage: 0.95, #running-req: 60, #queue-req: 28\n",
      "[2025-08-13 21:06:30] Decode batch. #running-req: 61, #token: 237366, token usage: 0.97, cuda graph: True, gen throughput (token/s): 620.15, #queue-req: 28\n",
      "[2025-08-13 21:06:30] INFO:     127.0.0.1:48150 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:30] Prefill batch. #new-seq: 1, #new-token: 2162, #cached-token: 471, token usage: 0.95, #running-req: 60, #queue-req: 28\n",
      "[2025-08-13 21:06:31] INFO:     127.0.0.1:39698 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:31] Prefill batch. #new-seq: 2, #new-token: 6017, #cached-token: 599, token usage: 0.93, #running-req: 60, #queue-req: 26\n",
      ".[2025-08-13 21:06:33] INFO:     127.0.0.1:54122 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:33] Prefill batch. #new-seq: 2, #new-token: 2356, #cached-token: 1111, token usage: 0.94, #running-req: 61, #queue-req: 25\n",
      "[2025-08-13 21:06:34] Decode batch. #running-req: 63, #token: 234883, token usage: 0.96, cuda graph: True, gen throughput (token/s): 672.34, #queue-req: 25\n",
      "[2025-08-13 21:06:35] INFO:     127.0.0.1:58360 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:35] Prefill batch. #new-seq: 1, #new-token: 4244, #cached-token: 409, token usage: 0.94, #running-req: 62, #queue-req: 25\n",
      "[2025-08-13 21:06:36] INFO:     127.0.0.1:59552 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:36] Prefill batch. #new-seq: 2, #new-token: 6616, #cached-token: 617, token usage: 0.95, #running-req: 62, #queue-req: 23\n",
      "[2025-08-13 21:06:36] INFO:     127.0.0.1:57312 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:37] INFO:     127.0.0.1:54202 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:37] Prefill batch. #new-seq: 1, #new-token: 2227, #cached-token: 460, token usage: 0.95, #running-req: 62, #queue-req: 25\n",
      "[2025-08-13 21:06:37] INFO:     127.0.0.1:58352 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:37] Prefill batch. #new-seq: 3, #new-token: 3079, #cached-token: 1252, token usage: 0.93, #running-req: 62, #queue-req: 22\n",
      "[2025-08-13 21:06:38] Decode batch. #running-req: 65, #token: 233174, token usage: 0.95, cuda graph: True, gen throughput (token/s): 605.20, #queue-req: 22\n",
      "[2025-08-13 21:06:39] INFO:     127.0.0.1:48120 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:39] Prefill batch. #new-seq: 2, #new-token: 5962, #cached-token: 537, token usage: 0.94, #running-req: 64, #queue-req: 20\n",
      "[2025-08-13 21:06:41] Decode batch. #running-req: 66, #token: 237554, token usage: 0.97, cuda graph: True, gen throughput (token/s): 783.17, #queue-req: 23\n",
      "[2025-08-13 21:06:43] INFO:     127.0.0.1:55302 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:44] Prefill batch. #new-seq: 1, #new-token: 4361, #cached-token: 459, token usage: 0.95, #running-req: 65, #queue-req: 22\n",
      ".[2025-08-13 21:06:44] Decode batch. #running-req: 66, #token: 238529, token usage: 0.97, cuda graph: True, gen throughput (token/s): 808.63, #queue-req: 22\n",
      "[2025-08-13 21:06:45] INFO:     127.0.0.1:60218 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:45] Prefill batch. #new-seq: 1, #new-token: 413, #cached-token: 146, token usage: 0.95, #running-req: 65, #queue-req: 21\n",
      "[2025-08-13 21:06:45] INFO:     127.0.0.1:48154 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:45] Prefill batch. #new-seq: 2, #new-token: 4407, #cached-token: 830, token usage: 0.94, #running-req: 65, #queue-req: 19\n",
      "[2025-08-13 21:06:47] INFO:     127.0.0.1:47604 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:47] Prefill batch. #new-seq: 2, #new-token: 4433, #cached-token: 262, token usage: 0.94, #running-req: 66, #queue-req: 20\n",
      "[2025-08-13 21:06:47] INFO:     127.0.0.1:47514 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:47] INFO:     127.0.0.1:47520 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:48] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 856, token usage: 0.94, #running-req: 66, #queue-req: 18\n",
      "[2025-08-13 21:06:48] Prefill batch. #new-seq: 1, #new-token: 427, #cached-token: 0, token usage: 0.97, #running-req: 67, #queue-req: 18\n",
      "[2025-08-13 21:06:49] Decode batch. #running-req: 68, #token: 239124, token usage: 0.97, cuda graph: True, gen throughput (token/s): 603.76, #queue-req: 18\n",
      "[2025-08-13 21:06:49] INFO:     127.0.0.1:47610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:50] INFO:     127.0.0.1:47622 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:51] INFO:     127.0.0.1:47640 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:51] Prefill batch. #new-seq: 2, #new-token: 2714, #cached-token: 559, token usage: 0.93, #running-req: 66, #queue-req: 20\n",
      "[2025-08-13 21:06:51] INFO:     127.0.0.1:46748 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:51] Prefill batch. #new-seq: 1, #new-token: 5031, #cached-token: 462, token usage: 0.93, #running-req: 66, #queue-req: 21\n",
      "[2025-08-13 21:06:52] Decode batch. #running-req: 67, #token: 234258, token usage: 0.95, cuda graph: True, gen throughput (token/s): 755.29, #queue-req: 21\n",
      "[2025-08-13 21:06:53] INFO:     127.0.0.1:46760 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:53] INFO:     127.0.0.1:46770 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:53] INFO:     127.0.0.1:55344 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:53] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 616, token usage: 0.90, #running-req: 64, #queue-req: 21\n",
      "[2025-08-13 21:06:53] Prefill batch. #new-seq: 3, #new-token: 4927, #cached-token: 610, token usage: 0.93, #running-req: 65, #queue-req: 19\n",
      "[2025-08-13 21:06:54] INFO:     127.0.0.1:43216 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:55] Prefill batch. #new-seq: 1, #new-token: 2783, #cached-token: 409, token usage: 0.94, #running-req: 67, #queue-req: 19\n",
      "[2025-08-13 21:06:56] INFO:     127.0.0.1:39654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:56] Prefill batch. #new-seq: 2, #new-token: 4586, #cached-token: 898, token usage: 0.94, #running-req: 67, #queue-req: 19\n",
      "[2025-08-13 21:06:57] Decode batch. #running-req: 69, #token: 234933, token usage: 0.96, cuda graph: True, gen throughput (token/s): 591.51, #queue-req: 19\n",
      "[2025-08-13 21:06:58] INFO:     127.0.0.1:39658 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:06:58] Prefill batch. #new-seq: 1, #new-token: 2888, #cached-token: 412, token usage: 0.94, #running-req: 68, #queue-req: 19\n",
      "[2025-08-13 21:07:00] INFO:     127.0.0.1:39674 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:00] INFO:     127.0.0.1:39680 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:00] INFO:     127.0.0.1:51744 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:00] INFO:     127.0.0.1:42892 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:00] Prefill batch. #new-seq: 3, #new-token: 6879, #cached-token: 1018, token usage: 0.92, #running-req: 65, #queue-req: 18\n",
      "[2025-08-13 21:07:01] Decode batch. #running-req: 68, #token: 224571, token usage: 0.91, cuda graph: True, gen throughput (token/s): 744.04, #queue-req: 18\n",
      "[2025-08-13 21:07:01] INFO:     127.0.0.1:42902 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:01] INFO:     127.0.0.1:43166 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:01] Prefill batch. #new-seq: 2, #new-token: 2256, #cached-token: 851, token usage: 0.91, #running-req: 66, #queue-req: 16\n",
      "[2025-08-13 21:07:01] INFO:     127.0.0.1:39694 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:01] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 909, token usage: 0.91, #running-req: 67, #queue-req: 14\n",
      "[2025-08-13 21:07:01] Prefill batch. #new-seq: 2, #new-token: 4198, #cached-token: 191, token usage: 0.94, #running-req: 68, #queue-req: 13\n",
      "[2025-08-13 21:07:03] INFO:     127.0.0.1:52562 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:03] INFO:     127.0.0.1:52610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:03] Prefill batch. #new-seq: 2, #new-token: 4727, #cached-token: 559, token usage: 0.92, #running-req: 69, #queue-req: 12\n",
      "[2025-08-13 21:07:03] INFO:     127.0.0.1:58342 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:03] Prefill batch. #new-seq: 1, #new-token: 4377, #cached-token: 445, token usage: 0.94, #running-req: 69, #queue-req: 11\n",
      "[2025-08-13 21:07:06] Decode batch. #running-req: 70, #token: 233423, token usage: 0.95, cuda graph: True, gen throughput (token/s): 561.23, #queue-req: 18\n",
      "[2025-08-13 21:07:06] INFO:     127.0.0.1:58374 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:06] INFO:     127.0.0.1:42584 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:06] Prefill batch. #new-seq: 1, #new-token: 4376, #cached-token: 446, token usage: 0.94, #running-req: 68, #queue-req: 18\n",
      ".[2025-08-13 21:07:07] INFO:     127.0.0.1:43202 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:07] Prefill batch. #new-seq: 1, #new-token: 4423, #cached-token: 392, token usage: 0.94, #running-req: 68, #queue-req: 17\n",
      "[2025-08-13 21:07:08] INFO:     127.0.0.1:46748 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:08] Prefill batch. #new-seq: 1, #new-token: 6902, #cached-token: 462, token usage: 0.94, #running-req: 68, #queue-req: 17\n",
      "[2025-08-13 21:07:08] INFO:     127.0.0.1:37778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:10] Decode batch. #running-req: 68, #token: 238403, token usage: 0.97, cuda graph: True, gen throughput (token/s): 629.17, #queue-req: 17\n",
      "[2025-08-13 21:07:10] INFO:     127.0.0.1:57312 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:11] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 542, token usage: 0.92, #running-req: 67, #queue-req: 17\n",
      "[2025-08-13 21:07:11] INFO:     127.0.0.1:51784 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:11] Prefill batch. #new-seq: 1, #new-token: 978, #cached-token: 0, token usage: 0.95, #running-req: 68, #queue-req: 17\n",
      "[2025-08-13 21:07:12] INFO:     127.0.0.1:47610 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:12] Prefill batch. #new-seq: 1, #new-token: 2100, #cached-token: 96, token usage: 0.95, #running-req: 67, #queue-req: 16\n",
      "[2025-08-13 21:07:14] Decode batch. #running-req: 68, #token: 237204, token usage: 0.96, cuda graph: True, gen throughput (token/s): 694.06, #queue-req: 19\n",
      "[2025-08-13 21:07:14] INFO:     127.0.0.1:48120 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:14] Prefill batch. #new-seq: 1, #new-token: 4366, #cached-token: 455, token usage: 0.95, #running-req: 67, #queue-req: 18\n",
      "[2025-08-13 21:07:15] INFO:     127.0.0.1:47604 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:15] Prefill batch. #new-seq: 1, #new-token: 4193, #cached-token: 144, token usage: 0.95, #running-req: 67, #queue-req: 18\n",
      "[2025-08-13 21:07:16] INFO:     127.0.0.1:47622 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:16] Prefill batch. #new-seq: 1, #new-token: 2020, #cached-token: 666, token usage: 0.95, #running-req: 67, #queue-req: 17\n",
      "[2025-08-13 21:07:17] INFO:     127.0.0.1:43882 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:18] Decode batch. #running-req: 67, #token: 235414, token usage: 0.96, cuda graph: True, gen throughput (token/s): 704.33, #queue-req: 19\n",
      "[2025-08-13 21:07:18] INFO:     127.0.0.1:58406 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:19] Prefill batch. #new-seq: 1, #new-token: 4369, #cached-token: 453, token usage: 0.94, #running-req: 66, #queue-req: 20\n",
      "[2025-08-13 21:07:19] INFO:     127.0.0.1:47640 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:19] Prefill batch. #new-seq: 1, #new-token: 4379, #cached-token: 443, token usage: 0.94, #running-req: 66, #queue-req: 19\n",
      "[2025-08-13 21:07:21] INFO:     127.0.0.1:46770 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:21] Prefill batch. #new-seq: 2, #new-token: 6667, #cached-token: 858, token usage: 0.94, #running-req: 66, #queue-req: 18\n",
      "[2025-08-13 21:07:22] INFO:     127.0.0.1:52610 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:22] Prefill batch. #new-seq: 2, #new-token: 2682, #cached-token: 818, token usage: 0.95, #running-req: 67, #queue-req: 16\n",
      "[2025-08-13 21:07:22] Decode batch. #running-req: 67, #token: 231726, token usage: 0.94, cuda graph: True, gen throughput (token/s): 623.18, #queue-req: 16\n",
      "[2025-08-13 21:07:22] INFO:     127.0.0.1:39658 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:22] Prefill batch. #new-seq: 1, #new-token: 2239, #cached-token: 159, token usage: 0.94, #running-req: 68, #queue-req: 15\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 21:07:24] INFO:     127.0.0.1:46760 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:24] Prefill batch. #new-seq: 1, #new-token: 2173, #cached-token: 460, token usage: 0.94, #running-req: 68, #queue-req: 17\n",
      "[2025-08-13 21:07:25] INFO:     127.0.0.1:42610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:25] Prefill batch. #new-seq: 1, #new-token: 4385, #cached-token: 446, token usage: 0.93, #running-req: 68, #queue-req: 17\n",
      "[2025-08-13 21:07:26] INFO:     127.0.0.1:37770 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:26] Prefill batch. #new-seq: 1, #new-token: 4373, #cached-token: 447, token usage: 0.95, #running-req: 68, #queue-req: 17\n",
      "[2025-08-13 21:07:26] Decode batch. #running-req: 68, #token: 236788, token usage: 0.96, cuda graph: True, gen throughput (token/s): 708.56, #queue-req: 17\n",
      "[2025-08-13 21:07:27] INFO:     127.0.0.1:39654 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:27] Prefill batch. #new-seq: 1, #new-token: 2544, #cached-token: 412, token usage: 0.95, #running-req: 68, #queue-req: 17\n",
      "[2025-08-13 21:07:28] INFO:     127.0.0.1:42578 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:28] Prefill batch. #new-seq: 2, #new-token: 3068, #cached-token: 914, token usage: 0.93, #running-req: 68, #queue-req: 15\n",
      "[2025-08-13 21:07:29] INFO:     127.0.0.1:39680 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:29] Prefill batch. #new-seq: 1, #new-token: 2240, #cached-token: 392, token usage: 0.94, #running-req: 69, #queue-req: 14\n",
      "[2025-08-13 21:07:30] Decode batch. #running-req: 70, #token: 234085, token usage: 0.95, cuda graph: True, gen throughput (token/s): 701.88, #queue-req: 15\n",
      "[2025-08-13 21:07:30] INFO:     127.0.0.1:52562 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:31] INFO:     127.0.0.1:39674 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:32] INFO:     127.0.0.1:39694 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:32] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 465, token usage: 0.91, #running-req: 67, #queue-req: 16\n",
      "[2025-08-13 21:07:32] Prefill batch. #new-seq: 1, #new-token: 1513, #cached-token: 0, token usage: 0.95, #running-req: 67, #queue-req: 16\n",
      "[2025-08-13 21:07:34] Decode batch. #running-req: 68, #token: 235008, token usage: 0.96, cuda graph: True, gen throughput (token/s): 712.26, #queue-req: 16\n",
      "[2025-08-13 21:07:34] INFO:     127.0.0.1:41580 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:34] Prefill batch. #new-seq: 2, #new-token: 2487, #cached-token: 614, token usage: 0.91, #running-req: 67, #queue-req: 14\n",
      "[2025-08-13 21:07:34] INFO:     127.0.0.1:58342 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:35] Prefill batch. #new-seq: 1, #new-token: 5846, #cached-token: 410, token usage: 0.92, #running-req: 68, #queue-req: 13\n",
      "[2025-08-13 21:07:36] INFO:     127.0.0.1:35288 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:36] Prefill batch. #new-seq: 2, #new-token: 2549, #cached-token: 932, token usage: 0.93, #running-req: 68, #queue-req: 11\n",
      "[2025-08-13 21:07:38] Decode batch. #running-req: 70, #token: 234072, token usage: 0.95, cuda graph: True, gen throughput (token/s): 731.31, #queue-req: 12\n",
      "[2025-08-13 21:07:38] INFO:     127.0.0.1:58374 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:38] Prefill batch. #new-seq: 1, #new-token: 4411, #cached-token: 96, token usage: 0.94, #running-req: 69, #queue-req: 16\n",
      "[2025-08-13 21:07:39] INFO:     127.0.0.1:58406 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:39] Prefill batch. #new-seq: 1, #new-token: 2477, #cached-token: 480, token usage: 0.94, #running-req: 69, #queue-req: 16\n",
      "[2025-08-13 21:07:41] INFO:     127.0.0.1:55316 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:41] Prefill batch. #new-seq: 1, #new-token: 2206, #cached-token: 449, token usage: 0.92, #running-req: 69, #queue-req: 17\n",
      "[2025-08-13 21:07:41] Decode batch. #running-req: 70, #token: 229238, token usage: 0.93, cuda graph: True, gen throughput (token/s): 775.31, #queue-req: 17\n",
      "[2025-08-13 21:07:43] INFO:     127.0.0.1:55328 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:43] Prefill batch. #new-seq: 1, #new-token: 7122, #cached-token: 409, token usage: 0.93, #running-req: 69, #queue-req: 17\n",
      "[2025-08-13 21:07:45] Decode batch. #running-req: 70, #token: 237001, token usage: 0.96, cuda graph: True, gen throughput (token/s): 797.06, #queue-req: 17\n",
      "[2025-08-13 21:07:47] INFO:     127.0.0.1:53868 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:48] Decode batch. #running-req: 69, #token: 235837, token usage: 0.96, cuda graph: True, gen throughput (token/s): 974.75, #queue-req: 17\n",
      "[2025-08-13 21:07:48] INFO:     127.0.0.1:42568 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:48] Prefill batch. #new-seq: 1, #new-token: 2216, #cached-token: 160, token usage: 0.94, #running-req: 68, #queue-req: 18\n",
      "[2025-08-13 21:07:49] INFO:     127.0.0.1:42576 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:51] Decode batch. #running-req: 68, #token: 231812, token usage: 0.94, cuda graph: True, gen throughput (token/s): 903.77, #queue-req: 19\n",
      "[2025-08-13 21:07:53] Decode batch. #running-req: 68, #token: 234532, token usage: 0.95, cuda graph: True, gen throughput (token/s): 940.26, #queue-req: 19\n",
      "[2025-08-13 21:07:56] INFO:     127.0.0.1:42602 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:56] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 625, token usage: 0.92, #running-req: 67, #queue-req: 19\n",
      "[2025-08-13 21:07:56] Prefill batch. #new-seq: 2, #new-token: 322, #cached-token: 144, token usage: 0.95, #running-req: 67, #queue-req: 18\n",
      "[2025-08-13 21:07:57] Decode batch. #running-req: 69, #token: 233886, token usage: 0.95, cuda graph: True, gen throughput (token/s): 720.84, #queue-req: 18\n",
      "[2025-08-13 21:07:59] INFO:     127.0.0.1:37726 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:07:59] Prefill batch. #new-seq: 1, #new-token: 2216, #cached-token: 124, token usage: 0.94, #running-req: 68, #queue-req: 17\n",
      "[2025-08-13 21:07:59] INFO:     127.0.0.1:37196 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:00] Prefill batch. #new-seq: 1, #new-token: 3358, #cached-token: 554, token usage: 0.94, #running-req: 68, #queue-req: 16\n",
      "[2025-08-13 21:08:01] Decode batch. #running-req: 69, #token: 235474, token usage: 0.96, cuda graph: True, gen throughput (token/s): 803.13, #queue-req: 18\n",
      "[2025-08-13 21:08:01] INFO:     127.0.0.1:37206 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:01] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 449, token usage: 0.94, #running-req: 68, #queue-req: 18\n",
      "[2025-08-13 21:08:01] INFO:     127.0.0.1:45776 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:01] Prefill batch. #new-seq: 1, #new-token: 2165, #cached-token: 467, token usage: 0.94, #running-req: 68, #queue-req: 17\n",
      "[2025-08-13 21:08:02] INFO:     127.0.0.1:43878 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:02] Prefill batch. #new-seq: 2, #new-token: 2785, #cached-token: 848, token usage: 0.94, #running-req: 68, #queue-req: 15\n",
      "[2025-08-13 21:08:04] Decode batch. #running-req: 70, #token: 235021, token usage: 0.96, cuda graph: True, gen throughput (token/s): 793.74, #queue-req: 17\n",
      "[2025-08-13 21:08:04] INFO:     127.0.0.1:46670 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:08:04] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 412, token usage: 0.95, #running-req: 69, #queue-req: 16\n",
      "[2025-08-13 21:08:06] INFO:     127.0.0.1:40674 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:07] Decode batch. #running-req: 69, #token: 235253, token usage: 0.96, cuda graph: True, gen throughput (token/s): 888.30, #queue-req: 17\n",
      "[2025-08-13 21:08:08] INFO:     127.0.0.1:41574 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:08] INFO:     127.0.0.1:53884 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:08] INFO:     127.0.0.1:53896 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:08] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 551, token usage: 0.92, #running-req: 66, #queue-req: 16\n",
      "[2025-08-13 21:08:08] Prefill batch. #new-seq: 1, #new-token: 565, #cached-token: 0, token usage: 0.95, #running-req: 66, #queue-req: 16\n",
      "[2025-08-13 21:08:10] INFO:     127.0.0.1:45976 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:10] Prefill batch. #new-seq: 3, #new-token: 6496, #cached-token: 1475, token usage: 0.91, #running-req: 66, #queue-req: 17\n",
      "[2025-08-13 21:08:11] INFO:     127.0.0.1:45986 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:11] Prefill batch. #new-seq: 1, #new-token: 2287, #cached-token: 126, token usage: 0.92, #running-req: 68, #queue-req: 16\n",
      "[2025-08-13 21:08:12] Decode batch. #running-req: 69, #token: 228997, token usage: 0.93, cuda graph: True, gen throughput (token/s): 603.49, #queue-req: 16\n",
      "[2025-08-13 21:08:14] INFO:     127.0.0.1:40678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:14] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 562, token usage: 0.91, #running-req: 68, #queue-req: 15\n",
      "[2025-08-13 21:08:14] Prefill batch. #new-seq: 1, #new-token: 1808, #cached-token: 0, token usage: 0.95, #running-req: 69, #queue-req: 15\n",
      "[2025-08-13 21:08:16] Decode batch. #running-req: 70, #token: 235170, token usage: 0.96, cuda graph: True, gen throughput (token/s): 739.10, #queue-req: 16\n",
      "[2025-08-13 21:08:17] INFO:     127.0.0.1:55316 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:17] Prefill batch. #new-seq: 1, #new-token: 6021, #cached-token: 481, token usage: 0.93, #running-req: 69, #queue-req: 15\n",
      "[2025-08-13 21:08:19] Decode batch. #running-req: 70, #token: 236155, token usage: 0.96, cuda graph: True, gen throughput (token/s): 828.44, #queue-req: 16\n",
      "[2025-08-13 21:08:19] INFO:     127.0.0.1:46000 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:19] INFO:     127.0.0.1:46014 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:19] INFO:     127.0.0.1:46030 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:19] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 568, token usage: 0.92, #running-req: 67, #queue-req: 16\n",
      "[2025-08-13 21:08:19] INFO:     127.0.0.1:34532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:19] Prefill batch. #new-seq: 1, #new-token: 827, #cached-token: 0, token usage: 0.94, #running-req: 68, #queue-req: 16\n",
      "[2025-08-13 21:08:20] INFO:     127.0.0.1:42576 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 21:08:21] INFO:     127.0.0.1:42286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:21] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.92, #running-req: 66, #queue-req: 16\n",
      "[2025-08-13 21:08:21] Prefill batch. #new-seq: 1, #new-token: 3709, #cached-token: 0, token usage: 0.95, #running-req: 66, #queue-req: 16\n",
      "[2025-08-13 21:08:23] INFO:     127.0.0.1:42264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:23] Prefill batch. #new-seq: 1, #new-token: 2199, #cached-token: 460, token usage: 0.95, #running-req: 66, #queue-req: 19\n",
      "[2025-08-13 21:08:23] INFO:     127.0.0.1:42602 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:24] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 700, token usage: 0.91, #running-req: 66, #queue-req: 16\n",
      "[2025-08-13 21:08:24] Prefill batch. #new-seq: 2, #new-token: 2473, #cached-token: 409, token usage: 0.94, #running-req: 68, #queue-req: 15\n",
      ".[2025-08-13 21:08:25] Decode batch. #running-req: 70, #token: 235310, token usage: 0.96, cuda graph: True, gen throughput (token/s): 446.48, #queue-req: 15\n",
      "[2025-08-13 21:08:27] INFO:     127.0.0.1:35130 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:27] Prefill batch. #new-seq: 1, #new-token: 2243, #cached-token: 442, token usage: 0.95, #running-req: 69, #queue-req: 14\n",
      "[2025-08-13 21:08:27] INFO:     127.0.0.1:55328 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:28] Prefill batch. #new-seq: 1, #new-token: 2157, #cached-token: 119, token usage: 0.95, #running-req: 69, #queue-req: 13\n",
      "[2025-08-13 21:08:28] Decode batch. #running-req: 70, #token: 237343, token usage: 0.97, cuda graph: True, gen throughput (token/s): 870.90, #queue-req: 13\n",
      "[2025-08-13 21:08:29] INFO:     127.0.0.1:42306 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:29] Prefill batch. #new-seq: 1, #new-token: 4367, #cached-token: 455, token usage: 0.95, #running-req: 69, #queue-req: 12\n",
      "[2025-08-13 21:08:30] INFO:     127.0.0.1:53884 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:30] INFO:     127.0.0.1:51738 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:30] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 455, token usage: 0.95, #running-req: 68, #queue-req: 14\n",
      "[2025-08-13 21:08:32] Decode batch. #running-req: 69, #token: 236214, token usage: 0.96, cuda graph: True, gen throughput (token/s): 809.53, #queue-req: 16\n",
      "[2025-08-13 21:08:33] INFO:     127.0.0.1:42568 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:33] INFO:     127.0.0.1:37206 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:34] INFO:     127.0.0.1:51752 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:34] INFO:     127.0.0.1:37196 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:34] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 465, token usage: 0.90, #running-req: 65, #queue-req: 15\n",
      "[2025-08-13 21:08:34] Prefill batch. #new-seq: 1, #new-token: 3705, #cached-token: 0, token usage: 0.94, #running-req: 65, #queue-req: 15\n",
      "[2025-08-13 21:08:36] Decode batch. #running-req: 66, #token: 230527, token usage: 0.94, cuda graph: True, gen throughput (token/s): 657.95, #queue-req: 16\n",
      "[2025-08-13 21:08:36] INFO:     127.0.0.1:43878 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:36] Prefill batch. #new-seq: 1, #new-token: 2257, #cached-token: 553, token usage: 0.94, #running-req: 65, #queue-req: 16\n",
      "[2025-08-13 21:08:37] INFO:     127.0.0.1:51772 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:37] Prefill batch. #new-seq: 1, #new-token: 2207, #cached-token: 448, token usage: 0.94, #running-req: 65, #queue-req: 15\n",
      "[2025-08-13 21:08:39] Decode batch. #running-req: 66, #token: 235434, token usage: 0.96, cuda graph: True, gen throughput (token/s): 812.45, #queue-req: 19\n",
      "[2025-08-13 21:08:39] INFO:     127.0.0.1:51800 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:39] Prefill batch. #new-seq: 1, #new-token: 2206, #cached-token: 449, token usage: 0.94, #running-req: 65, #queue-req: 18\n",
      "[2025-08-13 21:08:40] INFO:     127.0.0.1:53896 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:40] Prefill batch. #new-seq: 2, #new-token: 7269, #cached-token: 596, token usage: 0.93, #running-req: 65, #queue-req: 16\n",
      "[2025-08-13 21:08:43] Decode batch. #running-req: 67, #token: 238723, token usage: 0.97, cuda graph: True, gen throughput (token/s): 706.83, #queue-req: 18\n",
      "[2025-08-13 21:08:45] INFO:     127.0.0.1:55164 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:45] Prefill batch. #new-seq: 1, #new-token: 2240, #cached-token: 159, token usage: 0.94, #running-req: 66, #queue-req: 17\n",
      "[2025-08-13 21:08:46] INFO:     127.0.0.1:45976 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:46] Decode batch. #running-req: 67, #token: 222605, token usage: 0.91, cuda graph: True, gen throughput (token/s): 856.52, #queue-req: 17\n",
      "[2025-08-13 21:08:46] Prefill batch. #new-seq: 3, #new-token: 7021, #cached-token: 980, token usage: 0.91, #running-req: 66, #queue-req: 14\n",
      ".[2025-08-13 21:08:47] INFO:     127.0.0.1:35132 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:47] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 904, token usage: 0.92, #running-req: 68, #queue-req: 13\n",
      "[2025-08-13 21:08:47] Prefill batch. #new-seq: 1, #new-token: 399, #cached-token: 0, token usage: 0.95, #running-req: 69, #queue-req: 13\n",
      "[2025-08-13 21:08:48] INFO:     127.0.0.1:42306 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:48] Prefill batch. #new-seq: 2, #new-token: 2561, #cached-token: 576, token usage: 0.93, #running-req: 69, #queue-req: 11\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 21:08:49] INFO:     127.0.0.1:46000 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:49] Prefill batch. #new-seq: 2, #new-token: 4504, #cached-token: 238, token usage: 0.93, #running-req: 70, #queue-req: 11\n",
      "[2025-08-13 21:08:51] Decode batch. #running-req: 72, #token: 235525, token usage: 0.96, cuda graph: True, gen throughput (token/s): 593.66, #queue-req: 12\n",
      "[2025-08-13 21:08:52] INFO:     127.0.0.1:46014 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:52] Prefill batch. #new-seq: 1, #new-token: 4379, #cached-token: 441, token usage: 0.95, #running-req: 71, #queue-req: 11\n",
      "[2025-08-13 21:08:54] Decode batch. #running-req: 72, #token: 238397, token usage: 0.97, cuda graph: True, gen throughput (token/s): 891.71, #queue-req: 12\n",
      "[2025-08-13 21:08:56] INFO:     127.0.0.1:42264 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:57] Decode batch. #running-req: 71, #token: 236794, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1010.80, #queue-req: 12\n",
      "[2025-08-13 21:08:57] INFO:     127.0.0.1:35122 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:59] INFO:     127.0.0.1:51738 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:08:59] Prefill batch. #new-seq: 1, #new-token: 4872, #cached-token: 462, token usage: 0.94, #running-req: 69, #queue-req: 13\n",
      "[2025-08-13 21:09:00] INFO:     127.0.0.1:55100 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:00] Prefill batch. #new-seq: 2, #new-token: 4456, #cached-token: 253, token usage: 0.93, #running-req: 69, #queue-req: 12\n",
      "[2025-08-13 21:09:00] INFO:     127.0.0.1:45058 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:00] Prefill batch. #new-seq: 1, #new-token: 2399, #cached-token: 438, token usage: 0.94, #running-req: 70, #queue-req: 11\n",
      "[2025-08-13 21:09:00] Decode batch. #running-req: 70, #token: 233891, token usage: 0.95, cuda graph: True, gen throughput (token/s): 772.89, #queue-req: 11\n",
      "[2025-08-13 21:09:03] INFO:     127.0.0.1:51752 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:03] Prefill batch. #new-seq: 1, #new-token: 2145, #cached-token: 170, token usage: 0.94, #running-req: 70, #queue-req: 12\n",
      "[2025-08-13 21:09:04] Decode batch. #running-req: 71, #token: 234439, token usage: 0.95, cuda graph: True, gen throughput (token/s): 891.61, #queue-req: 12\n",
      "[2025-08-13 21:09:06] INFO:     127.0.0.1:51772 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:06] Decode batch. #running-req: 70, #token: 234980, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1030.50, #queue-req: 13\n",
      "[2025-08-13 21:09:08] INFO:     127.0.0.1:40662 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:09:08] INFO:     127.0.0.1:45086 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:08] Prefill batch. #new-seq: 1, #new-token: 3298, #cached-token: 466, token usage: 0.95, #running-req: 68, #queue-req: 13\n",
      "[2025-08-13 21:09:09] Decode batch. #running-req: 69, #token: 233451, token usage: 0.95, cuda graph: True, gen throughput (token/s): 902.54, #queue-req: 13\n",
      "[2025-08-13 21:09:09] INFO:     127.0.0.1:56310 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:09] Prefill batch. #new-seq: 1, #new-token: 2160, #cached-token: 472, token usage: 0.95, #running-req: 68, #queue-req: 13\n",
      "[2025-08-13 21:09:11] INFO:     127.0.0.1:56298 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:11] Prefill batch. #new-seq: 3, #new-token: 4721, #cached-token: 1317, token usage: 0.93, #running-req: 68, #queue-req: 11\n",
      ".[2025-08-13 21:09:13] Decode batch. #running-req: 71, #token: 233689, token usage: 0.95, cuda graph: True, gen throughput (token/s): 820.75, #queue-req: 11\n",
      "[2025-08-13 21:09:15] INFO:     127.0.0.1:56234 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:15] Prefill batch. #new-seq: 1, #new-token: 1031, #cached-token: 191, token usage: 0.94, #running-req: 70, #queue-req: 10\n",
      "[2025-08-13 21:09:16] Decode batch. #running-req: 71, #token: 233494, token usage: 0.95, cuda graph: True, gen throughput (token/s): 983.60, #queue-req: 10\n",
      "[2025-08-13 21:09:16] INFO:     127.0.0.1:57200 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:16] Prefill batch. #new-seq: 1, #new-token: 2863, #cached-token: 412, token usage: 0.94, #running-req: 70, #queue-req: 10\n",
      "[2025-08-13 21:09:19] Decode batch. #running-req: 71, #token: 235777, token usage: 0.96, cuda graph: True, gen throughput (token/s): 937.39, #queue-req: 11\n",
      "[2025-08-13 21:09:19] INFO:     127.0.0.1:39996 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:22] Decode batch. #running-req: 70, #token: 236508, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1008.97, #queue-req: 12\n",
      "[2025-08-13 21:09:24] INFO:     127.0.0.1:34510 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:24] Decode batch. #running-req: 69, #token: 235611, token usage: 0.96, cuda graph: True, gen throughput (token/s): 992.90, #queue-req: 12\n",
      "[2025-08-13 21:09:27] Decode batch. #running-req: 69, #token: 238371, token usage: 0.97, cuda graph: True, gen throughput (token/s): 952.49, #queue-req: 13\n",
      "[2025-08-13 21:09:29] INFO:     127.0.0.1:41582 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:29] Prefill batch. #new-seq: 1, #new-token: 5789, #cached-token: 481, token usage: 0.94, #running-req: 68, #queue-req: 13\n",
      "[2025-08-13 21:09:30] INFO:     127.0.0.1:41594 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:30] Prefill batch. #new-seq: 1, #new-token: 2277, #cached-token: 126, token usage: 0.95, #running-req: 68, #queue-req: 13\n",
      "[2025-08-13 21:09:31] Decode batch. #running-req: 69, #token: 235264, token usage: 0.96, cuda graph: True, gen throughput (token/s): 758.16, #queue-req: 13\n",
      "[2025-08-13 21:09:31] INFO:     127.0.0.1:34518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:31] Prefill batch. #new-seq: 2, #new-token: 4681, #cached-token: 597, token usage: 0.93, #running-req: 68, #queue-req: 11\n",
      "[2025-08-13 21:09:31] INFO:     127.0.0.1:41598 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:32] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 77, token usage: 0.95, #running-req: 69, #queue-req: 10\n",
      "[2025-08-13 21:09:33] INFO:     127.0.0.1:46678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:33] INFO:     127.0.0.1:46680 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:33] Prefill batch. #new-seq: 2, #new-token: 2227, #cached-token: 628, token usage: 0.93, #running-req: 68, #queue-req: 12\n",
      "[2025-08-13 21:09:34] Decode batch. #running-req: 70, #token: 232121, token usage: 0.94, cuda graph: True, gen throughput (token/s): 820.71, #queue-req: 12\n",
      "[2025-08-13 21:09:35] INFO:     127.0.0.1:34500 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:35] Prefill batch. #new-seq: 2, #new-token: 5097, #cached-token: 850, token usage: 0.93, #running-req: 69, #queue-req: 10\n",
      "[2025-08-13 21:09:37] INFO:     127.0.0.1:37664 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:37] INFO:     127.0.0.1:36062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:37] INFO:     127.0.0.1:36078 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:37] INFO:     127.0.0.1:36084 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:37] Prefill batch. #new-seq: 4, #new-token: 6147, #cached-token: 1499, token usage: 0.91, #running-req: 70, #queue-req: 8\n",
      "[2025-08-13 21:09:38] Decode batch. #running-req: 71, #token: 229041, token usage: 0.93, cuda graph: True, gen throughput (token/s): 768.17, #queue-req: 11\n",
      "[2025-08-13 21:09:39] INFO:     127.0.0.1:36092 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:39] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 464, token usage: 0.91, #running-req: 70, #queue-req: 11\n",
      "[2025-08-13 21:09:39] Prefill batch. #new-seq: 2, #new-token: 5783, #cached-token: 449, token usage: 0.94, #running-req: 70, #queue-req: 10\n",
      "[2025-08-13 21:09:41] INFO:     127.0.0.1:41800 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:42] INFO:     127.0.0.1:41582 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:42] Prefill batch. #new-seq: 2, #new-token: 5681, #cached-token: 885, token usage: 0.93, #running-req: 70, #queue-req: 8\n",
      "[2025-08-13 21:09:42] INFO:     127.0.0.1:56314 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:42] Prefill batch. #new-seq: 2, #new-token: 6626, #cached-token: 880, token usage: 0.94, #running-req: 71, #queue-req: 6\n",
      ".[2025-08-13 21:09:43] Decode batch. #running-req: 73, #token: 238065, token usage: 0.97, cuda graph: True, gen throughput (token/s): 542.87, #queue-req: 6\n",
      "[2025-08-13 21:09:46] INFO:     127.0.0.1:45092 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:46] Decode batch. #running-req: 72, #token: 237652, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1022.58, #queue-req: 8\n",
      "[2025-08-13 21:09:46] INFO:     127.0.0.1:55152 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:46] Prefill batch. #new-seq: 1, #new-token: 2346, #cached-token: 455, token usage: 0.95, #running-req: 71, #queue-req: 7\n",
      "[2025-08-13 21:09:47] INFO:     127.0.0.1:37710 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:47] INFO:     127.0.0.1:37742 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:47] Prefill batch. #new-seq: 1, #new-token: 4261, #cached-token: 446, token usage: 0.95, #running-req: 70, #queue-req: 6\n",
      "[2025-08-13 21:09:48] INFO:     127.0.0.1:55104 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:48] Prefill batch. #new-seq: 2, #new-token: 4838, #cached-token: 901, token usage: 0.95, #running-req: 70, #queue-req: 6\n",
      "[2025-08-13 21:09:49] INFO:     127.0.0.1:37754 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:50] Decode batch. #running-req: 71, #token: 235508, token usage: 0.96, cuda graph: True, gen throughput (token/s): 737.76, #queue-req: 10\n",
      "[2025-08-13 21:09:52] INFO:     127.0.0.1:41594 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:52] Prefill batch. #new-seq: 1, #new-token: 4181, #cached-token: 470, token usage: 0.95, #running-req: 70, #queue-req: 9\n",
      "[2025-08-13 21:09:53] INFO:     127.0.0.1:37780 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:53] Prefill batch. #new-seq: 1, #new-token: 6617, #cached-token: 146, token usage: 0.94, #running-req: 70, #queue-req: 8\n",
      "[2025-08-13 21:09:54] Decode batch. #running-req: 71, #token: 237747, token usage: 0.97, cuda graph: True, gen throughput (token/s): 733.20, #queue-req: 10\n",
      "[2025-08-13 21:09:54] INFO:     127.0.0.1:41598 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:54] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 1860, token usage: 0.89, #running-req: 70, #queue-req: 5\n",
      "[2025-08-13 21:09:54] INFO:     127.0.0.1:35262 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:54] INFO:     127.0.0.1:35266 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:54] INFO:     127.0.0.1:46678 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:54] INFO:     127.0.0.1:46680 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:54] Prefill batch. #new-seq: 3, #new-token: 6003, #cached-token: 291, token usage: 0.92, #running-req: 74, #queue-req: 3\n",
      ".[2025-08-13 21:09:55] Prefill batch. #new-seq: 1, #new-token: 2341, #cached-token: 461, token usage: 0.95, #running-req: 73, #queue-req: 4\n",
      "[2025-08-13 21:09:56] INFO:     127.0.0.1:37710 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:56] INFO:     127.0.0.1:37754 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:56] Prefill batch. #new-seq: 1, #new-token: 7121, #cached-token: 392, token usage: 0.93, #running-req: 73, #queue-req: 5\n",
      "[2025-08-13 21:09:56] INFO:     127.0.0.1:35280 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:57] Prefill batch. #new-seq: 1, #new-token: 2224, #cached-token: 409, token usage: 0.94, #running-req: 72, #queue-req: 4\n",
      "[2025-08-13 21:09:57] INFO:     127.0.0.1:36084 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:09:57] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 598, token usage: 0.93, #running-req: 72, #queue-req: 3\n",
      "[2025-08-13 21:09:57] Prefill batch. #new-seq: 1, #new-token: 462, #cached-token: 0, token usage: 0.96, #running-req: 73, #queue-req: 3\n",
      "[2025-08-13 21:10:00] INFO:     127.0.0.1:35286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:00] Decode batch. #running-req: 73, #token: 235202, token usage: 0.96, cuda graph: True, gen throughput (token/s): 496.01, #queue-req: 7\n",
      "[2025-08-13 21:10:00] INFO:     127.0.0.1:36078 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:01] INFO:     127.0.0.1:37664 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:01] Prefill batch. #new-seq: 1, #new-token: 4384, #cached-token: 446, token usage: 0.94, #running-req: 71, #queue-req: 6\n",
      "[2025-08-13 21:10:02] INFO:     127.0.0.1:34544 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:02] Prefill batch. #new-seq: 3, #new-token: 7655, #cached-token: 1000, token usage: 0.91, #running-req: 71, #queue-req: 3\n",
      "[2025-08-13 21:10:03] INFO:     127.0.0.1:36062 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:10:03] Prefill batch. #new-seq: 2, #new-token: 4871, #cached-token: 542, token usage: 0.93, #running-req: 73, #queue-req: 2\n",
      "[2025-08-13 21:10:04] INFO:     127.0.0.1:35292 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:04] INFO:     127.0.0.1:40654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:04] Prefill batch. #new-seq: 2, #new-token: 6844, #cached-token: 911, token usage: 0.92, #running-req: 73, #queue-req: 0\n",
      "[2025-08-13 21:10:05] Decode batch. #running-req: 75, #token: 234328, token usage: 0.95, cuda graph: True, gen throughput (token/s): 598.16, #queue-req: 4\n",
      "[2025-08-13 21:10:05] INFO:     127.0.0.1:57166 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:05] INFO:     127.0.0.1:57180 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:05] Prefill batch. #new-seq: 2, #new-token: 3451, #cached-token: 5282, token usage: 0.94, #running-req: 73, #queue-req: 4\n",
      "[2025-08-13 21:10:08] Decode batch. #running-req: 75, #token: 236449, token usage: 0.96, cuda graph: True, gen throughput (token/s): 937.95, #queue-req: 4\n",
      "[2025-08-13 21:10:08] INFO:     127.0.0.1:36092 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:08] Prefill batch. #new-seq: 2, #new-token: 2619, #cached-token: 2970, token usage: 0.94, #running-req: 74, #queue-req: 2\n",
      "[2025-08-13 21:10:09] INFO:     127.0.0.1:37742 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:09] Prefill batch. #new-seq: 1, #new-token: 426, #cached-token: 3907, token usage: 0.96, #running-req: 75, #queue-req: 1\n",
      "[2025-08-13 21:10:09] INFO:     127.0.0.1:35266 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:10] INFO:     127.0.0.1:37780 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:10] Prefill batch. #new-seq: 1, #new-token: 4528, #cached-token: 462, token usage: 0.92, #running-req: 74, #queue-req: 0\n",
      "[2025-08-13 21:10:10] INFO:     127.0.0.1:35262 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:11] Decode batch. #running-req: 74, #token: 227636, token usage: 0.93, cuda graph: True, gen throughput (token/s): 841.41, #queue-req: 0\n",
      "[2025-08-13 21:10:12] INFO:     127.0.0.1:57192 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:12] INFO:     127.0.0.1:56324 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:13] INFO:     127.0.0.1:47630 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:14] INFO:     127.0.0.1:35280 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:14] Decode batch. #running-req: 70, #token: 209976, token usage: 0.85, cuda graph: True, gen throughput (token/s): 1091.44, #queue-req: 0\n",
      "[2025-08-13 21:10:14] INFO:     127.0.0.1:35286 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:15] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 6890, token usage: 0.87, #running-req: 69, #queue-req: 0\n",
      "[2025-08-13 21:10:15] INFO:     127.0.0.1:40654 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:15] INFO:     127.0.0.1:57192 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:17] Decode batch. #running-req: 68, #token: 203718, token usage: 0.83, cuda graph: True, gen throughput (token/s): 1058.05, #queue-req: 0\n",
      "[2025-08-13 21:10:17] INFO:     127.0.0.1:34560 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:17] INFO:     127.0.0.1:35292 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:18] INFO:     127.0.0.1:57180 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:19] INFO:     127.0.0.1:57166 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:19] INFO:     127.0.0.1:35106 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:19] Decode batch. #running-req: 64, #token: 188592, token usage: 0.77, cuda graph: True, gen throughput (token/s): 1059.92, #queue-req: 0\n",
      "[2025-08-13 21:10:21] INFO:     127.0.0.1:35742 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:21] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 93, token usage: 0.77, #running-req: 62, #queue-req: 1\n",
      "[2025-08-13 21:10:21] Prefill batch. #new-seq: 2, #new-token: 811, #cached-token: 2678, token usage: 0.81, #running-req: 62, #queue-req: 0\n",
      "[2025-08-13 21:10:22] Decode batch. #running-req: 64, #token: 200837, token usage: 0.82, cuda graph: True, gen throughput (token/s): 784.20, #queue-req: 0\n",
      "[2025-08-13 21:10:24] INFO:     127.0.0.1:56312 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:25] Decode batch. #running-req: 63, #token: 199961, token usage: 0.81, cuda graph: True, gen throughput (token/s): 1063.67, #queue-req: 0\n",
      "[2025-08-13 21:10:26] INFO:     127.0.0.1:45080 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:27] Decode batch. #running-req: 62, #token: 198454, token usage: 0.81, cuda graph: True, gen throughput (token/s): 1039.46, #queue-req: 0\n",
      "[2025-08-13 21:10:28] INFO:     127.0.0.1:34554 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:28] INFO:     127.0.0.1:35106 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:28] INFO:     127.0.0.1:55116 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:29] Decode batch. #running-req: 59, #token: 193746, token usage: 0.79, cuda graph: True, gen throughput (token/s): 1006.57, #queue-req: 0\n",
      "[2025-08-13 21:10:30] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1020, token usage: 0.79, #running-req: 59, #queue-req: 2\n",
      "[2025-08-13 21:10:30] Prefill batch. #new-seq: 6, #new-token: 8192, #cached-token: 6062, token usage: 0.84, #running-req: 61, #queue-req: 2\n",
      "[2025-08-13 21:10:31] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 784, token usage: 0.88, #running-req: 66, #queue-req: 0\n",
      "[2025-08-13 21:10:31] Prefill batch. #new-seq: 1, #new-token: 2259, #cached-token: 0, token usage: 0.91, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:10:33] Prefill batch. #new-seq: 3, #new-token: 4808, #cached-token: 1037, token usage: 0.92, #running-req: 69, #queue-req: 1\n",
      "[2025-08-13 21:10:33] INFO:     127.0.0.1:55132 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:34] Prefill batch. #new-seq: 2, #new-token: 4852, #cached-token: 284, token usage: 0.92, #running-req: 71, #queue-req: 6\n",
      "[2025-08-13 21:10:34] INFO:     127.0.0.1:34554 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:34] Prefill batch. #new-seq: 1, #new-token: 4694, #cached-token: 463, token usage: 0.94, #running-req: 72, #queue-req: 5\n",
      "[2025-08-13 21:10:35] INFO:     127.0.0.1:57226 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:35] Prefill batch. #new-seq: 1, #new-token: 1133, #cached-token: 465, token usage: 0.95, #running-req: 72, #queue-req: 4\n",
      "[2025-08-13 21:10:36] INFO:     127.0.0.1:52610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:36] Prefill batch. #new-seq: 1, #new-token: 2725, #cached-token: 554, token usage: 0.94, #running-req: 72, #queue-req: 3\n",
      "[2025-08-13 21:10:36] Decode batch. #running-req: 73, #token: 233325, token usage: 0.95, cuda graph: True, gen throughput (token/s): 414.71, #queue-req: 3\n",
      ".[2025-08-13 21:10:38] INFO:     127.0.0.1:55140 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:38] Prefill batch. #new-seq: 2, #new-token: 3628, #cached-token: 928, token usage: 0.92, #running-req: 72, #queue-req: 4\n",
      "[2025-08-13 21:10:39] INFO:     127.0.0.1:57524 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:39] Prefill batch. #new-seq: 2, #new-token: 4834, #cached-token: 699, token usage: 0.92, #running-req: 73, #queue-req: 2\n",
      "[2025-08-13 21:10:40] Decode batch. #running-req: 75, #token: 232756, token usage: 0.95, cuda graph: True, gen throughput (token/s): 821.68, #queue-req: 2\n",
      "[2025-08-13 21:10:40] INFO:     127.0.0.1:41144 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:40] Prefill batch. #new-seq: 1, #new-token: 1616, #cached-token: 465, token usage: 0.94, #running-req: 74, #queue-req: 2\n",
      ".[2025-08-13 21:10:43] Decode batch. #running-req: 75, #token: 234657, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1016.94, #queue-req: 2\n",
      "[2025-08-13 21:10:44] INFO:     127.0.0.1:55116 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:45] Decode batch. #running-req: 74, #token: 235100, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1055.37, #queue-req: 3\n",
      "[2025-08-13 21:10:47] INFO:     127.0.0.1:57528 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:48] Decode batch. #running-req: 73, #token: 234081, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1042.93, #queue-req: 4\n",
      "[2025-08-13 21:10:48] INFO:     127.0.0.1:55132 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:49] INFO:     127.0.0.1:56898 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:51] INFO:     127.0.0.1:55176 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:51] Decode batch. #running-req: 70, #token: 229325, token usage: 0.93, cuda graph: True, gen throughput (token/s): 1044.76, #queue-req: 7\n",
      "[2025-08-13 21:10:53] INFO:     127.0.0.1:41200 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:53] Prefill batch. #new-seq: 1, #new-token: 2019, #cached-token: 7531, token usage: 0.96, #running-req: 69, #queue-req: 6\n",
      "[2025-08-13 21:10:53] INFO:     127.0.0.1:45066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:53] Prefill batch. #new-seq: 1, #new-token: 2329, #cached-token: 452, token usage: 0.94, #running-req: 69, #queue-req: 5\n",
      "[2025-08-13 21:10:54] Decode batch. #running-req: 70, #token: 235134, token usage: 0.96, cuda graph: True, gen throughput (token/s): 872.34, #queue-req: 7\n",
      "[2025-08-13 21:10:55] INFO:     127.0.0.1:45090 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:55] Prefill batch. #new-seq: 1, #new-token: 2572, #cached-token: 462, token usage: 0.95, #running-req: 69, #queue-req: 7\n",
      "[2025-08-13 21:10:57] INFO:     127.0.0.1:55140 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:57] Prefill batch. #new-seq: 2, #new-token: 4697, #cached-token: 906, token usage: 0.93, #running-req: 69, #queue-req: 5\n",
      "[2025-08-13 21:10:58] Decode batch. #running-req: 71, #token: 233507, token usage: 0.95, cuda graph: True, gen throughput (token/s): 823.54, #queue-req: 5\n",
      "[2025-08-13 21:10:58] INFO:     127.0.0.1:45102 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:58] Prefill batch. #new-seq: 2, #new-token: 2314, #cached-token: 561, token usage: 0.93, #running-req: 70, #queue-req: 3\n",
      "[2025-08-13 21:10:59] INFO:     127.0.0.1:55150 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:10:59] Prefill batch. #new-seq: 1, #new-token: 5377, #cached-token: 554, token usage: 0.93, #running-req: 71, #queue-req: 4\n",
      "[2025-08-13 21:11:01] Decode batch. #running-req: 72, #token: 235103, token usage: 0.96, cuda graph: True, gen throughput (token/s): 822.80, #queue-req: 5\n",
      "[2025-08-13 21:11:04] INFO:     127.0.0.1:42576 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:04] Decode batch. #running-req: 72, #token: 234010, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1030.34, #queue-req: 5\n",
      "[2025-08-13 21:11:04] Prefill batch. #new-seq: 1, #new-token: 2359, #cached-token: 443, token usage: 0.95, #running-req: 71, #queue-req: 4\n",
      "[2025-08-13 21:11:06] INFO:     127.0.0.1:45066 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:06] Prefill batch. #new-seq: 1, #new-token: 2583, #cached-token: 435, token usage: 0.95, #running-req: 71, #queue-req: 4\n",
      "[2025-08-13 21:11:07] Decode batch. #running-req: 72, #token: 236369, token usage: 0.96, cuda graph: True, gen throughput (token/s): 879.35, #queue-req: 5\n",
      "[2025-08-13 21:11:08] INFO:     127.0.0.1:55176 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:09] INFO:     127.0.0.1:39284 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:09] Prefill batch. #new-seq: 1, #new-token: 4169, #cached-token: 484, token usage: 0.93, #running-req: 70, #queue-req: 4\n",
      "[2025-08-13 21:11:10] Decode batch. #running-req: 71, #token: 233139, token usage: 0.95, cuda graph: True, gen throughput (token/s): 899.72, #queue-req: 6\n",
      "[2025-08-13 21:11:12] INFO:     127.0.0.1:50788 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:13] INFO:     127.0.0.1:39984 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:13] Decode batch. #running-req: 69, #token: 231515, token usage: 0.94, cuda graph: True, gen throughput (token/s): 1007.20, #queue-req: 8\n",
      "[2025-08-13 21:11:16] INFO:     127.0.0.1:54148 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:16] INFO:     127.0.0.1:45090 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:16] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.92, #running-req: 68, #queue-req: 8\n",
      "[2025-08-13 21:11:16] Prefill batch. #new-seq: 1, #new-token: 1033, #cached-token: 0, token usage: 0.96, #running-req: 68, #queue-req: 8\n",
      "[2025-08-13 21:11:17] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 122, token usage: 0.96, #running-req: 68, #queue-req: 7\n",
      "[2025-08-13 21:11:17] Decode batch. #running-req: 69, #token: 236838, token usage: 0.96, cuda graph: True, gen throughput (token/s): 718.07, #queue-req: 8\n",
      "[2025-08-13 21:11:19] INFO:     127.0.0.1:54160 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:19] Prefill batch. #new-seq: 1, #new-token: 2269, #cached-token: 134, token usage: 0.95, #running-req: 68, #queue-req: 8\n",
      "[2025-08-13 21:11:19] INFO:     127.0.0.1:45102 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:19] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 455, token usage: 0.95, #running-req: 68, #queue-req: 7\n",
      "[2025-08-13 21:11:20] Decode batch. #running-req: 69, #token: 235571, token usage: 0.96, cuda graph: True, gen throughput (token/s): 851.67, #queue-req: 7\n",
      "[2025-08-13 21:11:21] INFO:     127.0.0.1:45698 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:21] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 603, token usage: 0.90, #running-req: 68, #queue-req: 6\n",
      "[2025-08-13 21:11:21] INFO:     127.0.0.1:33120 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:21] Prefill batch. #new-seq: 1, #new-token: 4277, #cached-token: 0, token usage: 0.94, #running-req: 69, #queue-req: 6\n",
      ".[2025-08-13 21:11:22] Prefill batch. #new-seq: 1, #new-token: 2854, #cached-token: 441, token usage: 0.96, #running-req: 69, #queue-req: 5\n",
      "[2025-08-13 21:11:23] INFO:     127.0.0.1:39284 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:23] Prefill batch. #new-seq: 2, #new-token: 4943, #cached-token: 887, token usage: 0.94, #running-req: 69, #queue-req: 4\n",
      "[2025-08-13 21:11:25] Decode batch. #running-req: 71, #token: 236835, token usage: 0.96, cuda graph: True, gen throughput (token/s): 591.91, #queue-req: 5\n",
      "[2025-08-13 21:11:25] INFO:     127.0.0.1:54172 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:25] Prefill batch. #new-seq: 1, #new-token: 2171, #cached-token: 460, token usage: 0.95, #running-req: 70, #queue-req: 5\n",
      "[2025-08-13 21:11:26] INFO:     127.0.0.1:54186 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:11:26] Prefill batch. #new-seq: 1, #new-token: 4366, #cached-token: 456, token usage: 0.94, #running-req: 70, #queue-req: 4\n",
      "[2025-08-13 21:11:28] Decode batch. #running-req: 71, #token: 237673, token usage: 0.97, cuda graph: True, gen throughput (token/s): 831.29, #queue-req: 4\n",
      "[2025-08-13 21:11:29] INFO:     127.0.0.1:47620 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:29] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 452, token usage: 0.95, #running-req: 70, #queue-req: 4\n",
      "[2025-08-13 21:11:31] Decode batch. #running-req: 71, #token: 238656, token usage: 0.97, cuda graph: True, gen throughput (token/s): 942.45, #queue-req: 4\n",
      "[2025-08-13 21:11:33] INFO:     127.0.0.1:39984 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:33] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 462, token usage: 0.96, #running-req: 70, #queue-req: 3\n",
      "[2025-08-13 21:11:34] INFO:     127.0.0.1:58914 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:34] INFO:     127.0.0.1:54148 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:34] Prefill batch. #new-seq: 2, #new-token: 4774, #cached-token: 914, token usage: 0.94, #running-req: 69, #queue-req: 2\n",
      "[2025-08-13 21:11:35] Decode batch. #running-req: 71, #token: 228536, token usage: 0.93, cuda graph: True, gen throughput (token/s): 864.74, #queue-req: 2\n",
      "[2025-08-13 21:11:35] INFO:     127.0.0.1:47644 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:35] INFO:     127.0.0.1:47658 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:35] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4654, token usage: 0.95, #running-req: 69, #queue-req: 1\n",
      "[2025-08-13 21:11:35] INFO:     127.0.0.1:55152 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:35] Prefill batch. #new-seq: 1, #new-token: 5704, #cached-token: 393, token usage: 0.93, #running-req: 69, #queue-req: 0\n",
      "[2025-08-13 21:11:36] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2827, token usage: 0.96, #running-req: 70, #queue-req: 1\n",
      "[2025-08-13 21:11:36] INFO:     127.0.0.1:44004 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:36] INFO:     127.0.0.1:44020 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:36] Prefill batch. #new-seq: 1, #new-token: 2020, #cached-token: 2801, token usage: 0.94, #running-req: 69, #queue-req: 0\n",
      "[2025-08-13 21:11:37] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 413, token usage: 0.95, #running-req: 70, #queue-req: 4\n",
      "[2025-08-13 21:11:37] INFO:     127.0.0.1:54160 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:37] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 7135, token usage: 0.97, #running-req: 70, #queue-req: 2\n",
      "[2025-08-13 21:11:37] INFO:     127.0.0.1:44032 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:39] Decode batch. #running-req: 71, #token: 237923, token usage: 0.97, cuda graph: True, gen throughput (token/s): 736.39, #queue-req: 4\n",
      "[2025-08-13 21:11:41] INFO:     127.0.0.1:54172 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:41] Decode batch. #running-req: 70, #token: 236326, token usage: 0.96, cuda graph: True, gen throughput (token/s): 986.43, #queue-req: 4\n",
      "[2025-08-13 21:11:44] INFO:     127.0.0.1:44004 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:44] Prefill batch. #new-seq: 1, #new-token: 2273, #cached-token: 135, token usage: 0.95, #running-req: 69, #queue-req: 4\n",
      "[2025-08-13 21:11:44] Decode batch. #running-req: 69, #token: 234363, token usage: 0.95, cuda graph: True, gen throughput (token/s): 977.94, #queue-req: 4\n",
      "[2025-08-13 21:11:44] INFO:     127.0.0.1:47658 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:45] INFO:     127.0.0.1:47620 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:45] Prefill batch. #new-seq: 1, #new-token: 5076, #cached-token: 462, token usage: 0.94, #running-req: 68, #queue-req: 3\n",
      ".[2025-08-13 21:11:46] INFO:     127.0.0.1:41188 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:46] Prefill batch. #new-seq: 2, #new-token: 4840, #cached-token: 774, token usage: 0.94, #running-req: 68, #queue-req: 3\n",
      "[2025-08-13 21:11:47] INFO:     127.0.0.1:47644 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:47] Prefill batch. #new-seq: 2, #new-token: 2308, #cached-token: 918, token usage: 0.94, #running-req: 69, #queue-req: 1\n",
      "[2025-08-13 21:11:47] INFO:     127.0.0.1:44020 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:47] Prefill batch. #new-seq: 1, #new-token: 562, #cached-token: 435, token usage: 0.94, #running-req: 70, #queue-req: 0\n",
      "[2025-08-13 21:11:47] INFO:     127.0.0.1:44042 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:47] INFO:     127.0.0.1:44032 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:48] INFO:     127.0.0.1:55134 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:48] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 7333, token usage: 0.92, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:11:48] INFO:     127.0.0.1:44058 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:48] Decode batch. #running-req: 68, #token: 222981, token usage: 0.91, cuda graph: True, gen throughput (token/s): 673.17, #queue-req: 0\n",
      "[2025-08-13 21:11:49] INFO:     127.0.0.1:44042 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:50] INFO:     127.0.0.1:33126 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:51] Prefill batch. #new-seq: 2, #new-token: 223, #cached-token: 4768, token usage: 0.89, #running-req: 66, #queue-req: 0\n",
      "[2025-08-13 21:11:51] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4314, token usage: 0.91, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:11:51] Decode batch. #running-req: 69, #token: 223194, token usage: 0.91, cuda graph: True, gen throughput (token/s): 990.84, #queue-req: 0\n",
      "[2025-08-13 21:11:52] INFO:     127.0.0.1:44058 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:52] INFO:     127.0.0.1:33126 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:52] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 467, token usage: 0.88, #running-req: 67, #queue-req: 0\n",
      "[2025-08-13 21:11:52] INFO:     127.0.0.1:55114 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:53] INFO:     127.0.0.1:33142 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:54] Prefill batch. #new-seq: 3, #new-token: 4667, #cached-token: 713, token usage: 0.86, #running-req: 66, #queue-req: 0\n",
      "[2025-08-13 21:11:54] Decode batch. #running-req: 69, #token: 216937, token usage: 0.88, cuda graph: True, gen throughput (token/s): 835.40, #queue-req: 0\n",
      "[2025-08-13 21:11:55] INFO:     127.0.0.1:50786 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:56] Prefill batch. #new-seq: 1, #new-token: 5084, #cached-token: 409, token usage: 0.86, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:11:57] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1191, token usage: 0.89, #running-req: 69, #queue-req: 1\n",
      "[2025-08-13 21:11:57] INFO:     127.0.0.1:33140 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:57] Prefill batch. #new-seq: 2, #new-token: 5649, #cached-token: 409, token usage: 0.90, #running-req: 72, #queue-req: 0\n",
      "[2025-08-13 21:11:57] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 5763, token usage: 0.94, #running-req: 74, #queue-req: 0\n",
      "[2025-08-13 21:11:59] Decode batch. #running-req: 74, #token: 233038, token usage: 0.95, cuda graph: True, gen throughput (token/s): 647.87, #queue-req: 0\n",
      "[2025-08-13 21:11:59] INFO:     127.0.0.1:33140 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:11:59] INFO:     127.0.0.1:50804 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:00] INFO:     127.0.0.1:33150 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:00] INFO:     127.0.0.1:42306 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:00] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4653, token usage: 0.90, #running-req: 70, #queue-req: 0\n",
      "[2025-08-13 21:12:01] INFO:     127.0.0.1:58948 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:01] Decode batch. #running-req: 70, #token: 218462, token usage: 0.89, cuda graph: True, gen throughput (token/s): 1050.71, #queue-req: 0\n",
      "[2025-08-13 21:12:02] INFO:     127.0.0.1:33978 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:02] Prefill batch. #new-seq: 1, #new-token: 2208, #cached-token: 446, token usage: 0.88, #running-req: 69, #queue-req: 0\n",
      "[2025-08-13 21:12:02] INFO:     127.0.0.1:51142 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:04] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1071, token usage: 0.90, #running-req: 69, #queue-req: 0\n",
      "[2025-08-13 21:12:04] Prefill batch. #new-seq: 1, #new-token: 1973, #cached-token: 0, token usage: 0.93, #running-req: 70, #queue-req: 0\n",
      "[2025-08-13 21:12:05] Prefill batch. #new-seq: 1, #new-token: 2343, #cached-token: 458, token usage: 0.94, #running-req: 71, #queue-req: 2\n",
      "[2025-08-13 21:12:05] INFO:     127.0.0.1:41808 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:05] Prefill batch. #new-seq: 2, #new-token: 673, #cached-token: 872, token usage: 0.94, #running-req: 71, #queue-req: 1\n",
      "[2025-08-13 21:12:06] Decode batch. #running-req: 73, #token: 232171, token usage: 0.94, cuda graph: True, gen throughput (token/s): 666.44, #queue-req: 1\n",
      "[2025-08-13 21:12:06] INFO:     127.0.0.1:41814 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:06] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 8495, token usage: 0.96, #running-req: 72, #queue-req: 0\n",
      "[2025-08-13 21:12:07] INFO:     127.0.0.1:41814 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:08] Decode batch. #running-req: 73, #token: 233537, token usage: 0.95, cuda graph: True, gen throughput (token/s): 1030.74, #queue-req: 0\n",
      "[2025-08-13 21:12:11] INFO:     127.0.0.1:42306 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:11] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 450, token usage: 0.94, #running-req: 72, #queue-req: 0\n",
      "[2025-08-13 21:12:11] Decode batch. #running-req: 73, #token: 234462, token usage: 0.95, cuda graph: True, gen throughput (token/s): 956.05, #queue-req: 0\n",
      "[2025-08-13 21:12:14] Decode batch. #running-req: 73, #token: 237382, token usage: 0.97, cuda graph: True, gen throughput (token/s): 1024.98, #queue-req: 1\n",
      "[2025-08-13 21:12:15] INFO:     127.0.0.1:39088 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:15] Prefill batch. #new-seq: 1, #new-token: 3111, #cached-token: 480, token usage: 0.94, #running-req: 72, #queue-req: 0\n",
      "[2025-08-13 21:12:16] Prefill batch. #new-seq: 1, #new-token: 2216, #cached-token: 441, token usage: 0.95, #running-req: 73, #queue-req: 0\n",
      "[2025-08-13 21:12:16] INFO:     127.0.0.1:41808 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:17] INFO:     127.0.0.1:35756 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:18] Decode batch. #running-req: 72, #token: 233945, token usage: 0.95, cuda graph: True, gen throughput (token/s): 887.10, #queue-req: 1\n",
      "[2025-08-13 21:12:19] INFO:     127.0.0.1:58898 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:19] Prefill batch. #new-seq: 2, #new-token: 5815, #cached-token: 628, token usage: 0.93, #running-req: 71, #queue-req: 1\n",
      "[2025-08-13 21:12:20] INFO:     127.0.0.1:58906 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:21] Decode batch. #running-req: 72, #token: 230492, token usage: 0.94, cuda graph: True, gen throughput (token/s): 872.38, #queue-req: 2\n",
      "[2025-08-13 21:12:21] INFO:     127.0.0.1:58928 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:21] INFO:     127.0.0.1:58940 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:21] Prefill batch. #new-seq: 2, #new-token: 2041, #cached-token: 10672, token usage: 0.95, #running-req: 71, #queue-req: 1\n",
      "[2025-08-13 21:12:23] INFO:     127.0.0.1:58898 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:23] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 7024, token usage: 0.96, #running-req: 71, #queue-req: 0\n",
      "[2025-08-13 21:12:23] INFO:     127.0.0.1:58950 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:23] INFO:     127.0.0.1:41172 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:24] INFO:     127.0.0.1:53012 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:24] Decode batch. #running-req: 71, #token: 231005, token usage: 0.94, cuda graph: True, gen throughput (token/s): 938.85, #queue-req: 0\n",
      "[2025-08-13 21:12:24] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2222, token usage: 0.95, #running-req: 70, #queue-req: 0\n",
      "[2025-08-13 21:12:25] INFO:     127.0.0.1:48130 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:25] INFO:     127.0.0.1:48134 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:25] INFO:     127.0.0.1:58950 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:26] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 9945, token usage: 0.95, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:12:27] INFO:     127.0.0.1:48142 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:27] INFO:     127.0.0.1:35734 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:27] Decode batch. #running-req: 68, #token: 225290, token usage: 0.92, cuda graph: True, gen throughput (token/s): 974.41, #queue-req: 0\n",
      "[2025-08-13 21:12:27] Prefill batch. #new-seq: 2, #new-token: 2348, #cached-token: 4735, token usage: 0.93, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:12:28] Prefill batch. #new-seq: 1, #new-token: 325, #cached-token: 438, token usage: 0.95, #running-req: 70, #queue-req: 3\n",
      "[2025-08-13 21:12:30] Decode batch. #running-req: 71, #token: 234924, token usage: 0.96, cuda graph: True, gen throughput (token/s): 904.51, #queue-req: 3\n",
      "[2025-08-13 21:12:31] INFO:     127.0.0.1:58928 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:31] Prefill batch. #new-seq: 2, #new-token: 2557, #cached-token: 560, token usage: 0.94, #running-req: 70, #queue-req: 1\n",
      "[2025-08-13 21:12:31] INFO:     127.0.0.1:58906 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:31] Prefill batch. #new-seq: 1, #new-token: 2026, #cached-token: 461, token usage: 0.93, #running-req: 71, #queue-req: 0\n",
      "[2025-08-13 21:12:33] INFO:     127.0.0.1:58940 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:33] Decode batch. #running-req: 71, #token: 231307, token usage: 0.94, cuda graph: True, gen throughput (token/s): 873.67, #queue-req: 2\n",
      "[2025-08-13 21:12:33] INFO:     127.0.0.1:57238 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:33] Prefill batch. #new-seq: 1, #new-token: 5997, #cached-token: 393, token usage: 0.92, #running-req: 70, #queue-req: 1\n",
      "[2025-08-13 21:12:37] Decode batch. #running-req: 71, #token: 235799, token usage: 0.96, cuda graph: True, gen throughput (token/s): 854.00, #queue-req: 3\n",
      "[2025-08-13 21:12:37] INFO:     127.0.0.1:48134 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:37] INFO:     127.0.0.1:48130 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:37] Prefill batch. #new-seq: 2, #new-token: 2347, #cached-token: 4949, token usage: 0.94, #running-req: 69, #queue-req: 1\n",
      "[2025-08-13 21:12:38] INFO:     127.0.0.1:35734 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:38] Prefill batch. #new-seq: 1, #new-token: 4460, #cached-token: 124, token usage: 0.94, #running-req: 70, #queue-req: 0\n",
      "[2025-08-13 21:12:38] INFO:     127.0.0.1:50720 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:40] Decode batch. #running-req: 70, #token: 228893, token usage: 0.93, cuda graph: True, gen throughput (token/s): 831.95, #queue-req: 0\n",
      "[2025-08-13 21:12:40] INFO:     127.0.0.1:51130 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:40] INFO:     127.0.0.1:56910 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:40] INFO:     127.0.0.1:41156 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:40] Prefill batch. #new-seq: 3, #new-token: 4910, #cached-token: 7538, token usage: 0.91, #running-req: 67, #queue-req: 0\n",
      "[2025-08-13 21:12:40] INFO:     127.0.0.1:41162 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:40] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 467, token usage: 0.93, #running-req: 70, #queue-req: 0\n",
      "[2025-08-13 21:12:41] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.96, #running-req: 70, #queue-req: 3\n",
      "[2025-08-13 21:12:41] INFO:     127.0.0.1:41156 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:43] Decode batch. #running-req: 70, #token: 236627, token usage: 0.96, cuda graph: True, gen throughput (token/s): 797.03, #queue-req: 4\n",
      "[2025-08-13 21:12:45] INFO:     127.0.0.1:57484 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:46] INFO:     127.0.0.1:57498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:46] INFO:     127.0.0.1:57512 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:46] Prefill batch. #new-seq: 3, #new-token: 4027, #cached-token: 1026, token usage: 0.93, #running-req: 67, #queue-req: 4\n",
      "[2025-08-13 21:12:47] Decode batch. #running-req: 70, #token: 232092, token usage: 0.94, cuda graph: True, gen throughput (token/s): 877.60, #queue-req: 4\n",
      "[2025-08-13 21:12:47] INFO:     127.0.0.1:57238 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:47] Prefill batch. #new-seq: 3, #new-token: 290, #cached-token: 7378, token usage: 0.96, #running-req: 69, #queue-req: 1\n",
      "[2025-08-13 21:12:47] INFO:     127.0.0.1:57498 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:48] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4800, token usage: 0.96, #running-req: 71, #queue-req: 0\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 21:12:49] INFO:     127.0.0.1:57484 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:49] Decode batch. #running-req: 71, #token: 235043, token usage: 0.96, cuda graph: True, gen throughput (token/s): 979.58, #queue-req: 2\n",
      "[2025-08-13 21:12:50] INFO:     127.0.0.1:57542 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:50] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 2611, token usage: 0.95, #running-req: 70, #queue-req: 3\n",
      "[2025-08-13 21:12:50] INFO:     127.0.0.1:56910 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:12:50] Prefill batch. #new-seq: 2, #new-token: 3291, #cached-token: 558, token usage: 0.93, #running-req: 70, #queue-req: 1\n",
      "[2025-08-13 21:12:51] INFO:     127.0.0.1:41162 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:51] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 5147, token usage: 0.95, #running-req: 71, #queue-req: 0\n",
      "[2025-08-13 21:12:51] Prefill batch. #new-seq: 1, #new-token: 2224, #cached-token: 409, token usage: 0.95, #running-req: 72, #queue-req: 0\n",
      "[2025-08-13 21:12:53] Decode batch. #running-req: 73, #token: 236920, token usage: 0.96, cuda graph: True, gen throughput (token/s): 841.90, #queue-req: 0\n",
      "[2025-08-13 21:12:55] INFO:     127.0.0.1:57542 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:56] Decode batch. #running-req: 72, #token: 235069, token usage: 0.96, cuda graph: True, gen throughput (token/s): 1018.38, #queue-req: 0\n",
      "[2025-08-13 21:12:57] INFO:     127.0.0.1:57512 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:12:57] Prefill batch. #new-seq: 1, #new-token: 2643, #cached-token: 550, token usage: 0.94, #running-req: 71, #queue-req: 0\n",
      "[2025-08-13 21:12:59] Decode batch. #running-req: 72, #token: 236094, token usage: 0.96, cuda graph: True, gen throughput (token/s): 895.32, #queue-req: 1\n",
      "[2025-08-13 21:13:02] Decode batch. #running-req: 72, #token: 238974, token usage: 0.97, cuda graph: True, gen throughput (token/s): 959.97, #queue-req: 1\n",
      "[2025-08-13 21:13:03] INFO:     127.0.0.1:53026 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:04] INFO:     127.0.0.1:49152 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:04] Prefill batch. #new-seq: 1, #new-token: 2163, #cached-token: 470, token usage: 0.95, #running-req: 70, #queue-req: 0\n",
      "[2025-08-13 21:13:05] Decode batch. #running-req: 71, #token: 235221, token usage: 0.96, cuda graph: True, gen throughput (token/s): 913.08, #queue-req: 0\n",
      "[2025-08-13 21:13:07] INFO:     127.0.0.1:39100 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:08] Prefill batch. #new-seq: 1, #new-token: 2272, #cached-token: 132, token usage: 0.95, #running-req: 70, #queue-req: 1\n",
      "[2025-08-13 21:13:08] Decode batch. #running-req: 71, #token: 236975, token usage: 0.96, cuda graph: True, gen throughput (token/s): 934.72, #queue-req: 1\n",
      "[2025-08-13 21:13:10] INFO:     127.0.0.1:57784 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:10] Prefill batch. #new-seq: 1, #new-token: 1335, #cached-token: 96, token usage: 0.96, #running-req: 70, #queue-req: 1\n",
      "[2025-08-13 21:13:11] Decode batch. #running-req: 71, #token: 237134, token usage: 0.96, cuda graph: True, gen throughput (token/s): 976.47, #queue-req: 1\n",
      "[2025-08-13 21:13:14] Decode batch. #running-req: 71, #token: 239974, token usage: 0.98, cuda graph: True, gen throughput (token/s): 1005.29, #queue-req: 2\n",
      "[2025-08-13 21:13:14] INFO:     127.0.0.1:55118 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:14] INFO:     127.0.0.1:55120 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:14] INFO:     127.0.0.1:55144 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:14] INFO:     127.0.0.1:55164 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:14] Prefill batch. #new-seq: 3, #new-token: 3078, #cached-token: 4685, token usage: 0.91, #running-req: 67, #queue-req: 3\n",
      "[2025-08-13 21:13:15] INFO:     127.0.0.1:49196 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:15] Prefill batch. #new-seq: 3, #new-token: 62, #cached-token: 17708, token usage: 0.97, #running-req: 69, #queue-req: 0\n",
      "[2025-08-13 21:13:15] INFO:     127.0.0.1:50734 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:15] INFO:     127.0.0.1:50750 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:15] INFO:     127.0.0.1:55144 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:16] INFO:     127.0.0.1:50758 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:16] INFO:     127.0.0.1:50770 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:16] Prefill batch. #new-seq: 3, #new-token: 61, #cached-token: 11544, token usage: 0.94, #running-req: 67, #queue-req: 0\n",
      "[2025-08-13 21:13:17] Decode batch. #running-req: 70, #token: 231385, token usage: 0.94, cuda graph: True, gen throughput (token/s): 888.34, #queue-req: 0\n",
      "[2025-08-13 21:13:18] Prefill batch. #new-seq: 1, #new-token: 2333, #cached-token: 443, token usage: 0.94, #running-req: 70, #queue-req: 2\n",
      "[2025-08-13 21:13:19] INFO:     127.0.0.1:50814 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:19] INFO:     127.0.0.1:50818 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:19] Prefill batch. #new-seq: 3, #new-token: 3553, #cached-token: 3386, token usage: 0.94, #running-req: 69, #queue-req: 1\n",
      "[2025-08-13 21:13:20] INFO:     127.0.0.1:50828 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:20] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 5726, token usage: 0.97, #running-req: 71, #queue-req: 1\n",
      "[2025-08-13 21:13:20] Decode batch. #running-req: 72, #token: 237770, token usage: 0.97, cuda graph: True, gen throughput (token/s): 832.95, #queue-req: 1\n",
      "[2025-08-13 21:13:21] INFO:     127.0.0.1:50836 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:21] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2555, token usage: 0.96, #running-req: 71, #queue-req: 1\n",
      "[2025-08-13 21:13:22] INFO:     127.0.0.1:53018 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:23] INFO:     127.0.0.1:57786 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:23] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4080, token usage: 0.95, #running-req: 70, #queue-req: 0\n",
      "[2025-08-13 21:13:23] INFO:     127.0.0.1:48066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:23] INFO:     127.0.0.1:55118 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:23] Decode batch. #running-req: 69, #token: 230151, token usage: 0.94, cuda graph: True, gen throughput (token/s): 997.01, #queue-req: 0\n",
      "[2025-08-13 21:13:25] INFO:     127.0.0.1:55120 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:25] INFO:     127.0.0.1:55164 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:25] INFO:     127.0.0.1:49842 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:26] INFO:     127.0.0.1:50734 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:26] INFO:     127.0.0.1:50770 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:26] INFO:     127.0.0.1:50758 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:26] Decode batch. #running-req: 63, #token: 206044, token usage: 0.84, cuda graph: True, gen throughput (token/s): 982.38, #queue-req: 0\n",
      "[2025-08-13 21:13:28] INFO:     127.0.0.1:50818 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:28] INFO:     127.0.0.1:50814 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:29] Decode batch. #running-req: 61, #token: 200578, token usage: 0.82, cuda graph: True, gen throughput (token/s): 991.78, #queue-req: 0\n",
      "[2025-08-13 21:13:29] INFO:     127.0.0.1:50828 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:31] Decode batch. #running-req: 60, #token: 200479, token usage: 0.82, cuda graph: True, gen throughput (token/s): 971.23, #queue-req: 0\n",
      "[2025-08-13 21:13:31] INFO:     127.0.0.1:50836 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:31] INFO:     127.0.0.1:59494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:31] INFO:     127.0.0.1:49210 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:32] Prefill batch. #new-seq: 2, #new-token: 5091, #cached-token: 904, token usage: 0.77, #running-req: 57, #queue-req: 0\n",
      ".[2025-08-13 21:13:34] Decode batch. #running-req: 59, #token: 196780, token usage: 0.80, cuda graph: True, gen throughput (token/s): 825.66, #queue-req: 0\n",
      ".[2025-08-13 21:13:36] INFO:     127.0.0.1:51132 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:36] Prefill batch. #new-seq: 4, #new-token: 6941, #cached-token: 5996, token usage: 0.81, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:13:36] Decode batch. #running-req: 58, #token: 206021, token usage: 0.84, cuda graph: True, gen throughput (token/s): 961.12, #queue-req: 0\n",
      "[2025-08-13 21:13:36] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.84, #running-req: 62, #queue-req: 8\n",
      "[2025-08-13 21:13:37] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 570, token usage: 0.87, #running-req: 62, #queue-req: 4\n",
      "[2025-08-13 21:13:38] Prefill batch. #new-seq: 3, #new-token: 7471, #cached-token: 843, token usage: 0.90, #running-req: 66, #queue-req: 2\n",
      "[2025-08-13 21:13:42] Decode batch. #running-req: 69, #token: 232722, token usage: 0.95, cuda graph: True, gen throughput (token/s): 486.50, #queue-req: 2\n",
      "[2025-08-13 21:13:43] INFO:     127.0.0.1:53810 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:43] Prefill batch. #new-seq: 2, #new-token: 4615, #cached-token: 593, token usage: 0.90, #running-req: 68, #queue-req: 0\n",
      ".[2025-08-13 21:13:45] Decode batch. #running-req: 70, #token: 224781, token usage: 0.91, cuda graph: True, gen throughput (token/s): 879.87, #queue-req: 0\n",
      "[2025-08-13 21:13:45] INFO:     127.0.0.1:51150 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:45] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.93, #running-req: 69, #queue-req: 0\n",
      "[2025-08-13 21:13:48] Decode batch. #running-req: 70, #token: 231958, token usage: 0.94, cuda graph: True, gen throughput (token/s): 972.17, #queue-req: 0\n",
      "[2025-08-13 21:13:49] INFO:     127.0.0.1:51132 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:50] Prefill batch. #new-seq: 1, #new-token: 2636, #cached-token: 480, token usage: 0.93, #running-req: 69, #queue-req: 0\n",
      "[2025-08-13 21:13:51] Decode batch. #running-req: 70, #token: 232873, token usage: 0.95, cuda graph: True, gen throughput (token/s): 915.20, #queue-req: 0\n",
      "[2025-08-13 21:13:54] Decode batch. #running-req: 70, #token: 235673, token usage: 0.96, cuda graph: True, gen throughput (token/s): 992.01, #queue-req: 0\n",
      "[2025-08-13 21:13:55] INFO:     127.0.0.1:51150 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:56] Prefill batch. #new-seq: 1, #new-token: 2545, #cached-token: 412, token usage: 0.95, #running-req: 69, #queue-req: 0\n",
      "[2025-08-13 21:13:57] INFO:     127.0.0.1:53812 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:57] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2416, token usage: 0.96, #running-req: 69, #queue-req: 0\n",
      "[2025-08-13 21:13:57] Decode batch. #running-req: 70, #token: 236514, token usage: 0.96, cuda graph: True, gen throughput (token/s): 900.95, #queue-req: 0\n",
      "[2025-08-13 21:13:58] INFO:     127.0.0.1:37786 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:59] INFO:     127.0.0.1:53820 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:59] INFO:     127.0.0.1:49148 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:13:59] Prefill batch. #new-seq: 3, #new-token: 2392, #cached-token: 9653, token usage: 0.95, #running-req: 67, #queue-req: 0\n",
      "[2025-08-13 21:14:00] Decode batch. #running-req: 70, #token: 237165, token usage: 0.96, cuda graph: True, gen throughput (token/s): 928.65, #queue-req: 0\n",
      "[2025-08-13 21:14:00] INFO:     127.0.0.1:47600 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:14:01] INFO:     127.0.0.1:48070 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:02] INFO:     127.0.0.1:49156 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:03] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 3124, token usage: 0.93, #running-req: 67, #queue-req: 0\n",
      "[2025-08-13 21:14:03] Prefill batch. #new-seq: 1, #new-token: 3595, #cached-token: 449, token usage: 0.93, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:14:03] Decode batch. #running-req: 69, #token: 232065, token usage: 0.94, cuda graph: True, gen throughput (token/s): 874.12, #queue-req: 0\n",
      "[2025-08-13 21:14:03] INFO:     127.0.0.1:49160 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:03] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4630, token usage: 0.94, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:14:04] INFO:     127.0.0.1:49160 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:05] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 450, token usage: 0.94, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:14:06] INFO:     127.0.0.1:51908 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:06] Decode batch. #running-req: 68, #token: 232454, token usage: 0.95, cuda graph: True, gen throughput (token/s): 924.38, #queue-req: 0\n",
      "[2025-08-13 21:14:06] INFO:     127.0.0.1:53812 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:07] INFO:     127.0.0.1:33974 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:07] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.94, #running-req: 66, #queue-req: 0\n",
      "[2025-08-13 21:14:08] Prefill batch. #new-seq: 1, #new-token: 54, #cached-token: 144, token usage: 0.94, #running-req: 67, #queue-req: 1\n",
      "[2025-08-13 21:14:09] Decode batch. #running-req: 68, #token: 229307, token usage: 0.93, cuda graph: True, gen throughput (token/s): 957.36, #queue-req: 1\n",
      "[2025-08-13 21:14:09] INFO:     127.0.0.1:57498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:09] Prefill batch. #new-seq: 1, #new-token: 6457, #cached-token: 205, token usage: 0.93, #running-req: 67, #queue-req: 0\n",
      "[2025-08-13 21:14:09] INFO:     127.0.0.1:53820 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:09] INFO:     127.0.0.1:49148 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:12] INFO:     127.0.0.1:49826 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:12] INFO:     127.0.0.1:33988 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:12] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2858, token usage: 0.92, #running-req: 64, #queue-req: 0\n",
      "[2025-08-13 21:14:12] Prefill batch. #new-seq: 1, #new-token: 2153, #cached-token: 135, token usage: 0.92, #running-req: 65, #queue-req: 0\n",
      "[2025-08-13 21:14:13] Decode batch. #running-req: 66, #token: 228282, token usage: 0.93, cuda graph: True, gen throughput (token/s): 734.18, #queue-req: 0\n",
      "[2025-08-13 21:14:13] INFO:     127.0.0.1:49156 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:13] Prefill batch. #new-seq: 1, #new-token: 2408, #cached-token: 77, token usage: 0.92, #running-req: 65, #queue-req: 0\n",
      "[2025-08-13 21:14:13] Prefill batch. #new-seq: 1, #new-token: 3515, #cached-token: 554, token usage: 0.93, #running-req: 66, #queue-req: 0\n",
      "[2025-08-13 21:14:14] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 451, token usage: 0.94, #running-req: 67, #queue-req: 0\n",
      "[2025-08-13 21:14:14] INFO:     127.0.0.1:53074 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:14] Prefill batch. #new-seq: 1, #new-token: 3022, #cached-token: 412, token usage: 0.94, #running-req: 67, #queue-req: 0\n",
      "[2025-08-13 21:14:16] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 409, token usage: 0.95, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:14:16] Decode batch. #running-req: 69, #token: 235531, token usage: 0.96, cuda graph: True, gen throughput (token/s): 719.29, #queue-req: 0\n",
      "[2025-08-13 21:14:18] INFO:     127.0.0.1:33974 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:19] Prefill batch. #new-seq: 1, #new-token: 2220, #cached-token: 412, token usage: 0.95, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:14:19] INFO:     127.0.0.1:45312 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:19] Decode batch. #running-req: 68, #token: 233747, token usage: 0.95, cuda graph: True, gen throughput (token/s): 921.86, #queue-req: 0\n",
      "[2025-08-13 21:14:20] Prefill batch. #new-seq: 1, #new-token: 553, #cached-token: 77, token usage: 0.95, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:14:22] INFO:     127.0.0.1:39104 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:22] Decode batch. #running-req: 69, #token: 232782, token usage: 0.95, cuda graph: True, gen throughput (token/s): 963.41, #queue-req: 0\n",
      "[2025-08-13 21:14:22] Prefill batch. #new-seq: 1, #new-token: 404, #cached-token: 4023, token usage: 0.96, #running-req: 68, #queue-req: 0\n",
      "[2025-08-13 21:14:22] INFO:     127.0.0.1:33988 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:14:23] INFO:     127.0.0.1:39116 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:23] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 7537, token usage: 0.96, #running-req: 67, #queue-req: 0\n",
      "[2025-08-13 21:14:24] INFO:     127.0.0.1:59510 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:24] INFO:     127.0.0.1:59514 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:24] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 7224, token usage: 0.96, #running-req: 66, #queue-req: 0\n",
      "[2025-08-13 21:14:24] INFO:     127.0.0.1:59528 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:24] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2996, token usage: 0.96, #running-req: 67, #queue-req: 0\n",
      "[2025-08-13 21:14:25] Decode batch. #running-req: 68, #token: 237300, token usage: 0.97, cuda graph: True, gen throughput (token/s): 926.82, #queue-req: 0\n",
      "[2025-08-13 21:14:26] INFO:     127.0.0.1:51882 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:27] Prefill batch. #new-seq: 1, #new-token: 1212, #cached-token: 443, token usage: 0.96, #running-req: 67, #queue-req: 0\n",
      "[2025-08-13 21:14:28] Decode batch. #running-req: 68, #token: 238226, token usage: 0.97, cuda graph: True, gen throughput (token/s): 931.25, #queue-req: 0\n",
      "[2025-08-13 21:14:30] INFO:     127.0.0.1:53024 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:30] INFO:     127.0.0.1:53042 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:31] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2260, token usage: 0.96, #running-req: 66, #queue-req: 1\n",
      "[2025-08-13 21:14:31] Decode batch. #running-req: 67, #token: 236609, token usage: 0.96, cuda graph: True, gen throughput (token/s): 946.95, #queue-req: 1\n",
      "[2025-08-13 21:14:31] INFO:     127.0.0.1:39104 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:31] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.96, #running-req: 66, #queue-req: 0\n",
      "[2025-08-13 21:14:32] INFO:     127.0.0.1:59514 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:32] INFO:     127.0.0.1:39116 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:32] INFO:     127.0.0.1:53054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:33] INFO:     127.0.0.1:53060 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:33] INFO:     127.0.0.1:53062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:33] INFO:     127.0.0.1:53090 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:33] INFO:     127.0.0.1:53106 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:33] INFO:     127.0.0.1:59510 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:33] INFO:     127.0.0.1:59528 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:34] Decode batch. #running-req: 58, #token: 195937, token usage: 0.80, cuda graph: True, gen throughput (token/s): 944.84, #queue-req: 0\n",
      "[2025-08-13 21:14:34] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 7492, token usage: 0.83, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:14:34] Prefill batch. #new-seq: 4, #new-token: 84, #cached-token: 20636, token usage: 0.91, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 21:14:35] INFO:     127.0.0.1:53060 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:35] INFO:     127.0.0.1:53062 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:35] INFO:     127.0.0.1:53106 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:36] INFO:     127.0.0.1:48086 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:36] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 996, token usage: 0.84, #running-req: 59, #queue-req: 0\n",
      ".[2025-08-13 21:14:36] Prefill batch. #new-seq: 1, #new-token: 1833, #cached-token: 0, token usage: 0.88, #running-req: 61, #queue-req: 0\n",
      "[2025-08-13 21:14:37] Decode batch. #running-req: 62, #token: 217543, token usage: 0.88, cuda graph: True, gen throughput (token/s): 696.29, #queue-req: 0\n",
      "[2025-08-13 21:14:37] INFO:     127.0.0.1:48062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:39] INFO:     127.0.0.1:40344 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:39] Prefill batch. #new-seq: 2, #new-token: 2584, #cached-token: 5206, token usage: 0.88, #running-req: 60, #queue-req: 0\n",
      "[2025-08-13 21:14:39] INFO:     127.0.0.1:48072 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:39] INFO:     127.0.0.1:48094 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:40] Decode batch. #running-req: 60, #token: 213417, token usage: 0.87, cuda graph: True, gen throughput (token/s): 883.08, #queue-req: 0\n",
      "[2025-08-13 21:14:40] Prefill batch. #new-seq: 2, #new-token: 2245, #cached-token: 5209, token usage: 0.89, #running-req: 60, #queue-req: 0\n",
      "[2025-08-13 21:14:40] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 3982, token usage: 0.91, #running-req: 62, #queue-req: 0\n",
      "[2025-08-13 21:14:40] Prefill batch. #new-seq: 1, #new-token: 528, #cached-token: 0, token usage: 0.94, #running-req: 66, #queue-req: 0\n",
      "[2025-08-13 21:14:41] INFO:     127.0.0.1:53024 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:42] INFO:     127.0.0.1:53042 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:43] Prefill batch. #new-seq: 2, #new-token: 5367, #cached-token: 613, token usage: 0.92, #running-req: 65, #queue-req: 0\n",
      "[2025-08-13 21:14:44] INFO:     127.0.0.1:45296 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:44] Decode batch. #running-req: 66, #token: 229169, token usage: 0.93, cuda graph: True, gen throughput (token/s): 625.36, #queue-req: 0\n",
      "[2025-08-13 21:14:45] Prefill batch. #new-seq: 1, #new-token: 2199, #cached-token: 454, token usage: 0.94, #running-req: 66, #queue-req: 0\n",
      "[2025-08-13 21:14:45] INFO:     127.0.0.1:53054 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:45] INFO:     127.0.0.1:53090 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:46] INFO:     127.0.0.1:37782 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:47] Decode batch. #running-req: 64, #token: 217959, token usage: 0.89, cuda graph: True, gen throughput (token/s): 900.49, #queue-req: 0\n",
      "[2025-08-13 21:14:48] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 5665, token usage: 0.91, #running-req: 64, #queue-req: 0\n",
      "[2025-08-13 21:14:48] Prefill batch. #new-seq: 1, #new-token: 1275, #cached-token: 0, token usage: 0.94, #running-req: 66, #queue-req: 0\n",
      "[2025-08-13 21:14:50] INFO:     127.0.0.1:48062 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:50] Decode batch. #running-req: 66, #token: 230066, token usage: 0.94, cuda graph: True, gen throughput (token/s): 729.33, #queue-req: 0\n",
      "[2025-08-13 21:14:51] INFO:     127.0.0.1:48072 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:51] INFO:     127.0.0.1:48094 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:52] INFO:     127.0.0.1:37788 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:53] Prefill batch. #new-seq: 3, #new-token: 5787, #cached-token: 5592, token usage: 0.92, #running-req: 63, #queue-req: 1\n",
      "[2025-08-13 21:14:53] Decode batch. #running-req: 63, #token: 231340, token usage: 0.94, cuda graph: True, gen throughput (token/s): 961.74, #queue-req: 1\n",
      "[2025-08-13 21:14:54] INFO:     127.0.0.1:37728 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:54] Prefill batch. #new-seq: 1, #new-token: 2173, #cached-token: 461, token usage: 0.93, #running-req: 65, #queue-req: 0\n",
      "[2025-08-13 21:14:55] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 444, token usage: 0.91, #running-req: 66, #queue-req: 0\n",
      "[2025-08-13 21:14:55] INFO:     127.0.0.1:49212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:55] Prefill batch. #new-seq: 1, #new-token: 1514, #cached-token: 4851, token usage: 0.94, #running-req: 67, #queue-req: 0\n",
      "[2025-08-13 21:14:56] INFO:     127.0.0.1:51662 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:56] INFO:     127.0.0.1:51672 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:56] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 10441, token usage: 0.95, #running-req: 65, #queue-req: 0\n",
      "[2025-08-13 21:14:57] Decode batch. #running-req: 67, #token: 234539, token usage: 0.95, cuda graph: True, gen throughput (token/s): 690.12, #queue-req: 0\n",
      "[2025-08-13 21:14:58] INFO:     127.0.0.1:37782 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:14:59] Prefill batch. #new-seq: 1, #new-token: 2953, #cached-token: 480, token usage: 0.94, #running-req: 66, #queue-req: 0\n",
      "[2025-08-13 21:15:00] Decode batch. #running-req: 67, #token: 235660, token usage: 0.96, cuda graph: True, gen throughput (token/s): 880.77, #queue-req: 0\n",
      "[2025-08-13 21:15:00] INFO:     127.0.0.1:37788 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:15:00] INFO:     127.0.0.1:44196 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:00] INFO:     127.0.0.1:51662 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:00] INFO:     127.0.0.1:49190 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:15:03] Decode batch. #running-req: 63, #token: 219206, token usage: 0.89, cuda graph: True, gen throughput (token/s): 990.07, #queue-req: 0\n",
      "[2025-08-13 21:15:03] Prefill batch. #new-seq: 2, #new-token: 3623, #cached-token: 855, token usage: 0.89, #running-req: 63, #queue-req: 0\n",
      "[2025-08-13 21:15:03] INFO:     127.0.0.1:51680 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:03] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4769, token usage: 0.91, #running-req: 64, #queue-req: 0\n",
      "[2025-08-13 21:15:04] INFO:     127.0.0.1:49212 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:15:04] INFO:     127.0.0.1:49162 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:04] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2762, token usage: 0.88, #running-req: 63, #queue-req: 0\n",
      "[2025-08-13 21:15:05] INFO:     127.0.0.1:51672 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:05] Decode batch. #running-req: 63, #token: 216487, token usage: 0.88, cuda graph: True, gen throughput (token/s): 873.10, #queue-req: 0\n",
      "[2025-08-13 21:15:06] Prefill batch. #new-seq: 1, #new-token: 2635, #cached-token: 480, token usage: 0.88, #running-req: 63, #queue-req: 0\n",
      "[2025-08-13 21:15:07] INFO:     127.0.0.1:49166 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:07] INFO:     127.0.0.1:49174 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:07] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 7115, token usage: 0.89, #running-req: 62, #queue-req: 0\n",
      "[2025-08-13 21:15:07] INFO:     127.0.0.1:45314 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:08] Decode batch. #running-req: 63, #token: 218123, token usage: 0.89, cuda graph: True, gen throughput (token/s): 900.95, #queue-req: 0\n",
      "[2025-08-13 21:15:08] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 460, token usage: 0.89, #running-req: 63, #queue-req: 0\n",
      "[2025-08-13 21:15:09] INFO:     127.0.0.1:51922 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:10] Prefill batch. #new-seq: 1, #new-token: 2284, #cached-token: 125, token usage: 0.88, #running-req: 63, #queue-req: 0\n",
      "[2025-08-13 21:15:11] Decode batch. #running-req: 64, #token: 219842, token usage: 0.89, cuda graph: True, gen throughput (token/s): 891.94, #queue-req: 0\n",
      "[2025-08-13 21:15:12] INFO:     127.0.0.1:51680 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:15:13] INFO:     127.0.0.1:49162 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:14] Decode batch. #running-req: 62, #token: 211868, token usage: 0.86, cuda graph: True, gen throughput (token/s): 966.79, #queue-req: 0\n",
      "[2025-08-13 21:15:14] INFO:     127.0.0.1:49850 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:14] INFO:     127.0.0.1:49824 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:15] INFO:     127.0.0.1:44482 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:15] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 7330, token usage: 0.86, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 21:15:15] Prefill batch. #new-seq: 1, #new-token: 2241, #cached-token: 393, token usage: 0.86, #running-req: 60, #queue-req: 0\n",
      "[2025-08-13 21:15:15] INFO:     127.0.0.1:49174 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:15] INFO:     127.0.0.1:49166 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:16] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 439, token usage: 0.83, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 21:15:16] INFO:     127.0.0.1:51978 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:16] Decode batch. #running-req: 59, #token: 204723, token usage: 0.83, cuda graph: True, gen throughput (token/s): 880.64, #queue-req: 0\n",
      "[2025-08-13 21:15:17] INFO:     127.0.0.1:37704 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:18] INFO:     127.0.0.1:49830 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:19] Decode batch. #running-req: 57, #token: 195309, token usage: 0.79, cuda graph: True, gen throughput (token/s): 977.54, #queue-req: 0\n",
      "[2025-08-13 21:15:20] INFO:     127.0.0.1:49852 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:20] Prefill batch. #new-seq: 1, #new-token: 2308, #cached-token: 393, token usage: 0.79, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:15:20] Prefill batch. #new-seq: 6, #new-token: 6090, #cached-token: 7986, token usage: 0.82, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:15:20] INFO:     127.0.0.1:37714 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:15:22] Decode batch. #running-req: 62, #token: 207412, token usage: 0.84, cuda graph: True, gen throughput (token/s): 763.54, #queue-req: 0\n",
      "[2025-08-13 21:15:22] INFO:     127.0.0.1:38534 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:23] INFO:     127.0.0.1:47586 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:23] INFO:     127.0.0.1:47610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:23] Prefill batch. #new-seq: 3, #new-token: 2396, #cached-token: 10195, token usage: 0.84, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 21:15:24] INFO:     127.0.0.1:49824 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:25] Decode batch. #running-req: 61, #token: 202744, token usage: 0.82, cuda graph: True, gen throughput (token/s): 903.61, #queue-req: 0\n",
      "[2025-08-13 21:15:25] Prefill batch. #new-seq: 1, #new-token: 7055, #cached-token: 463, token usage: 0.82, #running-req: 61, #queue-req: 0\n",
      "[2025-08-13 21:15:28] Decode batch. #running-req: 62, #token: 212278, token usage: 0.86, cuda graph: True, gen throughput (token/s): 767.62, #queue-req: 0\n",
      "[2025-08-13 21:15:28] INFO:     127.0.0.1:47610 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:29] INFO:     127.0.0.1:49698 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:29] INFO:     127.0.0.1:49830 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:29] INFO:     127.0.0.1:49852 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:29] INFO:     127.0.0.1:47612 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:30] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 5192, token usage: 0.81, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:15:30] Decode batch. #running-req: 58, #token: 200414, token usage: 0.82, cuda graph: True, gen throughput (token/s): 932.30, #queue-req: 0\n",
      "[2025-08-13 21:15:31] INFO:     127.0.0.1:47586 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:32] Prefill batch. #new-seq: 2, #new-token: 4708, #cached-token: 895, token usage: 0.80, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:15:33] Prefill batch. #new-seq: 3, #new-token: 6730, #cached-token: 1022, token usage: 0.82, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 21:15:34] Decode batch. #running-req: 62, #token: 209419, token usage: 0.85, cuda graph: True, gen throughput (token/s): 678.31, #queue-req: 0\n",
      "[2025-08-13 21:15:36] INFO:     127.0.0.1:51890 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:36] INFO:     127.0.0.1:40322 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:36] Decode batch. #running-req: 60, #token: 201728, token usage: 0.82, cuda graph: True, gen throughput (token/s): 972.19, #queue-req: 0\n",
      "[2025-08-13 21:15:37] Prefill batch. #new-seq: 2, #new-token: 3405, #cached-token: 5112, token usage: 0.84, #running-req: 60, #queue-req: 0\n",
      "[2025-08-13 21:15:39] INFO:     127.0.0.1:40322 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:39] INFO:     127.0.0.1:40338 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:39] Decode batch. #running-req: 60, #token: 203271, token usage: 0.83, cuda graph: True, gen throughput (token/s): 862.97, #queue-req: 0\n",
      "[2025-08-13 21:15:40] INFO:     127.0.0.1:47612 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:40] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4403, token usage: 0.83, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 21:15:40] INFO:     127.0.0.1:37748 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:42] Decode batch. #running-req: 59, #token: 200923, token usage: 0.82, cuda graph: True, gen throughput (token/s): 985.32, #queue-req: 0\n",
      "[2025-08-13 21:15:42] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1443, token usage: 0.82, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 21:15:42] Prefill batch. #new-seq: 1, #new-token: 1349, #cached-token: 0, token usage: 0.85, #running-req: 61, #queue-req: 0\n",
      "[2025-08-13 21:15:45] INFO:     127.0.0.1:51946 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:45] Decode batch. #running-req: 61, #token: 204374, token usage: 0.83, cuda graph: True, gen throughput (token/s): 745.97, #queue-req: 0\n",
      "[2025-08-13 21:15:45] INFO:     127.0.0.1:34026 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:45] INFO:     127.0.0.1:34028 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:46] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 3174, token usage: 0.82, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 21:15:46] Prefill batch. #new-seq: 2, #new-token: 2308, #cached-token: 4932, token usage: 0.83, #running-req: 60, #queue-req: 0\n",
      "[2025-08-13 21:15:47] INFO:     127.0.0.1:40338 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:48] Decode batch. #running-req: 61, #token: 204760, token usage: 0.83, cuda graph: True, gen throughput (token/s): 906.41, #queue-req: 0\n",
      "[2025-08-13 21:15:48] Prefill batch. #new-seq: 1, #new-token: 2135, #cached-token: 151, token usage: 0.83, #running-req: 61, #queue-req: 0\n",
      "[2025-08-13 21:15:48] INFO:     127.0.0.1:45286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:49] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4775, token usage: 0.84, #running-req: 61, #queue-req: 0\n",
      "[2025-08-13 21:15:50] Decode batch. #running-req: 62, #token: 209390, token usage: 0.85, cuda graph: True, gen throughput (token/s): 913.94, #queue-req: 0\n",
      "[2025-08-13 21:15:51] INFO:     127.0.0.1:54372 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:51] INFO:     127.0.0.1:44228 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:53] Prefill batch. #new-seq: 2, #new-token: 996, #cached-token: 560, token usage: 0.84, #running-req: 60, #queue-req: 0\n",
      "[2025-08-13 21:15:53] Decode batch. #running-req: 62, #token: 208562, token usage: 0.85, cuda graph: True, gen throughput (token/s): 928.66, #queue-req: 0\n",
      "[2025-08-13 21:15:54] INFO:     127.0.0.1:34028 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:54] INFO:     127.0.0.1:34026 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:15:55] Decode batch. #running-req: 60, #token: 203649, token usage: 0.83, cuda graph: True, gen throughput (token/s): 990.32, #queue-req: 0\n",
      "[2025-08-13 21:15:56] Prefill batch. #new-seq: 2, #new-token: 4675, #cached-token: 848, token usage: 0.83, #running-req: 60, #queue-req: 0\n",
      "[2025-08-13 21:15:57] INFO:     127.0.0.1:45286 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:15:58] Decode batch. #running-req: 61, #token: 206295, token usage: 0.84, cuda graph: True, gen throughput (token/s): 863.77, #queue-req: 0\n",
      "[2025-08-13 21:15:59] INFO:     127.0.0.1:47488 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:15:59] INFO:     127.0.0.1:37718 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:00] Prefill batch. #new-seq: 1, #new-token: 2282, #cached-token: 126, token usage: 0.82, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 21:16:01] Decode batch. #running-req: 60, #token: 203855, token usage: 0.83, cuda graph: True, gen throughput (token/s): 900.79, #queue-req: 0\n",
      "[2025-08-13 21:16:02] INFO:     127.0.0.1:51858 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:02] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 5192, token usage: 0.83, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 21:16:03] INFO:     127.0.0.1:51858 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:03] Decode batch. #running-req: 59, #token: 201445, token usage: 0.82, cuda graph: True, gen throughput (token/s): 960.25, #queue-req: 0\n",
      "[2025-08-13 21:16:04] Prefill batch. #new-seq: 1, #new-token: 2890, #cached-token: 462, token usage: 0.82, #running-req: 59, #queue-req: 0\n",
      "[2025-08-13 21:16:06] INFO:     127.0.0.1:51870 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:06] INFO:     127.0.0.1:51894 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:06] INFO:     127.0.0.1:51938 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:06] INFO:     127.0.0.1:51956 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:06] INFO:     127.0.0.1:51972 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:06] Decode batch. #running-req: 60, #token: 181713, token usage: 0.74, cuda graph: True, gen throughput (token/s): 873.92, #queue-req: 0\n",
      "[2025-08-13 21:16:06] Prefill batch. #new-seq: 3, #new-token: 62, #cached-token: 17135, token usage: 0.80, #running-req: 55, #queue-req: 0\n",
      ".[2025-08-13 21:16:06] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 5015, token usage: 0.82, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:06] INFO:     127.0.0.1:38490 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:07] INFO:     127.0.0.1:51956 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:07] INFO:     127.0.0.1:51894 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:08] INFO:     127.0.0.1:54390 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:08] INFO:     127.0.0.1:47514 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:09] Decode batch. #running-req: 54, #token: 178968, token usage: 0.73, cuda graph: True, gen throughput (token/s): 944.91, #queue-req: 0\n",
      "[2025-08-13 21:16:09] INFO:     127.0.0.1:51992 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:10] Prefill batch. #new-seq: 2, #new-token: 2372, #cached-token: 5250, token usage: 0.73, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:16:11] Decode batch. #running-req: 55, #token: 183513, token usage: 0.75, cuda graph: True, gen throughput (token/s): 897.85, #queue-req: 0\n",
      "[2025-08-13 21:16:11] Prefill batch. #new-seq: 1, #new-token: 2703, #cached-token: 463, token usage: 0.75, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:16:12] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.76, #running-req: 56, #queue-req: 2\n",
      "[2025-08-13 21:16:12] Prefill batch. #new-seq: 3, #new-token: 6035, #cached-token: 599, token usage: 0.79, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:16:15] Decode batch. #running-req: 59, #token: 202821, token usage: 0.82, cuda graph: True, gen throughput (token/s): 580.33, #queue-req: 0\n",
      "[2025-08-13 21:16:15] INFO:     127.0.0.1:51870 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:15] INFO:     127.0.0.1:51972 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:16] INFO:     127.0.0.1:44952 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:17] Prefill batch. #new-seq: 3, #new-token: 7754, #cached-token: 5729, token usage: 0.81, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:16:17] Decode batch. #running-req: 56, #token: 207783, token usage: 0.85, cuda graph: True, gen throughput (token/s): 955.99, #queue-req: 0\n",
      "[2025-08-13 21:16:20] INFO:     127.0.0.1:51992 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:20] INFO:     127.0.0.1:54374 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:21] Decode batch. #running-req: 57, #token: 204729, token usage: 0.83, cuda graph: True, gen throughput (token/s): 746.58, #queue-req: 0\n",
      "[2025-08-13 21:16:22] Prefill batch. #new-seq: 2, #new-token: 3051, #cached-token: 745, token usage: 0.84, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:16:22] INFO:     127.0.0.1:44958 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:22] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4956, token usage: 0.85, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:23] Decode batch. #running-req: 59, #token: 210121, token usage: 0.85, cuda graph: True, gen throughput (token/s): 846.71, #queue-req: 0\n",
      "[2025-08-13 21:16:23] INFO:     127.0.0.1:44958 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:24] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 451, token usage: 0.84, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:26] Decode batch. #running-req: 59, #token: 210215, token usage: 0.86, cuda graph: True, gen throughput (token/s): 883.07, #queue-req: 0\n",
      "[2025-08-13 21:16:26] INFO:     127.0.0.1:44952 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:27] INFO:     127.0.0.1:44498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:27] Prefill batch. #new-seq: 1, #new-token: 4375, #cached-token: 455, token usage: 0.83, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:16:28] Prefill batch. #new-seq: 1, #new-token: 2278, #cached-token: 128, token usage: 0.85, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:29] INFO:     127.0.0.1:44210 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:29] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 6043, token usage: 0.86, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:29] Decode batch. #running-req: 59, #token: 206490, token usage: 0.84, cuda graph: True, gen throughput (token/s): 744.44, #queue-req: 0\n",
      "[2025-08-13 21:16:29] INFO:     127.0.0.1:40886 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:30] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 450, token usage: 0.84, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:31] INFO:     127.0.0.1:44216 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:31] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4799, token usage: 0.86, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:32] Decode batch. #running-req: 59, #token: 211204, token usage: 0.86, cuda graph: True, gen throughput (token/s): 843.55, #queue-req: 0\n",
      "[2025-08-13 21:16:32] INFO:     127.0.0.1:38578 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:33] Prefill batch. #new-seq: 1, #new-token: 2283, #cached-token: 131, token usage: 0.85, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:34] Decode batch. #running-req: 59, #token: 212820, token usage: 0.87, cuda graph: True, gen throughput (token/s): 881.92, #queue-req: 0\n",
      "[2025-08-13 21:16:37] Decode batch. #running-req: 59, #token: 215180, token usage: 0.88, cuda graph: True, gen throughput (token/s): 949.89, #queue-req: 0\n",
      "[2025-08-13 21:16:37] INFO:     127.0.0.1:44210 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:38] INFO:     127.0.0.1:37734 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:38] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 5214, token usage: 0.86, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:16:38] INFO:     127.0.0.1:38502 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:38] Prefill batch. #new-seq: 1, #new-token: 2178, #cached-token: 0, token usage: 0.85, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:39] Prefill batch. #new-seq: 1, #new-token: 7376, #cached-token: 463, token usage: 0.86, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:40] INFO:     127.0.0.1:54426 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:41] INFO:     127.0.0.1:37756 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:41] Prefill batch. #new-seq: 2, #new-token: 200, #cached-token: 3042, token usage: 0.88, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:16:41] Decode batch. #running-req: 59, #token: 217423, token usage: 0.88, cuda graph: True, gen throughput (token/s): 528.30, #queue-req: 0\n",
      "[2025-08-13 21:16:42] INFO:     127.0.0.1:44216 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:43] Prefill batch. #new-seq: 1, #new-token: 2156, #cached-token: 476, token usage: 0.87, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:44] Decode batch. #running-req: 59, #token: 217424, token usage: 0.88, cuda graph: True, gen throughput (token/s): 854.33, #queue-req: 0\n",
      "[2025-08-13 21:16:44] INFO:     127.0.0.1:49700 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:44] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2629, token usage: 0.89, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:45] INFO:     127.0.0.1:49700 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:46] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 122, token usage: 0.88, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:47] INFO:     127.0.0.1:58556 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:47] Decode batch. #running-req: 58, #token: 215797, token usage: 0.88, cuda graph: True, gen throughput (token/s): 868.02, #queue-req: 0\n",
      "[2025-08-13 21:16:47] Prefill batch. #new-seq: 1, #new-token: 1751, #cached-token: 481, token usage: 0.88, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:48] INFO:     127.0.0.1:54396 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:49] INFO:     127.0.0.1:37734 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:49] Decode batch. #running-req: 57, #token: 212644, token usage: 0.86, cuda graph: True, gen throughput (token/s): 850.96, #queue-req: 0\n",
      "[2025-08-13 21:16:50] INFO:     127.0.0.1:37756 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:51] Prefill batch. #new-seq: 3, #new-token: 5853, #cached-token: 1033, token usage: 0.86, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:16:53] Decode batch. #running-req: 59, #token: 214486, token usage: 0.87, cuda graph: True, gen throughput (token/s): 761.30, #queue-req: 0\n",
      "[2025-08-13 21:16:53] INFO:     127.0.0.1:47486 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:53] INFO:     127.0.0.1:44510 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:16:55] Prefill batch. #new-seq: 1, #new-token: 2349, #cached-token: 453, token usage: 0.84, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:16:55] Prefill batch. #new-seq: 1, #new-token: 7421, #cached-token: 463, token usage: 0.85, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:16:56] Decode batch. #running-req: 59, #token: 217401, token usage: 0.88, cuda graph: True, gen throughput (token/s): 677.47, #queue-req: 0\n",
      "[2025-08-13 21:16:58] Decode batch. #running-req: 59, #token: 219761, token usage: 0.89, cuda graph: True, gen throughput (token/s): 922.33, #queue-req: 0\n",
      "[2025-08-13 21:17:01] INFO:     127.0.0.1:44506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:01] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2738, token usage: 0.90, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:01] Decode batch. #running-req: 58, #token: 222080, token usage: 0.90, cuda graph: True, gen throughput (token/s): 904.82, #queue-req: 0\n",
      "[2025-08-13 21:17:03] INFO:     127.0.0.1:44518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:03] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 5115, token usage: 0.91, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:04] Decode batch. #running-req: 59, #token: 224518, token usage: 0.91, cuda graph: True, gen throughput (token/s): 902.84, #queue-req: 0\n",
      "[2025-08-13 21:17:04] INFO:     127.0.0.1:47496 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:04] INFO:     127.0.0.1:47506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:04] INFO:     127.0.0.1:47510 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:04] Prefill batch. #new-seq: 3, #new-token: 62, #cached-token: 13585, token usage: 0.91, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:17:04] INFO:     127.0.0.1:47496 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 21:17:04] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 5456, token usage: 0.91, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:04] INFO:     127.0.0.1:50502 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:05] Prefill batch. #new-seq: 1, #new-token: 2591, #cached-token: 439, token usage: 0.87, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:06] INFO:     127.0.0.1:47524 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:06] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 5433, token usage: 0.88, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:07] Decode batch. #running-req: 59, #token: 216878, token usage: 0.88, cuda graph: True, gen throughput (token/s): 821.42, #queue-req: 0\n",
      "[2025-08-13 21:17:07] INFO:     127.0.0.1:60286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:07] INFO:     127.0.0.1:47532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:08] Prefill batch. #new-seq: 2, #new-token: 2942, #cached-token: 5064, token usage: 0.87, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:17:09] INFO:     127.0.0.1:60260 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:09] Decode batch. #running-req: 58, #token: 215511, token usage: 0.88, cuda graph: True, gen throughput (token/s): 836.24, #queue-req: 0\n",
      "[2025-08-13 21:17:10] INFO:     127.0.0.1:47506 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:10] INFO:     127.0.0.1:44506 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:10] INFO:     127.0.0.1:47510 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:11] INFO:     127.0.0.1:44518 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:12] Decode batch. #running-req: 54, #token: 204715, token usage: 0.83, cuda graph: True, gen throughput (token/s): 892.49, #queue-req: 0\n",
      "[2025-08-13 21:17:13] Prefill batch. #new-seq: 1, #new-token: 2228, #cached-token: 147, token usage: 0.84, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:17:14] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 437, token usage: 0.85, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:17:14] Prefill batch. #new-seq: 3, #new-token: 6714, #cached-token: 992, token usage: 0.85, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:17:15] INFO:     127.0.0.1:38512 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:15] INFO:     127.0.0.1:38518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:15] Decode batch. #running-req: 59, #token: 206444, token usage: 0.84, cuda graph: True, gen throughput (token/s): 677.09, #queue-req: 0\n",
      "[2025-08-13 21:17:15] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 10700, token usage: 0.88, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:17:15] INFO:     127.0.0.1:47524 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:16] INFO:     127.0.0.1:38546 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:16] Prefill batch. #new-seq: 2, #new-token: 4407, #cached-token: 5243, token usage: 0.86, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:17:17] INFO:     127.0.0.1:47532 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:18] Decode batch. #running-req: 58, #token: 213586, token usage: 0.87, cuda graph: True, gen throughput (token/s): 783.79, #queue-req: 0\n",
      "[2025-08-13 21:17:18] Prefill batch. #new-seq: 1, #new-token: 2156, #cached-token: 478, token usage: 0.87, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:20] INFO:     127.0.0.1:60282 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:21] Decode batch. #running-req: 58, #token: 217033, token usage: 0.88, cuda graph: True, gen throughput (token/s): 846.45, #queue-req: 0\n",
      "[2025-08-13 21:17:21] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 77, token usage: 0.88, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:23] Decode batch. #running-req: 59, #token: 219480, token usage: 0.89, cuda graph: True, gen throughput (token/s): 892.30, #queue-req: 0\n",
      "[2025-08-13 21:17:24] INFO:     127.0.0.1:40898 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:24] INFO:     127.0.0.1:40900 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:24] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 8476, token usage: 0.89, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:17:24] INFO:     127.0.0.1:38512 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:24] INFO:     127.0.0.1:38518 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:25] INFO:     127.0.0.1:38546 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:26] INFO:     127.0.0.1:57496 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:26] Decode batch. #running-req: 55, #token: 203344, token usage: 0.83, cuda graph: True, gen throughput (token/s): 899.56, #queue-req: 0\n",
      "[2025-08-13 21:17:27] INFO:     127.0.0.1:40912 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:28] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 6904, token usage: 0.83, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:17:28] Prefill batch. #new-seq: 1, #new-token: 3528, #cached-token: 0, token usage: 0.87, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:29] Decode batch. #running-req: 59, #token: 215013, token usage: 0.87, cuda graph: True, gen throughput (token/s): 641.64, #queue-req: 0\n",
      "[2025-08-13 21:17:29] INFO:     127.0.0.1:58532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:30] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2745, token usage: 0.88, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:30] INFO:     127.0.0.1:40898 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:32] INFO:     127.0.0.1:58536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:32] Decode batch. #running-req: 57, #token: 211906, token usage: 0.86, cuda graph: True, gen throughput (token/s): 885.75, #queue-req: 0\n",
      "[2025-08-13 21:17:32] Prefill batch. #new-seq: 2, #new-token: 2457, #cached-token: 585, token usage: 0.86, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:17:33] INFO:     127.0.0.1:41796 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:33] INFO:     127.0.0.1:40900 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:34] Prefill batch. #new-seq: 2, #new-token: 2305, #cached-token: 934, token usage: 0.85, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:17:35] Decode batch. #running-req: 59, #token: 211152, token usage: 0.86, cuda graph: True, gen throughput (token/s): 785.55, #queue-req: 0\n",
      "[2025-08-13 21:17:36] INFO:     127.0.0.1:58540 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:36] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4633, token usage: 0.86, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:37] INFO:     127.0.0.1:38560 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:37] INFO:     127.0.0.1:40912 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:38] Decode batch. #running-req: 57, #token: 204554, token usage: 0.83, cuda graph: True, gen throughput (token/s): 914.68, #queue-req: 0\n",
      "[2025-08-13 21:17:38] INFO:     127.0.0.1:58540 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:38] INFO:     127.0.0.1:58532 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:40] Decode batch. #running-req: 55, #token: 200126, token usage: 0.81, cuda graph: True, gen throughput (token/s): 927.75, #queue-req: 0\n",
      "[2025-08-13 21:17:41] INFO:     127.0.0.1:54410 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:41] INFO:     127.0.0.1:36790 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:41] Prefill batch. #new-seq: 2, #new-token: 1324, #cached-token: 3817, token usage: 0.81, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:17:42] Prefill batch. #new-seq: 3, #new-token: 7193, #cached-token: 1353, token usage: 0.82, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:17:42] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 119, token usage: 0.85, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:43] Decode batch. #running-req: 59, #token: 209564, token usage: 0.85, cuda graph: True, gen throughput (token/s): 693.63, #queue-req: 0\n",
      "[2025-08-13 21:17:46] Decode batch. #running-req: 59, #token: 211924, token usage: 0.86, cuda graph: True, gen throughput (token/s): 923.25, #queue-req: 0\n",
      "[2025-08-13 21:17:46] INFO:     127.0.0.1:54436 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:46] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 9517, token usage: 0.86, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:47] INFO:     127.0.0.1:54436 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:48] Prefill batch. #new-seq: 1, #new-token: 7268, #cached-token: 409, token usage: 0.83, #running-req: 58, #queue-req: 0\n",
      "[2025-08-13 21:17:49] Decode batch. #running-req: 59, #token: 212552, token usage: 0.86, cuda graph: True, gen throughput (token/s): 731.42, #queue-req: 0\n",
      "[2025-08-13 21:17:50] INFO:     127.0.0.1:54410 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:17:51] Decode batch. #running-req: 58, #token: 210469, token usage: 0.86, cuda graph: True, gen throughput (token/s): 931.82, #queue-req: 0\n",
      "[2025-08-13 21:17:53] INFO:     127.0.0.1:38556 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:53] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.86, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:17:54] INFO:     127.0.0.1:38568 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:54] INFO:     127.0.0.1:38586 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:54] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 9433, token usage: 0.86, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:17:54] Decode batch. #running-req: 58, #token: 212846, token usage: 0.87, cuda graph: True, gen throughput (token/s): 904.10, #queue-req: 0\n",
      "[2025-08-13 21:17:55] INFO:     127.0.0.1:38568 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:56] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 449, token usage: 0.85, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:17:57] Decode batch. #running-req: 58, #token: 213244, token usage: 0.87, cuda graph: True, gen throughput (token/s): 841.75, #queue-req: 0\n",
      "[2025-08-13 21:17:57] INFO:     127.0.0.1:38596 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:57] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 5863, token usage: 0.87, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:17:58] INFO:     127.0.0.1:34808 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:58] INFO:     127.0.0.1:55382 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:59] INFO:     127.0.0.1:42208 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:59] INFO:     127.0.0.1:38556 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:17:59] Decode batch. #running-req: 54, #token: 200900, token usage: 0.82, cuda graph: True, gen throughput (token/s): 903.53, #queue-req: 0\n",
      "[2025-08-13 21:18:02] Decode batch. #running-req: 54, #token: 191789, token usage: 0.78, cuda graph: True, gen throughput (token/s): 897.55, #queue-req: 0\n",
      "[2025-08-13 21:18:02] INFO:     127.0.0.1:57488 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:02] INFO:     127.0.0.1:57490 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:02] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 7379, token usage: 0.81, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:18:02] Prefill batch. #new-seq: 5, #new-token: 7661, #cached-token: 5586, token usage: 0.83, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:18:03] INFO:     127.0.0.1:38586 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:04] Prefill batch. #new-seq: 1, #new-token: 2810, #cached-token: 465, token usage: 0.84, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:18:05] Decode batch. #running-req: 58, #token: 211345, token usage: 0.86, cuda graph: True, gen throughput (token/s): 668.57, #queue-req: 0\n",
      "[2025-08-13 21:18:06] INFO:     127.0.0.1:57508 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:06] INFO:     127.0.0.1:38596 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:06] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4417, token usage: 0.84, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:18:07] Prefill batch. #new-seq: 1, #new-token: 2478, #cached-token: 438, token usage: 0.84, #running-req: 57, #queue-req: 0\n",
      "[2025-08-13 21:18:07] INFO:     127.0.0.1:41790 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:08] Decode batch. #running-req: 57, #token: 199405, token usage: 0.81, cuda graph: True, gen throughput (token/s): 837.45, #queue-req: 0\n",
      "[2025-08-13 21:18:08] INFO:     127.0.0.1:60258 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:08] INFO:     127.0.0.1:42194 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:08] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4285, token usage: 0.80, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:18:09] INFO:     127.0.0.1:34394 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:09] INFO:     127.0.0.1:57490 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:09] INFO:     127.0.0.1:60258 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:10] Decode batch. #running-req: 53, #token: 184935, token usage: 0.75, cuda graph: True, gen throughput (token/s): 928.82, #queue-req: 0\n",
      "[2025-08-13 21:18:11] INFO:     127.0.0.1:57488 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:12] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.74, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:18:12] Prefill batch. #new-seq: 1, #new-token: 1584, #cached-token: 0, token usage: 0.77, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:18:13] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1257, token usage: 0.78, #running-req: 53, #queue-req: 1\n",
      "[2025-08-13 21:18:13] Prefill batch. #new-seq: 2, #new-token: 4035, #cached-token: 472, token usage: 0.81, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:18:14] INFO:     127.0.0.1:60270 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:14] INFO:     127.0.0.1:60272 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:14] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 5554, token usage: 0.83, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:18:14] INFO:     127.0.0.1:57508 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:18:15] Decode batch. #running-req: 57, #token: 200226, token usage: 0.81, cuda graph: True, gen throughput (token/s): 484.75, #queue-req: 0\n",
      "[2025-08-13 21:18:15] INFO:     127.0.0.1:34778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:16] Prefill batch. #new-seq: 1, #new-token: 2752, #cached-token: 480, token usage: 0.80, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:18:17] Decode batch. #running-req: 57, #token: 199365, token usage: 0.81, cuda graph: True, gen throughput (token/s): 859.25, #queue-req: 0\n",
      "[2025-08-13 21:18:18] INFO:     127.0.0.1:60294 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:18] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4633, token usage: 0.81, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:18:18] INFO:     127.0.0.1:60274 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:19] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 439, token usage: 0.82, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:18:20] Decode batch. #running-req: 57, #token: 201161, token usage: 0.82, cuda graph: True, gen throughput (token/s): 906.73, #queue-req: 0\n",
      "[2025-08-13 21:18:22] Decode batch. #running-req: 57, #token: 203441, token usage: 0.83, cuda graph: True, gen throughput (token/s): 918.67, #queue-req: 0\n",
      "[2025-08-13 21:18:22] INFO:     127.0.0.1:60270 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:22] INFO:     127.0.0.1:60272 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:18:23] Prefill batch. #new-seq: 1, #new-token: 3974, #cached-token: 413, token usage: 0.81, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:18:25] Decode batch. #running-req: 56, #token: 204356, token usage: 0.83, cuda graph: True, gen throughput (token/s): 795.48, #queue-req: 0\n",
      "[2025-08-13 21:18:25] INFO:     127.0.0.1:60294 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:25] INFO:     127.0.0.1:55398 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:26] Prefill batch. #new-seq: 2, #new-token: 2368, #cached-token: 5806, token usage: 0.82, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:18:27] INFO:     127.0.0.1:44458 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:28] Decode batch. #running-req: 55, #token: 200884, token usage: 0.82, cuda graph: True, gen throughput (token/s): 843.45, #queue-req: 0\n",
      "[2025-08-13 21:18:28] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 625, token usage: 0.82, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:18:28] Prefill batch. #new-seq: 1, #new-token: 1352, #cached-token: 0, token usage: 0.85, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:18:31] Decode batch. #running-req: 56, #token: 212662, token usage: 0.86, cuda graph: True, gen throughput (token/s): 644.14, #queue-req: 0\n",
      "[2025-08-13 21:18:32] INFO:     127.0.0.1:41772 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:32] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4800, token usage: 0.87, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:18:34] Decode batch. #running-req: 56, #token: 214921, token usage: 0.87, cuda graph: True, gen throughput (token/s): 894.21, #queue-req: 0\n",
      "[2025-08-13 21:18:34] INFO:     127.0.0.1:41782 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:34] INFO:     127.0.0.1:41810 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:34] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 9572, token usage: 0.88, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:18:35] INFO:     127.0.0.1:41810 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:35] INFO:     127.0.0.1:55398 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:36] Decode batch. #running-req: 54, #token: 207816, token usage: 0.85, cuda graph: True, gen throughput (token/s): 873.28, #queue-req: 0\n",
      "[2025-08-13 21:18:36] INFO:     127.0.0.1:50540 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:37] INFO:     127.0.0.1:60254 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:37] Prefill batch. #new-seq: 1, #new-token: 2360, #cached-token: 148, token usage: 0.81, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:18:37] INFO:     127.0.0.1:36818 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:39] INFO:     127.0.0.1:60268 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:39] Decode batch. #running-req: 52, #token: 191004, token usage: 0.78, cuda graph: True, gen throughput (token/s): 808.97, #queue-req: 0\n",
      "[2025-08-13 21:18:39] Prefill batch. #new-seq: 2, #new-token: 5096, #cached-token: 8241, token usage: 0.81, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:18:40] Prefill batch. #new-seq: 3, #new-token: 4763, #cached-token: 1357, token usage: 0.83, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:18:41] INFO:     127.0.0.1:41772 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:42] Decode batch. #running-req: 55, #token: 205921, token usage: 0.84, cuda graph: True, gen throughput (token/s): 654.37, #queue-req: 0\n",
      "[2025-08-13 21:18:42] Prefill batch. #new-seq: 1, #new-token: 2157, #cached-token: 476, token usage: 0.84, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:18:43] INFO:     127.0.0.1:41782 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:43] INFO:     127.0.0.1:60280 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:44] INFO:     127.0.0.1:60268 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:44] INFO:     127.0.0.1:60266 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:44] INFO:     127.0.0.1:34790 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:44] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 5433, token usage: 0.77, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:18:45] Decode batch. #running-req: 52, #token: 190680, token usage: 0.78, cuda graph: True, gen throughput (token/s): 833.30, #queue-req: 0\n",
      "[2025-08-13 21:18:45] INFO:     127.0.0.1:60280 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:46] INFO:     127.0.0.1:60288 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:47] Decode batch. #running-req: 50, #token: 183281, token usage: 0.75, cuda graph: True, gen throughput (token/s): 893.26, #queue-req: 0\n",
      "[2025-08-13 21:18:47] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.76, #running-req: 50, #queue-req: 0\n",
      "[2025-08-13 21:18:48] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1052, token usage: 0.77, #running-req: 51, #queue-req: 2\n",
      "[2025-08-13 21:18:48] Prefill batch. #new-seq: 3, #new-token: 3988, #cached-token: 631, token usage: 0.80, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:18:49] INFO:     127.0.0.1:34406 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:50] Decode batch. #running-req: 55, #token: 198004, token usage: 0.81, cuda graph: True, gen throughput (token/s): 620.68, #queue-req: 0\n",
      "[2025-08-13 21:18:51] INFO:     127.0.0.1:34792 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:52] Prefill batch. #new-seq: 2, #new-token: 2371, #cached-token: 5251, token usage: 0.81, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:18:53] Decode batch. #running-req: 56, #token: 202579, token usage: 0.82, cuda graph: True, gen throughput (token/s): 840.87, #queue-req: 0\n",
      "[2025-08-13 21:18:55] Decode batch. #running-req: 56, #token: 204819, token usage: 0.83, cuda graph: True, gen throughput (token/s): 918.03, #queue-req: 0\n",
      "[2025-08-13 21:18:56] INFO:     127.0.0.1:60288 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:57] Prefill batch. #new-seq: 1, #new-token: 2702, #cached-token: 412, token usage: 0.82, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:18:58] Decode batch. #running-req: 56, #token: 205266, token usage: 0.83, cuda graph: True, gen throughput (token/s): 823.16, #queue-req: 0\n",
      "[2025-08-13 21:18:59] INFO:     127.0.0.1:38772 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:18:59] INFO:     127.0.0.1:50518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:00] Prefill batch. #new-seq: 2, #new-token: 278, #cached-token: 9961, token usage: 0.84, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:19:00] INFO:     127.0.0.1:34792 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:00] INFO:     127.0.0.1:50530 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:00] INFO:     127.0.0.1:39678 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:00] Decode batch. #running-req: 53, #token: 197123, token usage: 0.80, cuda graph: True, gen throughput (token/s): 892.86, #queue-req: 0\n",
      "[2025-08-13 21:19:01] INFO:     127.0.0.1:50518 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:01] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2640, token usage: 0.77, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:19:03] Decode batch. #running-req: 53, #token: 191959, token usage: 0.78, cuda graph: True, gen throughput (token/s): 915.29, #queue-req: 0\n",
      "[2025-08-13 21:19:03] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1056, token usage: 0.78, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:19:03] Prefill batch. #new-seq: 1, #new-token: 4279, #cached-token: 0, token usage: 0.82, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:19:06] INFO:     127.0.0.1:50546 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:06] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2381, token usage: 0.84, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:19:06] Decode batch. #running-req: 56, #token: 206674, token usage: 0.84, cuda graph: True, gen throughput (token/s): 623.55, #queue-req: 0\n",
      "[2025-08-13 21:19:06] INFO:     127.0.0.1:51062 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:07] INFO:     127.0.0.1:42216 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:07] INFO:     127.0.0.1:34386 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:07] INFO:     127.0.0.1:34418 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:07] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4231, token usage: 0.80, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:19:09] Decode batch. #running-req: 53, #token: 198116, token usage: 0.81, cuda graph: True, gen throughput (token/s): 893.85, #queue-req: 0\n",
      "[2025-08-13 21:19:09] INFO:     127.0.0.1:36804 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:10] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 439, token usage: 0.79, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:19:10] INFO:     127.0.0.1:50530 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:10] Prefill batch. #new-seq: 1, #new-token: 3060, #cached-token: 480, token usage: 0.79, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:19:11] Prefill batch. #new-seq: 3, #new-token: 4397, #cached-token: 1310, token usage: 0.80, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:19:12] Decode batch. #running-req: 56, #token: 201681, token usage: 0.82, cuda graph: True, gen throughput (token/s): 699.33, #queue-req: 0\n",
      "[2025-08-13 21:19:13] INFO:     127.0.0.1:38786 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:14] INFO:     127.0.0.1:34432 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:14] INFO:     127.0.0.1:34442 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:14] INFO:     127.0.0.1:53914 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:14] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 14684, token usage: 0.78, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:19:14] Decode batch. #running-req: 54, #token: 188282, token usage: 0.77, cuda graph: True, gen throughput (token/s): 919.32, #queue-req: 0\n",
      "[2025-08-13 21:19:14] INFO:     127.0.0.1:50546 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:16] INFO:     127.0.0.1:34386 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:16] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 449, token usage: 0.76, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:19:17] Decode batch. #running-req: 53, #token: 188838, token usage: 0.77, cuda graph: True, gen throughput (token/s): 843.42, #queue-req: 0\n",
      "[2025-08-13 21:19:17] Prefill batch. #new-seq: 3, #new-token: 6424, #cached-token: 975, token usage: 0.77, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:19:20] Decode batch. #running-req: 56, #token: 197502, token usage: 0.80, cuda graph: True, gen throughput (token/s): 781.09, #queue-req: 0\n",
      "[2025-08-13 21:19:21] INFO:     127.0.0.1:37260 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:22] INFO:     127.0.0.1:39664 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:22] Decode batch. #running-req: 54, #token: 192472, token usage: 0.78, cuda graph: True, gen throughput (token/s): 950.58, #queue-req: 0\n",
      "[2025-08-13 21:19:22] INFO:     127.0.0.1:47496 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:22] INFO:     127.0.0.1:34442 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:22] INFO:     127.0.0.1:34432 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:23] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 7456, token usage: 0.73, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:19:24] Decode batch. #running-req: 52, #token: 180499, token usage: 0.73, cuda graph: True, gen throughput (token/s): 924.78, #queue-req: 0\n",
      "[2025-08-13 21:19:25] Prefill batch. #new-seq: 2, #new-token: 3686, #cached-token: 586, token usage: 0.72, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:19:25] INFO:     127.0.0.1:38802 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:25] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.74, #running-req: 54, #queue-req: 1\n",
      "[2025-08-13 21:19:25] Prefill batch. #new-seq: 2, #new-token: 3656, #cached-token: 392, token usage: 0.77, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:19:26] Prefill batch. #new-seq: 1, #new-token: 296, #cached-token: 436, token usage: 0.78, #running-req: 56, #queue-req: 0\n",
      "[2025-08-13 21:19:27] INFO:     127.0.0.1:42186 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:27] INFO:     127.0.0.1:42172 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:28] Decode batch. #running-req: 54, #token: 185654, token usage: 0.76, cuda graph: True, gen throughput (token/s): 559.88, #queue-req: 0\n",
      "[2025-08-13 21:19:29] Prefill batch. #new-seq: 2, #new-token: 2673, #cached-token: 584, token usage: 0.76, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:19:30] INFO:     127.0.0.1:47496 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:30] Decode batch. #running-req: 55, #token: 183430, token usage: 0.75, cuda graph: True, gen throughput (token/s): 880.21, #queue-req: 0\n",
      "[2025-08-13 21:19:31] Prefill batch. #new-seq: 1, #new-token: 5144, #cached-token: 463, token usage: 0.75, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:19:33] INFO:     127.0.0.1:42192 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:33] INFO:     127.0.0.1:42212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:33] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 7580, token usage: 0.77, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:19:33] Decode batch. #running-req: 56, #token: 190850, token usage: 0.78, cuda graph: True, gen throughput (token/s): 799.47, #queue-req: 0\n",
      "[2025-08-13 21:19:36] Decode batch. #running-req: 56, #token: 193090, token usage: 0.79, cuda graph: True, gen throughput (token/s): 981.80, #queue-req: 0\n",
      "[2025-08-13 21:19:36] INFO:     127.0.0.1:36784 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:36] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4633, token usage: 0.79, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:19:38] Decode batch. #running-req: 56, #token: 195349, token usage: 0.79, cuda graph: True, gen throughput (token/s): 955.60, #queue-req: 0\n",
      "[2025-08-13 21:19:39] INFO:     127.0.0.1:60260 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:40] INFO:     127.0.0.1:36784 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:40] Decode batch. #running-req: 54, #token: 183972, token usage: 0.75, cuda graph: True, gen throughput (token/s): 947.09, #queue-req: 0\n",
      "[2025-08-13 21:19:40] INFO:     127.0.0.1:42212 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:40] INFO:     127.0.0.1:42192 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:42] INFO:     127.0.0.1:33600 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:42] Decode batch. #running-req: 52, #token: 179899, token usage: 0.73, cuda graph: True, gen throughput (token/s): 926.32, #queue-req: 0\n",
      "[2025-08-13 21:19:43] Prefill batch. #new-seq: 1, #new-token: 1581, #cached-token: 393, token usage: 0.73, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:19:44] Prefill batch. #new-seq: 4, #new-token: 8192, #cached-token: 1957, token usage: 0.74, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:19:44] Prefill batch. #new-seq: 1, #new-token: 1831, #cached-token: 0, token usage: 0.78, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:19:45] INFO:     127.0.0.1:60244 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:45] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 3630, token usage: 0.79, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:19:46] Decode batch. #running-req: 56, #token: 193793, token usage: 0.79, cuda graph: True, gen throughput (token/s): 643.15, #queue-req: 0\n",
      "[2025-08-13 21:19:48] Decode batch. #running-req: 56, #token: 196033, token usage: 0.80, cuda graph: True, gen throughput (token/s): 945.59, #queue-req: 0\n",
      "[2025-08-13 21:19:50] INFO:     127.0.0.1:60282 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:51] Decode batch. #running-req: 55, #token: 194025, token usage: 0.79, cuda graph: True, gen throughput (token/s): 934.90, #queue-req: 0\n",
      "[2025-08-13 21:19:51] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.79, #running-req: 55, #queue-req: 0\n",
      "[2025-08-13 21:19:53] INFO:     127.0.0.1:39682 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:53] INFO:     127.0.0.1:60244 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:53] Decode batch. #running-req: 54, #token: 191423, token usage: 0.78, cuda graph: True, gen throughput (token/s): 855.59, #queue-req: 0\n",
      "[2025-08-13 21:19:55] Prefill batch. #new-seq: 2, #new-token: 4141, #cached-token: 530, token usage: 0.78, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:19:56] Decode batch. #running-req: 56, #token: 197750, token usage: 0.80, cuda graph: True, gen throughput (token/s): 804.34, #queue-req: 0\n",
      "[2025-08-13 21:19:56] INFO:     127.0.0.1:33378 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:57] INFO:     127.0.0.1:33596 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:57] Prefill batch. #new-seq: 2, #new-token: 302, #cached-token: 3150, token usage: 0.79, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:19:58] INFO:     127.0.0.1:33612 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:58] INFO:     127.0.0.1:33624 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:58] INFO:     127.0.0.1:33628 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:19:58] Prefill batch. #new-seq: 3, #new-token: 62, #cached-token: 9945, token usage: 0.80, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:19:58] Decode batch. #running-req: 56, #token: 196567, token usage: 0.80, cuda graph: True, gen throughput (token/s): 914.39, #queue-req: 0\n",
      "[2025-08-13 21:19:59] INFO:     127.0.0.1:33628 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:20:01] Decode batch. #running-req: 55, #token: 196624, token usage: 0.80, cuda graph: True, gen throughput (token/s): 941.63, #queue-req: 0\n",
      "[2025-08-13 21:20:03] INFO:     127.0.0.1:37672 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:03] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 9676, token usage: 0.81, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:20:03] INFO:     127.0.0.1:33448 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:03] Decode batch. #running-req: 55, #token: 195729, token usage: 0.80, cuda graph: True, gen throughput (token/s): 925.76, #queue-req: 0\n",
      "[2025-08-13 21:20:04] Prefill batch. #new-seq: 1, #new-token: 4001, #cached-token: 413, token usage: 0.80, #running-req: 54, #queue-req: 0\n",
      "[2025-08-13 21:20:05] INFO:     127.0.0.1:33596 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:06] INFO:     127.0.0.1:33612 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:06] INFO:     127.0.0.1:33624 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:06] Decode batch. #running-req: 52, #token: 192405, token usage: 0.78, cuda graph: True, gen throughput (token/s): 784.98, #queue-req: 0\n",
      ".[2025-08-13 21:20:07] INFO:     127.0.0.1:38742 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:07] Prefill batch. #new-seq: 1, #new-token: 2472, #cached-token: 437, token usage: 0.77, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:20:08] Prefill batch. #new-seq: 1, #new-token: 2158, #cached-token: 474, token usage: 0.78, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:20:08] Prefill batch. #new-seq: 1, #new-token: 5492, #cached-token: 481, token usage: 0.79, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:09] Decode batch. #running-req: 54, #token: 200350, token usage: 0.81, cuda graph: True, gen throughput (token/s): 630.49, #queue-req: 0\n",
      "[2025-08-13 21:20:11] INFO:     127.0.0.1:37686 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:11] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4800, token usage: 0.82, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:11] Decode batch. #running-req: 54, #token: 202529, token usage: 0.82, cuda graph: True, gen throughput (token/s): 895.92, #queue-req: 0\n",
      "[2025-08-13 21:20:12] INFO:     127.0.0.1:37672 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:13] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.79, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:13] Prefill batch. #new-seq: 1, #new-token: 1262, #cached-token: 0, token usage: 0.82, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:14] INFO:     127.0.0.1:36498 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:15] Decode batch. #running-req: 53, #token: 201209, token usage: 0.82, cuda graph: True, gen throughput (token/s): 632.07, #queue-req: 0\n",
      "[2025-08-13 21:20:15] Prefill batch. #new-seq: 1, #new-token: 4613, #cached-token: 466, token usage: 0.82, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:17] INFO:     127.0.0.1:35220 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:18] Decode batch. #running-req: 53, #token: 204947, token usage: 0.83, cuda graph: True, gen throughput (token/s): 741.86, #queue-req: 0\n",
      "[2025-08-13 21:20:18] INFO:     127.0.0.1:39684 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:18] INFO:     127.0.0.1:33386 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:18] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4592, token usage: 0.83, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:20:19] INFO:     127.0.0.1:39690 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:20] Prefill batch. #new-seq: 3, #new-token: 5300, #cached-token: 6126, token usage: 0.83, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:20:21] INFO:     127.0.0.1:37686 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:21] Decode batch. #running-req: 53, #token: 206645, token usage: 0.84, cuda graph: True, gen throughput (token/s): 707.42, #queue-req: 0\n",
      "[2025-08-13 21:20:22] Prefill batch. #new-seq: 1, #new-token: 2223, #cached-token: 410, token usage: 0.84, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:22] INFO:     127.0.0.1:51064 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:23] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 450, token usage: 0.84, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:24] Decode batch. #running-req: 54, #token: 209695, token usage: 0.85, cuda graph: True, gen throughput (token/s): 733.58, #queue-req: 0\n",
      "[2025-08-13 21:20:25] INFO:     127.0.0.1:39684 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:26] INFO:     127.0.0.1:55150 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:26] Decode batch. #running-req: 52, #token: 204517, token usage: 0.83, cuda graph: True, gen throughput (token/s): 867.82, #queue-req: 0\n",
      "[2025-08-13 21:20:27] INFO:     127.0.0.1:38754 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:27] Prefill batch. #new-seq: 1, #new-token: 2312, #cached-token: 450, token usage: 0.79, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:20:28] INFO:     127.0.0.1:33406 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:28] Prefill batch. #new-seq: 1, #new-token: 1565, #cached-token: 159, token usage: 0.79, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:20:28] INFO:     127.0.0.1:38758 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:28] INFO:     127.0.0.1:38778 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:28] INFO:     127.0.0.1:38782 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:29] INFO:     127.0.0.1:39690 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:29] Decode batch. #running-req: 48, #token: 174572, token usage: 0.71, cuda graph: True, gen throughput (token/s): 760.22, #queue-req: 0\n",
      "[2025-08-13 21:20:29] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 7538, token usage: 0.74, #running-req: 48, #queue-req: 0\n",
      "[2025-08-13 21:20:29] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 9582, token usage: 0.77, #running-req: 49, #queue-req: 0\n",
      "[2025-08-13 21:20:29] Prefill batch. #new-seq: 1, #new-token: 1784, #cached-token: 0, token usage: 0.81, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:20:30] Prefill batch. #new-seq: 1, #new-token: 195, #cached-token: 413, token usage: 0.81, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:20:30] Prefill batch. #new-seq: 1, #new-token: 4390, #cached-token: 441, token usage: 0.82, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:33] Decode batch. #running-req: 54, #token: 206978, token usage: 0.84, cuda graph: True, gen throughput (token/s): 538.08, #queue-req: 0\n",
      "[2025-08-13 21:20:33] INFO:     127.0.0.1:57102 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:34] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 438, token usage: 0.83, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:35] INFO:     127.0.0.1:37252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:35] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2772, token usage: 0.84, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:35] INFO:     127.0.0.1:33372 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:35] Decode batch. #running-req: 54, #token: 204583, token usage: 0.83, cuda graph: True, gen throughput (token/s): 834.51, #queue-req: 0\n",
      "[2025-08-13 21:20:36] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 460, token usage: 0.83, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:38] Decode batch. #running-req: 54, #token: 206800, token usage: 0.84, cuda graph: True, gen throughput (token/s): 863.82, #queue-req: 0\n",
      "[2025-08-13 21:20:38] INFO:     127.0.0.1:35704 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:38] INFO:     127.0.0.1:38778 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:38] INFO:     127.0.0.1:38782 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:38] INFO:     127.0.0.1:38758 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:40] Decode batch. #running-req: 50, #token: 190391, token usage: 0.77, cuda graph: True, gen throughput (token/s): 875.83, #queue-req: 0\n",
      "[2025-08-13 21:20:41] INFO:     127.0.0.1:37270 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:42] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 6041, token usage: 0.78, #running-req: 49, #queue-req: 0\n",
      "[2025-08-13 21:20:42] Prefill batch. #new-seq: 1, #new-token: 5160, #cached-token: 0, token usage: 0.81, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:44] Decode batch. #running-req: 54, #token: 205781, token usage: 0.84, cuda graph: True, gen throughput (token/s): 574.84, #queue-req: 0\n",
      "[2025-08-13 21:20:44] INFO:     127.0.0.1:37252 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:45] Prefill batch. #new-seq: 1, #new-token: 2162, #cached-token: 471, token usage: 0.83, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:45] INFO:     127.0.0.1:53496 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:46] Prefill batch. #new-seq: 1, #new-token: 2998, #cached-token: 465, token usage: 0.84, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:47] Decode batch. #running-req: 54, #token: 209127, token usage: 0.85, cuda graph: True, gen throughput (token/s): 734.81, #queue-req: 0\n",
      "[2025-08-13 21:20:49] Decode batch. #running-req: 54, #token: 211287, token usage: 0.86, cuda graph: True, gen throughput (token/s): 868.28, #queue-req: 0\n",
      "[2025-08-13 21:20:50] INFO:     127.0.0.1:36512 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:51] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 144, token usage: 0.85, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:51] INFO:     127.0.0.1:37270 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:52] Decode batch. #running-req: 53, #token: 205201, token usage: 0.83, cuda graph: True, gen throughput (token/s): 847.32, #queue-req: 0\n",
      "[2025-08-13 21:20:52] Prefill batch. #new-seq: 1, #new-token: 2171, #cached-token: 461, token usage: 0.84, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:53] INFO:     127.0.0.1:53918 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:53] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4507, token usage: 0.85, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:20:53] INFO:     127.0.0.1:35720 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:53] INFO:     127.0.0.1:53918 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:54] INFO:     127.0.0.1:57076 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:54] Decode batch. #running-req: 51, #token: 199323, token usage: 0.81, cuda graph: True, gen throughput (token/s): 797.19, #queue-req: 0\n",
      "[2025-08-13 21:20:54] INFO:     127.0.0.1:53934 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:55] INFO:     127.0.0.1:51044 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:55] INFO:     127.0.0.1:51056 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:56] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 7537, token usage: 0.78, #running-req: 48, #queue-req: 0\n",
      "[2025-08-13 21:20:56] Prefill batch. #new-seq: 5, #new-token: 6023, #cached-token: 10574, token usage: 0.82, #running-req: 49, #queue-req: 0\n",
      "[2025-08-13 21:20:57] INFO:     127.0.0.1:53934 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:57] Decode batch. #running-req: 54, #token: 200296, token usage: 0.81, cuda graph: True, gen throughput (token/s): 701.37, #queue-req: 0\n",
      "[2025-08-13 21:20:58] INFO:     127.0.0.1:37814 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:20:59] Prefill batch. #new-seq: 2, #new-token: 5342, #cached-token: 927, token usage: 0.81, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:21:00] Decode batch. #running-req: 54, #token: 204570, token usage: 0.83, cuda graph: True, gen throughput (token/s): 741.00, #queue-req: 0\n",
      "[2025-08-13 21:21:01] INFO:     127.0.0.1:53834 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:01] INFO:     127.0.0.1:53480 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:02] Decode batch. #running-req: 52, #token: 195191, token usage: 0.79, cuda graph: True, gen throughput (token/s): 888.16, #queue-req: 0\n",
      "[2025-08-13 21:21:03] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 441, token usage: 0.79, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:21:03] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 463, token usage: 0.80, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:21:03] Prefill batch. #new-seq: 1, #new-token: 1574, #cached-token: 0, token usage: 0.83, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:21:05] INFO:     127.0.0.1:36494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:05] INFO:     127.0.0.1:36514 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:05] INFO:     127.0.0.1:36516 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:05] Prefill batch. #new-seq: 3, #new-token: 62, #cached-token: 14795, token usage: 0.84, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:21:05] INFO:     127.0.0.1:51056 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:05] INFO:     127.0.0.1:51044 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:06] Decode batch. #running-req: 52, #token: 198399, token usage: 0.81, cuda graph: True, gen throughput (token/s): 609.88, #queue-req: 0\n",
      "[2025-08-13 21:21:06] INFO:     127.0.0.1:53474 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:07] INFO:     127.0.0.1:36530 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:08] Prefill batch. #new-seq: 4, #new-token: 7585, #cached-token: 5892, token usage: 0.80, #running-req: 50, #queue-req: 0\n",
      "[2025-08-13 21:21:09] INFO:     127.0.0.1:36530 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 21:21:09] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 2800, token usage: 0.83, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:21:09] Decode batch. #running-req: 54, #token: 203192, token usage: 0.83, cuda graph: True, gen throughput (token/s): 671.68, #queue-req: 0\n",
      "[2025-08-13 21:21:10] INFO:     127.0.0.1:44002 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:10] INFO:     127.0.0.1:36514 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:11] Decode batch. #running-req: 52, #token: 199824, token usage: 0.81, cuda graph: True, gen throughput (token/s): 890.97, #queue-req: 0\n",
      "[2025-08-13 21:21:12] Prefill batch. #new-seq: 2, #new-token: 2566, #cached-token: 574, token usage: 0.81, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:21:13] INFO:     127.0.0.1:55136 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:14] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 5113, token usage: 0.83, #running-req: 53, #queue-req: 0\n",
      "[2025-08-13 21:21:14] INFO:     127.0.0.1:36494 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:14] INFO:     127.0.0.1:36516 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:14] INFO:     127.0.0.1:55148 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:14] Decode batch. #running-req: 51, #token: 187839, token usage: 0.76, cuda graph: True, gen throughput (token/s): 807.00, #queue-req: 0\n",
      "[2025-08-13 21:21:15] INFO:     127.0.0.1:53468 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:16] INFO:     127.0.0.1:55144 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:16] Decode batch. #running-req: 49, #token: 183630, token usage: 0.75, cuda graph: True, gen throughput (token/s): 876.61, #queue-req: 0\n",
      "[2025-08-13 21:21:16] Prefill batch. #new-seq: 2, #new-token: 7095, #cached-token: 2842, token usage: 0.76, #running-req: 49, #queue-req: 0\n",
      ".[2025-08-13 21:21:16] Prefill batch. #new-seq: 2, #new-token: 5319, #cached-token: 1075, token usage: 0.79, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:21:20] Decode batch. #running-req: 53, #token: 200648, token usage: 0.82, cuda graph: True, gen throughput (token/s): 599.96, #queue-req: 0\n",
      "[2025-08-13 21:21:20] INFO:     127.0.0.1:55156 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:20] INFO:     127.0.0.1:60574 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:20] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 9997, token usage: 0.80, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:21:21] INFO:     127.0.0.1:55136 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:22] Decode batch. #running-req: 51, #token: 194144, token usage: 0.79, cuda graph: True, gen throughput (token/s): 864.45, #queue-req: 0\n",
      "[2025-08-13 21:21:22] Prefill batch. #new-seq: 2, #new-token: 2742, #cached-token: 888, token usage: 0.79, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:21:25] Decode batch. #running-req: 53, #token: 199009, token usage: 0.81, cuda graph: True, gen throughput (token/s): 811.74, #queue-req: 0\n",
      "[2025-08-13 21:21:25] INFO:     127.0.0.1:55144 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:26] Prefill batch. #new-seq: 1, #new-token: 2558, #cached-token: 159, token usage: 0.81, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:21:27] INFO:     127.0.0.1:33390 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:27] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4260, token usage: 0.82, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:21:27] Decode batch. #running-req: 52, #token: 201231, token usage: 0.82, cuda graph: True, gen throughput (token/s): 795.81, #queue-req: 0\n",
      "[2025-08-13 21:21:28] INFO:     127.0.0.1:33390 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:28] INFO:     127.0.0.1:55156 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:30] Decode batch. #running-req: 51, #token: 189719, token usage: 0.77, cuda graph: True, gen throughput (token/s): 893.57, #queue-req: 0\n",
      "[2025-08-13 21:21:31] Prefill batch. #new-seq: 1, #new-token: 396, #cached-token: 437, token usage: 0.77, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:21:31] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.78, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:21:31] Prefill batch. #new-seq: 1, #new-token: 1582, #cached-token: 0, token usage: 0.81, #running-req: 52, #queue-req: 0\n",
      "[2025-08-13 21:21:32] INFO:     127.0.0.1:37228 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:32] INFO:     127.0.0.1:33414 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:32] INFO:     127.0.0.1:43976 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:33] INFO:     127.0.0.1:60212 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:33] INFO:     127.0.0.1:57100 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:33] Decode batch. #running-req: 48, #token: 177513, token usage: 0.72, cuda graph: True, gen throughput (token/s): 602.28, #queue-req: 0\n",
      "[2025-08-13 21:21:33] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.74, #running-req: 48, #queue-req: 0\n",
      "[2025-08-13 21:21:33] INFO:     127.0.0.1:33426 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:33] INFO:     127.0.0.1:33442 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:35] Decode batch. #running-req: 47, #token: 183764, token usage: 0.75, cuda graph: True, gen throughput (token/s): 845.79, #queue-req: 0\n",
      "[2025-08-13 21:21:35] INFO:     127.0.0.1:53636 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:36] Prefill batch. #new-seq: 3, #new-token: 341, #cached-token: 9005, token usage: 0.76, #running-req: 46, #queue-req: 0\n",
      "[2025-08-13 21:21:37] INFO:     127.0.0.1:49510 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:37] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 442, token usage: 0.75, #running-req: 48, #queue-req: 0\n",
      "[2025-08-13 21:21:37] Prefill batch. #new-seq: 2, #new-token: 3937, #cached-token: 596, token usage: 0.75, #running-req: 49, #queue-req: 0\n",
      "[2025-08-13 21:21:38] Prefill batch. #new-seq: 2, #new-token: 3848, #cached-token: 894, token usage: 0.77, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:21:38] Decode batch. #running-req: 53, #token: 193470, token usage: 0.79, cuda graph: True, gen throughput (token/s): 650.53, #queue-req: 0\n",
      "[2025-08-13 21:21:41] Decode batch. #running-req: 53, #token: 195590, token usage: 0.80, cuda graph: True, gen throughput (token/s): 897.09, #queue-req: 0\n",
      "[2025-08-13 21:21:41] INFO:     127.0.0.1:33414 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:42] INFO:     127.0.0.1:53482 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:42] INFO:     127.0.0.1:60238 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:21:42] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4632, token usage: 0.78, #running-req: 50, #queue-req: 0\n",
      "[2025-08-13 21:21:42] Prefill batch. #new-seq: 1, #new-token: 2221, #cached-token: 412, token usage: 0.78, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:21:43] INFO:     127.0.0.1:33442 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:43] Decode batch. #running-req: 51, #token: 190014, token usage: 0.77, cuda graph: True, gen throughput (token/s): 806.97, #queue-req: 0\n",
      "[2025-08-13 21:21:44] Prefill batch. #new-seq: 1, #new-token: 2278, #cached-token: 134, token usage: 0.78, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:21:44] INFO:     127.0.0.1:35214 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:44] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2541, token usage: 0.78, #running-req: 51, #queue-req: 0\n",
      "[2025-08-13 21:21:45] INFO:     127.0.0.1:33426 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:21:45] INFO:     127.0.0.1:57080 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:45] INFO:     127.0.0.1:35214 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:46] Decode batch. #running-req: 49, #token: 184270, token usage: 0.75, cuda graph: True, gen throughput (token/s): 795.52, #queue-req: 0\n",
      "[2025-08-13 21:21:46] INFO:     127.0.0.1:35224 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:47] Prefill batch. #new-seq: 3, #new-token: 446, #cached-token: 8187, token usage: 0.75, #running-req: 48, #queue-req: 0\n",
      "[2025-08-13 21:21:47] INFO:     127.0.0.1:35224 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:48] Decode batch. #running-req: 50, #token: 179524, token usage: 0.73, cuda graph: True, gen throughput (token/s): 867.70, #queue-req: 0\n",
      "[2025-08-13 21:21:49] Prefill batch. #new-seq: 1, #new-token: 5294, #cached-token: 464, token usage: 0.73, #running-req: 50, #queue-req: 0\n",
      "[2025-08-13 21:21:49] INFO:     127.0.0.1:53816 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:49] INFO:     127.0.0.1:60260 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:50] INFO:     127.0.0.1:53482 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:51] INFO:     127.0.0.1:49520 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:51] Decode batch. #running-req: 48, #token: 169990, token usage: 0.69, cuda graph: True, gen throughput (token/s): 731.20, #queue-req: 0\n",
      "[2025-08-13 21:21:53] Decode batch. #running-req: 47, #token: 171870, token usage: 0.70, cuda graph: True, gen throughput (token/s): 897.67, #queue-req: 0\n",
      "[2025-08-13 21:21:53] Prefill batch. #new-seq: 3, #new-token: 7583, #cached-token: 1377, token usage: 0.70, #running-req: 47, #queue-req: 0\n",
      "[2025-08-13 21:21:53] Prefill batch. #new-seq: 1, #new-token: 2278, #cached-token: 126, token usage: 0.73, #running-req: 50, #queue-req: 0\n",
      "[2025-08-13 21:21:56] Decode batch. #running-req: 51, #token: 183748, token usage: 0.75, cuda graph: True, gen throughput (token/s): 663.83, #queue-req: 0\n",
      "[2025-08-13 21:21:58] Decode batch. #running-req: 51, #token: 185788, token usage: 0.76, cuda graph: True, gen throughput (token/s): 916.28, #queue-req: 0\n",
      "[2025-08-13 21:21:59] INFO:     127.0.0.1:57092 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:21:59] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 5273, token usage: 0.76, #running-req: 50, #queue-req: 0\n",
      "[2025-08-13 21:22:00] Decode batch. #running-req: 51, #token: 187846, token usage: 0.76, cuda graph: True, gen throughput (token/s): 894.25, #queue-req: 0\n",
      "[2025-08-13 21:22:01] INFO:     127.0.0.1:53788 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:02] Prefill batch. #new-seq: 1, #new-token: 1357, #cached-token: 128, token usage: 0.76, #running-req: 50, #queue-req: 0\n",
      "[2025-08-13 21:22:03] Decode batch. #running-req: 51, #token: 188194, token usage: 0.77, cuda graph: True, gen throughput (token/s): 836.43, #queue-req: 0\n",
      "[2025-08-13 21:22:04] INFO:     127.0.0.1:37800 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:05] Decode batch. #running-req: 50, #token: 184514, token usage: 0.75, cuda graph: True, gen throughput (token/s): 882.63, #queue-req: 0\n",
      "[2025-08-13 21:22:05] INFO:     127.0.0.1:37254 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:06] INFO:     127.0.0.1:35692 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:06] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4801, token usage: 0.71, #running-req: 48, #queue-req: 0\n",
      ".[2025-08-13 21:22:06] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 439, token usage: 0.71, #running-req: 49, #queue-req: 0\n",
      "[2025-08-13 21:22:06] INFO:     127.0.0.1:46852 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:07] INFO:     127.0.0.1:57092 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:07] INFO:     127.0.0.1:53806 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:07] Decode batch. #running-req: 48, #token: 166235, token usage: 0.68, cuda graph: True, gen throughput (token/s): 883.61, #queue-req: 0\n",
      "[2025-08-13 21:22:09] Decode batch. #running-req: 47, #token: 168115, token usage: 0.68, cuda graph: True, gen throughput (token/s): 909.20, #queue-req: 0\n",
      "[2025-08-13 21:22:09] Prefill batch. #new-seq: 1, #new-token: 2264, #cached-token: 142, token usage: 0.68, #running-req: 47, #queue-req: 0\n",
      "[2025-08-13 21:22:09] Prefill batch. #new-seq: 2, #new-token: 4726, #cached-token: 879, token usage: 0.69, #running-req: 48, #queue-req: 0\n",
      "[2025-08-13 21:22:11] INFO:     127.0.0.1:37796 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:11] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2720, token usage: 0.72, #running-req: 49, #queue-req: 0\n",
      "[2025-08-13 21:22:12] INFO:     127.0.0.1:35692 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:22:12] Decode batch. #running-req: 49, #token: 172646, token usage: 0.70, cuda graph: True, gen throughput (token/s): 703.76, #queue-req: 0\n",
      "[2025-08-13 21:22:14] Decode batch. #running-req: 49, #token: 174606, token usage: 0.71, cuda graph: True, gen throughput (token/s): 897.87, #queue-req: 0\n",
      "[2025-08-13 21:22:17] Decode batch. #running-req: 49, #token: 176566, token usage: 0.72, cuda graph: True, gen throughput (token/s): 891.78, #queue-req: 0\n",
      "[2025-08-13 21:22:18] INFO:     127.0.0.1:37796 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:19] Decode batch. #running-req: 48, #token: 176087, token usage: 0.72, cuda graph: True, gen throughput (token/s): 888.99, #queue-req: 0\n",
      "[2025-08-13 21:22:19] Prefill batch. #new-seq: 1, #new-token: 5368, #cached-token: 412, token usage: 0.72, #running-req: 48, #queue-req: 0\n",
      "[2025-08-13 21:22:20] INFO:     127.0.0.1:53610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:21] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 448, token usage: 0.73, #running-req: 48, #queue-req: 0\n",
      "[2025-08-13 21:22:21] INFO:     127.0.0.1:53620 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:21] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 7972, token usage: 0.74, #running-req: 48, #queue-req: 0\n",
      "[2025-08-13 21:22:22] Decode batch. #running-req: 49, #token: 181543, token usage: 0.74, cuda graph: True, gen throughput (token/s): 662.35, #queue-req: 0\n",
      "[2025-08-13 21:22:22] INFO:     127.0.0.1:49494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:22:24] Decode batch. #running-req: 48, #token: 180170, token usage: 0.73, cuda graph: True, gen throughput (token/s): 889.37, #queue-req: 0\n",
      "[2025-08-13 21:22:25] INFO:     127.0.0.1:53634 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:25] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 11863, token usage: 0.74, #running-req: 47, #queue-req: 0\n",
      "[2025-08-13 21:22:26] INFO:     127.0.0.1:53634 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:26] Decode batch. #running-req: 47, #token: 170757, token usage: 0.69, cuda graph: True, gen throughput (token/s): 875.34, #queue-req: 0\n",
      "[2025-08-13 21:22:26] INFO:     127.0.0.1:46938 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:28] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 393, token usage: 0.70, #running-req: 46, #queue-req: 1\n",
      "[2025-08-13 21:22:28] Prefill batch. #new-seq: 2, #new-token: 3745, #cached-token: 439, token usage: 0.73, #running-req: 46, #queue-req: 0\n",
      "[2025-08-13 21:22:29] Decode batch. #running-req: 48, #token: 183678, token usage: 0.75, cuda graph: True, gen throughput (token/s): 549.46, #queue-req: 0\n",
      "[2025-08-13 21:22:30] INFO:     127.0.0.1:53620 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:30] INFO:     127.0.0.1:53798 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:22:31] INFO:     127.0.0.1:43992 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:31] INFO:     127.0.0.1:48368 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:31] Prefill batch. #new-seq: 2, #new-token: 2419, #cached-token: 3216, token usage: 0.66, #running-req: 45, #queue-req: 0\n",
      ".[2025-08-13 21:22:32] Decode batch. #running-req: 46, #token: 165987, token usage: 0.68, cuda graph: True, gen throughput (token/s): 801.56, #queue-req: 0\n",
      "[2025-08-13 21:22:34] INFO:     127.0.0.1:44012 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:34] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.68, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:22:34] INFO:     127.0.0.1:60584 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:34] Decode batch. #running-req: 45, #token: 164153, token usage: 0.67, cuda graph: True, gen throughput (token/s): 879.74, #queue-req: 0\n",
      "[2025-08-13 21:22:35] Prefill batch. #new-seq: 1, #new-token: 1941, #cached-token: 148, token usage: 0.67, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:22:36] INFO:     127.0.0.1:37222 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:36] Decode batch. #running-req: 45, #token: 161202, token usage: 0.66, cuda graph: True, gen throughput (token/s): 822.61, #queue-req: 0\n",
      "[2025-08-13 21:22:37] INFO:     127.0.0.1:60206 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:37] INFO:     127.0.0.1:44026 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:38] Prefill batch. #new-seq: 3, #new-token: 7766, #cached-token: 5674, token usage: 0.65, #running-req: 43, #queue-req: 0\n",
      "[2025-08-13 21:22:39] INFO:     127.0.0.1:43992 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:39] Decode batch. #running-req: 45, #token: 164612, token usage: 0.67, cuda graph: True, gen throughput (token/s): 653.10, #queue-req: 0\n",
      "[2025-08-13 21:22:40] Prefill batch. #new-seq: 1, #new-token: 2218, #cached-token: 413, token usage: 0.67, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:22:41] Decode batch. #running-req: 46, #token: 168657, token usage: 0.69, cuda graph: True, gen throughput (token/s): 802.69, #queue-req: 0\n",
      "[2025-08-13 21:22:41] INFO:     127.0.0.1:44012 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:42] INFO:     127.0.0.1:53832 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:43] Prefill batch. #new-seq: 2, #new-token: 2178, #cached-token: 3245, token usage: 0.67, #running-req: 44, #queue-req: 0\n",
      "[2025-08-13 21:22:43] Decode batch. #running-req: 46, #token: 168212, token usage: 0.68, cuda graph: True, gen throughput (token/s): 798.12, #queue-req: 0\n",
      "[2025-08-13 21:22:45] Decode batch. #running-req: 46, #token: 170052, token usage: 0.69, cuda graph: True, gen throughput (token/s): 892.40, #queue-req: 0\n",
      "[2025-08-13 21:22:45] INFO:     127.0.0.1:44026 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:46] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 466, token usage: 0.68, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:22:47] INFO:     127.0.0.1:50308 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:48] Decode batch. #running-req: 45, #token: 166390, token usage: 0.68, cuda graph: True, gen throughput (token/s): 794.48, #queue-req: 0\n",
      "[2025-08-13 21:22:48] Prefill batch. #new-seq: 1, #new-token: 920, #cached-token: 144, token usage: 0.68, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:22:49] INFO:     127.0.0.1:49524 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:49] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 9726, token usage: 0.69, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:22:50] INFO:     127.0.0.1:53832 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:50] Decode batch. #running-req: 45, #token: 166689, token usage: 0.68, cuda graph: True, gen throughput (token/s): 837.27, #queue-req: 0\n",
      "[2025-08-13 21:22:51] Prefill batch. #new-seq: 1, #new-token: 4980, #cached-token: 480, token usage: 0.68, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:22:51] INFO:     127.0.0.1:49538 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:51] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4632, token usage: 0.70, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:22:52] INFO:     127.0.0.1:49538 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:52] INFO:     127.0.0.1:49548 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:52] Decode batch. #running-req: 44, #token: 164262, token usage: 0.67, cuda graph: True, gen throughput (token/s): 703.96, #queue-req: 0\n",
      "[2025-08-13 21:22:52] INFO:     127.0.0.1:49524 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:53] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 5462, token usage: 0.65, #running-req: 43, #queue-req: 0\n",
      "[2025-08-13 21:22:54] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 997, token usage: 0.66, #running-req: 44, #queue-req: 0\n",
      "[2025-08-13 21:22:54] Prefill batch. #new-seq: 1, #new-token: 1498, #cached-token: 0, token usage: 0.69, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:22:55] Decode batch. #running-req: 46, #token: 171377, token usage: 0.70, cuda graph: True, gen throughput (token/s): 589.65, #queue-req: 0\n",
      "[2025-08-13 21:22:56] INFO:     127.0.0.1:48380 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:57] Prefill batch. #new-seq: 1, #new-token: 1323, #cached-token: 473, token usage: 0.69, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:22:57] INFO:     127.0.0.1:60552 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:57] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2294, token usage: 0.69, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:22:58] Decode batch. #running-req: 46, #token: 170875, token usage: 0.70, cuda graph: True, gen throughput (token/s): 805.35, #queue-req: 0\n",
      "[2025-08-13 21:22:58] INFO:     127.0.0.1:60552 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:58] INFO:     127.0.0.1:60568 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:22:59] Prefill batch. #new-seq: 2, #new-token: 291, #cached-token: 4750, token usage: 0.69, #running-req: 44, #queue-req: 0\n",
      "[2025-08-13 21:23:00] Decode batch. #running-req: 46, #token: 170790, token usage: 0.69, cuda graph: True, gen throughput (token/s): 849.00, #queue-req: 0\n",
      "[2025-08-13 21:23:00] INFO:     127.0.0.1:60568 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:01] Prefill batch. #new-seq: 1, #new-token: 2345, #cached-token: 455, token usage: 0.68, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:23:01] INFO:     127.0.0.1:60590 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:01] INFO:     127.0.0.1:49548 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:01] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2863, token usage: 0.67, #running-req: 44, #queue-req: 0\n",
      "[2025-08-13 21:23:02] INFO:     127.0.0.1:50006 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:02] Decode batch. #running-req: 44, #token: 163028, token usage: 0.66, cuda graph: True, gen throughput (token/s): 773.59, #queue-req: 0\n",
      "[2025-08-13 21:23:03] INFO:     127.0.0.1:46942 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:04] INFO:     127.0.0.1:60210 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:04] Decode batch. #running-req: 42, #token: 157406, token usage: 0.64, cuda graph: True, gen throughput (token/s): 847.77, #queue-req: 0\n",
      "[2025-08-13 21:23:04] Prefill batch. #new-seq: 1, #new-token: 2392, #cached-token: 440, token usage: 0.64, #running-req: 42, #queue-req: 0\n",
      "[2025-08-13 21:23:05] Prefill batch. #new-seq: 3, #new-token: 5185, #cached-token: 1049, token usage: 0.65, #running-req: 43, #queue-req: 0\n",
      "[2025-08-13 21:23:06] INFO:     127.0.0.1:41494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:07] Prefill batch. #new-seq: 1, #new-token: 1490, #cached-token: 159, token usage: 0.67, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:23:07] Decode batch. #running-req: 46, #token: 165819, token usage: 0.67, cuda graph: True, gen throughput (token/s): 624.20, #queue-req: 0\n",
      "[2025-08-13 21:23:07] INFO:     127.0.0.1:37244 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:07] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2697, token usage: 0.68, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:23:09] INFO:     127.0.0.1:60590 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:09] Decode batch. #running-req: 45, #token: 165098, token usage: 0.67, cuda graph: True, gen throughput (token/s): 860.99, #queue-req: 0\n",
      "[2025-08-13 21:23:10] Prefill batch. #new-seq: 1, #new-token: 3661, #cached-token: 410, token usage: 0.67, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:23:11] INFO:     127.0.0.1:59290 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:11] INFO:     127.0.0.1:50280 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:11] INFO:     127.0.0.1:36530 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:12] Decode batch. #running-req: 43, #token: 156619, token usage: 0.64, cuda graph: True, gen throughput (token/s): 744.66, #queue-req: 0\n",
      "[2025-08-13 21:23:12] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4800, token usage: 0.66, #running-req: 43, #queue-req: 0\n",
      "[2025-08-13 21:23:12] INFO:     127.0.0.1:36530 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 21:23:13] Prefill batch. #new-seq: 3, #new-token: 3052, #cached-token: 3795, token usage: 0.65, #running-req: 43, #queue-req: 0\n",
      "[2025-08-13 21:23:14] Decode batch. #running-req: 46, #token: 163870, token usage: 0.67, cuda graph: True, gen throughput (token/s): 764.06, #queue-req: 0\n",
      "[2025-08-13 21:23:14] INFO:     127.0.0.1:60222 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:14] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4800, token usage: 0.67, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:23:15] INFO:     127.0.0.1:37244 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:15] Prefill batch. #new-seq: 1, #new-token: 2240, #cached-token: 392, token usage: 0.66, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:23:16] Decode batch. #running-req: 46, #token: 165546, token usage: 0.67, cuda graph: True, gen throughput (token/s): 790.18, #queue-req: 0\n",
      "[2025-08-13 21:23:16] INFO:     127.0.0.1:58304 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:17] Prefill batch. #new-seq: 1, #new-token: 1025, #cached-token: 126, token usage: 0.67, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:23:18] Decode batch. #running-req: 46, #token: 166941, token usage: 0.68, cuda graph: True, gen throughput (token/s): 815.80, #queue-req: 0\n",
      "[2025-08-13 21:23:19] INFO:     127.0.0.1:60254 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:19] INFO:     127.0.0.1:60276 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:19] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 14338, token usage: 0.68, #running-req: 44, #queue-req: 0\n",
      "[2025-08-13 21:23:19] INFO:     127.0.0.1:60254 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:20] Prefill batch. #new-seq: 1, #new-token: 7226, #cached-token: 463, token usage: 0.65, #running-req: 45, #queue-req: 0\n",
      "[2025-08-13 21:23:21] INFO:     127.0.0.1:54208 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:21] Decode batch. #running-req: 45, #token: 163616, token usage: 0.67, cuda graph: True, gen throughput (token/s): 651.64, #queue-req: 0\n",
      "[2025-08-13 21:23:22] INFO:     127.0.0.1:46924 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:22] INFO:     127.0.0.1:60222 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:23:23] INFO:     127.0.0.1:59282 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:23] INFO:     127.0.0.1:46922 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:23:23] Prefill batch. #new-seq: 1, #new-token: 7600, #cached-token: 481, token usage: 0.61, #running-req: 41, #queue-req: 0\n",
      "[2025-08-13 21:23:24] Prefill batch. #new-seq: 2, #new-token: 4522, #cached-token: 913, token usage: 0.64, #running-req: 42, #queue-req: 0\n",
      "[2025-08-13 21:23:24] Decode batch. #running-req: 42, #token: 154971, token usage: 0.63, cuda graph: True, gen throughput (token/s): 618.65, #queue-req: 0\n",
      "[2025-08-13 21:23:24] INFO:     127.0.0.1:46834 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:24] INFO:     127.0.0.1:46844 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:24] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 7628, token usage: 0.66, #running-req: 42, #queue-req: 0\n",
      "[2025-08-13 21:23:26] INFO:     127.0.0.1:33392 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:26] Decode batch. #running-req: 43, #token: 157075, token usage: 0.64, cuda graph: True, gen throughput (token/s): 712.61, #queue-req: 0\n",
      "[2025-08-13 21:23:27] INFO:     127.0.0.1:60276 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:28] Prefill batch. #new-seq: 2, #new-token: 5629, #cached-token: 925, token usage: 0.63, #running-req: 42, #queue-req: 0\n",
      "[2025-08-13 21:23:29] Decode batch. #running-req: 44, #token: 159977, token usage: 0.65, cuda graph: True, gen throughput (token/s): 684.10, #queue-req: 0\n",
      "[2025-08-13 21:23:31] INFO:     127.0.0.1:41502 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:23:31] Decode batch. #running-req: 43, #token: 159951, token usage: 0.65, cuda graph: True, gen throughput (token/s): 853.49, #queue-req: 0\n",
      "[2025-08-13 21:23:31] INFO:     127.0.0.1:46844 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:31] INFO:     127.0.0.1:46834 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:32] INFO:     127.0.0.1:48330 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:32] INFO:     127.0.0.1:48336 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:33] Decode batch. #running-req: 39, #token: 140351, token usage: 0.57, cuda graph: True, gen throughput (token/s): 837.07, #queue-req: 0\n",
      "[2025-08-13 21:23:33] INFO:     127.0.0.1:58530 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:33] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 15015, token usage: 0.62, #running-req: 38, #queue-req: 0\n",
      "[2025-08-13 21:23:35] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 805, token usage: 0.63, #running-req: 40, #queue-req: 1\n",
      "[2025-08-13 21:23:35] Prefill batch. #new-seq: 2, #new-token: 1415, #cached-token: 129, token usage: 0.66, #running-req: 41, #queue-req: 0\n",
      "[2025-08-13 21:23:36] Decode batch. #running-req: 43, #token: 163836, token usage: 0.67, cuda graph: True, gen throughput (token/s): 565.98, #queue-req: 0\n",
      "[2025-08-13 21:23:36] INFO:     127.0.0.1:48350 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:36] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2739, token usage: 0.67, #running-req: 42, #queue-req: 0\n",
      "[2025-08-13 21:23:37] INFO:     127.0.0.1:48354 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:37] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2813, token usage: 0.67, #running-req: 42, #queue-req: 0\n",
      "[2025-08-13 21:23:38] INFO:     127.0.0.1:48382 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:38] INFO:     127.0.0.1:46912 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:38] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 8740, token usage: 0.67, #running-req: 41, #queue-req: 0\n",
      "[2025-08-13 21:23:38] Decode batch. #running-req: 43, #token: 165631, token usage: 0.67, cuda graph: True, gen throughput (token/s): 809.15, #queue-req: 0\n",
      "[2025-08-13 21:23:38] INFO:     127.0.0.1:48354 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:39] Prefill batch. #new-seq: 1, #new-token: 6975, #cached-token: 412, token usage: 0.67, #running-req: 42, #queue-req: 0\n",
      "[2025-08-13 21:23:41] Decode batch. #running-req: 43, #token: 171896, token usage: 0.70, cuda graph: True, gen throughput (token/s): 616.06, #queue-req: 0\n",
      "[2025-08-13 21:23:42] INFO:     127.0.0.1:48336 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:42] INFO:     127.0.0.1:48330 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:43] Decode batch. #running-req: 41, #token: 159104, token usage: 0.65, cuda graph: True, gen throughput (token/s): 805.01, #queue-req: 0\n",
      "[2025-08-13 21:23:44] INFO:     127.0.0.1:48350 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:45] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 410, token usage: 0.64, #running-req: 40, #queue-req: 2\n",
      "[2025-08-13 21:23:45] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 890, token usage: 0.68, #running-req: 40, #queue-req: 0\n",
      "[2025-08-13 21:23:45] Prefill batch. #new-seq: 1, #new-token: 1709, #cached-token: 0, token usage: 0.71, #running-req: 42, #queue-req: 0\n",
      "[2025-08-13 21:23:47] Decode batch. #running-req: 43, #token: 176376, token usage: 0.72, cuda graph: True, gen throughput (token/s): 421.73, #queue-req: 0\n",
      "[2025-08-13 21:23:47] INFO:     127.0.0.1:48382 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:47] INFO:     127.0.0.1:46912 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:48] INFO:     127.0.0.1:58308 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:49] Decode batch. #running-req: 40, #token: 163962, token usage: 0.67, cuda graph: True, gen throughput (token/s): 767.24, #queue-req: 0\n",
      "[2025-08-13 21:23:49] INFO:     127.0.0.1:50266 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:49] Prefill batch. #new-seq: 3, #new-token: 7819, #cached-token: 8691, token usage: 0.67, #running-req: 39, #queue-req: 0\n",
      "[2025-08-13 21:23:50] Prefill batch. #new-seq: 1, #new-token: 2358, #cached-token: 443, token usage: 0.70, #running-req: 42, #queue-req: 0\n",
      "[2025-08-13 21:23:51] INFO:     127.0.0.1:50266 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:52] Decode batch. #running-req: 42, #token: 168468, token usage: 0.69, cuda graph: True, gen throughput (token/s): 547.96, #queue-req: 0\n",
      "[2025-08-13 21:23:52] Prefill batch. #new-seq: 1, #new-token: 5444, #cached-token: 464, token usage: 0.69, #running-req: 42, #queue-req: 0\n",
      "[2025-08-13 21:23:54] Decode batch. #running-req: 43, #token: 175623, token usage: 0.71, cuda graph: True, gen throughput (token/s): 642.46, #queue-req: 0\n",
      "[2025-08-13 21:23:55] INFO:     127.0.0.1:50272 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:55] INFO:     127.0.0.1:50296 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:23:55] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 9601, token usage: 0.72, #running-req: 41, #queue-req: 0\n",
      "[2025-08-13 21:23:57] Decode batch. #running-req: 43, #token: 177381, token usage: 0.72, cuda graph: True, gen throughput (token/s): 778.91, #queue-req: 0\n",
      "[2025-08-13 21:23:59] Decode batch. #running-req: 43, #token: 179101, token usage: 0.73, cuda graph: True, gen throughput (token/s): 780.86, #queue-req: 0\n",
      "[2025-08-13 21:24:01] Decode batch. #running-req: 43, #token: 180821, token usage: 0.74, cuda graph: True, gen throughput (token/s): 776.77, #queue-req: 0\n",
      "[2025-08-13 21:24:02] INFO:     127.0.0.1:50272 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:02] INFO:     127.0.0.1:50296 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:03] Decode batch. #running-req: 41, #token: 173488, token usage: 0.71, cuda graph: True, gen throughput (token/s): 770.13, #queue-req: 0\n",
      "[2025-08-13 21:24:04] Prefill batch. #new-seq: 2, #new-token: 5288, #cached-token: 1096, token usage: 0.71, #running-req: 41, #queue-req: 0\n",
      "[2025-08-13 21:24:06] Decode batch. #running-req: 43, #token: 180472, token usage: 0.73, cuda graph: True, gen throughput (token/s): 646.92, #queue-req: 0\n",
      "[2025-08-13 21:24:08] Decode batch. #running-req: 43, #token: 182192, token usage: 0.74, cuda graph: True, gen throughput (token/s): 782.26, #queue-req: 0\n",
      "[2025-08-13 21:24:10] Decode batch. #running-req: 43, #token: 181572, token usage: 0.74, cuda graph: True, gen throughput (token/s): 776.44, #queue-req: 0\n",
      "[2025-08-13 21:24:10] INFO:     127.0.0.1:59300 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:10] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2775, token usage: 0.75, #running-req: 42, #queue-req: 0\n",
      "[2025-08-13 21:24:13] Decode batch. #running-req: 43, #token: 185650, token usage: 0.76, cuda graph: True, gen throughput (token/s): 758.62, #queue-req: 0\n",
      "[2025-08-13 21:24:15] Decode batch. #running-req: 43, #token: 187370, token usage: 0.76, cuda graph: True, gen throughput (token/s): 760.58, #queue-req: 0\n",
      "[2025-08-13 21:24:17] Decode batch. #running-req: 43, #token: 189090, token usage: 0.77, cuda graph: True, gen throughput (token/s): 755.29, #queue-req: 0\n",
      "[2025-08-13 21:24:18] INFO:     127.0.0.1:59300 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:24:19] Decode batch. #running-req: 42, #token: 188291, token usage: 0.77, cuda graph: True, gen throughput (token/s): 739.17, #queue-req: 0\n",
      "[2025-08-13 21:24:21] INFO:     127.0.0.1:33398 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:22] Decode batch. #running-req: 41, #token: 185609, token usage: 0.75, cuda graph: True, gen throughput (token/s): 732.65, #queue-req: 0\n",
      "[2025-08-13 21:24:22] Prefill batch. #new-seq: 1, #new-token: 2011, #cached-token: 474, token usage: 0.76, #running-req: 41, #queue-req: 0\n",
      "[2025-08-13 21:24:24] Decode batch. #running-req: 42, #token: 189291, token usage: 0.77, cuda graph: True, gen throughput (token/s): 685.88, #queue-req: 0\n",
      "[2025-08-13 21:24:26] Decode batch. #running-req: 42, #token: 190971, token usage: 0.78, cuda graph: True, gen throughput (token/s): 738.71, #queue-req: 0\n",
      "[2025-08-13 21:24:28] INFO:     127.0.0.1:54190 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:28] INFO:     127.0.0.1:54196 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:28] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2838, token usage: 0.73, #running-req: 40, #queue-req: 0\n",
      "[2025-08-13 21:24:29] Decode batch. #running-req: 41, #token: 179281, token usage: 0.73, cuda graph: True, gen throughput (token/s): 726.69, #queue-req: 0\n",
      "[2025-08-13 21:24:29] INFO:     127.0.0.1:56558 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:29] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 478, token usage: 0.72, #running-req: 41, #queue-req: 0\n",
      ".[2025-08-13 21:24:29] Prefill batch. #new-seq: 1, #new-token: 5298, #cached-token: 0, token usage: 0.76, #running-req: 41, #queue-req: 0\n",
      "[2025-08-13 21:24:31] INFO:     127.0.0.1:37590 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:32] INFO:     127.0.0.1:58504 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:32] Decode batch. #running-req: 39, #token: 180769, token usage: 0.74, cuda graph: True, gen throughput (token/s): 430.15, #queue-req: 0\n",
      "[2025-08-13 21:24:33] Prefill batch. #new-seq: 2, #new-token: 2502, #cached-token: 859, token usage: 0.74, #running-req: 39, #queue-req: 0\n",
      "[2025-08-13 21:24:35] Decode batch. #running-req: 41, #token: 184885, token usage: 0.75, cuda graph: True, gen throughput (token/s): 660.41, #queue-req: 0\n",
      "[2025-08-13 21:24:36] INFO:     127.0.0.1:54220 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:36] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4088, token usage: 0.76, #running-req: 40, #queue-req: 0\n",
      "[2025-08-13 21:24:36] INFO:     127.0.0.1:56550 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:36] INFO:     127.0.0.1:38840 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:36] INFO:     127.0.0.1:54220 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:37] INFO:     127.0.0.1:54196 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:37] Decode batch. #running-req: 38, #token: 169991, token usage: 0.69, cuda graph: True, gen throughput (token/s): 721.67, #queue-req: 0\n",
      "[2025-08-13 21:24:39] INFO:     127.0.0.1:54230 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:39] INFO:     127.0.0.1:49990 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:24:39] Prefill batch. #new-seq: 5, #new-token: 6418, #cached-token: 13671, token usage: 0.70, #running-req: 35, #queue-req: 0\n",
      "[2025-08-13 21:24:40] Decode batch. #running-req: 40, #token: 177898, token usage: 0.72, cuda graph: True, gen throughput (token/s): 556.84, #queue-req: 0\n",
      "[2025-08-13 21:24:40] INFO:     127.0.0.1:54230 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:41] Prefill batch. #new-seq: 1, #new-token: 5553, #cached-token: 463, token usage: 0.70, #running-req: 39, #queue-req: 0\n",
      "[2025-08-13 21:24:42] Decode batch. #running-req: 40, #token: 177603, token usage: 0.72, cuda graph: True, gen throughput (token/s): 595.13, #queue-req: 0\n",
      "[2025-08-13 21:24:44] INFO:     127.0.0.1:50008 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:44] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4632, token usage: 0.73, #running-req: 39, #queue-req: 0\n",
      "[2025-08-13 21:24:45] Decode batch. #running-req: 40, #token: 179221, token usage: 0.73, cuda graph: True, gen throughput (token/s): 736.51, #queue-req: 0\n",
      "[2025-08-13 21:24:45] INFO:     127.0.0.1:50008 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:46] INFO:     127.0.0.1:41538 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:47] Decode batch. #running-req: 38, #token: 167625, token usage: 0.68, cuda graph: True, gen throughput (token/s): 731.17, #queue-req: 0\n",
      "[2025-08-13 21:24:47] Prefill batch. #new-seq: 2, #new-token: 2643, #cached-token: 890, token usage: 0.68, #running-req: 38, #queue-req: 0\n",
      "[2025-08-13 21:24:47] INFO:     127.0.0.1:49990 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:48] Prefill batch. #new-seq: 1, #new-token: 2161, #cached-token: 472, token usage: 0.66, #running-req: 39, #queue-req: 0\n",
      "[2025-08-13 21:24:48] INFO:     127.0.0.1:50022 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:48] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4632, token usage: 0.69, #running-req: 40, #queue-req: 0\n",
      "[2025-08-13 21:24:49] INFO:     127.0.0.1:37610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:49] Decode batch. #running-req: 39, #token: 164512, token usage: 0.67, cuda graph: True, gen throughput (token/s): 627.83, #queue-req: 0\n",
      "[2025-08-13 21:24:50] Prefill batch. #new-seq: 1, #new-token: 2359, #cached-token: 443, token usage: 0.67, #running-req: 39, #queue-req: 0\n",
      "[2025-08-13 21:24:51] Decode batch. #running-req: 40, #token: 168457, token usage: 0.69, cuda graph: True, gen throughput (token/s): 696.08, #queue-req: 0\n",
      "[2025-08-13 21:24:54] Decode batch. #running-req: 40, #token: 170057, token usage: 0.69, cuda graph: True, gen throughput (token/s): 768.63, #queue-req: 0\n",
      "[2025-08-13 21:24:54] INFO:     127.0.0.1:50022 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:55] Prefill batch. #new-seq: 1, #new-token: 2361, #cached-token: 441, token usage: 0.68, #running-req: 39, #queue-req: 0\n",
      "[2025-08-13 21:24:55] INFO:     127.0.0.1:58314 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:55] INFO:     127.0.0.1:58330 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:56] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 14685, token usage: 0.69, #running-req: 38, #queue-req: 0\n",
      "[2025-08-13 21:24:56] Decode batch. #running-req: 40, #token: 169690, token usage: 0.69, cuda graph: True, gen throughput (token/s): 686.25, #queue-req: 0\n",
      "[2025-08-13 21:24:56] INFO:     127.0.0.1:58330 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:57] Prefill batch. #new-seq: 1, #new-token: 7494, #cached-token: 551, token usage: 0.64, #running-req: 39, #queue-req: 0\n",
      "[2025-08-13 21:24:57] INFO:     127.0.0.1:58454 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:24:58] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 3795, token usage: 0.69, #running-req: 40, #queue-req: 0\n",
      "[2025-08-13 21:24:59] Decode batch. #running-req: 40, #token: 169326, token usage: 0.69, cuda graph: True, gen throughput (token/s): 560.68, #queue-req: 0\n",
      "[2025-08-13 21:25:00] INFO:     127.0.0.1:58464 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:00] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2388, token usage: 0.69, #running-req: 39, #queue-req: 0\n",
      "[2025-08-13 21:25:01] Decode batch. #running-req: 40, #token: 170945, token usage: 0.70, cuda graph: True, gen throughput (token/s): 757.07, #queue-req: 0\n",
      "[2025-08-13 21:25:02] INFO:     127.0.0.1:58476 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:02] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4799, token usage: 0.70, #running-req: 39, #queue-req: 0\n",
      "[2025-08-13 21:25:02] INFO:     127.0.0.1:37620 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:03] Decode batch. #running-req: 39, #token: 169118, token usage: 0.69, cuda graph: True, gen throughput (token/s): 748.48, #queue-req: 0\n",
      "[2025-08-13 21:25:03] INFO:     127.0.0.1:58314 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:03] INFO:     127.0.0.1:58454 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:03] INFO:     127.0.0.1:58290 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:05] Decode batch. #running-req: 36, #token: 159036, token usage: 0.65, cuda graph: True, gen throughput (token/s): 731.71, #queue-req: 0\n",
      "[2025-08-13 21:25:05] INFO:     127.0.0.1:58492 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:05] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 451, token usage: 0.63, #running-req: 35, #queue-req: 0\n",
      "[2025-08-13 21:25:06] INFO:     127.0.0.1:58506 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:06] INFO:     127.0.0.1:58518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:07] INFO:     127.0.0.1:58464 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:07] Decode batch. #running-req: 33, #token: 149054, token usage: 0.61, cuda graph: True, gen throughput (token/s): 636.71, #queue-req: 0\n",
      "[2025-08-13 21:25:07] Prefill batch. #new-seq: 3, #new-token: 2203, #cached-token: 7906, token usage: 0.64, #running-req: 33, #queue-req: 0\n",
      ".[2025-08-13 21:25:07] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1270, token usage: 0.64, #running-req: 36, #queue-req: 0\n",
      "[2025-08-13 21:25:08] Prefill batch. #new-seq: 1, #new-token: 3622, #cached-token: 0, token usage: 0.68, #running-req: 38, #queue-req: 0\n",
      "[2025-08-13 21:25:09] INFO:     127.0.0.1:58288 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:10] INFO:     127.0.0.1:58476 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:25:10] Prefill batch. #new-seq: 1, #new-token: 2360, #cached-token: 442, token usage: 0.66, #running-req: 37, #queue-req: 0\n",
      "[2025-08-13 21:25:11] Decode batch. #running-req: 38, #token: 165795, token usage: 0.67, cuda graph: True, gen throughput (token/s): 416.69, #queue-req: 0\n",
      "[2025-08-13 21:25:11] INFO:     127.0.0.1:38816 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:11] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 6070, token usage: 0.68, #running-req: 37, #queue-req: 0\n",
      "[2025-08-13 21:25:13] Decode batch. #running-req: 38, #token: 167334, token usage: 0.68, cuda graph: True, gen throughput (token/s): 724.17, #queue-req: 0\n",
      "[2025-08-13 21:25:14] INFO:     127.0.0.1:60008 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:14] INFO:     127.0.0.1:58506 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:14] INFO:     127.0.0.1:36530 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:14] INFO:     127.0.0.1:38832 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:14] INFO:     127.0.0.1:38838 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:14] INFO:     127.0.0.1:41532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:15] Decode batch. #running-req: 32, #token: 148628, token usage: 0.60, cuda graph: True, gen throughput (token/s): 708.47, #queue-req: 0\n",
      "[2025-08-13 21:25:15] INFO:     127.0.0.1:58518 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:15] INFO:     127.0.0.1:38816 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:16] Prefill batch. #new-seq: 3, #new-token: 61, #cached-token: 12844, token usage: 0.61, #running-req: 30, #queue-req: 0\n",
      "..[2025-08-13 21:25:16] INFO:     127.0.0.1:58280 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:17] Decode batch. #running-req: 32, #token: 144182, token usage: 0.59, cuda graph: True, gen throughput (token/s): 669.80, #queue-req: 0\n",
      "[2025-08-13 21:25:17] Prefill batch. #new-seq: 4, #new-token: 4804, #cached-token: 8568, token usage: 0.62, #running-req: 32, #queue-req: 0\n",
      "[2025-08-13 21:25:18] INFO:     127.0.0.1:58280 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:19] Decode batch. #running-req: 35, #token: 150353, token usage: 0.61, cuda graph: True, gen throughput (token/s): 588.07, #queue-req: 0\n",
      "[2025-08-13 21:25:19] Prefill batch. #new-seq: 1, #new-token: 2341, #cached-token: 460, token usage: 0.61, #running-req: 35, #queue-req: 0\n",
      "[2025-08-13 21:25:21] INFO:     127.0.0.1:41534 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:21] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 9688, token usage: 0.63, #running-req: 35, #queue-req: 0\n",
      "[2025-08-13 21:25:21] Decode batch. #running-req: 36, #token: 154163, token usage: 0.63, cuda graph: True, gen throughput (token/s): 653.04, #queue-req: 0\n",
      "[2025-08-13 21:25:22] INFO:     127.0.0.1:41534 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:22] INFO:     127.0.0.1:56898 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:23] INFO:     127.0.0.1:36530 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:23] INFO:     127.0.0.1:38838 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:23] INFO:     127.0.0.1:38832 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:23] INFO:     127.0.0.1:41540 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:23] INFO:     127.0.0.1:41546 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:23] Decode batch. #running-req: 31, #token: 121141, token usage: 0.49, cuda graph: True, gen throughput (token/s): 733.58, #queue-req: 0\n",
      "[2025-08-13 21:25:25] Decode batch. #running-req: 29, #token: 122301, token usage: 0.50, cuda graph: True, gen throughput (token/s): 693.88, #queue-req: 0\n",
      "[2025-08-13 21:25:26] INFO:     127.0.0.1:56530 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:26] INFO:     127.0.0.1:56536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:26] Decode batch. #running-req: 27, #token: 113723, token usage: 0.46, cuda graph: True, gen throughput (token/s): 690.00, #queue-req: 0\n",
      "[2025-08-13 21:25:26] Prefill batch. #new-seq: 3, #new-token: 60, #cached-token: 14234, token usage: 0.52, #running-req: 27, #queue-req: 0\n",
      "[2025-08-13 21:25:27] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 6669, token usage: 0.54, #running-req: 30, #queue-req: 3\n",
      "[2025-08-13 21:25:27] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 892, token usage: 0.57, #running-req: 32, #queue-req: 1\n",
      "[2025-08-13 21:25:27] Prefill batch. #new-seq: 2, #new-token: 2997, #cached-token: 440, token usage: 0.60, #running-req: 34, #queue-req: 0\n",
      "[2025-08-13 21:25:29] INFO:     127.0.0.1:41540 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:30] Decode batch. #running-req: 35, #token: 148592, token usage: 0.60, cuda graph: True, gen throughput (token/s): 377.67, #queue-req: 0\n",
      "[2025-08-13 21:25:30] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 449, token usage: 0.60, #running-req: 35, #queue-req: 0\n",
      "[2025-08-13 21:25:30] INFO:     127.0.0.1:56536 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:31] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 449, token usage: 0.60, #running-req: 35, #queue-req: 0\n",
      "[2025-08-13 21:25:32] Decode batch. #running-req: 36, #token: 149295, token usage: 0.61, cuda graph: True, gen throughput (token/s): 606.74, #queue-req: 0\n",
      "[2025-08-13 21:25:34] INFO:     127.0.0.1:56546 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:34] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 5273, token usage: 0.61, #running-req: 35, #queue-req: 0\n",
      "[2025-08-13 21:25:34] Decode batch. #running-req: 36, #token: 150754, token usage: 0.61, cuda graph: True, gen throughput (token/s): 733.88, #queue-req: 0\n",
      "[2025-08-13 21:25:35] INFO:     127.0.0.1:56546 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:35] INFO:     127.0.0.1:41546 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:35] INFO:     127.0.0.1:56530 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:36] Decode batch. #running-req: 33, #token: 138199, token usage: 0.56, cuda graph: True, gen throughput (token/s): 734.13, #queue-req: 0\n",
      "[2025-08-13 21:25:37] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1274, token usage: 0.57, #running-req: 33, #queue-req: 0\n",
      "[2025-08-13 21:25:37] Prefill batch. #new-seq: 1, #new-token: 1905, #cached-token: 0, token usage: 0.60, #running-req: 35, #queue-req: 0\n",
      "[2025-08-13 21:25:39] Decode batch. #running-req: 36, #token: 149669, token usage: 0.61, cuda graph: True, gen throughput (token/s): 491.68, #queue-req: 0\n",
      "[2025-08-13 21:25:41] Decode batch. #running-req: 36, #token: 151109, token usage: 0.61, cuda graph: True, gen throughput (token/s): 732.94, #queue-req: 0\n",
      "[2025-08-13 21:25:43] INFO:     127.0.0.1:37602 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:43] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 14370, token usage: 0.62, #running-req: 35, #queue-req: 0\n",
      "[2025-08-13 21:25:43] INFO:     127.0.0.1:36698 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:43] Decode batch. #running-req: 35, #token: 149426, token usage: 0.61, cuda graph: True, gen throughput (token/s): 728.01, #queue-req: 0\n",
      "[2025-08-13 21:25:43] INFO:     127.0.0.1:37602 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:25:44] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 450, token usage: 0.55, #running-req: 34, #queue-req: 0\n",
      "[2025-08-13 21:25:45] Decode batch. #running-req: 35, #token: 139168, token usage: 0.57, cuda graph: True, gen throughput (token/s): 664.06, #queue-req: 0\n",
      "[2025-08-13 21:25:47] Decode batch. #running-req: 35, #token: 140568, token usage: 0.57, cuda graph: True, gen throughput (token/s): 748.10, #queue-req: 0\n",
      "[2025-08-13 21:25:47] INFO:     127.0.0.1:58304 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:47] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 7907, token usage: 0.57, #running-req: 34, #queue-req: 0\n",
      "[2025-08-13 21:25:47] INFO:     127.0.0.1:58304 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 21:25:47] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 5907, token usage: 0.57, #running-req: 34, #queue-req: 0\n",
      "[2025-08-13 21:25:48] INFO:     127.0.0.1:58980 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:49] Decode batch. #running-req: 34, #token: 137328, token usage: 0.56, cuda graph: True, gen throughput (token/s): 733.18, #queue-req: 0\n",
      "[2025-08-13 21:25:49] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 454, token usage: 0.56, #running-req: 34, #queue-req: 0\n",
      "[2025-08-13 21:25:51] Decode batch. #running-req: 35, #token: 141076, token usage: 0.57, cuda graph: True, gen throughput (token/s): 667.55, #queue-req: 0\n",
      "[2025-08-13 21:25:51] INFO:     127.0.0.1:59384 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:52] Prefill batch. #new-seq: 1, #new-token: 2206, #cached-token: 449, token usage: 0.55, #running-req: 34, #queue-req: 0\n",
      "[2025-08-13 21:25:53] Decode batch. #running-req: 35, #token: 136833, token usage: 0.56, cuda graph: True, gen throughput (token/s): 680.35, #queue-req: 0\n",
      "[2025-08-13 21:25:55] Decode batch. #running-req: 35, #token: 138233, token usage: 0.56, cuda graph: True, gen throughput (token/s): 775.35, #queue-req: 0\n",
      "[2025-08-13 21:25:56] Decode batch. #running-req: 35, #token: 139633, token usage: 0.57, cuda graph: True, gen throughput (token/s): 771.71, #queue-req: 0\n",
      "[2025-08-13 21:25:57] INFO:     127.0.0.1:56904 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:57] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4631, token usage: 0.57, #running-req: 34, #queue-req: 0\n",
      "[2025-08-13 21:25:58] INFO:     127.0.0.1:56904 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:58] INFO:     127.0.0.1:57542 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:25:58] Decode batch. #running-req: 33, #token: 121776, token usage: 0.50, cuda graph: True, gen throughput (token/s): 750.73, #queue-req: 0\n",
      "[2025-08-13 21:26:00] Prefill batch. #new-seq: 1, #new-token: 2342, #cached-token: 459, token usage: 0.50, #running-req: 33, #queue-req: 0\n",
      "[2025-08-13 21:26:00] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 478, token usage: 0.51, #running-req: 34, #queue-req: 0\n",
      "[2025-08-13 21:26:00] Prefill batch. #new-seq: 1, #new-token: 5457, #cached-token: 0, token usage: 0.54, #running-req: 34, #queue-req: 0\n",
      "[2025-08-13 21:26:02] Decode batch. #running-req: 35, #token: 139169, token usage: 0.57, cuda graph: True, gen throughput (token/s): 381.85, #queue-req: 0\n",
      "[2025-08-13 21:26:04] Decode batch. #running-req: 35, #token: 140569, token usage: 0.57, cuda graph: True, gen throughput (token/s): 763.45, #queue-req: 0\n",
      "[2025-08-13 21:26:04] INFO:     127.0.0.1:54194 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:05] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.56, #running-req: 34, #queue-req: 0\n",
      "[2025-08-13 21:26:06] Decode batch. #running-req: 35, #token: 141041, token usage: 0.57, cuda graph: True, gen throughput (token/s): 677.35, #queue-req: 0\n",
      "[2025-08-13 21:26:07] Decode batch. #running-req: 35, #token: 142441, token usage: 0.58, cuda graph: True, gen throughput (token/s): 759.02, #queue-req: 0\n",
      "[2025-08-13 21:26:09] INFO:     127.0.0.1:48326 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:26:09] Decode batch. #running-req: 34, #token: 140526, token usage: 0.57, cuda graph: True, gen throughput (token/s): 753.19, #queue-req: 0\n",
      "[2025-08-13 21:26:11] Decode batch. #running-req: 34, #token: 141886, token usage: 0.58, cuda graph: True, gen throughput (token/s): 738.07, #queue-req: 0\n",
      "[2025-08-13 21:26:13] Decode batch. #running-req: 34, #token: 143246, token usage: 0.58, cuda graph: True, gen throughput (token/s): 732.63, #queue-req: 0\n",
      "[2025-08-13 21:26:15] Decode batch. #running-req: 34, #token: 144606, token usage: 0.59, cuda graph: True, gen throughput (token/s): 727.04, #queue-req: 0\n",
      "[2025-08-13 21:26:17] Decode batch. #running-req: 34, #token: 145966, token usage: 0.59, cuda graph: True, gen throughput (token/s): 721.43, #queue-req: 0\n",
      "[2025-08-13 21:26:19] Decode batch. #running-req: 34, #token: 147326, token usage: 0.60, cuda graph: True, gen throughput (token/s): 714.67, #queue-req: 0\n",
      "[2025-08-13 21:26:21] Decode batch. #running-req: 34, #token: 148686, token usage: 0.60, cuda graph: True, gen throughput (token/s): 707.62, #queue-req: 0\n",
      "[2025-08-13 21:26:21] INFO:     127.0.0.1:57546 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:21] INFO:     127.0.0.1:57562 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:21] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 7359, token usage: 0.61, #running-req: 32, #queue-req: 0\n",
      "[2025-08-13 21:26:21] INFO:     127.0.0.1:58992 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:22] Prefill batch. #new-seq: 1, #new-token: 5998, #cached-token: 553, token usage: 0.60, #running-req: 33, #queue-req: 0\n",
      "[2025-08-13 21:26:23] Decode batch. #running-req: 34, #token: 152805, token usage: 0.62, cuda graph: True, gen throughput (token/s): 534.39, #queue-req: 0\n",
      "[2025-08-13 21:26:25] Decode batch. #running-req: 34, #token: 154165, token usage: 0.63, cuda graph: True, gen throughput (token/s): 698.44, #queue-req: 0\n",
      "[2025-08-13 21:26:26] INFO:     127.0.0.1:48316 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:27] INFO:     127.0.0.1:48304 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:27] Decode batch. #running-req: 32, #token: 146809, token usage: 0.60, cuda graph: True, gen throughput (token/s): 691.16, #queue-req: 0\n",
      "[2025-08-13 21:26:27] Prefill batch. #new-seq: 2, #new-token: 297, #cached-token: 5212, token usage: 0.61, #running-req: 32, #queue-req: 0\n",
      "[2025-08-13 21:26:27] INFO:     127.0.0.1:57562 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:28] INFO:     127.0.0.1:48304 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:28] INFO:     127.0.0.1:57546 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:28] INFO:     127.0.0.1:48334 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:29] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 8015, token usage: 0.57, #running-req: 30, #queue-req: 0\n",
      "[2025-08-13 21:26:29] Decode batch. #running-req: 31, #token: 141606, token usage: 0.58, cuda graph: True, gen throughput (token/s): 665.77, #queue-req: 0\n",
      "[2025-08-13 21:26:30] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1315, token usage: 0.58, #running-req: 31, #queue-req: 0\n",
      "[2025-08-13 21:26:30] Prefill batch. #new-seq: 1, #new-token: 4978, #cached-token: 0, token usage: 0.61, #running-req: 33, #queue-req: 0\n",
      "[2025-08-13 21:26:32] Decode batch. #running-req: 34, #token: 156114, token usage: 0.63, cuda graph: True, gen throughput (token/s): 412.79, #queue-req: 0\n",
      "[2025-08-13 21:26:32] INFO:     127.0.0.1:58944 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:33] Prefill batch. #new-seq: 1, #new-token: 1878, #cached-token: 410, token usage: 0.62, #running-req: 33, #queue-req: 0\n",
      "[2025-08-13 21:26:34] Decode batch. #running-req: 34, #token: 155547, token usage: 0.63, cuda graph: True, gen throughput (token/s): 632.55, #queue-req: 0\n",
      "[2025-08-13 21:26:34] INFO:     127.0.0.1:48342 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:34] INFO:     127.0.0.1:48348 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:34] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 7531, token usage: 0.63, #running-req: 32, #queue-req: 0\n",
      "[2025-08-13 21:26:36] INFO:     127.0.0.1:48334 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:36] Decode batch. #running-req: 34, #token: 149242, token usage: 0.61, cuda graph: True, gen throughput (token/s): 676.03, #queue-req: 0\n",
      "[2025-08-13 21:26:37] INFO:     127.0.0.1:36700 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:37] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.61, #running-req: 32, #queue-req: 0\n",
      "[2025-08-13 21:26:37] Prefill batch. #new-seq: 1, #new-token: 7740, #cached-token: 463, token usage: 0.61, #running-req: 33, #queue-req: 0\n",
      "[2025-08-13 21:26:39] Decode batch. #running-req: 34, #token: 158338, token usage: 0.64, cuda graph: True, gen throughput (token/s): 489.11, #queue-req: 0\n",
      "[2025-08-13 21:26:41] INFO:     127.0.0.1:33616 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:41] Decode batch. #running-req: 33, #token: 156265, token usage: 0.64, cuda graph: True, gen throughput (token/s): 682.81, #queue-req: 0\n",
      "[2025-08-13 21:26:41] INFO:     127.0.0.1:48348 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:41] INFO:     127.0.0.1:48342 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:42] INFO:     127.0.0.1:36710 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:43] Decode batch. #running-req: 30, #token: 146208, token usage: 0.59, cuda graph: True, gen throughput (token/s): 657.35, #queue-req: 0\n",
      "[2025-08-13 21:26:43] Prefill batch. #new-seq: 2, #new-token: 2373, #cached-token: 5250, token usage: 0.61, #running-req: 30, #queue-req: 0\n",
      "[2025-08-13 21:26:43] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 481, token usage: 0.62, #running-req: 32, #queue-req: 1\n",
      "[2025-08-13 21:26:43] Prefill batch. #new-seq: 2, #new-token: 3798, #cached-token: 472, token usage: 0.66, #running-req: 32, #queue-req: 0\n",
      "[2025-08-13 21:26:46] INFO:     127.0.0.1:36700 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:26:46] INFO:     127.0.0.1:54172 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:46] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 10044, token usage: 0.66, #running-req: 32, #queue-req: 0\n",
      "[2025-08-13 21:26:46] Decode batch. #running-req: 33, #token: 161813, token usage: 0.66, cuda graph: True, gen throughput (token/s): 378.24, #queue-req: 0\n",
      "[2025-08-13 21:26:48] Decode batch. #running-req: 33, #token: 163133, token usage: 0.66, cuda graph: True, gen throughput (token/s): 650.44, #queue-req: 0\n",
      "[2025-08-13 21:26:50] Decode batch. #running-req: 33, #token: 164453, token usage: 0.67, cuda graph: True, gen throughput (token/s): 647.53, #queue-req: 0\n",
      "[2025-08-13 21:26:51] INFO:     127.0.0.1:51936 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:51] INFO:     127.0.0.1:36710 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:52] Decode batch. #running-req: 31, #token: 159093, token usage: 0.65, cuda graph: True, gen throughput (token/s): 639.26, #queue-req: 0\n",
      "[2025-08-13 21:26:52] INFO:     127.0.0.1:54172 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:53] INFO:     127.0.0.1:54184 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:53] Prefill batch. #new-seq: 2, #new-token: 443, #cached-token: 5238, token usage: 0.61, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:26:54] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 467, token usage: 0.61, #running-req: 31, #queue-req: 0\n",
      "[2025-08-13 21:26:54] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 551, token usage: 0.62, #running-req: 32, #queue-req: 0\n",
      "[2025-08-13 21:26:54] Prefill batch. #new-seq: 1, #new-token: 1489, #cached-token: 0, token usage: 0.66, #running-req: 32, #queue-req: 0\n",
      "[2025-08-13 21:26:55] Decode batch. #running-req: 33, #token: 162887, token usage: 0.66, cuda graph: True, gen throughput (token/s): 389.50, #queue-req: 0\n",
      "[2025-08-13 21:26:56] INFO:     127.0.0.1:59366 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:56] INFO:     127.0.0.1:59368 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:56] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 9582, token usage: 0.66, #running-req: 31, #queue-req: 0\n",
      "[2025-08-13 21:26:57] INFO:     127.0.0.1:59398 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:26:57] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.67, #running-req: 32, #queue-req: 0\n",
      "[2025-08-13 21:26:58] Decode batch. #running-req: 33, #token: 164264, token usage: 0.67, cuda graph: True, gen throughput (token/s): 630.06, #queue-req: 0\n",
      "[2025-08-13 21:27:00] Decode batch. #running-req: 33, #token: 165584, token usage: 0.67, cuda graph: True, gen throughput (token/s): 647.42, #queue-req: 0\n",
      "[2025-08-13 21:27:01] INFO:     127.0.0.1:54184 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:02] Decode batch. #running-req: 32, #token: 162387, token usage: 0.66, cuda graph: True, gen throughput (token/s): 647.10, #queue-req: 0\n",
      "[2025-08-13 21:27:02] Prefill batch. #new-seq: 1, #new-token: 2170, #cached-token: 460, token usage: 0.66, #running-req: 32, #queue-req: 0\n",
      "[2025-08-13 21:27:03] INFO:     127.0.0.1:59366 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:03] INFO:     127.0.0.1:59368 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:27:04] Prefill batch. #new-seq: 1, #new-token: 2393, #cached-token: 438, token usage: 0.64, #running-req: 31, #queue-req: 0\n",
      "[2025-08-13 21:27:04] Decode batch. #running-req: 32, #token: 159280, token usage: 0.65, cuda graph: True, gen throughput (token/s): 531.51, #queue-req: 0\n",
      "[2025-08-13 21:27:04] INFO:     127.0.0.1:59398 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:04] INFO:     127.0.0.1:59406 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:04] INFO:     127.0.0.1:59408 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:27:04] Prefill batch. #new-seq: 2, #new-token: 775, #cached-token: 6261, token usage: 0.63, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:06] INFO:     127.0.0.1:58988 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:06] Decode batch. #running-req: 30, #token: 144729, token usage: 0.59, cuda graph: True, gen throughput (token/s): 608.38, #queue-req: 0\n",
      "[2025-08-13 21:27:06] INFO:     127.0.0.1:58946 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:07] Prefill batch. #new-seq: 2, #new-token: 2374, #cached-token: 5248, token usage: 0.61, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:08] Decode batch. #running-req: 31, #token: 152663, token usage: 0.62, cuda graph: True, gen throughput (token/s): 578.93, #queue-req: 0\n",
      "[2025-08-13 21:27:10] Decode batch. #running-req: 31, #token: 153903, token usage: 0.63, cuda graph: True, gen throughput (token/s): 650.03, #queue-req: 0\n",
      "[2025-08-13 21:27:10] INFO:     127.0.0.1:59406 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:27:11] INFO:     127.0.0.1:59408 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:12] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 466, token usage: 0.60, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:12] Decode batch. #running-req: 30, #token: 150444, token usage: 0.61, cuda graph: True, gen throughput (token/s): 571.88, #queue-req: 0\n",
      "[2025-08-13 21:27:13] INFO:     127.0.0.1:58946 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:14] Decode batch. #running-req: 29, #token: 147130, token usage: 0.60, cuda graph: True, gen throughput (token/s): 629.83, #queue-req: 0\n",
      "[2025-08-13 21:27:14] INFO:     127.0.0.1:58960 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:14] INFO:     127.0.0.1:58964 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:14] Prefill batch. #new-seq: 3, #new-token: 5834, #cached-token: 15105, token usage: 0.60, #running-req: 27, #queue-req: 0\n",
      "[2025-08-13 21:27:15] INFO:     127.0.0.1:58960 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:16] Prefill batch. #new-seq: 1, #new-token: 7525, #cached-token: 464, token usage: 0.59, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:17] Decode batch. #running-req: 30, #token: 147949, token usage: 0.60, cuda graph: True, gen throughput (token/s): 369.79, #queue-req: 0\n",
      "[2025-08-13 21:27:17] INFO:     127.0.0.1:43344 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:17] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4800, token usage: 0.62, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:18] INFO:     127.0.0.1:43348 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:18] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.62, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:19] Decode batch. #running-req: 30, #token: 153543, token usage: 0.62, cuda graph: True, gen throughput (token/s): 614.23, #queue-req: 0\n",
      "[2025-08-13 21:27:21] Decode batch. #running-req: 30, #token: 154743, token usage: 0.63, cuda graph: True, gen throughput (token/s): 624.43, #queue-req: 0\n",
      "[2025-08-13 21:27:22] INFO:     127.0.0.1:58964 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:22] Prefill batch. #new-seq: 1, #new-token: 3430, #cached-token: 481, token usage: 0.61, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:23] Decode batch. #running-req: 30, #token: 154860, token usage: 0.63, cuda graph: True, gen throughput (token/s): 529.23, #queue-req: 0\n",
      "[2025-08-13 21:27:24] INFO:     127.0.0.1:43344 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:25] Prefill batch. #new-seq: 1, #new-token: 2224, #cached-token: 410, token usage: 0.57, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:25] INFO:     127.0.0.1:33610 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:25] INFO:     127.0.0.1:33628 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:25] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 12736, token usage: 0.62, #running-req: 30, #queue-req: 0\n",
      "[2025-08-13 21:27:25] INFO:     127.0.0.1:43348 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:25] Decode batch. #running-req: 29, #token: 149295, token usage: 0.61, cuda graph: True, gen throughput (token/s): 550.39, #queue-req: 0\n",
      "[2025-08-13 21:27:25] INFO:     127.0.0.1:33628 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:27] Prefill batch. #new-seq: 2, #new-token: 5633, #cached-token: 1076, token usage: 0.58, #running-req: 28, #queue-req: 0\n",
      "[2025-08-13 21:27:28] Decode batch. #running-req: 30, #token: 148576, token usage: 0.60, cuda graph: True, gen throughput (token/s): 484.12, #queue-req: 0\n",
      "[2025-08-13 21:27:30] Decode batch. #running-req: 30, #token: 149776, token usage: 0.61, cuda graph: True, gen throughput (token/s): 641.59, #queue-req: 0\n",
      "[2025-08-13 21:27:31] INFO:     127.0.0.1:33644 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:31] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.61, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:31] INFO:     127.0.0.1:33610 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:32] Decode batch. #running-req: 29, #token: 146491, token usage: 0.60, cuda graph: True, gen throughput (token/s): 627.17, #queue-req: 0\n",
      "[2025-08-13 21:27:32] Prefill batch. #new-seq: 1, #new-token: 3042, #cached-token: 392, token usage: 0.60, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:34] Decode batch. #running-req: 30, #token: 150720, token usage: 0.61, cuda graph: True, gen throughput (token/s): 552.84, #queue-req: 0\n",
      "[2025-08-13 21:27:34] INFO:     127.0.0.1:58304 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:34] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 7907, token usage: 0.61, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:36] Decode batch. #running-req: 30, #token: 151939, token usage: 0.62, cuda graph: True, gen throughput (token/s): 624.07, #queue-req: 0\n",
      "[2025-08-13 21:27:36] INFO:     127.0.0.1:52794 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:37] Prefill batch. #new-seq: 1, #new-token: 2074, #cached-token: 412, token usage: 0.60, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:37] INFO:     127.0.0.1:35226 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:37] INFO:     127.0.0.1:33644 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:38] Decode batch. #running-req: 28, #token: 142174, token usage: 0.58, cuda graph: True, gen throughput (token/s): 570.32, #queue-req: 0\n",
      "[2025-08-13 21:27:39] Prefill batch. #new-seq: 2, #new-token: 2358, #cached-token: 933, token usage: 0.58, #running-req: 28, #queue-req: 0\n",
      "[2025-08-13 21:27:39] INFO:     127.0.0.1:52798 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:39] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4654, token usage: 0.59, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:40] Decode batch. #running-req: 30, #token: 145694, token usage: 0.59, cuda graph: True, gen throughput (token/s): 550.26, #queue-req: 0\n",
      "[2025-08-13 21:27:41] INFO:     127.0.0.1:58304 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:42] Decode batch. #running-req: 29, #token: 139229, token usage: 0.57, cuda graph: True, gen throughput (token/s): 641.30, #queue-req: 0\n",
      "[2025-08-13 21:27:42] Prefill batch. #new-seq: 1, #new-token: 7631, #cached-token: 464, token usage: 0.57, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:44] Decode batch. #running-req: 30, #token: 148056, token usage: 0.60, cuda graph: True, gen throughput (token/s): 458.86, #queue-req: 0\n",
      "[2025-08-13 21:27:46] Decode batch. #running-req: 30, #token: 149256, token usage: 0.61, cuda graph: True, gen throughput (token/s): 643.08, #queue-req: 0\n",
      "[2025-08-13 21:27:46] INFO:     127.0.0.1:52798 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:47] Prefill batch. #new-seq: 1, #new-token: 7340, #cached-token: 465, token usage: 0.59, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:48] INFO:     127.0.0.1:35242 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:48] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 16126, token usage: 0.62, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:49] Decode batch. #running-req: 30, #token: 153444, token usage: 0.62, cuda graph: True, gen throughput (token/s): 454.40, #queue-req: 0\n",
      "[2025-08-13 21:27:50] INFO:     127.0.0.1:41836 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:51] Decode batch. #running-req: 29, #token: 151564, token usage: 0.62, cuda graph: True, gen throughput (token/s): 626.47, #queue-req: 0\n",
      "[2025-08-13 21:27:51] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 449, token usage: 0.62, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:52] INFO:     127.0.0.1:35252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:52] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4801, token usage: 0.63, #running-req: 29, #queue-req: 0\n",
      "[2025-08-13 21:27:53] Decode batch. #running-req: 30, #token: 155124, token usage: 0.63, cuda graph: True, gen throughput (token/s): 554.96, #queue-req: 0\n",
      "[2025-08-13 21:27:55] Decode batch. #running-req: 30, #token: 156324, token usage: 0.64, cuda graph: True, gen throughput (token/s): 628.15, #queue-req: 0\n",
      "[2025-08-13 21:27:55] INFO:     127.0.0.1:35242 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:27:55] INFO:     127.0.0.1:57326 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:55] INFO:     127.0.0.1:57328 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:27:56] Decode batch. #running-req: 27, #token: 132161, token usage: 0.54, cuda graph: True, gen throughput (token/s): 631.16, #queue-req: 0\n",
      "[2025-08-13 21:27:57] Prefill batch. #new-seq: 2, #new-token: 4699, #cached-token: 905, token usage: 0.54, #running-req: 27, #queue-req: 0\n",
      "[2025-08-13 21:27:58] INFO:     127.0.0.1:35252 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:27:58] Decode batch. #running-req: 28, #token: 133497, token usage: 0.54, cuda graph: True, gen throughput (token/s): 524.09, #queue-req: 0\n",
      "[2025-08-13 21:28:00] INFO:     127.0.0.1:33646 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:00] Decode batch. #running-req: 27, #token: 132929, token usage: 0.54, cuda graph: True, gen throughput (token/s): 638.31, #queue-req: 0\n",
      "[2025-08-13 21:28:01] Prefill batch. #new-seq: 1, #new-token: 2096, #cached-token: 413, token usage: 0.54, #running-req: 27, #queue-req: 0\n",
      "[2025-08-13 21:28:02] Decode batch. #running-req: 28, #token: 136135, token usage: 0.55, cuda graph: True, gen throughput (token/s): 569.54, #queue-req: 0\n",
      "[2025-08-13 21:28:04] Decode batch. #running-req: 28, #token: 137255, token usage: 0.56, cuda graph: True, gen throughput (token/s): 633.55, #queue-req: 0\n",
      "[2025-08-13 21:28:06] Decode batch. #running-req: 28, #token: 138375, token usage: 0.56, cuda graph: True, gen throughput (token/s): 627.15, #queue-req: 0\n",
      "[2025-08-13 21:28:08] Decode batch. #running-req: 28, #token: 139495, token usage: 0.57, cuda graph: True, gen throughput (token/s): 622.75, #queue-req: 0\n",
      "[2025-08-13 21:28:08] INFO:     127.0.0.1:33196 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:09] INFO:     127.0.0.1:55252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:09] Prefill batch. #new-seq: 2, #new-token: 2375, #cached-token: 8996, token usage: 0.56, #running-req: 26, #queue-req: 0\n",
      "[2025-08-13 21:28:09] Decode batch. #running-req: 26, #token: 138829, token usage: 0.56, cuda graph: True, gen throughput (token/s): 604.22, #queue-req: 0\n",
      "[2025-08-13 21:28:11] Decode batch. #running-req: 28, #token: 139977, token usage: 0.57, cuda graph: True, gen throughput (token/s): 557.82, #queue-req: 0\n",
      "[2025-08-13 21:28:13] Decode batch. #running-req: 28, #token: 138873, token usage: 0.56, cuda graph: True, gen throughput (token/s): 617.18, #queue-req: 0\n",
      "[2025-08-13 21:28:13] INFO:     127.0.0.1:51912 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:13] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2687, token usage: 0.57, #running-req: 27, #queue-req: 0\n",
      "[2025-08-13 21:28:15] Decode batch. #running-req: 28, #token: 142236, token usage: 0.58, cuda graph: True, gen throughput (token/s): 610.65, #queue-req: 0\n",
      "[2025-08-13 21:28:15] INFO:     127.0.0.1:55252 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:16] INFO:     127.0.0.1:51914 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:16] INFO:     127.0.0.1:51918 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:16] INFO:     127.0.0.1:51928 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:16] Prefill batch. #new-seq: 3, #new-token: 62, #cached-token: 20482, token usage: 0.55, #running-req: 24, #queue-req: 0\n",
      "[2025-08-13 21:28:16] Prefill batch. #new-seq: 1, #new-token: 3284, #cached-token: 451, token usage: 0.55, #running-req: 27, #queue-req: 0\n",
      "[2025-08-13 21:28:16] INFO:     127.0.0.1:51928 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 21:28:17] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 7659, token usage: 0.55, #running-req: 27, #queue-req: 0\n",
      "[2025-08-13 21:28:17] INFO:     127.0.0.1:33658 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:17] Decode batch. #running-req: 27, #token: 130209, token usage: 0.53, cuda graph: True, gen throughput (token/s): 516.43, #queue-req: 0\n",
      "[2025-08-13 21:28:17] INFO:     127.0.0.1:51912 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:17] INFO:     127.0.0.1:51918 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:19] INFO:     127.0.0.1:44348 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:19] Decode batch. #running-req: 24, #token: 120272, token usage: 0.49, cuda graph: True, gen throughput (token/s): 601.07, #queue-req: 0\n",
      "[2025-08-13 21:28:20] INFO:     127.0.0.1:36144 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:20] Decode batch. #running-req: 23, #token: 117003, token usage: 0.48, cuda graph: True, gen throughput (token/s): 589.86, #queue-req: 0\n",
      "[2025-08-13 21:28:21] INFO:     127.0.0.1:36130 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:22] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 452, token usage: 0.44, #running-req: 22, #queue-req: 0\n",
      ".[2025-08-13 21:28:22] Prefill batch. #new-seq: 4, #new-token: 5280, #cached-token: 1738, token usage: 0.45, #running-req: 23, #queue-req: 0\n",
      "[2025-08-13 21:28:22] INFO:     127.0.0.1:51914 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:23] Decode batch. #running-req: 26, #token: 113304, token usage: 0.46, cuda graph: True, gen throughput (token/s): 424.20, #queue-req: 0\n",
      "[2025-08-13 21:28:23] Prefill batch. #new-seq: 1, #new-token: 2220, #cached-token: 413, token usage: 0.46, #running-req: 26, #queue-req: 0\n",
      "[2025-08-13 21:28:24] Decode batch. #running-req: 27, #token: 116584, token usage: 0.47, cuda graph: True, gen throughput (token/s): 587.08, #queue-req: 0\n",
      "[2025-08-13 21:28:26] Decode batch. #running-req: 27, #token: 117664, token usage: 0.48, cuda graph: True, gen throughput (token/s): 666.18, #queue-req: 0\n",
      "[2025-08-13 21:28:26] INFO:     127.0.0.1:36158 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:26] INFO:     127.0.0.1:36170 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:26] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4632, token usage: 0.43, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:28:27] INFO:     127.0.0.1:36170 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:28] Decode batch. #running-req: 25, #token: 102544, token usage: 0.42, cuda graph: True, gen throughput (token/s): 659.57, #queue-req: 0\n",
      "[2025-08-13 21:28:28] Prefill batch. #new-seq: 2, #new-token: 6581, #cached-token: 904, token usage: 0.42, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:28:30] INFO:     127.0.0.1:41842 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:30] Decode batch. #running-req: 26, #token: 106152, token usage: 0.43, cuda graph: True, gen throughput (token/s): 495.12, #queue-req: 0\n",
      "[2025-08-13 21:28:31] Prefill batch. #new-seq: 1, #new-token: 3282, #cached-token: 480, token usage: 0.43, #running-req: 26, #queue-req: 0\n",
      "[2025-08-13 21:28:31] Decode batch. #running-req: 27, #token: 110491, token usage: 0.45, cuda graph: True, gen throughput (token/s): 577.97, #queue-req: 0\n",
      "[2025-08-13 21:28:33] Decode batch. #running-req: 27, #token: 111571, token usage: 0.45, cuda graph: True, gen throughput (token/s): 697.91, #queue-req: 0\n",
      "[2025-08-13 21:28:34] INFO:     127.0.0.1:33666 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:34] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 12231, token usage: 0.46, #running-req: 26, #queue-req: 0\n",
      "[2025-08-13 21:28:35] Decode batch. #running-req: 27, #token: 112669, token usage: 0.46, cuda graph: True, gen throughput (token/s): 682.05, #queue-req: 0\n",
      "[2025-08-13 21:28:36] Decode batch. #running-req: 27, #token: 113749, token usage: 0.46, cuda graph: True, gen throughput (token/s): 688.14, #queue-req: 0\n",
      "[2025-08-13 21:28:36] INFO:     127.0.0.1:41840 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:37] Prefill batch. #new-seq: 1, #new-token: 5270, #cached-token: 480, token usage: 0.45, #running-req: 26, #queue-req: 0\n",
      "[2025-08-13 21:28:38] Decode batch. #running-req: 27, #token: 115798, token usage: 0.47, cuda graph: True, gen throughput (token/s): 515.96, #queue-req: 0\n",
      "[2025-08-13 21:28:40] Decode batch. #running-req: 27, #token: 116878, token usage: 0.48, cuda graph: True, gen throughput (token/s): 675.82, #queue-req: 0\n",
      "[2025-08-13 21:28:40] INFO:     127.0.0.1:33666 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:28:41] Decode batch. #running-req: 26, #token: 105951, token usage: 0.43, cuda graph: True, gen throughput (token/s): 691.90, #queue-req: 0\n",
      "[2025-08-13 21:28:43] Decode batch. #running-req: 26, #token: 106991, token usage: 0.44, cuda graph: True, gen throughput (token/s): 689.74, #queue-req: 0\n",
      "[2025-08-13 21:28:44] Decode batch. #running-req: 26, #token: 108031, token usage: 0.44, cuda graph: True, gen throughput (token/s): 685.94, #queue-req: 0\n",
      "[2025-08-13 21:28:46] Decode batch. #running-req: 26, #token: 109071, token usage: 0.44, cuda graph: True, gen throughput (token/s): 682.35, #queue-req: 0\n",
      "[2025-08-13 21:28:46] INFO:     127.0.0.1:33208 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:46] INFO:     127.0.0.1:35906 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:47] INFO:     127.0.0.1:33210 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:47] Decode batch. #running-req: 23, #token: 97817, token usage: 0.40, cuda graph: True, gen throughput (token/s): 653.59, #queue-req: 0\n",
      "[2025-08-13 21:28:48] INFO:     127.0.0.1:53038 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:49] Prefill batch. #new-seq: 1, #new-token: 2348, #cached-token: 454, token usage: 0.39, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:28:49] Decode batch. #running-req: 23, #token: 97385, token usage: 0.40, cuda graph: True, gen throughput (token/s): 549.33, #queue-req: 0\n",
      "[2025-08-13 21:28:50] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 1007, token usage: 0.40, #running-req: 23, #queue-req: 1\n",
      "[2025-08-13 21:28:50] Prefill batch. #new-seq: 2, #new-token: 4196, #cached-token: 450, token usage: 0.43, #running-req: 24, #queue-req: 0\n",
      "[2025-08-13 21:28:52] INFO:     127.0.0.1:57344 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:52] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 9988, token usage: 0.45, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:28:52] Decode batch. #running-req: 25, #token: 110760, token usage: 0.45, cuda graph: True, gen throughput (token/s): 371.79, #queue-req: 0\n",
      "[2025-08-13 21:28:52] INFO:     127.0.0.1:57344 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 21:28:52] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 7988, token usage: 0.44, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:28:53] Decode batch. #running-req: 26, #token: 109805, token usage: 0.45, cuda graph: True, gen throughput (token/s): 659.54, #queue-req: 0\n",
      "[2025-08-13 21:28:55] Decode batch. #running-req: 26, #token: 110845, token usage: 0.45, cuda graph: True, gen throughput (token/s): 664.57, #queue-req: 0\n",
      "[2025-08-13 21:28:56] INFO:     127.0.0.1:44342 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:56] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 5910, token usage: 0.45, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:28:56] Decode batch. #running-req: 26, #token: 111904, token usage: 0.46, cuda graph: True, gen throughput (token/s): 649.46, #queue-req: 0\n",
      "[2025-08-13 21:28:58] Decode batch. #running-req: 26, #token: 112944, token usage: 0.46, cuda graph: True, gen throughput (token/s): 661.80, #queue-req: 0\n",
      "[2025-08-13 21:28:59] INFO:     127.0.0.1:33202 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:28:59] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4798, token usage: 0.46, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:00] Decode batch. #running-req: 26, #token: 114002, token usage: 0.46, cuda graph: True, gen throughput (token/s): 646.76, #queue-req: 0\n",
      "[2025-08-13 21:29:01] INFO:     127.0.0.1:44342 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:01] Decode batch. #running-req: 25, #token: 109374, token usage: 0.44, cuda graph: True, gen throughput (token/s): 646.70, #queue-req: 0\n",
      "[2025-08-13 21:29:02] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 449, token usage: 0.45, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:03] Decode batch. #running-req: 26, #token: 112755, token usage: 0.46, cuda graph: True, gen throughput (token/s): 580.01, #queue-req: 0\n",
      "[2025-08-13 21:29:04] Decode batch. #running-req: 26, #token: 113795, token usage: 0.46, cuda graph: True, gen throughput (token/s): 662.91, #queue-req: 0\n",
      "[2025-08-13 21:29:05] INFO:     127.0.0.1:33202 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:05] Prefill batch. #new-seq: 1, #new-token: 5632, #cached-token: 466, token usage: 0.45, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:07] Decode batch. #running-req: 26, #token: 116002, token usage: 0.47, cuda graph: True, gen throughput (token/s): 486.31, #queue-req: 0\n",
      "[2025-08-13 21:29:08] INFO:     127.0.0.1:35896 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:08] Decode batch. #running-req: 25, #token: 113327, token usage: 0.46, cuda graph: True, gen throughput (token/s): 640.60, #queue-req: 0\n",
      "[2025-08-13 21:29:08] Prefill batch. #new-seq: 1, #new-token: 1601, #cached-token: 481, token usage: 0.46, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:09] INFO:     127.0.0.1:53030 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:09] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2658, token usage: 0.47, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:10] Decode batch. #running-req: 26, #token: 115983, token usage: 0.47, cuda graph: True, gen throughput (token/s): 582.04, #queue-req: 0\n",
      "[2025-08-13 21:29:12] Decode batch. #running-req: 26, #token: 117023, token usage: 0.48, cuda graph: True, gen throughput (token/s): 639.48, #queue-req: 0\n",
      "[2025-08-13 21:29:12] INFO:     127.0.0.1:53048 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:12] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 10094, token usage: 0.48, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:12] INFO:     127.0.0.1:53048 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:13] Decode batch. #running-req: 25, #token: 108396, token usage: 0.44, cuda graph: True, gen throughput (token/s): 639.63, #queue-req: 0\n",
      "[2025-08-13 21:29:13] Prefill batch. #new-seq: 1, #new-token: 7781, #cached-token: 464, token usage: 0.44, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:15] INFO:     127.0.0.1:53030 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:16] Decode batch. #running-req: 25, #token: 114867, token usage: 0.47, cuda graph: True, gen throughput (token/s): 436.56, #queue-req: 0\n",
      "[2025-08-13 21:29:16] Prefill batch. #new-seq: 1, #new-token: 2419, #cached-token: 437, token usage: 0.47, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:16] INFO:     127.0.0.1:41364 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:17] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 9804, token usage: 0.48, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:17] INFO:     127.0.0.1:41364 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:17] Decode batch. #running-req: 25, #token: 109035, token usage: 0.44, cuda graph: True, gen throughput (token/s): 553.19, #queue-req: 0\n",
      "[2025-08-13 21:29:18] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 449, token usage: 0.45, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:19] Decode batch. #running-req: 26, #token: 112406, token usage: 0.46, cuda graph: True, gen throughput (token/s): 573.92, #queue-req: 0\n",
      "[2025-08-13 21:29:19] INFO:     127.0.0.1:41374 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:20] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4798, token usage: 0.46, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:21] Decode batch. #running-req: 26, #token: 113464, token usage: 0.46, cuda graph: True, gen throughput (token/s): 650.05, #queue-req: 0\n",
      "[2025-08-13 21:29:22] Decode batch. #running-req: 26, #token: 114504, token usage: 0.47, cuda graph: True, gen throughput (token/s): 656.95, #queue-req: 0\n",
      "[2025-08-13 21:29:24] Decode batch. #running-req: 26, #token: 115544, token usage: 0.47, cuda graph: True, gen throughput (token/s): 653.07, #queue-req: 0\n",
      "[2025-08-13 21:29:25] INFO:     127.0.0.1:41388 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:25] INFO:     127.0.0.1:35694 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:25] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 9602, token usage: 0.47, #running-req: 24, #queue-req: 0\n",
      "[2025-08-13 21:29:25] INFO:     127.0.0.1:41374 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:26] Decode batch. #running-req: 25, #token: 112101, token usage: 0.46, cuda graph: True, gen throughput (token/s): 633.29, #queue-req: 0\n",
      "[2025-08-13 21:29:26] Prefill batch. #new-seq: 1, #new-token: 2162, #cached-token: 471, token usage: 0.46, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:27] Decode batch. #running-req: 26, #token: 115379, token usage: 0.47, cuda graph: True, gen throughput (token/s): 581.64, #queue-req: 0\n",
      "[2025-08-13 21:29:28] INFO:     127.0.0.1:39916 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:28] INFO:     127.0.0.1:35702 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:29] Prefill batch. #new-seq: 2, #new-token: 2375, #cached-token: 4955, token usage: 0.46, #running-req: 24, #queue-req: 0\n",
      "[2025-08-13 21:29:29] Decode batch. #running-req: 26, #token: 115012, token usage: 0.47, cuda graph: True, gen throughput (token/s): 558.36, #queue-req: 0\n",
      "[2025-08-13 21:29:30] INFO:     127.0.0.1:41388 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:30] INFO:     127.0.0.1:35694 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:31] Decode batch. #running-req: 24, #token: 107015, token usage: 0.44, cuda graph: True, gen throughput (token/s): 652.52, #queue-req: 0\n",
      "[2025-08-13 21:29:32] Prefill batch. #new-seq: 2, #new-token: 8109, #cached-token: 940, token usage: 0.44, #running-req: 24, #queue-req: 0\n",
      "[2025-08-13 21:29:33] Decode batch. #running-req: 26, #token: 116156, token usage: 0.47, cuda graph: True, gen throughput (token/s): 430.68, #queue-req: 0\n",
      "[2025-08-13 21:29:34] Decode batch. #running-req: 26, #token: 117196, token usage: 0.48, cuda graph: True, gen throughput (token/s): 650.62, #queue-req: 0\n",
      "[2025-08-13 21:29:35] INFO:     127.0.0.1:35702 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:36] Prefill batch. #new-seq: 1, #new-token: 2517, #cached-token: 434, token usage: 0.46, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:36] Decode batch. #running-req: 26, #token: 116538, token usage: 0.47, cuda graph: True, gen throughput (token/s): 557.72, #queue-req: 0\n",
      "[2025-08-13 21:29:38] Decode batch. #running-req: 26, #token: 117578, token usage: 0.48, cuda graph: True, gen throughput (token/s): 647.80, #queue-req: 0\n",
      "[2025-08-13 21:29:39] INFO:     127.0.0.1:39870 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:39] Prefill batch. #new-seq: 1, #new-token: 458, #cached-token: 464, token usage: 0.47, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:40] Decode batch. #running-req: 26, #token: 114914, token usage: 0.47, cuda graph: True, gen throughput (token/s): 613.10, #queue-req: 0\n",
      "[2025-08-13 21:29:41] Decode batch. #running-req: 26, #token: 115954, token usage: 0.47, cuda graph: True, gen throughput (token/s): 645.67, #queue-req: 0\n",
      "[2025-08-13 21:29:42] INFO:     127.0.0.1:35260 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:42] INFO:     127.0.0.1:51928 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:43] Decode batch. #running-req: 24, #token: 105323, token usage: 0.43, cuda graph: True, gen throughput (token/s): 642.08, #queue-req: 0\n",
      "[2025-08-13 21:29:43] Prefill batch. #new-seq: 2, #new-token: 2375, #cached-token: 10107, token usage: 0.47, #running-req: 24, #queue-req: 0\n",
      "[2025-08-13 21:29:44] INFO:     127.0.0.1:51928 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:45] Decode batch. #running-req: 25, #token: 108670, token usage: 0.44, cuda graph: True, gen throughput (token/s): 563.79, #queue-req: 0\n",
      "[2025-08-13 21:29:45] Prefill batch. #new-seq: 1, #new-token: 2341, #cached-token: 461, token usage: 0.44, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:46] Decode batch. #running-req: 26, #token: 112032, token usage: 0.46, cuda graph: True, gen throughput (token/s): 575.10, #queue-req: 0\n",
      "[2025-08-13 21:29:48] INFO:     127.0.0.1:39886 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:48] INFO:     127.0.0.1:39896 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:48] INFO:     127.0.0.1:39902 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:48] INFO:     127.0.0.1:39906 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:48] Prefill batch. #new-seq: 3, #new-token: 63, #cached-token: 12158, token usage: 0.45, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:29:48] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2856, token usage: 0.46, #running-req: 25, #queue-req: 0\n",
      "[2025-08-13 21:29:48] Decode batch. #running-req: 26, #token: 113148, token usage: 0.46, cuda graph: True, gen throughput (token/s): 637.73, #queue-req: 0\n",
      "[2025-08-13 21:29:50] Decode batch. #running-req: 26, #token: 114188, token usage: 0.46, cuda graph: True, gen throughput (token/s): 662.13, #queue-req: 0\n",
      "[2025-08-13 21:29:51] Decode batch. #running-req: 26, #token: 115228, token usage: 0.47, cuda graph: True, gen throughput (token/s): 660.09, #queue-req: 0\n",
      "[2025-08-13 21:29:52] INFO:     127.0.0.1:59930 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:53] Decode batch. #running-req: 25, #token: 95406, token usage: 0.39, cuda graph: True, gen throughput (token/s): 653.65, #queue-req: 0\n",
      "[2025-08-13 21:29:53] INFO:     127.0.0.1:39902 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:53] INFO:     127.0.0.1:39896 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:53] INFO:     127.0.0.1:39906 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:53] INFO:     127.0.0.1:39886 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:29:53] INFO:     127.0.0.1:36362 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:53] INFO:     127.0.0.1:36378 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:54] Decode batch. #running-req: 19, #token: 85619, token usage: 0.35, cuda graph: True, gen throughput (token/s): 588.47, #queue-req: 0\n",
      "[2025-08-13 21:29:55] INFO:     127.0.0.1:36384 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:55] Decode batch. #running-req: 18, #token: 81080, token usage: 0.33, cuda graph: True, gen throughput (token/s): 568.17, #queue-req: 0\n",
      "[2025-08-13 21:29:56] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 6682, token usage: 0.36, #running-req: 18, #queue-req: 0\n",
      "[2025-08-13 21:29:56] Prefill batch. #new-seq: 5, #new-token: 8192, #cached-token: 11904, token usage: 0.40, #running-req: 19, #queue-req: 1\n",
      "[2025-08-13 21:29:56] Prefill batch. #new-seq: 2, #new-token: 2538, #cached-token: 473, token usage: 0.43, #running-req: 23, #queue-req: 0\n",
      "[2025-08-13 21:29:58] INFO:     127.0.0.1:36362 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:29:58] Decode batch. #running-req: 24, #token: 102306, token usage: 0.42, cuda graph: True, gen throughput (token/s): 344.68, #queue-req: 0\n",
      "[2025-08-13 21:29:58] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 481, token usage: 0.42, #running-req: 24, #queue-req: 0\n",
      "[2025-08-13 21:29:58] Prefill batch. #new-seq: 1, #new-token: 3558, #cached-token: 0, token usage: 0.45, #running-req: 24, #queue-req: 0\n",
      "[2025-08-13 21:30:01] Decode batch. #running-req: 25, #token: 115055, token usage: 0.47, cuda graph: True, gen throughput (token/s): 348.71, #queue-req: 0\n",
      "[2025-08-13 21:30:02] Decode batch. #running-req: 25, #token: 116055, token usage: 0.47, cuda graph: True, gen throughput (token/s): 632.46, #queue-req: 0\n",
      "[2025-08-13 21:30:03] INFO:     127.0.0.1:36384 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:03] INFO:     127.0.0.1:36378 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:04] Decode batch. #running-req: 23, #token: 107115, token usage: 0.44, cuda graph: True, gen throughput (token/s): 624.41, #queue-req: 0\n",
      "[2025-08-13 21:30:05] Prefill batch. #new-seq: 2, #new-token: 2513, #cached-token: 903, token usage: 0.44, #running-req: 23, #queue-req: 0\n",
      "[2025-08-13 21:30:05] Decode batch. #running-req: 25, #token: 110634, token usage: 0.45, cuda graph: True, gen throughput (token/s): 544.25, #queue-req: 0\n",
      "[2025-08-13 21:30:06] INFO:     127.0.0.1:35286 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:30:07] Decode batch. #running-req: 24, #token: 108383, token usage: 0.44, cuda graph: True, gen throughput (token/s): 638.16, #queue-req: 0\n",
      "[2025-08-13 21:30:09] Decode batch. #running-req: 24, #token: 109343, token usage: 0.44, cuda graph: True, gen throughput (token/s): 628.80, #queue-req: 0\n",
      "[2025-08-13 21:30:10] Decode batch. #running-req: 24, #token: 110303, token usage: 0.45, cuda graph: True, gen throughput (token/s): 626.73, #queue-req: 0\n",
      "[2025-08-13 21:30:12] Decode batch. #running-req: 24, #token: 111263, token usage: 0.45, cuda graph: True, gen throughput (token/s): 627.68, #queue-req: 0\n",
      "[2025-08-13 21:30:13] Decode batch. #running-req: 24, #token: 112223, token usage: 0.46, cuda graph: True, gen throughput (token/s): 624.90, #queue-req: 0\n",
      "[2025-08-13 21:30:14] INFO:     127.0.0.1:52728 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:15] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.46, #running-req: 23, #queue-req: 0\n",
      "[2025-08-13 21:30:15] Decode batch. #running-req: 24, #token: 113202, token usage: 0.46, cuda graph: True, gen throughput (token/s): 610.58, #queue-req: 0\n",
      "[2025-08-13 21:30:15] INFO:     127.0.0.1:52740 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:15] INFO:     127.0.0.1:52750 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:15] INFO:     127.0.0.1:52752 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:15] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4800, token usage: 0.40, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:30:15] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 15042, token usage: 0.46, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:30:16] Decode batch. #running-req: 24, #token: 114218, token usage: 0.46, cuda graph: True, gen throughput (token/s): 591.69, #queue-req: 0\n",
      "[2025-08-13 21:30:16] INFO:     127.0.0.1:57344 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:16] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 9988, token usage: 0.46, #running-req: 23, #queue-req: 0\n",
      "[2025-08-13 21:30:18] Decode batch. #running-req: 24, #token: 115196, token usage: 0.47, cuda graph: True, gen throughput (token/s): 603.84, #queue-req: 0\n",
      "[2025-08-13 21:30:19] Decode batch. #running-req: 24, #token: 116156, token usage: 0.47, cuda graph: True, gen throughput (token/s): 610.66, #queue-req: 0\n",
      "[2025-08-13 21:30:20] INFO:     127.0.0.1:52728 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:20] INFO:     127.0.0.1:52752 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:20] INFO:     127.0.0.1:52740 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:20] INFO:     127.0.0.1:52750 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:21] Decode batch. #running-req: 20, #token: 93555, token usage: 0.38, cuda graph: True, gen throughput (token/s): 590.86, #queue-req: 0\n",
      "[2025-08-13 21:30:21] INFO:     127.0.0.1:57344 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:22] Decode batch. #running-req: 19, #token: 84599, token usage: 0.34, cuda graph: True, gen throughput (token/s): 577.38, #queue-req: 0\n",
      "[2025-08-13 21:30:23] Prefill batch. #new-seq: 1, #new-token: 3201, #cached-token: 392, token usage: 0.35, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:30:24] Decode batch. #running-req: 20, #token: 88568, token usage: 0.36, cuda graph: True, gen throughput (token/s): 472.17, #queue-req: 0\n",
      "[2025-08-13 21:30:24] Prefill batch. #new-seq: 1, #new-token: 2159, #cached-token: 475, token usage: 0.36, #running-req: 20, #queue-req: 0\n",
      "[2025-08-13 21:30:24] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 1326, token usage: 0.37, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:30:24] Prefill batch. #new-seq: 1, #new-token: 6674, #cached-token: 0, token usage: 0.40, #running-req: 23, #queue-req: 0\n",
      "[2025-08-13 21:30:27] Decode batch. #running-req: 24, #token: 106519, token usage: 0.43, cuda graph: True, gen throughput (token/s): 296.78, #queue-req: 0\n",
      "[2025-08-13 21:30:27] INFO:     127.0.0.1:60288 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:27] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4800, token usage: 0.43, #running-req: 23, #queue-req: 0\n",
      "[2025-08-13 21:30:29] Decode batch. #running-req: 24, #token: 107498, token usage: 0.44, cuda graph: True, gen throughput (token/s): 619.48, #queue-req: 0\n",
      "[2025-08-13 21:30:29] INFO:     127.0.0.1:42088 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:30] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 454, token usage: 0.43, #running-req: 23, #queue-req: 0\n",
      "[2025-08-13 21:30:30] Decode batch. #running-req: 24, #token: 107132, token usage: 0.44, cuda graph: True, gen throughput (token/s): 547.06, #queue-req: 0\n",
      "[2025-08-13 21:30:31] INFO:     127.0.0.1:60290 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:31] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 8097, token usage: 0.44, #running-req: 23, #queue-req: 0\n",
      "[2025-08-13 21:30:32] Decode batch. #running-req: 24, #token: 108111, token usage: 0.44, cuda graph: True, gen throughput (token/s): 623.13, #queue-req: 0\n",
      "[2025-08-13 21:30:33] INFO:     127.0.0.1:60288 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:33] INFO:     127.0.0.1:60290 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:33] Decode batch. #running-req: 22, #token: 96859, token usage: 0.39, cuda graph: True, gen throughput (token/s): 624.09, #queue-req: 0\n",
      "[2025-08-13 21:30:33] INFO:     127.0.0.1:36616 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:34] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4081, token usage: 0.40, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:30:34] Prefill batch. #new-seq: 2, #new-token: 7747, #cached-token: 1073, token usage: 0.40, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:30:35] Decode batch. #running-req: 24, #token: 105512, token usage: 0.43, cuda graph: True, gen throughput (token/s): 413.17, #queue-req: 0\n",
      "[2025-08-13 21:30:37] Decode batch. #running-req: 24, #token: 106472, token usage: 0.43, cuda graph: True, gen throughput (token/s): 636.85, #queue-req: 0\n",
      "[2025-08-13 21:30:38] INFO:     127.0.0.1:49446 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:38] Decode batch. #running-req: 23, #token: 104184, token usage: 0.42, cuda graph: True, gen throughput (token/s): 628.06, #queue-req: 0\n",
      "[2025-08-13 21:30:39] INFO:     127.0.0.1:36630 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:39] Prefill batch. #new-seq: 2, #new-token: 8192, #cached-token: 10657, token usage: 0.42, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:30:39] Prefill batch. #new-seq: 1, #new-token: 1586, #cached-token: 0, token usage: 0.46, #running-req: 23, #queue-req: 0\n",
      "[2025-08-13 21:30:40] INFO:     127.0.0.1:36616 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:40] INFO:     127.0.0.1:42076 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:40] INFO:     127.0.0.1:36630 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:41] Decode batch. #running-req: 21, #token: 97186, token usage: 0.40, cuda graph: True, gen throughput (token/s): 353.63, #queue-req: 0\n",
      "[2025-08-13 21:30:42] INFO:     127.0.0.1:36646 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:30:42] Prefill batch. #new-seq: 3, #new-token: 5878, #cached-token: 5848, token usage: 0.40, #running-req: 20, #queue-req: 0\n",
      "[2025-08-13 21:30:43] Decode batch. #running-req: 23, #token: 103931, token usage: 0.42, cuda graph: True, gen throughput (token/s): 433.39, #queue-req: 0\n",
      "[2025-08-13 21:30:44] Decode batch. #running-req: 23, #token: 104851, token usage: 0.43, cuda graph: True, gen throughput (token/s): 624.84, #queue-req: 0\n",
      "[2025-08-13 21:30:46] Decode batch. #running-req: 23, #token: 105771, token usage: 0.43, cuda graph: True, gen throughput (token/s): 621.02, #queue-req: 0\n",
      "[2025-08-13 21:30:47] INFO:     127.0.0.1:36646 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:47] Decode batch. #running-req: 22, #token: 102116, token usage: 0.42, cuda graph: True, gen throughput (token/s): 614.93, #queue-req: 0\n",
      "[2025-08-13 21:30:48] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 468, token usage: 0.42, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:30:49] Decode batch. #running-req: 23, #token: 105185, token usage: 0.43, cuda graph: True, gen throughput (token/s): 539.39, #queue-req: 0\n",
      "[2025-08-13 21:30:50] INFO:     127.0.0.1:43724 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:51] Decode batch. #running-req: 22, #token: 102421, token usage: 0.42, cuda graph: True, gen throughput (token/s): 610.56, #queue-req: 0\n",
      "[2025-08-13 21:30:51] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 413, token usage: 0.42, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:30:52] Decode batch. #running-req: 23, #token: 103515, token usage: 0.42, cuda graph: True, gen throughput (token/s): 602.87, #queue-req: 0\n",
      "[2025-08-13 21:30:53] INFO:     127.0.0.1:35252 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:53] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4800, token usage: 0.42, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:30:54] Decode batch. #running-req: 23, #token: 104454, token usage: 0.42, cuda graph: True, gen throughput (token/s): 604.46, #queue-req: 0\n",
      "[2025-08-13 21:30:54] INFO:     127.0.0.1:35252 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:55] INFO:     127.0.0.1:49418 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:55] Decode batch. #running-req: 21, #token: 98085, token usage: 0.40, cuda graph: True, gen throughput (token/s): 602.80, #queue-req: 0\n",
      "[2025-08-13 21:30:56] Prefill batch. #new-seq: 2, #new-token: 4453, #cached-token: 869, token usage: 0.40, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:30:57] INFO:     127.0.0.1:35274 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:30:57] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 8415, token usage: 0.42, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:30:57] Decode batch. #running-req: 23, #token: 103447, token usage: 0.42, cuda graph: True, gen throughput (token/s): 473.13, #queue-req: 0\n",
      "[2025-08-13 21:30:58] Decode batch. #running-req: 23, #token: 104367, token usage: 0.42, cuda graph: True, gen throughput (token/s): 622.18, #queue-req: 0\n",
      "[2025-08-13 21:31:00] Decode batch. #running-req: 23, #token: 105287, token usage: 0.43, cuda graph: True, gen throughput (token/s): 617.87, #queue-req: 0\n",
      "[2025-08-13 21:31:01] INFO:     127.0.0.1:37462 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:01] Decode batch. #running-req: 22, #token: 92938, token usage: 0.38, cuda graph: True, gen throughput (token/s): 620.54, #queue-req: 0\n",
      "[2025-08-13 21:31:01] INFO:     127.0.0.1:35274 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:03] INFO:     127.0.0.1:45808 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:03] Prefill batch. #new-seq: 3, #new-token: 6630, #cached-token: 3823, token usage: 0.35, #running-req: 20, #queue-req: 0\n",
      "[2025-08-13 21:31:03] Decode batch. #running-req: 20, #token: 92244, token usage: 0.38, cuda graph: True, gen throughput (token/s): 620.91, #queue-req: 0\n",
      "[2025-08-13 21:31:05] Decode batch. #running-req: 23, #token: 93187, token usage: 0.38, cuda graph: True, gen throughput (token/s): 470.42, #queue-req: 0\n",
      "[2025-08-13 21:31:06] Decode batch. #running-req: 23, #token: 94107, token usage: 0.38, cuda graph: True, gen throughput (token/s): 656.78, #queue-req: 0\n",
      "[2025-08-13 21:31:06] INFO:     127.0.0.1:45818 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:06] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.38, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:31:07] Decode batch. #running-req: 23, #token: 95046, token usage: 0.39, cuda graph: True, gen throughput (token/s): 642.82, #queue-req: 0\n",
      "[2025-08-13 21:31:08] INFO:     127.0.0.1:45808 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:08] INFO:     127.0.0.1:45822 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:09] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.38, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:31:09] Prefill batch. #new-seq: 1, #new-token: 2678, #cached-token: 441, token usage: 0.38, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:31:09] Decode batch. #running-req: 23, #token: 95971, token usage: 0.39, cuda graph: True, gen throughput (token/s): 535.73, #queue-req: 0\n",
      "[2025-08-13 21:31:11] Decode batch. #running-req: 23, #token: 96891, token usage: 0.39, cuda graph: True, gen throughput (token/s): 650.69, #queue-req: 0\n",
      "[2025-08-13 21:31:11] INFO:     127.0.0.1:45818 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:12] Decode batch. #running-req: 22, #token: 93285, token usage: 0.38, cuda graph: True, gen throughput (token/s): 638.55, #queue-req: 0\n",
      "[2025-08-13 21:31:12] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 467, token usage: 0.38, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:31:13] INFO:     127.0.0.1:43728 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:14] Decode batch. #running-req: 22, #token: 92350, token usage: 0.38, cuda graph: True, gen throughput (token/s): 566.98, #queue-req: 0\n",
      "[2025-08-13 21:31:14] INFO:     127.0.0.1:45822 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:14] INFO:     127.0.0.1:49430 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:15] Decode batch. #running-req: 20, #token: 85239, token usage: 0.35, cuda graph: True, gen throughput (token/s): 613.10, #queue-req: 0\n",
      "[2025-08-13 21:31:15] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 451, token usage: 0.35, #running-req: 20, #queue-req: 0\n",
      "[2025-08-13 21:31:16] INFO:     127.0.0.1:52632 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:16] Decode batch. #running-req: 20, #token: 83701, token usage: 0.34, cuda graph: True, gen throughput (token/s): 529.43, #queue-req: 0\n",
      "[2025-08-13 21:31:17] Prefill batch. #new-seq: 1, #new-token: 7353, #cached-token: 466, token usage: 0.34, #running-req: 20, #queue-req: 0\n",
      "[2025-08-13 21:31:17] Prefill batch. #new-seq: 2, #new-token: 4714, #cached-token: 889, token usage: 0.37, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:31:19] Decode batch. #running-req: 23, #token: 96664, token usage: 0.39, cuda graph: True, gen throughput (token/s): 357.77, #queue-req: 0\n",
      "[2025-08-13 21:31:20] INFO:     127.0.0.1:43698 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:20] INFO:     127.0.0.1:43714 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:20] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 10999, token usage: 0.40, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:31:20] Decode batch. #running-req: 23, #token: 97622, token usage: 0.40, cuda graph: True, gen throughput (token/s): 633.43, #queue-req: 0\n",
      "[2025-08-13 21:31:21] INFO:     127.0.0.1:47096 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:22] Decode batch. #running-req: 22, #token: 82381, token usage: 0.34, cuda graph: True, gen throughput (token/s): 646.34, #queue-req: 0\n",
      "[2025-08-13 21:31:22] INFO:     127.0.0.1:52638 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:23] Prefill batch. #new-seq: 2, #new-token: 7264, #cached-token: 917, token usage: 0.34, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:31:24] Decode batch. #running-req: 23, #token: 90508, token usage: 0.37, cuda graph: True, gen throughput (token/s): 429.52, #queue-req: 0\n",
      "[2025-08-13 21:31:25] INFO:     127.0.0.1:43698 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:25] INFO:     127.0.0.1:43714 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:25] Decode batch. #running-req: 21, #token: 81024, token usage: 0.33, cuda graph: True, gen throughput (token/s): 667.49, #queue-req: 0\n",
      "[2025-08-13 21:31:26] INFO:     127.0.0.1:37476 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:26] INFO:     127.0.0.1:37482 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:26] Decode batch. #running-req: 19, #token: 75245, token usage: 0.31, cuda graph: True, gen throughput (token/s): 637.63, #queue-req: 0\n",
      "[2025-08-13 21:31:27] Prefill batch. #new-seq: 3, #new-token: 7527, #cached-token: 7895, token usage: 0.33, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:31:27] Prefill batch. #new-seq: 1, #new-token: 4382, #cached-token: 448, token usage: 0.36, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:31:28] INFO:     127.0.0.1:37482 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:29] Decode batch. #running-req: 22, #token: 90321, token usage: 0.37, cuda graph: True, gen throughput (token/s): 344.31, #queue-req: 0\n",
      "[2025-08-13 21:31:29] Prefill batch. #new-seq: 1, #new-token: 2338, #cached-token: 463, token usage: 0.37, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:31:30] Decode batch. #running-req: 23, #token: 93564, token usage: 0.38, cuda graph: True, gen throughput (token/s): 568.12, #queue-req: 0\n",
      "[2025-08-13 21:31:32] Decode batch. #running-req: 23, #token: 94484, token usage: 0.38, cuda graph: True, gen throughput (token/s): 658.27, #queue-req: 0\n",
      "[2025-08-13 21:31:33] INFO:     127.0.0.1:37476 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:33] Decode batch. #running-req: 22, #token: 92891, token usage: 0.38, cuda graph: True, gen throughput (token/s): 646.49, #queue-req: 0\n",
      "[2025-08-13 21:31:33] Prefill batch. #new-seq: 1, #new-token: 5457, #cached-token: 481, token usage: 0.38, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:31:35] Decode batch. #running-req: 23, #token: 99264, token usage: 0.40, cuda graph: True, gen throughput (token/s): 467.99, #queue-req: 0\n",
      "[2025-08-13 21:31:37] Decode batch. #running-req: 23, #token: 100184, token usage: 0.41, cuda graph: True, gen throughput (token/s): 631.01, #queue-req: 0\n",
      "[2025-08-13 21:31:38] Decode batch. #running-req: 23, #token: 101104, token usage: 0.41, cuda graph: True, gen throughput (token/s): 628.74, #queue-req: 0\n",
      "[2025-08-13 21:31:40] Decode batch. #running-req: 23, #token: 102024, token usage: 0.41, cuda graph: True, gen throughput (token/s): 627.79, #queue-req: 0\n",
      "[2025-08-13 21:31:40] INFO:     127.0.0.1:49450 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:31:40] INFO:     127.0.0.1:39876 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:41] Decode batch. #running-req: 21, #token: 87799, token usage: 0.36, cuda graph: True, gen throughput (token/s): 630.53, #queue-req: 0\n",
      "[2025-08-13 21:31:41] Prefill batch. #new-seq: 1, #new-token: 2361, #cached-token: 441, token usage: 0.36, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:31:43] Decode batch. #running-req: 22, #token: 91025, token usage: 0.37, cuda graph: True, gen throughput (token/s): 546.35, #queue-req: 0\n",
      "[2025-08-13 21:31:44] Decode batch. #running-req: 22, #token: 91905, token usage: 0.37, cuda graph: True, gen throughput (token/s): 637.07, #queue-req: 0\n",
      "[2025-08-13 21:31:45] INFO:     127.0.0.1:49406 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:45] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 5592, token usage: 0.38, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:31:45] Decode batch. #running-req: 22, #token: 92804, token usage: 0.38, cuda graph: True, gen throughput (token/s): 624.87, #queue-req: 0\n",
      "[2025-08-13 21:31:46] INFO:     127.0.0.1:34680 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:46] INFO:     127.0.0.1:49406 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:47] Decode batch. #running-req: 20, #token: 84767, token usage: 0.34, cuda graph: True, gen throughput (token/s): 612.92, #queue-req: 0\n",
      "[2025-08-13 21:31:47] INFO:     127.0.0.1:57474 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:47] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 465, token usage: 0.32, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:31:48] Decode batch. #running-req: 20, #token: 78202, token usage: 0.32, cuda graph: True, gen throughput (token/s): 601.24, #queue-req: 0\n",
      "[2025-08-13 21:31:48] Prefill batch. #new-seq: 2, #new-token: 3720, #cached-token: 909, token usage: 0.32, #running-req: 20, #queue-req: 0\n",
      "[2025-08-13 21:31:50] INFO:     127.0.0.1:52616 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:50] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4800, token usage: 0.34, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:31:50] Decode batch. #running-req: 21, #token: 82781, token usage: 0.34, cuda graph: True, gen throughput (token/s): 521.73, #queue-req: 0\n",
      "[2025-08-13 21:31:51] Decode batch. #running-req: 22, #token: 83683, token usage: 0.34, cuda graph: True, gen throughput (token/s): 674.71, #queue-req: 0\n",
      "[2025-08-13 21:31:52] INFO:     127.0.0.1:57468 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:52] Decode batch. #running-req: 21, #token: 83290, token usage: 0.34, cuda graph: True, gen throughput (token/s): 664.14, #queue-req: 0\n",
      "[2025-08-13 21:31:53] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.34, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:31:53] Prefill batch. #new-seq: 1, #new-token: 2047, #cached-token: 0, token usage: 0.37, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:31:55] Decode batch. #running-req: 22, #token: 94551, token usage: 0.38, cuda graph: True, gen throughput (token/s): 353.44, #queue-req: 0\n",
      "[2025-08-13 21:31:55] INFO:     127.0.0.1:52616 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:31:56] Prefill batch. #new-seq: 1, #new-token: 2172, #cached-token: 461, token usage: 0.37, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:31:56] Decode batch. #running-req: 22, #token: 93129, token usage: 0.38, cuda graph: True, gen throughput (token/s): 546.39, #queue-req: 0\n",
      "[2025-08-13 21:31:58] Decode batch. #running-req: 22, #token: 94009, token usage: 0.38, cuda graph: True, gen throughput (token/s): 635.99, #queue-req: 0\n",
      "[2025-08-13 21:31:59] Decode batch. #running-req: 22, #token: 90917, token usage: 0.37, cuda graph: True, gen throughput (token/s): 630.96, #queue-req: 0\n",
      "[2025-08-13 21:31:59] INFO:     127.0.0.1:39914 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:00] Prefill batch. #new-seq: 1, #new-token: 1639, #cached-token: 467, token usage: 0.33, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:32:00] INFO:     127.0.0.1:47110 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:00] INFO:     127.0.0.1:47126 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:00] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 10848, token usage: 0.38, #running-req: 22, #queue-req: 0\n",
      "[2025-08-13 21:32:01] Decode batch. #running-req: 22, #token: 93450, token usage: 0.38, cuda graph: True, gen throughput (token/s): 551.40, #queue-req: 0\n",
      "[2025-08-13 21:32:02] Decode batch. #running-req: 22, #token: 94330, token usage: 0.38, cuda graph: True, gen throughput (token/s): 630.66, #queue-req: 0\n",
      "[2025-08-13 21:32:03] Decode batch. #running-req: 22, #token: 95210, token usage: 0.39, cuda graph: True, gen throughput (token/s): 626.30, #queue-req: 0\n",
      "[2025-08-13 21:32:04] INFO:     127.0.0.1:47126 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:04] INFO:     127.0.0.1:47110 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:05] INFO:     127.0.0.1:46958 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:05] Decode batch. #running-req: 19, #token: 85301, token usage: 0.35, cuda graph: True, gen throughput (token/s): 616.00, #queue-req: 0\n",
      "[2025-08-13 21:32:06] Decode batch. #running-req: 19, #token: 86061, token usage: 0.35, cuda graph: True, gen throughput (token/s): 571.64, #queue-req: 0\n",
      "[2025-08-13 21:32:07] Prefill batch. #new-seq: 1, #new-token: 2464, #cached-token: 437, token usage: 0.35, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:32:07] Prefill batch. #new-seq: 2, #new-token: 4029, #cached-token: 919, token usage: 0.36, #running-req: 20, #queue-req: 0\n",
      "[2025-08-13 21:32:08] Decode batch. #running-req: 22, #token: 93419, token usage: 0.38, cuda graph: True, gen throughput (token/s): 409.15, #queue-req: 0\n",
      "[2025-08-13 21:32:08] INFO:     127.0.0.1:39890 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:08] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2595, token usage: 0.38, #running-req: 21, #queue-req: 0\n",
      "[2025-08-13 21:32:09] INFO:     127.0.0.1:48270 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:32:09] INFO:     127.0.0.1:39906 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:09] Decode batch. #running-req: 20, #token: 84194, token usage: 0.34, cuda graph: True, gen throughput (token/s): 611.76, #queue-req: 0\n",
      "[2025-08-13 21:32:10] Prefill batch. #new-seq: 1, #new-token: 2242, #cached-token: 446, token usage: 0.34, #running-req: 20, #queue-req: 0\n",
      "[2025-08-13 21:32:11] Decode batch. #running-req: 21, #token: 87254, token usage: 0.35, cuda graph: True, gen throughput (token/s): 533.06, #queue-req: 0\n",
      "[2025-08-13 21:32:12] Decode batch. #running-req: 21, #token: 88094, token usage: 0.36, cuda graph: True, gen throughput (token/s): 628.26, #queue-req: 0\n",
      "[2025-08-13 21:32:13] INFO:     127.0.0.1:39890 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:14] Decode batch. #running-req: 20, #token: 86581, token usage: 0.35, cuda graph: True, gen throughput (token/s): 607.98, #queue-req: 0\n",
      "[2025-08-13 21:32:14] Prefill batch. #new-seq: 1, #new-token: 2354, #cached-token: 439, token usage: 0.35, #running-req: 20, #queue-req: 0\n",
      "[2025-08-13 21:32:15] Decode batch. #running-req: 21, #token: 85911, token usage: 0.35, cuda graph: True, gen throughput (token/s): 533.05, #queue-req: 0\n",
      "[2025-08-13 21:32:15] INFO:     127.0.0.1:34684 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:15] INFO:     127.0.0.1:45912 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:17] Decode batch. #running-req: 19, #token: 84583, token usage: 0.34, cuda graph: True, gen throughput (token/s): 577.41, #queue-req: 0\n",
      "[2025-08-13 21:32:17] Prefill batch. #new-seq: 2, #new-token: 8155, #cached-token: 925, token usage: 0.35, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:32:19] Decode batch. #running-req: 21, #token: 93646, token usage: 0.38, cuda graph: True, gen throughput (token/s): 387.41, #queue-req: 0\n",
      "[2025-08-13 21:32:20] INFO:     127.0.0.1:48264 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:20] Decode batch. #running-req: 21, #token: 90249, token usage: 0.37, cuda graph: True, gen throughput (token/s): 595.08, #queue-req: 0\n",
      "[2025-08-13 21:32:20] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4681, token usage: 0.38, #running-req: 20, #queue-req: 0\n",
      "[2025-08-13 21:32:21] INFO:     127.0.0.1:34694 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:21] Decode batch. #running-req: 20, #token: 91270, token usage: 0.37, cuda graph: True, gen throughput (token/s): 576.31, #queue-req: 0\n",
      "[2025-08-13 21:32:21] Prefill batch. #new-seq: 1, #new-token: 195, #cached-token: 462, token usage: 0.37, #running-req: 20, #queue-req: 0\n",
      "[2025-08-13 21:32:23] INFO:     127.0.0.1:57490 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:23] Decode batch. #running-req: 20, #token: 86456, token usage: 0.35, cuda graph: True, gen throughput (token/s): 590.61, #queue-req: 0\n",
      "[2025-08-13 21:32:24] Prefill batch. #new-seq: 1, #new-token: 5873, #cached-token: 625, token usage: 0.35, #running-req: 20, #queue-req: 0\n",
      "[2025-08-13 21:32:25] Decode batch. #running-req: 21, #token: 93308, token usage: 0.38, cuda graph: True, gen throughput (token/s): 424.80, #queue-req: 0\n",
      "[2025-08-13 21:32:25] INFO:     127.0.0.1:48264 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:32:26] Decode batch. #running-req: 20, #token: 89733, token usage: 0.36, cuda graph: True, gen throughput (token/s): 591.96, #queue-req: 0\n",
      "[2025-08-13 21:32:28] Decode batch. #running-req: 20, #token: 90533, token usage: 0.37, cuda graph: True, gen throughput (token/s): 586.71, #queue-req: 0\n",
      "[2025-08-13 21:32:29] Decode batch. #running-req: 20, #token: 91333, token usage: 0.37, cuda graph: True, gen throughput (token/s): 582.69, #queue-req: 0\n",
      "[2025-08-13 21:32:30] Decode batch. #running-req: 20, #token: 92133, token usage: 0.37, cuda graph: True, gen throughput (token/s): 580.09, #queue-req: 0\n",
      "[2025-08-13 21:32:32] Decode batch. #running-req: 20, #token: 92933, token usage: 0.38, cuda graph: True, gen throughput (token/s): 576.45, #queue-req: 0\n",
      "[2025-08-13 21:32:33] INFO:     127.0.0.1:35676 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:33] Decode batch. #running-req: 19, #token: 91198, token usage: 0.37, cuda graph: True, gen throughput (token/s): 568.23, #queue-req: 0\n",
      "[2025-08-13 21:32:33] INFO:     127.0.0.1:34702 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:33] INFO:     127.0.0.1:34712 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:33] INFO:     127.0.0.1:34724 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:34] Prefill batch. #new-seq: 2, #new-token: 41, #cached-token: 14618, token usage: 0.35, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:32:34] INFO:     127.0.0.1:34702 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:34] Decode batch. #running-req: 17, #token: 78215, token usage: 0.32, cuda graph: True, gen throughput (token/s): 527.19, #queue-req: 0\n",
      "[2025-08-13 21:32:35] Prefill batch. #new-seq: 2, #new-token: 5271, #cached-token: 1085, token usage: 0.32, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:32:35] Prefill batch. #new-seq: 1, #new-token: 2354, #cached-token: 447, token usage: 0.34, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:32:36] Decode batch. #running-req: 20, #token: 86564, token usage: 0.35, cuda graph: True, gen throughput (token/s): 365.35, #queue-req: 0\n",
      "[2025-08-13 21:32:38] Decode batch. #running-req: 20, #token: 87364, token usage: 0.36, cuda graph: True, gen throughput (token/s): 596.34, #queue-req: 0\n",
      "[2025-08-13 21:32:38] INFO:     127.0.0.1:34712 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:39] Decode batch. #running-req: 19, #token: 83644, token usage: 0.34, cuda graph: True, gen throughput (token/s): 586.54, #queue-req: 0\n",
      "[2025-08-13 21:32:39] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 466, token usage: 0.34, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:32:41] Decode batch. #running-req: 20, #token: 86678, token usage: 0.35, cuda graph: True, gen throughput (token/s): 516.43, #queue-req: 0\n",
      "[2025-08-13 21:32:42] Decode batch. #running-req: 20, #token: 87478, token usage: 0.36, cuda graph: True, gen throughput (token/s): 594.18, #queue-req: 0\n",
      "[2025-08-13 21:32:42] INFO:     127.0.0.1:57480 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:42] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 9966, token usage: 0.36, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:32:43] INFO:     127.0.0.1:46950 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:43] Decode batch. #running-req: 19, #token: 84270, token usage: 0.34, cuda graph: True, gen throughput (token/s): 576.93, #queue-req: 0\n",
      "[2025-08-13 21:32:44] Prefill batch. #new-seq: 1, #new-token: 1663, #cached-token: 474, token usage: 0.34, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:32:44] INFO:     127.0.0.1:35154 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:44] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4800, token usage: 0.35, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:32:44] INFO:     127.0.0.1:46766 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:45] INFO:     127.0.0.1:46738 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:45] Decode batch. #running-req: 18, #token: 76990, token usage: 0.31, cuda graph: True, gen throughput (token/s): 518.53, #queue-req: 0\n",
      "[2025-08-13 21:32:46] Prefill batch. #new-seq: 2, #new-token: 391, #cached-token: 905, token usage: 0.32, #running-req: 18, #queue-req: 0\n",
      "[2025-08-13 21:32:46] Decode batch. #running-req: 20, #token: 78153, token usage: 0.32, cuda graph: True, gen throughput (token/s): 553.17, #queue-req: 0\n",
      "[2025-08-13 21:32:46] INFO:     127.0.0.1:45928 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:47] INFO:     127.0.0.1:57480 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:47] Decode batch. #running-req: 18, #token: 57461, token usage: 0.23, cuda graph: True, gen throughput (token/s): 649.35, #queue-req: 0\n",
      "[2025-08-13 21:32:47] INFO:     127.0.0.1:35164 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:47] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 7937, token usage: 0.23, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:32:48] INFO:     127.0.0.1:35154 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:48] INFO:     127.0.0.1:35164 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:48] Decode batch. #running-req: 16, #token: 46082, token usage: 0.19, cuda graph: True, gen throughput (token/s): 641.60, #queue-req: 0\n",
      "[2025-08-13 21:32:48] Prefill batch. #new-seq: 1, #new-token: 965, #cached-token: 449, token usage: 0.19, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:32:49] Decode batch. #running-req: 17, #token: 47721, token usage: 0.19, cuda graph: True, gen throughput (token/s): 616.85, #queue-req: 0\n",
      "[2025-08-13 21:32:50] Prefill batch. #new-seq: 2, #new-token: 6736, #cached-token: 894, token usage: 0.20, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:32:50] Prefill batch. #new-seq: 1, #new-token: 2165, #cached-token: 468, token usage: 0.22, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:32:51] Decode batch. #running-req: 20, #token: 57414, token usage: 0.23, cuda graph: True, gen throughput (token/s): 394.08, #queue-req: 0\n",
      "[2025-08-13 21:32:52] Decode batch. #running-req: 20, #token: 58214, token usage: 0.24, cuda graph: True, gen throughput (token/s): 739.31, #queue-req: 0\n",
      "[2025-08-13 21:32:53] Decode batch. #running-req: 20, #token: 59014, token usage: 0.24, cuda graph: True, gen throughput (token/s): 734.39, #queue-req: 0\n",
      "[2025-08-13 21:32:54] INFO:     127.0.0.1:35684 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:54] Decode batch. #running-req: 19, #token: 56019, token usage: 0.23, cuda graph: True, gen throughput (token/s): 723.30, #queue-req: 0\n",
      "[2025-08-13 21:32:55] Prefill batch. #new-seq: 1, #new-token: 7663, #cached-token: 554, token usage: 0.23, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:32:56] Decode batch. #running-req: 20, #token: 64597, token usage: 0.26, cuda graph: True, gen throughput (token/s): 415.61, #queue-req: 0\n",
      "[2025-08-13 21:32:56] INFO:     127.0.0.1:50896 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:32:57] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 470, token usage: 0.26, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:32:58] Decode batch. #running-req: 20, #token: 65185, token usage: 0.27, cuda graph: True, gen throughput (token/s): 647.64, #queue-req: 0\n",
      "[2025-08-13 21:32:59] Decode batch. #running-req: 20, #token: 65985, token usage: 0.27, cuda graph: True, gen throughput (token/s): 696.37, #queue-req: 0\n",
      "[2025-08-13 21:33:00] Decode batch. #running-req: 20, #token: 66785, token usage: 0.27, cuda graph: True, gen throughput (token/s): 691.83, #queue-req: 0\n",
      "[2025-08-13 21:33:00] INFO:     127.0.0.1:45896 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:00] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.27, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:33:01] Decode batch. #running-req: 20, #token: 67604, token usage: 0.27, cuda graph: True, gen throughput (token/s): 672.35, #queue-req: 0\n",
      "[2025-08-13 21:33:02] Decode batch. #running-req: 20, #token: 68404, token usage: 0.28, cuda graph: True, gen throughput (token/s): 683.24, #queue-req: 0\n",
      "[2025-08-13 21:33:03] Decode batch. #running-req: 20, #token: 69204, token usage: 0.28, cuda graph: True, gen throughput (token/s): 679.97, #queue-req: 0\n",
      "[2025-08-13 21:33:04] INFO:     127.0.0.1:45896 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:05] Decode batch. #running-req: 19, #token: 65485, token usage: 0.27, cuda graph: True, gen throughput (token/s): 666.67, #queue-req: 0\n",
      "[2025-08-13 21:33:05] Prefill batch. #new-seq: 1, #new-token: 3340, #cached-token: 412, token usage: 0.27, #running-req: 19, #queue-req: 0\n",
      "[2025-08-13 21:33:05] INFO:     127.0.0.1:52638 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:06] INFO:     127.0.0.1:45936 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:06] Decode batch. #running-req: 18, #token: 60572, token usage: 0.25, cuda graph: True, gen throughput (token/s): 519.53, #queue-req: 0\n",
      "[2025-08-13 21:33:06] Prefill batch. #new-seq: 2, #new-token: 7587, #cached-token: 5113, token usage: 0.26, #running-req: 18, #queue-req: 0\n",
      "[2025-08-13 21:33:07] INFO:     127.0.0.1:50886 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:33:08] Decode batch. #running-req: 19, #token: 72159, token usage: 0.29, cuda graph: True, gen throughput (token/s): 395.18, #queue-req: 0\n",
      "[2025-08-13 21:33:09] INFO:     127.0.0.1:52626 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:09] Decode batch. #running-req: 18, #token: 71320, token usage: 0.29, cuda graph: True, gen throughput (token/s): 618.73, #queue-req: 0\n",
      "[2025-08-13 21:33:10] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.29, #running-req: 18, #queue-req: 0\n",
      "[2025-08-13 21:33:10] Prefill batch. #new-seq: 1, #new-token: 1569, #cached-token: 0, token usage: 0.32, #running-req: 18, #queue-req: 0\n",
      "[2025-08-13 21:33:11] INFO:     127.0.0.1:45936 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:11] Decode batch. #running-req: 18, #token: 77525, token usage: 0.32, cuda graph: True, gen throughput (token/s): 321.21, #queue-req: 0\n",
      "[2025-08-13 21:33:12] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 451, token usage: 0.32, #running-req: 18, #queue-req: 0\n",
      "[2025-08-13 21:33:13] Decode batch. #running-req: 19, #token: 80622, token usage: 0.33, cuda graph: True, gen throughput (token/s): 497.29, #queue-req: 0\n",
      "[2025-08-13 21:33:13] INFO:     127.0.0.1:60756 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:14] Decode batch. #running-req: 18, #token: 73817, token usage: 0.30, cuda graph: True, gen throughput (token/s): 587.83, #queue-req: 0\n",
      "[2025-08-13 21:33:14] Prefill batch. #new-seq: 1, #new-token: 418, #cached-token: 438, token usage: 0.30, #running-req: 18, #queue-req: 0\n",
      "[2025-08-13 21:33:15] Decode batch. #running-req: 19, #token: 74987, token usage: 0.31, cuda graph: True, gen throughput (token/s): 586.99, #queue-req: 0\n",
      "[2025-08-13 21:33:16] INFO:     127.0.0.1:50858 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:17] Decode batch. #running-req: 18, #token: 72413, token usage: 0.29, cuda graph: True, gen throughput (token/s): 606.27, #queue-req: 0\n",
      "[2025-08-13 21:33:17] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 450, token usage: 0.30, #running-req: 18, #queue-req: 0\n",
      "[2025-08-13 21:33:18] INFO:     127.0.0.1:46704 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:18] INFO:     127.0.0.1:46718 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:18] Prefill batch. #new-seq: 2, #new-token: 42, #cached-token: 8946, token usage: 0.31, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:33:18] Decode batch. #running-req: 19, #token: 75545, token usage: 0.31, cuda graph: True, gen throughput (token/s): 501.41, #queue-req: 0\n",
      "[2025-08-13 21:33:18] INFO:     127.0.0.1:46704 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:19] Prefill batch. #new-seq: 1, #new-token: 2359, #cached-token: 443, token usage: 0.29, #running-req: 18, #queue-req: 0\n",
      "[2025-08-13 21:33:20] Decode batch. #running-req: 19, #token: 72996, token usage: 0.30, cuda graph: True, gen throughput (token/s): 515.01, #queue-req: 0\n",
      "[2025-08-13 21:33:20] INFO:     127.0.0.1:46728 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:20] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4687, token usage: 0.30, #running-req: 18, #queue-req: 0\n",
      "[2025-08-13 21:33:21] Decode batch. #running-req: 19, #token: 73775, token usage: 0.30, cuda graph: True, gen throughput (token/s): 605.37, #queue-req: 0\n",
      "[2025-08-13 21:33:22] INFO:     127.0.0.1:46718 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:22] Decode batch. #running-req: 18, #token: 72105, token usage: 0.29, cuda graph: True, gen throughput (token/s): 619.81, #queue-req: 0\n",
      "[2025-08-13 21:33:23] Prefill batch. #new-seq: 1, #new-token: 2162, #cached-token: 471, token usage: 0.30, #running-req: 18, #queue-req: 0\n",
      "[2025-08-13 21:33:23] Decode batch. #running-req: 19, #token: 75078, token usage: 0.31, cuda graph: True, gen throughput (token/s): 516.04, #queue-req: 0\n",
      "[2025-08-13 21:33:24] INFO:     127.0.0.1:46728 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:33:25] Decode batch. #running-req: 18, #token: 71443, token usage: 0.29, cuda graph: True, gen throughput (token/s): 610.55, #queue-req: 0\n",
      "[2025-08-13 21:33:25] INFO:     127.0.0.1:34656 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:26] Decode batch. #running-req: 17, #token: 64039, token usage: 0.26, cuda graph: True, gen throughput (token/s): 594.60, #queue-req: 0\n",
      "[2025-08-13 21:33:26] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 439, token usage: 0.26, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:33:26] INFO:     127.0.0.1:46750 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:26] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.26, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:33:27] Decode batch. #running-req: 18, #token: 65032, token usage: 0.26, cuda graph: True, gen throughput (token/s): 589.53, #queue-req: 0\n",
      "[2025-08-13 21:33:28] Decode batch. #running-req: 18, #token: 65752, token usage: 0.27, cuda graph: True, gen throughput (token/s): 623.66, #queue-req: 0\n",
      "[2025-08-13 21:33:29] Decode batch. #running-req: 18, #token: 64277, token usage: 0.26, cuda graph: True, gen throughput (token/s): 620.16, #queue-req: 0\n",
      "[2025-08-13 21:33:29] INFO:     127.0.0.1:60742 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:29] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2656, token usage: 0.27, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:33:30] INFO:     127.0.0.1:46750 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:31] Decode batch. #running-req: 17, #token: 62683, token usage: 0.25, cuda graph: True, gen throughput (token/s): 596.12, #queue-req: 0\n",
      "[2025-08-13 21:33:31] Prefill batch. #new-seq: 1, #new-token: 2162, #cached-token: 470, token usage: 0.26, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:33:32] Decode batch. #running-req: 18, #token: 65558, token usage: 0.27, cuda graph: True, gen throughput (token/s): 531.27, #queue-req: 0\n",
      "[2025-08-13 21:33:33] INFO:     127.0.0.1:35900 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:33] Decode batch. #running-req: 17, #token: 55816, token usage: 0.23, cuda graph: True, gen throughput (token/s): 626.11, #queue-req: 0\n",
      "[2025-08-13 21:33:33] INFO:     127.0.0.1:60742 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:34] Decode batch. #running-req: 16, #token: 54122, token usage: 0.22, cuda graph: True, gen throughput (token/s): 612.02, #queue-req: 0\n",
      "[2025-08-13 21:33:35] Prefill batch. #new-seq: 2, #new-token: 2755, #cached-token: 875, token usage: 0.22, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:33:35] Decode batch. #running-req: 18, #token: 57539, token usage: 0.23, cuda graph: True, gen throughput (token/s): 504.20, #queue-req: 0\n",
      "[2025-08-13 21:33:37] Decode batch. #running-req: 18, #token: 58259, token usage: 0.24, cuda graph: True, gen throughput (token/s): 656.70, #queue-req: 0\n",
      "[2025-08-13 21:33:38] Decode batch. #running-req: 18, #token: 58979, token usage: 0.24, cuda graph: True, gen throughput (token/s): 655.71, #queue-req: 0\n",
      "[2025-08-13 21:33:39] Decode batch. #running-req: 18, #token: 59699, token usage: 0.24, cuda graph: True, gen throughput (token/s): 654.98, #queue-req: 0\n",
      "[2025-08-13 21:33:40] Decode batch. #running-req: 18, #token: 60419, token usage: 0.25, cuda graph: True, gen throughput (token/s): 651.54, #queue-req: 0\n",
      "[2025-08-13 21:33:41] INFO:     127.0.0.1:41832 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:41] INFO:     127.0.0.1:41848 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:41] INFO:     127.0.0.1:41854 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:41] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4800, token usage: 0.21, #running-req: 15, #queue-req: 0\n",
      "[2025-08-13 21:33:41] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 6081, token usage: 0.23, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:33:41] Decode batch. #running-req: 17, #token: 57337, token usage: 0.23, cuda graph: True, gen throughput (token/s): 608.65, #queue-req: 0\n",
      "[2025-08-13 21:33:41] INFO:     127.0.0.1:41848 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:42] Decode batch. #running-req: 16, #token: 52257, token usage: 0.21, cuda graph: True, gen throughput (token/s): 619.63, #queue-req: 0\n",
      "[2025-08-13 21:33:42] Prefill batch. #new-seq: 2, #new-token: 4225, #cached-token: 916, token usage: 0.21, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:33:43] Decode batch. #running-req: 18, #token: 57259, token usage: 0.23, cuda graph: True, gen throughput (token/s): 485.40, #queue-req: 0\n",
      "[2025-08-13 21:33:44] INFO:     127.0.0.1:41854 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:45] Decode batch. #running-req: 17, #token: 53474, token usage: 0.22, cuda graph: True, gen throughput (token/s): 663.37, #queue-req: 0\n",
      "[2025-08-13 21:33:45] INFO:     127.0.0.1:52666 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:46] Decode batch. #running-req: 16, #token: 44776, token usage: 0.18, cuda graph: True, gen throughput (token/s): 658.94, #queue-req: 0\n",
      "[2025-08-13 21:33:46] Prefill batch. #new-seq: 2, #new-token: 7941, #cached-token: 905, token usage: 0.18, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:33:47] Decode batch. #running-req: 18, #token: 53436, token usage: 0.22, cuda graph: True, gen throughput (token/s): 376.59, #queue-req: 0\n",
      "[2025-08-13 21:33:47] INFO:     127.0.0.1:59102 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:48] INFO:     127.0.0.1:50872 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:48] Decode batch. #running-req: 16, #token: 47648, token usage: 0.19, cuda graph: True, gen throughput (token/s): 648.79, #queue-req: 0\n",
      "[2025-08-13 21:33:48] Prefill batch. #new-seq: 2, #new-token: 2370, #cached-token: 4586, token usage: 0.21, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:33:49] INFO:     127.0.0.1:50872 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:50] Decode batch. #running-req: 17, #token: 50674, token usage: 0.21, cuda graph: True, gen throughput (token/s): 551.64, #queue-req: 0\n",
      "[2025-08-13 21:33:50] Prefill batch. #new-seq: 1, #new-token: 1856, #cached-token: 449, token usage: 0.21, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:33:51] Decode batch. #running-req: 18, #token: 53233, token usage: 0.22, cuda graph: True, gen throughput (token/s): 579.87, #queue-req: 0\n",
      "[2025-08-13 21:33:52] Decode batch. #running-req: 18, #token: 53953, token usage: 0.22, cuda graph: True, gen throughput (token/s): 680.68, #queue-req: 0\n",
      "[2025-08-13 21:33:53] Decode batch. #running-req: 18, #token: 54673, token usage: 0.22, cuda graph: True, gen throughput (token/s): 677.53, #queue-req: 0\n",
      "[2025-08-13 21:33:54] INFO:     127.0.0.1:52644 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:54] INFO:     127.0.0.1:52656 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:54] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4799, token usage: 0.21, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:33:54] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4632, token usage: 0.22, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:33:54] Decode batch. #running-req: 18, #token: 55431, token usage: 0.23, cuda graph: True, gen throughput (token/s): 642.27, #queue-req: 0\n",
      "[2025-08-13 21:33:54] INFO:     127.0.0.1:52656 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:55] INFO:     127.0.0.1:35970 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:55] Decode batch. #running-req: 16, #token: 48507, token usage: 0.20, cuda graph: True, gen throughput (token/s): 654.66, #queue-req: 0\n",
      "[2025-08-13 21:33:56] Prefill batch. #new-seq: 1, #new-token: 2347, #cached-token: 454, token usage: 0.20, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:33:56] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 445, token usage: 0.21, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:33:56] Decode batch. #running-req: 18, #token: 53872, token usage: 0.22, cuda graph: True, gen throughput (token/s): 453.28, #queue-req: 0\n",
      "[2025-08-13 21:33:57] INFO:     127.0.0.1:51716 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:57] INFO:     127.0.0.1:52644 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:33:58] Decode batch. #running-req: 16, #token: 47483, token usage: 0.19, cuda graph: True, gen throughput (token/s): 670.67, #queue-req: 0\n",
      "[2025-08-13 21:33:59] Decode batch. #running-req: 16, #token: 48123, token usage: 0.20, cuda graph: True, gen throughput (token/s): 640.31, #queue-req: 0\n",
      "[2025-08-13 21:33:59] Prefill batch. #new-seq: 1, #new-token: 2202, #cached-token: 453, token usage: 0.20, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:33:59] Prefill batch. #new-seq: 1, #new-token: 5618, #cached-token: 481, token usage: 0.21, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:34:00] INFO:     127.0.0.1:34644 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:00] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2747, token usage: 0.23, #running-req: 17, #queue-req: 0\n",
      "[2025-08-13 21:34:00] Decode batch. #running-req: 18, #token: 56671, token usage: 0.23, cuda graph: True, gen throughput (token/s): 381.79, #queue-req: 0\n",
      "[2025-08-13 21:34:01] Decode batch. #running-req: 18, #token: 57391, token usage: 0.23, cuda graph: True, gen throughput (token/s): 661.89, #queue-req: 0\n",
      "[2025-08-13 21:34:03] Decode batch. #running-req: 18, #token: 58111, token usage: 0.24, cuda graph: True, gen throughput (token/s): 656.37, #queue-req: 0\n",
      "[2025-08-13 21:34:04] Decode batch. #running-req: 18, #token: 58831, token usage: 0.24, cuda graph: True, gen throughput (token/s): 653.88, #queue-req: 0\n",
      "[2025-08-13 21:34:04] INFO:     127.0.0.1:34644 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:34:05] Decode batch. #running-req: 17, #token: 57056, token usage: 0.23, cuda graph: True, gen throughput (token/s): 629.84, #queue-req: 0\n",
      "[2025-08-13 21:34:06] Decode batch. #running-req: 17, #token: 57736, token usage: 0.23, cuda graph: True, gen throughput (token/s): 624.69, #queue-req: 0\n",
      "[2025-08-13 21:34:07] Decode batch. #running-req: 17, #token: 58416, token usage: 0.24, cuda graph: True, gen throughput (token/s): 620.21, #queue-req: 0\n",
      "[2025-08-13 21:34:07] INFO:     127.0.0.1:34654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:07] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 5751, token usage: 0.24, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:34:08] INFO:     127.0.0.1:34654 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:08] Decode batch. #running-req: 16, #token: 53705, token usage: 0.22, cuda graph: True, gen throughput (token/s): 601.14, #queue-req: 0\n",
      "[2025-08-13 21:34:09] Prefill batch. #new-seq: 1, #new-token: 2349, #cached-token: 453, token usage: 0.22, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:34:09] Decode batch. #running-req: 17, #token: 56716, token usage: 0.23, cuda graph: True, gen throughput (token/s): 514.62, #queue-req: 0\n",
      "[2025-08-13 21:34:10] Decode batch. #running-req: 17, #token: 57396, token usage: 0.23, cuda graph: True, gen throughput (token/s): 624.55, #queue-req: 0\n",
      "[2025-08-13 21:34:11] Decode batch. #running-req: 17, #token: 58076, token usage: 0.24, cuda graph: True, gen throughput (token/s): 621.87, #queue-req: 0\n",
      "[2025-08-13 21:34:12] INFO:     127.0.0.1:35910 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:12] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4800, token usage: 0.24, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:34:13] Decode batch. #running-req: 17, #token: 58774, token usage: 0.24, cuda graph: True, gen throughput (token/s): 605.78, #queue-req: 0\n",
      "[2025-08-13 21:34:14] Decode batch. #running-req: 17, #token: 59454, token usage: 0.24, cuda graph: True, gen throughput (token/s): 618.97, #queue-req: 0\n",
      "[2025-08-13 21:34:14] INFO:     127.0.0.1:35916 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:14] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2855, token usage: 0.24, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:34:15] Decode batch. #running-req: 17, #token: 60152, token usage: 0.24, cuda graph: True, gen throughput (token/s): 599.02, #queue-req: 0\n",
      "[2025-08-13 21:34:16] INFO:     127.0.0.1:35910 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:16] Decode batch. #running-req: 16, #token: 56317, token usage: 0.23, cuda graph: True, gen throughput (token/s): 605.71, #queue-req: 0\n",
      "[2025-08-13 21:34:16] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 467, token usage: 0.23, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:34:17] INFO:     127.0.0.1:35948 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:17] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.24, #running-req: 16, #queue-req: 0\n",
      "[2025-08-13 21:34:17] Decode batch. #running-req: 17, #token: 59240, token usage: 0.24, cuda graph: True, gen throughput (token/s): 505.80, #queue-req: 0\n",
      "[2025-08-13 21:34:18] INFO:     127.0.0.1:35916 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:34:18] INFO:     127.0.0.1:35962 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:18] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4801, token usage: 0.23, #running-req: 15, #queue-req: 0\n",
      "[2025-08-13 21:34:18] Decode batch. #running-req: 16, #token: 57351, token usage: 0.23, cuda graph: True, gen throughput (token/s): 589.13, #queue-req: 0\n",
      "[2025-08-13 21:34:19] Decode batch. #running-req: 16, #token: 57991, token usage: 0.24, cuda graph: True, gen throughput (token/s): 589.83, #queue-req: 0\n",
      "[2025-08-13 21:34:20] INFO:     127.0.0.1:35948 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:20] Decode batch. #running-req: 15, #token: 54121, token usage: 0.22, cuda graph: True, gen throughput (token/s): 581.58, #queue-req: 0\n",
      "[2025-08-13 21:34:21] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 467, token usage: 0.22, #running-req: 15, #queue-req: 0\n",
      "[2025-08-13 21:34:22] Decode batch. #running-req: 16, #token: 56985, token usage: 0.23, cuda graph: True, gen throughput (token/s): 493.29, #queue-req: 0\n",
      "[2025-08-13 21:34:22] INFO:     127.0.0.1:35962 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:23] Prefill batch. #new-seq: 1, #new-token: 3907, #cached-token: 481, token usage: 0.22, #running-req: 15, #queue-req: 0\n",
      "[2025-08-13 21:34:23] Decode batch. #running-req: 16, #token: 57091, token usage: 0.23, cuda graph: True, gen throughput (token/s): 434.99, #queue-req: 0\n",
      "[2025-08-13 21:34:24] INFO:     127.0.0.1:59110 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:24] Decode batch. #running-req: 15, #token: 55703, token usage: 0.23, cuda graph: True, gen throughput (token/s): 592.89, #queue-req: 0\n",
      "[2025-08-13 21:34:24] INFO:     127.0.0.1:35984 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:25] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2695, token usage: 0.23, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:34:25] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.23, #running-req: 15, #queue-req: 0\n",
      "[2025-08-13 21:34:25] Prefill batch. #new-seq: 1, #new-token: 1733, #cached-token: 0, token usage: 0.26, #running-req: 15, #queue-req: 0\n",
      "[2025-08-13 21:34:26] Decode batch. #running-req: 16, #token: 66235, token usage: 0.27, cuda graph: True, gen throughput (token/s): 272.07, #queue-req: 0\n",
      "[2025-08-13 21:34:28] Decode batch. #running-req: 16, #token: 66875, token usage: 0.27, cuda graph: True, gen throughput (token/s): 551.12, #queue-req: 0\n",
      "[2025-08-13 21:34:29] Decode batch. #running-req: 16, #token: 67515, token usage: 0.27, cuda graph: True, gen throughput (token/s): 546.99, #queue-req: 0\n",
      "[2025-08-13 21:34:30] INFO:     127.0.0.1:35984 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:30] Decode batch. #running-req: 15, #token: 65745, token usage: 0.27, cuda graph: True, gen throughput (token/s): 542.58, #queue-req: 0\n",
      "[2025-08-13 21:34:30] INFO:     127.0.0.1:59114 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:30] INFO:     127.0.0.1:55668 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:31] INFO:     127.0.0.1:51724 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:31] Decode batch. #running-req: 12, #token: 55494, token usage: 0.23, cuda graph: True, gen throughput (token/s): 483.52, #queue-req: 0\n",
      "[2025-08-13 21:34:32] Decode batch. #running-req: 12, #token: 55974, token usage: 0.23, cuda graph: True, gen throughput (token/s): 451.89, #queue-req: 0\n",
      "[2025-08-13 21:34:33] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 481, token usage: 0.23, #running-req: 12, #queue-req: 2\n",
      "[2025-08-13 21:34:33] Prefill batch. #new-seq: 4, #new-token: 5994, #cached-token: 1543, token usage: 0.26, #running-req: 12, #queue-req: 0\n",
      "[2025-08-13 21:34:35] Decode batch. #running-req: 16, #token: 70793, token usage: 0.29, cuda graph: True, gen throughput (token/s): 200.09, #queue-req: 0\n",
      "[2025-08-13 21:34:36] Decode batch. #running-req: 16, #token: 71433, token usage: 0.29, cuda graph: True, gen throughput (token/s): 535.85, #queue-req: 0\n",
      "[2025-08-13 21:34:37] Decode batch. #running-req: 16, #token: 72073, token usage: 0.29, cuda graph: True, gen throughput (token/s): 533.05, #queue-req: 0\n",
      "[2025-08-13 21:34:38] Decode batch. #running-req: 16, #token: 72713, token usage: 0.30, cuda graph: True, gen throughput (token/s): 528.82, #queue-req: 0\n",
      "[2025-08-13 21:34:39] Decode batch. #running-req: 16, #token: 73353, token usage: 0.30, cuda graph: True, gen throughput (token/s): 527.42, #queue-req: 0\n",
      "[2025-08-13 21:34:41] INFO:     127.0.0.1:52564 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:41] Decode batch. #running-req: 16, #token: 63616, token usage: 0.26, cuda graph: True, gen throughput (token/s): 525.97, #queue-req: 0\n",
      "[2025-08-13 21:34:41] Prefill batch. #new-seq: 1, #new-token: 339, #cached-token: 443, token usage: 0.26, #running-req: 15, #queue-req: 0\n",
      "[2025-08-13 21:34:42] Decode batch. #running-req: 16, #token: 64570, token usage: 0.26, cuda graph: True, gen throughput (token/s): 518.97, #queue-req: 0\n",
      "[2025-08-13 21:34:43] Decode batch. #running-req: 16, #token: 65210, token usage: 0.27, cuda graph: True, gen throughput (token/s): 560.20, #queue-req: 0\n",
      "[2025-08-13 21:34:44] Decode batch. #running-req: 16, #token: 65850, token usage: 0.27, cuda graph: True, gen throughput (token/s): 556.71, #queue-req: 0\n",
      "[2025-08-13 21:34:45] INFO:     127.0.0.1:51732 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:45] Decode batch. #running-req: 15, #token: 57044, token usage: 0.23, cuda graph: True, gen throughput (token/s): 557.13, #queue-req: 0\n",
      "[2025-08-13 21:34:45] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.23, #running-req: 15, #queue-req: 0\n",
      "[2025-08-13 21:34:46] Decode batch. #running-req: 16, #token: 60027, token usage: 0.24, cuda graph: True, gen throughput (token/s): 480.32, #queue-req: 0\n",
      "[2025-08-13 21:34:47] INFO:     127.0.0.1:51744 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:47] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2866, token usage: 0.25, #running-req: 15, #queue-req: 0\n",
      "[2025-08-13 21:34:48] Decode batch. #running-req: 16, #token: 60686, token usage: 0.25, cuda graph: True, gen throughput (token/s): 562.19, #queue-req: 0\n",
      "[2025-08-13 21:34:49] Decode batch. #running-req: 16, #token: 61326, token usage: 0.25, cuda graph: True, gen throughput (token/s): 572.57, #queue-req: 0\n",
      "[2025-08-13 21:34:49] INFO:     127.0.0.1:41740 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:49] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4799, token usage: 0.25, #running-req: 15, #queue-req: 0\n",
      "[2025-08-13 21:34:50] INFO:     127.0.0.1:41768 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:34:50] Decode batch. #running-req: 15, #token: 57861, token usage: 0.24, cuda graph: True, gen throughput (token/s): 553.62, #queue-req: 0\n",
      "[2025-08-13 21:34:50] INFO:     127.0.0.1:41756 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:50] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4304, token usage: 0.24, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:34:51] INFO:     127.0.0.1:51744 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:51] Decode batch. #running-req: 14, #token: 55898, token usage: 0.23, cuda graph: True, gen throughput (token/s): 538.26, #queue-req: 0\n",
      "[2025-08-13 21:34:52] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.23, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:34:52] Prefill batch. #new-seq: 1, #new-token: 1563, #cached-token: 0, token usage: 0.26, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:34:53] Decode batch. #running-req: 15, #token: 66298, token usage: 0.27, cuda graph: True, gen throughput (token/s): 269.49, #queue-req: 0\n",
      "[2025-08-13 21:34:53] INFO:     127.0.0.1:41740 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:54] INFO:     127.0.0.1:42874 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:54] Decode batch. #running-req: 13, #token: 61483, token usage: 0.25, cuda graph: True, gen throughput (token/s): 495.52, #queue-req: 0\n",
      "[2025-08-13 21:34:55] INFO:     127.0.0.1:41756 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:55] Decode batch. #running-req: 12, #token: 57993, token usage: 0.24, cuda graph: True, gen throughput (token/s): 458.85, #queue-req: 0\n",
      "[2025-08-13 21:34:56] Prefill batch. #new-seq: 3, #new-token: 4629, #cached-token: 1374, token usage: 0.24, #running-req: 12, #queue-req: 0\n",
      "[2025-08-13 21:34:57] Decode batch. #running-req: 15, #token: 63218, token usage: 0.26, cuda graph: True, gen throughput (token/s): 355.96, #queue-req: 0\n",
      "[2025-08-13 21:34:57] INFO:     127.0.0.1:41396 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:58] INFO:     127.0.0.1:41764 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:34:58] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4800, token usage: 0.23, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 21:34:58] Prefill batch. #new-seq: 1, #new-token: 2350, #cached-token: 452, token usage: 0.23, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:34:58] Decode batch. #running-req: 15, #token: 58575, token usage: 0.24, cuda graph: True, gen throughput (token/s): 428.24, #queue-req: 0\n",
      "[2025-08-13 21:34:59] Decode batch. #running-req: 15, #token: 59175, token usage: 0.24, cuda graph: True, gen throughput (token/s): 549.39, #queue-req: 0\n",
      "[2025-08-13 21:35:00] Decode batch. #running-req: 15, #token: 59775, token usage: 0.24, cuda graph: True, gen throughput (token/s): 548.02, #queue-req: 0\n",
      "[2025-08-13 21:35:01] INFO:     127.0.0.1:41384 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:01] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4654, token usage: 0.24, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:01] Decode batch. #running-req: 15, #token: 60394, token usage: 0.25, cuda graph: True, gen throughput (token/s): 533.14, #queue-req: 0\n",
      "[2025-08-13 21:35:02] INFO:     127.0.0.1:41764 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:02] Prefill batch. #new-seq: 1, #new-token: 2165, #cached-token: 467, token usage: 0.23, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:03] Decode batch. #running-req: 15, #token: 58699, token usage: 0.24, cuda graph: True, gen throughput (token/s): 448.89, #queue-req: 0\n",
      "[2025-08-13 21:35:04] Decode batch. #running-req: 15, #token: 59299, token usage: 0.24, cuda graph: True, gen throughput (token/s): 549.25, #queue-req: 0\n",
      "[2025-08-13 21:35:04] INFO:     127.0.0.1:41384 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:05] Decode batch. #running-req: 14, #token: 55530, token usage: 0.23, cuda graph: True, gen throughput (token/s): 540.13, #queue-req: 0\n",
      "[2025-08-13 21:35:05] Prefill batch. #new-seq: 1, #new-token: 2167, #cached-token: 467, token usage: 0.23, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:06] Decode batch. #running-req: 15, #token: 58336, token usage: 0.24, cuda graph: True, gen throughput (token/s): 460.42, #queue-req: 0\n",
      "[2025-08-13 21:35:07] Decode batch. #running-req: 15, #token: 58936, token usage: 0.24, cuda graph: True, gen throughput (token/s): 551.71, #queue-req: 0\n",
      "[2025-08-13 21:35:08] Decode batch. #running-req: 15, #token: 59536, token usage: 0.24, cuda graph: True, gen throughput (token/s): 547.61, #queue-req: 0\n",
      "[2025-08-13 21:35:09] Decode batch. #running-req: 15, #token: 60136, token usage: 0.24, cuda graph: True, gen throughput (token/s): 542.58, #queue-req: 0\n",
      "[2025-08-13 21:35:10] INFO:     127.0.0.1:55654 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:10] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4801, token usage: 0.25, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:11] Decode batch. #running-req: 15, #token: 60754, token usage: 0.25, cuda graph: True, gen throughput (token/s): 524.96, #queue-req: 0\n",
      "[2025-08-13 21:35:12] Decode batch. #running-req: 15, #token: 61354, token usage: 0.25, cuda graph: True, gen throughput (token/s): 537.94, #queue-req: 0\n",
      "[2025-08-13 21:35:13] Decode batch. #running-req: 15, #token: 61954, token usage: 0.25, cuda graph: True, gen throughput (token/s): 535.83, #queue-req: 0\n",
      "[2025-08-13 21:35:14] INFO:     127.0.0.1:55654 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:14] Decode batch. #running-req: 14, #token: 58045, token usage: 0.24, cuda graph: True, gen throughput (token/s): 529.93, #queue-req: 0\n",
      "[2025-08-13 21:35:15] Prefill batch. #new-seq: 1, #new-token: 3496, #cached-token: 413, token usage: 0.24, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:15] Decode batch. #running-req: 15, #token: 62115, token usage: 0.25, cuda graph: True, gen throughput (token/s): 403.70, #queue-req: 0\n",
      "[2025-08-13 21:35:16] Decode batch. #running-req: 15, #token: 62715, token usage: 0.26, cuda graph: True, gen throughput (token/s): 534.97, #queue-req: 0\n",
      "[2025-08-13 21:35:18] Decode batch. #running-req: 15, #token: 63315, token usage: 0.26, cuda graph: True, gen throughput (token/s): 533.06, #queue-req: 0\n",
      "[2025-08-13 21:35:19] Decode batch. #running-req: 15, #token: 63915, token usage: 0.26, cuda graph: True, gen throughput (token/s): 528.17, #queue-req: 0\n",
      "[2025-08-13 21:35:20] Decode batch. #running-req: 15, #token: 64515, token usage: 0.26, cuda graph: True, gen throughput (token/s): 526.77, #queue-req: 0\n",
      "[2025-08-13 21:35:21] Decode batch. #running-req: 15, #token: 65115, token usage: 0.26, cuda graph: True, gen throughput (token/s): 525.22, #queue-req: 0\n",
      "[2025-08-13 21:35:21] INFO:     127.0.0.1:60250 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:22] Decode batch. #running-req: 14, #token: 64514, token usage: 0.26, cuda graph: True, gen throughput (token/s): 503.44, #queue-req: 0\n",
      "[2025-08-13 21:35:22] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 461, token usage: 0.26, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:23] INFO:     127.0.0.1:52536 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:23] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4633, token usage: 0.26, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:23] Decode batch. #running-req: 15, #token: 65247, token usage: 0.27, cuda graph: True, gen throughput (token/s): 502.62, #queue-req: 0\n",
      "[2025-08-13 21:35:24] INFO:     127.0.0.1:52550 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:24] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 6387, token usage: 0.27, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:24] Decode batch. #running-req: 15, #token: 65866, token usage: 0.27, cuda graph: True, gen throughput (token/s): 510.14, #queue-req: 0\n",
      "[2025-08-13 21:35:25] INFO:     127.0.0.1:52536 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:25] INFO:     127.0.0.1:52550 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:26] Decode batch. #running-req: 13, #token: 56298, token usage: 0.23, cuda graph: True, gen throughput (token/s): 496.31, #queue-req: 0\n",
      "[2025-08-13 21:35:26] Prefill batch. #new-seq: 1, #new-token: 2356, #cached-token: 446, token usage: 0.23, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 21:35:27] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 448, token usage: 0.24, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:27] Decode batch. #running-req: 15, #token: 61543, token usage: 0.25, cuda graph: True, gen throughput (token/s): 352.85, #queue-req: 0\n",
      "[2025-08-13 21:35:28] INFO:     127.0.0.1:60244 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:28] Decode batch. #running-req: 14, #token: 58878, token usage: 0.24, cuda graph: True, gen throughput (token/s): 534.92, #queue-req: 0\n",
      "[2025-08-13 21:35:29] Prefill batch. #new-seq: 1, #new-token: 2360, #cached-token: 441, token usage: 0.24, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:30] Decode batch. #running-req: 15, #token: 61803, token usage: 0.25, cuda graph: True, gen throughput (token/s): 431.21, #queue-req: 0\n",
      "[2025-08-13 21:35:31] Decode batch. #running-req: 15, #token: 62403, token usage: 0.25, cuda graph: True, gen throughput (token/s): 535.74, #queue-req: 0\n",
      "[2025-08-13 21:35:32] Decode batch. #running-req: 15, #token: 63003, token usage: 0.26, cuda graph: True, gen throughput (token/s): 534.29, #queue-req: 0\n",
      "[2025-08-13 21:35:32] INFO:     127.0.0.1:42858 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:33] Decode batch. #running-req: 14, #token: 51808, token usage: 0.21, cuda graph: True, gen throughput (token/s): 539.14, #queue-req: 0\n",
      "[2025-08-13 21:35:33] INFO:     127.0.0.1:52360 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:34] INFO:     127.0.0.1:42860 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:34] INFO:     127.0.0.1:42888 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:34] Decode batch. #running-req: 11, #token: 43459, token usage: 0.18, cuda graph: True, gen throughput (token/s): 508.22, #queue-req: 0\n",
      "[2025-08-13 21:35:35] Decode batch. #running-req: 11, #token: 43899, token usage: 0.18, cuda graph: True, gen throughput (token/s): 458.59, #queue-req: 0\n",
      "[2025-08-13 21:35:35] Prefill batch. #new-seq: 4, #new-token: 2695, #cached-token: 10135, token usage: 0.21, #running-req: 11, #queue-req: 0\n",
      "[2025-08-13 21:35:36] Decode batch. #running-req: 15, #token: 55486, token usage: 0.23, cuda graph: True, gen throughput (token/s): 396.79, #queue-req: 0\n",
      "[2025-08-13 21:35:37] INFO:     127.0.0.1:42888 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:37] Decode batch. #running-req: 14, #token: 51980, token usage: 0.21, cuda graph: True, gen throughput (token/s): 561.18, #queue-req: 0\n",
      "[2025-08-13 21:35:38] Decode batch. #running-req: 14, #token: 52540, token usage: 0.21, cuda graph: True, gen throughput (token/s): 540.96, #queue-req: 0\n",
      "[2025-08-13 21:35:38] Prefill batch. #new-seq: 1, #new-token: 420, #cached-token: 437, token usage: 0.21, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:39] INFO:     127.0.0.1:42860 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:39] Decode batch. #running-req: 14, #token: 49047, token usage: 0.20, cuda graph: True, gen throughput (token/s): 541.82, #queue-req: 0\n",
      "[2025-08-13 21:35:40] INFO:     127.0.0.1:58086 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:40] Decode batch. #running-req: 13, #token: 47253, token usage: 0.19, cuda graph: True, gen throughput (token/s): 549.14, #queue-req: 0\n",
      "[2025-08-13 21:35:40] Prefill batch. #new-seq: 2, #new-token: 2183, #cached-token: 3252, token usage: 0.20, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 21:35:41] INFO:     127.0.0.1:60642 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:41] Decode batch. #running-req: 14, #token: 48935, token usage: 0.20, cuda graph: True, gen throughput (token/s): 459.82, #queue-req: 0\n",
      "[2025-08-13 21:35:42] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 451, token usage: 0.20, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:42] INFO:     127.0.0.1:60242 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:43] Decode batch. #running-req: 14, #token: 40238, token usage: 0.16, cuda graph: True, gen throughput (token/s): 466.64, #queue-req: 0\n",
      "[2025-08-13 21:35:44] Prefill batch. #new-seq: 1, #new-token: 2345, #cached-token: 455, token usage: 0.17, #running-req: 14, #queue-req: 0\n",
      "[2025-08-13 21:35:44] Decode batch. #running-req: 15, #token: 43146, token usage: 0.18, cuda graph: True, gen throughput (token/s): 488.14, #queue-req: 0\n",
      "[2025-08-13 21:35:44] INFO:     127.0.0.1:58100 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:44] INFO:     127.0.0.1:58086 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:45] Decode batch. #running-req: 13, #token: 36856, token usage: 0.15, cuda graph: True, gen throughput (token/s): 596.78, #queue-req: 0\n",
      ".[2025-08-13 21:35:45] Prefill batch. #new-seq: 1, #new-token: 7524, #cached-token: 466, token usage: 0.15, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 21:35:46] Decode batch. #running-req: 14, #token: 44962, token usage: 0.18, cuda graph: True, gen throughput (token/s): 317.79, #queue-req: 0\n",
      "[2025-08-13 21:35:47] Decode batch. #running-req: 14, #token: 45522, token usage: 0.19, cuda graph: True, gen throughput (token/s): 571.03, #queue-req: 0\n",
      "[2025-08-13 21:35:48] INFO:     127.0.0.1:60266 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:48] Decode batch. #running-req: 13, #token: 42043, token usage: 0.17, cuda graph: True, gen throughput (token/s): 555.49, #queue-req: 0\n",
      "[2025-08-13 21:35:49] Prefill batch. #new-seq: 1, #new-token: 2349, #cached-token: 452, token usage: 0.17, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 21:35:49] Decode batch. #running-req: 14, #token: 44939, token usage: 0.18, cuda graph: True, gen throughput (token/s): 463.23, #queue-req: 0\n",
      "[2025-08-13 21:35:50] Decode batch. #running-req: 14, #token: 45499, token usage: 0.19, cuda graph: True, gen throughput (token/s): 573.19, #queue-req: 0\n",
      "[2025-08-13 21:35:51] Decode batch. #running-req: 14, #token: 46059, token usage: 0.19, cuda graph: True, gen throughput (token/s): 568.31, #queue-req: 0\n",
      "[2025-08-13 21:35:52] Decode batch. #running-req: 14, #token: 46619, token usage: 0.19, cuda graph: True, gen throughput (token/s): 569.55, #queue-req: 0\n",
      "[2025-08-13 21:35:53] Decode batch. #running-req: 14, #token: 47179, token usage: 0.19, cuda graph: True, gen throughput (token/s): 564.71, #queue-req: 0\n",
      "[2025-08-13 21:35:54] INFO:     127.0.0.1:60620 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:54] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.19, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 21:35:54] Decode batch. #running-req: 14, #token: 47758, token usage: 0.19, cuda graph: True, gen throughput (token/s): 548.66, #queue-req: 0\n",
      "[2025-08-13 21:35:55] Decode batch. #running-req: 14, #token: 48318, token usage: 0.20, cuda graph: True, gen throughput (token/s): 561.37, #queue-req: 0\n",
      "[2025-08-13 21:35:55] INFO:     127.0.0.1:60620 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:56] INFO:     127.0.0.1:53552 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:56] Decode batch. #running-req: 12, #token: 41587, token usage: 0.17, cuda graph: True, gen throughput (token/s): 521.36, #queue-req: 0\n",
      "[2025-08-13 21:35:57] Decode batch. #running-req: 12, #token: 42067, token usage: 0.17, cuda graph: True, gen throughput (token/s): 504.49, #queue-req: 0\n",
      "[2025-08-13 21:35:57] Prefill batch. #new-seq: 2, #new-token: 8045, #cached-token: 928, token usage: 0.17, #running-req: 12, #queue-req: 0\n",
      "[2025-08-13 21:35:59] INFO:     127.0.0.1:60626 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:35:59] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4631, token usage: 0.21, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 21:35:59] Decode batch. #running-req: 14, #token: 50699, token usage: 0.21, cuda graph: True, gen throughput (token/s): 314.50, #queue-req: 0\n",
      "[2025-08-13 21:35:59] INFO:     127.0.0.1:60626 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:00] Decode batch. #running-req: 13, #token: 46956, token usage: 0.19, cuda graph: True, gen throughput (token/s): 532.12, #queue-req: 0\n",
      "[2025-08-13 21:36:00] Prefill batch. #new-seq: 1, #new-token: 2359, #cached-token: 441, token usage: 0.19, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 21:36:01] Decode batch. #running-req: 14, #token: 49860, token usage: 0.20, cuda graph: True, gen throughput (token/s): 446.24, #queue-req: 0\n",
      "[2025-08-13 21:36:02] Decode batch. #running-req: 14, #token: 50420, token usage: 0.21, cuda graph: True, gen throughput (token/s): 550.38, #queue-req: 0\n",
      "[2025-08-13 21:36:03] Decode batch. #running-req: 14, #token: 50980, token usage: 0.21, cuda graph: True, gen throughput (token/s): 547.78, #queue-req: 0\n",
      "[2025-08-13 21:36:04] Decode batch. #running-req: 14, #token: 51540, token usage: 0.21, cuda graph: True, gen throughput (token/s): 546.23, #queue-req: 0\n",
      "[2025-08-13 21:36:05] Decode batch. #running-req: 14, #token: 52100, token usage: 0.21, cuda graph: True, gen throughput (token/s): 543.35, #queue-req: 0\n",
      "[2025-08-13 21:36:06] Decode batch. #running-req: 14, #token: 52660, token usage: 0.21, cuda graph: True, gen throughput (token/s): 539.64, #queue-req: 0\n",
      "[2025-08-13 21:36:08] Decode batch. #running-req: 14, #token: 53220, token usage: 0.22, cuda graph: True, gen throughput (token/s): 533.81, #queue-req: 0\n",
      "[2025-08-13 21:36:09] Decode batch. #running-req: 14, #token: 53780, token usage: 0.22, cuda graph: True, gen throughput (token/s): 533.22, #queue-req: 0\n",
      "[2025-08-13 21:36:10] Decode batch. #running-req: 14, #token: 54340, token usage: 0.22, cuda graph: True, gen throughput (token/s): 533.46, #queue-req: 0\n",
      "[2025-08-13 21:36:10] INFO:     127.0.0.1:54348 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:10] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 5908, token usage: 0.22, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 21:36:11] Decode batch. #running-req: 14, #token: 54919, token usage: 0.22, cuda graph: True, gen throughput (token/s): 518.16, #queue-req: 0\n",
      "[2025-08-13 21:36:11] INFO:     127.0.0.1:54348 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:12] Decode batch. #running-req: 13, #token: 49890, token usage: 0.20, cuda graph: True, gen throughput (token/s): 515.35, #queue-req: 0\n",
      "[2025-08-13 21:36:12] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 448, token usage: 0.20, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 21:36:13] Decode batch. #running-req: 14, #token: 52790, token usage: 0.21, cuda graph: True, gen throughput (token/s): 441.29, #queue-req: 0\n",
      "[2025-08-13 21:36:14] Decode batch. #running-req: 14, #token: 53350, token usage: 0.22, cuda graph: True, gen throughput (token/s): 536.88, #queue-req: 0\n",
      "[2025-08-13 21:36:15] Decode batch. #running-req: 14, #token: 53910, token usage: 0.22, cuda graph: True, gen throughput (token/s): 536.79, #queue-req: 0\n",
      "[2025-08-13 21:36:16] Decode batch. #running-req: 14, #token: 54470, token usage: 0.22, cuda graph: True, gen throughput (token/s): 534.35, #queue-req: 0\n",
      "[2025-08-13 21:36:17] Decode batch. #running-req: 14, #token: 55030, token usage: 0.22, cuda graph: True, gen throughput (token/s): 531.27, #queue-req: 0\n",
      "[2025-08-13 21:36:18] Decode batch. #running-req: 14, #token: 55590, token usage: 0.23, cuda graph: True, gen throughput (token/s): 527.35, #queue-req: 0\n",
      "[2025-08-13 21:36:19] Decode batch. #running-req: 14, #token: 56150, token usage: 0.23, cuda graph: True, gen throughput (token/s): 524.33, #queue-req: 0\n",
      "[2025-08-13 21:36:20] Decode batch. #running-req: 14, #token: 56710, token usage: 0.23, cuda graph: True, gen throughput (token/s): 525.29, #queue-req: 0\n",
      "[2025-08-13 21:36:21] INFO:     127.0.0.1:52368 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:21] INFO:     127.0.0.1:52382 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:21] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.21, #running-req: 12, #queue-req: 0\n",
      "[2025-08-13 21:36:21] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4800, token usage: 0.23, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 21:36:21] Decode batch. #running-req: 14, #token: 57308, token usage: 0.23, cuda graph: True, gen throughput (token/s): 494.58, #queue-req: 0\n",
      "[2025-08-13 21:36:23] Decode batch. #running-req: 14, #token: 57868, token usage: 0.24, cuda graph: True, gen throughput (token/s): 517.21, #queue-req: 0\n",
      "[2025-08-13 21:36:23] INFO:     127.0.0.1:57484 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:24] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4800, token usage: 0.24, #running-req: 13, #queue-req: 0\n",
      "[2025-08-13 21:36:24] Decode batch. #running-req: 14, #token: 58447, token usage: 0.24, cuda graph: True, gen throughput (token/s): 503.65, #queue-req: 0\n",
      "[2025-08-13 21:36:25] Decode batch. #running-req: 14, #token: 59007, token usage: 0.24, cuda graph: True, gen throughput (token/s): 514.93, #queue-req: 0\n",
      "[2025-08-13 21:36:25] INFO:     127.0.0.1:52368 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:25] INFO:     127.0.0.1:52382 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:26] Decode batch. #running-req: 12, #token: 50483, token usage: 0.21, cuda graph: True, gen throughput (token/s): 477.77, #queue-req: 0\n",
      ".[2025-08-13 21:36:26] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 468, token usage: 0.21, #running-req: 12, #queue-req: 0\n",
      "[2025-08-13 21:36:27] Decode batch. #running-req: 13, #token: 53238, token usage: 0.22, cuda graph: True, gen throughput (token/s): 415.75, #queue-req: 0\n",
      "[2025-08-13 21:36:27] INFO:     127.0.0.1:57484 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:28] Decode batch. #running-req: 12, #token: 49214, token usage: 0.20, cuda graph: True, gen throughput (token/s): 478.71, #queue-req: 0\n",
      "[2025-08-13 21:36:28] Prefill batch. #new-seq: 1, #new-token: 2161, #cached-token: 473, token usage: 0.20, #running-req: 12, #queue-req: 0\n",
      "[2025-08-13 21:36:29] Decode batch. #running-req: 13, #token: 51974, token usage: 0.21, cuda graph: True, gen throughput (token/s): 422.25, #queue-req: 0\n",
      "[2025-08-13 21:36:30] INFO:     127.0.0.1:57494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:30] INFO:     127.0.0.1:57496 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:30] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.20, #running-req: 11, #queue-req: 0\n",
      "[2025-08-13 21:36:30] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2743, token usage: 0.21, #running-req: 12, #queue-req: 0\n",
      "[2025-08-13 21:36:30] Decode batch. #running-req: 13, #token: 52532, token usage: 0.21, cuda graph: True, gen throughput (token/s): 475.32, #queue-req: 0\n",
      "[2025-08-13 21:36:31] Decode batch. #running-req: 13, #token: 53052, token usage: 0.22, cuda graph: True, gen throughput (token/s): 501.00, #queue-req: 0\n",
      "[2025-08-13 21:36:32] Decode batch. #running-req: 13, #token: 53572, token usage: 0.22, cuda graph: True, gen throughput (token/s): 500.22, #queue-req: 0\n",
      "[2025-08-13 21:36:33] INFO:     127.0.0.1:53548 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:33] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2856, token usage: 0.22, #running-req: 12, #queue-req: 0\n",
      "[2025-08-13 21:36:33] INFO:     127.0.0.1:57494 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:33] INFO:     127.0.0.1:57496 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:33] Decode batch. #running-req: 11, #token: 47139, token usage: 0.19, cuda graph: True, gen throughput (token/s): 474.94, #queue-req: 0\n",
      ".[2025-08-13 21:36:34] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 481, token usage: 0.19, #running-req: 11, #queue-req: 0\n",
      "[2025-08-13 21:36:34] Prefill batch. #new-seq: 1, #new-token: 1798, #cached-token: 0, token usage: 0.23, #running-req: 11, #queue-req: 0\n",
      "[2025-08-13 21:36:36] Decode batch. #running-req: 12, #token: 57641, token usage: 0.23, cuda graph: True, gen throughput (token/s): 215.88, #queue-req: 0\n",
      "[2025-08-13 21:36:37] Decode batch. #running-req: 12, #token: 58121, token usage: 0.24, cuda graph: True, gen throughput (token/s): 443.98, #queue-req: 0\n",
      "[2025-08-13 21:36:37] INFO:     127.0.0.1:53548 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:36:37] INFO:     127.0.0.1:53558 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:37] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.23, #running-req: 10, #queue-req: 0\n",
      "[2025-08-13 21:36:38] Decode batch. #running-req: 11, #token: 56024, token usage: 0.23, cuda graph: True, gen throughput (token/s): 413.73, #queue-req: 0\n",
      "[2025-08-13 21:36:39] INFO:     127.0.0.1:53566 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:39] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4799, token usage: 0.23, #running-req: 10, #queue-req: 0\n",
      "[2025-08-13 21:36:39] Decode batch. #running-req: 11, #token: 56483, token usage: 0.23, cuda graph: True, gen throughput (token/s): 401.56, #queue-req: 0\n",
      "[2025-08-13 21:36:40] Decode batch. #running-req: 11, #token: 56923, token usage: 0.23, cuda graph: True, gen throughput (token/s): 411.15, #queue-req: 0\n",
      "[2025-08-13 21:36:41] INFO:     127.0.0.1:53580 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:41] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 9989, token usage: 0.23, #running-req: 10, #queue-req: 0\n",
      "[2025-08-13 21:36:41] INFO:     127.0.0.1:53580 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "API request failed: 'choices' key is empty in response.\n",
      "[2025-08-13 21:36:41] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 7989, token usage: 0.22, #running-req: 10, #queue-req: 0\n",
      "[2025-08-13 21:36:41] INFO:     127.0.0.1:53558 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:41] Decode batch. #running-req: 10, #token: 50857, token usage: 0.21, cuda graph: True, gen throughput (token/s): 390.80, #queue-req: 0\n",
      ".[2025-08-13 21:36:41] INFO:     127.0.0.1:51140 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:42] Decode batch. #running-req: 9, #token: 48462, token usage: 0.20, cuda graph: True, gen throughput (token/s): 369.85, #queue-req: 0\n",
      "[2025-08-13 21:36:42] INFO:     127.0.0.1:53566 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:43] Decode batch. #running-req: 8, #token: 44287, token usage: 0.18, cuda graph: True, gen throughput (token/s): 342.86, #queue-req: 0\n",
      "[2025-08-13 21:36:43] Prefill batch. #new-seq: 1, #new-token: 2354, #cached-token: 448, token usage: 0.18, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:36:43] INFO:     127.0.0.1:40268 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:43] Prefill batch. #new-seq: 1, #new-token: 8192, #cached-token: 554, token usage: 0.17, #running-req: 9, #queue-req: 0\n",
      "[2025-08-13 21:36:44] Prefill batch. #new-seq: 2, #new-token: 1745, #cached-token: 4800, token usage: 0.22, #running-req: 9, #queue-req: 0\n",
      "[2025-08-13 21:36:45] Decode batch. #running-req: 10, #token: 57025, token usage: 0.23, cuda graph: True, gen throughput (token/s): 162.09, #queue-req: 0\n",
      "[2025-08-13 21:36:46] Decode batch. #running-req: 10, #token: 57425, token usage: 0.23, cuda graph: True, gen throughput (token/s): 371.04, #queue-req: 0\n",
      "[2025-08-13 21:36:47] Decode batch. #running-req: 10, #token: 57825, token usage: 0.24, cuda graph: True, gen throughput (token/s): 371.71, #queue-req: 0\n",
      "[2025-08-13 21:36:48] INFO:     127.0.0.1:40268 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:48] Decode batch. #running-req: 9, #token: 53698, token usage: 0.22, cuda graph: True, gen throughput (token/s): 359.61, #queue-req: 0\n",
      "[2025-08-13 21:36:49] Prefill batch. #new-seq: 1, #new-token: 2156, #cached-token: 478, token usage: 0.22, #running-req: 9, #queue-req: 0\n",
      "[2025-08-13 21:36:50] Decode batch. #running-req: 10, #token: 56227, token usage: 0.23, cuda graph: True, gen throughput (token/s): 298.07, #queue-req: 0\n",
      "[2025-08-13 21:36:51] Decode batch. #running-req: 10, #token: 56627, token usage: 0.23, cuda graph: True, gen throughput (token/s): 373.53, #queue-req: 0\n",
      "[2025-08-13 21:36:52] Decode batch. #running-req: 10, #token: 57027, token usage: 0.23, cuda graph: True, gen throughput (token/s): 373.82, #queue-req: 0\n",
      "[2025-08-13 21:36:52] INFO:     127.0.0.1:34846 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:36:53] Decode batch. #running-req: 9, #token: 53113, token usage: 0.22, cuda graph: True, gen throughput (token/s): 356.94, #queue-req: 0\n",
      "[2025-08-13 21:36:54] Decode batch. #running-req: 9, #token: 53473, token usage: 0.22, cuda graph: True, gen throughput (token/s): 343.34, #queue-req: 0\n",
      "[2025-08-13 21:36:54] INFO:     127.0.0.1:34834 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:54] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 8171, token usage: 0.22, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:36:55] INFO:     127.0.0.1:34834 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:55] Decode batch. #running-req: 8, #token: 46090, token usage: 0.19, cuda graph: True, gen throughput (token/s): 330.84, #queue-req: 0\n",
      "[2025-08-13 21:36:56] Prefill batch. #new-seq: 1, #new-token: 2264, #cached-token: 452, token usage: 0.19, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:36:56] Decode batch. #running-req: 9, #token: 48693, token usage: 0.20, cuda graph: True, gen throughput (token/s): 282.90, #queue-req: 0\n",
      "[2025-08-13 21:36:57] INFO:     127.0.0.1:34854 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:36:57] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4799, token usage: 0.20, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:36:57] Decode batch. #running-req: 9, #token: 49072, token usage: 0.20, cuda graph: True, gen throughput (token/s): 348.57, #queue-req: 0\n",
      "[2025-08-13 21:36:58] Decode batch. #running-req: 9, #token: 49432, token usage: 0.20, cuda graph: True, gen throughput (token/s): 354.88, #queue-req: 0\n",
      "[2025-08-13 21:36:59] Decode batch. #running-req: 9, #token: 49792, token usage: 0.20, cuda graph: True, gen throughput (token/s): 355.13, #queue-req: 0\n",
      "[2025-08-13 21:37:00] INFO:     127.0.0.1:34854 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:00] Decode batch. #running-req: 8, #token: 45629, token usage: 0.19, cuda graph: True, gen throughput (token/s): 347.75, #queue-req: 0\n",
      "[2025-08-13 21:37:01] Prefill batch. #new-seq: 1, #new-token: 2158, #cached-token: 476, token usage: 0.19, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:37:01] Decode batch. #running-req: 9, #token: 48189, token usage: 0.20, cuda graph: True, gen throughput (token/s): 287.50, #queue-req: 0\n",
      "[2025-08-13 21:37:02] Decode batch. #running-req: 9, #token: 48549, token usage: 0.20, cuda graph: True, gen throughput (token/s): 360.23, #queue-req: 0\n",
      "[2025-08-13 21:37:03] Decode batch. #running-req: 9, #token: 48909, token usage: 0.20, cuda graph: True, gen throughput (token/s): 359.73, #queue-req: 0\n",
      "[2025-08-13 21:37:04] Decode batch. #running-req: 9, #token: 49269, token usage: 0.20, cuda graph: True, gen throughput (token/s): 359.15, #queue-req: 0\n",
      "[2025-08-13 21:37:05] Decode batch. #running-req: 9, #token: 49629, token usage: 0.20, cuda graph: True, gen throughput (token/s): 357.07, #queue-req: 0\n",
      "[2025-08-13 21:37:06] Decode batch. #running-req: 9, #token: 49989, token usage: 0.20, cuda graph: True, gen throughput (token/s): 352.77, #queue-req: 0\n",
      "[2025-08-13 21:37:07] Decode batch. #running-req: 9, #token: 50349, token usage: 0.20, cuda graph: True, gen throughput (token/s): 353.09, #queue-req: 0\n",
      "[2025-08-13 21:37:08] INFO:     127.0.0.1:51704 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:08] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4798, token usage: 0.21, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:37:08] INFO:     127.0.0.1:58616 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:08] Decode batch. #running-req: 8, #token: 39833, token usage: 0.16, cuda graph: True, gen throughput (token/s): 342.06, #queue-req: 0\n",
      "[2025-08-13 21:37:09] Decode batch. #running-req: 8, #token: 40153, token usage: 0.16, cuda graph: True, gen throughput (token/s): 351.50, #queue-req: 0\n",
      "[2025-08-13 21:37:10] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 449, token usage: 0.16, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:37:11] Decode batch. #running-req: 9, #token: 42861, token usage: 0.17, cuda graph: True, gen throughput (token/s): 301.06, #queue-req: 0\n",
      "[2025-08-13 21:37:11] INFO:     127.0.0.1:51704 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:11] Decode batch. #running-req: 8, #token: 38702, token usage: 0.16, cuda graph: True, gen throughput (token/s): 367.68, #queue-req: 0\n",
      "[2025-08-13 21:37:12] Prefill batch. #new-seq: 1, #new-token: 3590, #cached-token: 481, token usage: 0.16, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:37:13] Decode batch. #running-req: 9, #token: 42722, token usage: 0.17, cuda graph: True, gen throughput (token/s): 270.44, #queue-req: 0\n",
      "[2025-08-13 21:37:14] Decode batch. #running-req: 9, #token: 43082, token usage: 0.18, cuda graph: True, gen throughput (token/s): 377.01, #queue-req: 0\n",
      "[2025-08-13 21:37:15] Decode batch. #running-req: 9, #token: 43442, token usage: 0.18, cuda graph: True, gen throughput (token/s): 376.92, #queue-req: 0\n",
      "[2025-08-13 21:37:16] Decode batch. #running-req: 9, #token: 43802, token usage: 0.18, cuda graph: True, gen throughput (token/s): 374.92, #queue-req: 0\n",
      "[2025-08-13 21:37:17] Decode batch. #running-req: 9, #token: 44162, token usage: 0.18, cuda graph: True, gen throughput (token/s): 374.86, #queue-req: 0\n",
      "[2025-08-13 21:37:18] Decode batch. #running-req: 9, #token: 44522, token usage: 0.18, cuda graph: True, gen throughput (token/s): 373.37, #queue-req: 0\n",
      "[2025-08-13 21:37:18] Decode batch. #running-req: 9, #token: 44882, token usage: 0.18, cuda graph: True, gen throughput (token/s): 372.17, #queue-req: 0\n",
      "[2025-08-13 21:37:19] Decode batch. #running-req: 9, #token: 45242, token usage: 0.18, cuda graph: True, gen throughput (token/s): 371.66, #queue-req: 0\n",
      "[2025-08-13 21:37:20] Decode batch. #running-req: 9, #token: 45602, token usage: 0.19, cuda graph: True, gen throughput (token/s): 369.42, #queue-req: 0\n",
      "[2025-08-13 21:37:21] INFO:     127.0.0.1:41930 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:21] Decode batch. #running-req: 8, #token: 34180, token usage: 0.14, cuda graph: True, gen throughput (token/s): 370.78, #queue-req: 0\n",
      "[2025-08-13 21:37:22] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 450, token usage: 0.14, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:37:22] INFO:     127.0.0.1:41916 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:22] Decode batch. #running-req: 8, #token: 32725, token usage: 0.13, cuda graph: True, gen throughput (token/s): 306.92, #queue-req: 0\n",
      "[2025-08-13 21:37:23] Decode batch. #running-req: 8, #token: 33045, token usage: 0.13, cuda graph: True, gen throughput (token/s): 374.67, #queue-req: 0\n",
      "[2025-08-13 21:37:23] Prefill batch. #new-seq: 1, #new-token: 2352, #cached-token: 450, token usage: 0.13, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:37:24] Decode batch. #running-req: 9, #token: 35757, token usage: 0.15, cuda graph: True, gen throughput (token/s): 323.39, #queue-req: 0\n",
      "[2025-08-13 21:37:25] Decode batch. #running-req: 9, #token: 36117, token usage: 0.15, cuda graph: True, gen throughput (token/s): 402.55, #queue-req: 0\n",
      "[2025-08-13 21:37:26] INFO:     127.0.0.1:48158 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:26] Decode batch. #running-req: 8, #token: 32783, token usage: 0.13, cuda graph: True, gen throughput (token/s): 396.12, #queue-req: 0\n",
      "[2025-08-13 21:37:27] Prefill batch. #new-seq: 1, #new-token: 2351, #cached-token: 451, token usage: 0.13, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:37:27] Decode batch. #running-req: 9, #token: 35459, token usage: 0.14, cuda graph: True, gen throughput (token/s): 303.28, #queue-req: 0\n",
      "[2025-08-13 21:37:28] Decode batch. #running-req: 9, #token: 35819, token usage: 0.15, cuda graph: True, gen throughput (token/s): 403.96, #queue-req: 0\n",
      "[2025-08-13 21:37:28] INFO:     127.0.0.1:53580 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:29] INFO:     127.0.0.1:41516 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:29] Decode batch. #running-req: 7, #token: 23377, token usage: 0.10, cuda graph: True, gen throughput (token/s): 396.99, #queue-req: 0\n",
      "[2025-08-13 21:37:30] Decode batch. #running-req: 7, #token: 23657, token usage: 0.10, cuda graph: True, gen throughput (token/s): 363.41, #queue-req: 0\n",
      "[2025-08-13 21:37:30] Prefill batch. #new-seq: 2, #new-token: 4161, #cached-token: 1295, token usage: 0.10, #running-req: 7, #queue-req: 0\n",
      "[2025-08-13 21:37:31] Decode batch. #running-req: 9, #token: 28526, token usage: 0.12, cuda graph: True, gen throughput (token/s): 266.24, #queue-req: 0\n",
      "[2025-08-13 21:37:32] Decode batch. #running-req: 9, #token: 28886, token usage: 0.12, cuda graph: True, gen throughput (token/s): 433.38, #queue-req: 0\n",
      "[2025-08-13 21:37:33] Decode batch. #running-req: 9, #token: 29246, token usage: 0.12, cuda graph: True, gen throughput (token/s): 428.57, #queue-req: 0\n",
      "[2025-08-13 21:37:33] Decode batch. #running-req: 9, #token: 29606, token usage: 0.12, cuda graph: True, gen throughput (token/s): 427.58, #queue-req: 0\n",
      "[2025-08-13 21:37:34] Decode batch. #running-req: 9, #token: 29966, token usage: 0.12, cuda graph: True, gen throughput (token/s): 428.12, #queue-req: 0\n",
      "[2025-08-13 21:37:34] INFO:     127.0.0.1:58600 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:35] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.12, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:37:35] Decode batch. #running-req: 9, #token: 30345, token usage: 0.12, cuda graph: True, gen throughput (token/s): 413.75, #queue-req: 0\n",
      "[2025-08-13 21:37:36] Decode batch. #running-req: 9, #token: 30705, token usage: 0.12, cuda graph: True, gen throughput (token/s): 425.30, #queue-req: 0\n",
      "[2025-08-13 21:37:37] Decode batch. #running-req: 9, #token: 31065, token usage: 0.13, cuda graph: True, gen throughput (token/s): 423.16, #queue-req: 0\n",
      "[2025-08-13 21:37:37] INFO:     127.0.0.1:58600 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:38] Decode batch. #running-req: 8, #token: 26904, token usage: 0.11, cuda graph: True, gen throughput (token/s): 414.21, #queue-req: 0\n",
      "[2025-08-13 21:37:38] Prefill batch. #new-seq: 1, #new-token: 2166, #cached-token: 468, token usage: 0.11, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:37:39] Decode batch. #running-req: 9, #token: 29480, token usage: 0.12, cuda graph: True, gen throughput (token/s): 331.38, #queue-req: 0\n",
      "[2025-08-13 21:37:39] Decode batch. #running-req: 9, #token: 29840, token usage: 0.12, cuda graph: True, gen throughput (token/s): 428.79, #queue-req: 0\n",
      "[2025-08-13 21:37:40] Decode batch. #running-req: 9, #token: 30200, token usage: 0.12, cuda graph: True, gen throughput (token/s): 429.04, #queue-req: 0\n",
      "[2025-08-13 21:37:41] Decode batch. #running-req: 9, #token: 30560, token usage: 0.12, cuda graph: True, gen throughput (token/s): 426.03, #queue-req: 0\n",
      "[2025-08-13 21:37:42] Decode batch. #running-req: 9, #token: 30920, token usage: 0.13, cuda graph: True, gen throughput (token/s): 425.18, #queue-req: 0\n",
      "[2025-08-13 21:37:43] Decode batch. #running-req: 9, #token: 31280, token usage: 0.13, cuda graph: True, gen throughput (token/s): 422.96, #queue-req: 0\n",
      "[2025-08-13 21:37:43] INFO:     127.0.0.1:48168 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:43] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4715, token usage: 0.13, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:37:43] INFO:     127.0.0.1:47466 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:44] Decode batch. #running-req: 8, #token: 26598, token usage: 0.11, cuda graph: True, gen throughput (token/s): 402.45, #queue-req: 0\n",
      "[2025-08-13 21:37:44] Decode batch. #running-req: 8, #token: 26918, token usage: 0.11, cuda graph: True, gen throughput (token/s): 401.57, #queue-req: 0\n",
      "[2025-08-13 21:37:45] Prefill batch. #new-seq: 1, #new-token: 2348, #cached-token: 454, token usage: 0.11, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:37:46] Decode batch. #running-req: 9, #token: 29625, token usage: 0.12, cuda graph: True, gen throughput (token/s): 338.06, #queue-req: 0\n",
      "[2025-08-13 21:37:46] INFO:     127.0.0.1:48168 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:37:46] Decode batch. #running-req: 8, #token: 25560, token usage: 0.10, cuda graph: True, gen throughput (token/s): 425.09, #queue-req: 0\n",
      "[2025-08-13 21:37:47] Decode batch. #running-req: 8, #token: 25880, token usage: 0.11, cuda graph: True, gen throughput (token/s): 407.43, #queue-req: 0\n",
      "[2025-08-13 21:37:47] Prefill batch. #new-seq: 1, #new-token: 5935, #cached-token: 481, token usage: 0.11, #running-req: 8, #queue-req: 0\n",
      "[2025-08-13 21:37:49] Decode batch. #running-req: 9, #token: 32255, token usage: 0.13, cuda graph: True, gen throughput (token/s): 249.25, #queue-req: 0\n",
      "[2025-08-13 21:37:49] INFO:     127.0.0.1:47450 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:37:49] Decode batch. #running-req: 8, #token: 28552, token usage: 0.12, cuda graph: True, gen throughput (token/s): 411.96, #queue-req: 0\n",
      "[2025-08-13 21:37:50] Decode batch. #running-req: 8, #token: 28872, token usage: 0.12, cuda graph: True, gen throughput (token/s): 392.25, #queue-req: 0\n",
      "[2025-08-13 21:37:51] Decode batch. #running-req: 8, #token: 29192, token usage: 0.12, cuda graph: True, gen throughput (token/s): 392.19, #queue-req: 0\n",
      "[2025-08-13 21:37:52] Decode batch. #running-req: 8, #token: 29512, token usage: 0.12, cuda graph: True, gen throughput (token/s): 392.24, #queue-req: 0\n",
      "[2025-08-13 21:37:53] Decode batch. #running-req: 8, #token: 29832, token usage: 0.12, cuda graph: True, gen throughput (token/s): 390.06, #queue-req: 0\n",
      "[2025-08-13 21:37:54] Decode batch. #running-req: 8, #token: 30152, token usage: 0.12, cuda graph: True, gen throughput (token/s): 389.05, #queue-req: 0\n",
      "[2025-08-13 21:37:54] Decode batch. #running-req: 8, #token: 30472, token usage: 0.12, cuda graph: True, gen throughput (token/s): 387.25, #queue-req: 0\n",
      "[2025-08-13 21:37:55] Decode batch. #running-req: 8, #token: 30792, token usage: 0.13, cuda graph: True, gen throughput (token/s): 385.71, #queue-req: 0\n",
      "[2025-08-13 21:37:56] Decode batch. #running-req: 8, #token: 31112, token usage: 0.13, cuda graph: True, gen throughput (token/s): 384.06, #queue-req: 0\n",
      "[2025-08-13 21:37:57] Decode batch. #running-req: 8, #token: 31432, token usage: 0.13, cuda graph: True, gen throughput (token/s): 384.42, #queue-req: 0\n",
      "[2025-08-13 21:37:58] Decode batch. #running-req: 8, #token: 31752, token usage: 0.13, cuda graph: True, gen throughput (token/s): 383.06, #queue-req: 0\n",
      "[2025-08-13 21:37:59] Decode batch. #running-req: 8, #token: 32072, token usage: 0.13, cuda graph: True, gen throughput (token/s): 382.10, #queue-req: 0\n",
      "[2025-08-13 21:37:59] Decode batch. #running-req: 8, #token: 32392, token usage: 0.13, cuda graph: True, gen throughput (token/s): 376.60, #queue-req: 0\n",
      "[2025-08-13 21:38:00] Decode batch. #running-req: 8, #token: 32712, token usage: 0.13, cuda graph: True, gen throughput (token/s): 378.48, #queue-req: 0\n",
      "[2025-08-13 21:38:01] Decode batch. #running-req: 8, #token: 33032, token usage: 0.13, cuda graph: True, gen throughput (token/s): 375.60, #queue-req: 0\n",
      "[2025-08-13 21:38:02] Decode batch. #running-req: 8, #token: 33352, token usage: 0.14, cuda graph: True, gen throughput (token/s): 376.70, #queue-req: 0\n",
      "[2025-08-13 21:38:03] Decode batch. #running-req: 8, #token: 33672, token usage: 0.14, cuda graph: True, gen throughput (token/s): 375.20, #queue-req: 0\n",
      "[2025-08-13 21:38:04] Decode batch. #running-req: 8, #token: 33992, token usage: 0.14, cuda graph: True, gen throughput (token/s): 374.43, #queue-req: 0\n",
      "[2025-08-13 21:38:04] Decode batch. #running-req: 8, #token: 34312, token usage: 0.14, cuda graph: True, gen throughput (token/s): 373.02, #queue-req: 0\n",
      "[2025-08-13 21:38:05] Decode batch. #running-req: 8, #token: 34632, token usage: 0.14, cuda graph: True, gen throughput (token/s): 369.56, #queue-req: 0\n",
      "[2025-08-13 21:38:06] INFO:     127.0.0.1:60080 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:06] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.14, #running-req: 7, #queue-req: 0\n",
      "[2025-08-13 21:38:06] Decode batch. #running-req: 8, #token: 34970, token usage: 0.14, cuda graph: True, gen throughput (token/s): 354.94, #queue-req: 0\n",
      "[2025-08-13 21:38:07] Decode batch. #running-req: 8, #token: 35290, token usage: 0.14, cuda graph: True, gen throughput (token/s): 367.49, #queue-req: 0\n",
      "[2025-08-13 21:38:07] INFO:     127.0.0.1:60086 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:07] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4801, token usage: 0.14, #running-req: 7, #queue-req: 0\n",
      "[2025-08-13 21:38:08] Decode batch. #running-req: 8, #token: 35629, token usage: 0.14, cuda graph: True, gen throughput (token/s): 357.22, #queue-req: 0\n",
      "[2025-08-13 21:38:09] INFO:     127.0.0.1:60080 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:38:09] Decode batch. #running-req: 7, #token: 31437, token usage: 0.13, cuda graph: True, gen throughput (token/s): 362.32, #queue-req: 0\n",
      "[2025-08-13 21:38:10] Decode batch. #running-req: 7, #token: 31717, token usage: 0.13, cuda graph: True, gen throughput (token/s): 331.09, #queue-req: 0\n",
      "[2025-08-13 21:38:10] INFO:     127.0.0.1:60086 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:10] INFO:     127.0.0.1:50006 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:38:10] INFO:     127.0.0.1:50002 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:10] Decode batch. #running-req: 4, #token: 19050, token usage: 0.08, cuda graph: True, gen throughput (token/s): 288.30, #queue-req: 0\n",
      "[2025-08-13 21:38:11] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4801, token usage: 0.10, #running-req: 4, #queue-req: 0\n",
      "[2025-08-13 21:38:11] Prefill batch. #new-seq: 1, #new-token: 7513, #cached-token: 466, token usage: 0.10, #running-req: 5, #queue-req: 0\n",
      "[2025-08-13 21:38:12] Decode batch. #running-req: 6, #token: 31102, token usage: 0.13, cuda graph: True, gen throughput (token/s): 108.78, #queue-req: 0\n",
      "[2025-08-13 21:38:12] INFO:     127.0.0.1:50002 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:38:13] Decode batch. #running-req: 5, #token: 26925, token usage: 0.11, cuda graph: True, gen throughput (token/s): 265.85, #queue-req: 0\n",
      "[2025-08-13 21:38:14] Decode batch. #running-req: 5, #token: 27125, token usage: 0.11, cuda graph: True, gen throughput (token/s): 250.63, #queue-req: 0\n",
      "[2025-08-13 21:38:14] INFO:     127.0.0.1:50010 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:14] Decode batch. #running-req: 4, #token: 22950, token usage: 0.09, cuda graph: True, gen throughput (token/s): 227.01, #queue-req: 0\n",
      "[2025-08-13 21:38:15] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 462, token usage: 0.09, #running-req: 4, #queue-req: 0\n",
      "[2025-08-13 21:38:15] Decode batch. #running-req: 5, #token: 23299, token usage: 0.09, cuda graph: True, gen throughput (token/s): 224.88, #queue-req: 0\n",
      "[2025-08-13 21:38:16] Decode batch. #running-req: 5, #token: 23499, token usage: 0.10, cuda graph: True, gen throughput (token/s): 260.12, #queue-req: 0\n",
      "[2025-08-13 21:38:16] INFO:     127.0.0.1:36970 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:17] Decode batch. #running-req: 4, #token: 16397, token usage: 0.07, cuda graph: True, gen throughput (token/s): 236.89, #queue-req: 0\n",
      "[2025-08-13 21:38:17] Prefill batch. #new-seq: 1, #new-token: 2308, #cached-token: 493, token usage: 0.07, #running-req: 4, #queue-req: 0\n",
      "[2025-08-13 21:38:18] Decode batch. #running-req: 5, #token: 18920, token usage: 0.08, cuda graph: True, gen throughput (token/s): 179.19, #queue-req: 0\n",
      "[2025-08-13 21:38:18] Decode batch. #running-req: 5, #token: 19120, token usage: 0.08, cuda graph: True, gen throughput (token/s): 273.17, #queue-req: 0\n",
      "[2025-08-13 21:38:19] Decode batch. #running-req: 5, #token: 19320, token usage: 0.08, cuda graph: True, gen throughput (token/s): 272.75, #queue-req: 0\n",
      "[2025-08-13 21:38:20] Decode batch. #running-req: 5, #token: 19520, token usage: 0.08, cuda graph: True, gen throughput (token/s): 271.86, #queue-req: 0\n",
      "[2025-08-13 21:38:21] Decode batch. #running-req: 5, #token: 19720, token usage: 0.08, cuda graph: True, gen throughput (token/s): 271.52, #queue-req: 0\n",
      "[2025-08-13 21:38:21] INFO:     127.0.0.1:49470 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:21] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4633, token usage: 0.08, #running-req: 4, #queue-req: 0\n",
      "[2025-08-13 21:38:21] Decode batch. #running-req: 5, #token: 19939, token usage: 0.08, cuda graph: True, gen throughput (token/s): 260.62, #queue-req: 0\n",
      "[2025-08-13 21:38:22] Decode batch. #running-req: 5, #token: 20139, token usage: 0.08, cuda graph: True, gen throughput (token/s): 271.04, #queue-req: 0\n",
      "[2025-08-13 21:38:23] Decode batch. #running-req: 5, #token: 20339, token usage: 0.08, cuda graph: True, gen throughput (token/s): 269.69, #queue-req: 0\n",
      "[2025-08-13 21:38:23] INFO:     127.0.0.1:49470 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:23] Decode batch. #running-req: 4, #token: 16144, token usage: 0.07, cuda graph: True, gen throughput (token/s): 264.04, #queue-req: 0\n",
      "[2025-08-13 21:38:24] Decode batch. #running-req: 4, #token: 16304, token usage: 0.07, cuda graph: True, gen throughput (token/s): 227.96, #queue-req: 0\n",
      "[2025-08-13 21:38:25] Prefill batch. #new-seq: 1, #new-token: 4369, #cached-token: 461, token usage: 0.07, #running-req: 4, #queue-req: 0\n",
      "[2025-08-13 21:38:25] Decode batch. #running-req: 5, #token: 20867, token usage: 0.08, cuda graph: True, gen throughput (token/s): 157.58, #queue-req: 0\n",
      "[2025-08-13 21:38:26] INFO:     127.0.0.1:49476 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:26] Decode batch. #running-req: 4, #token: 16755, token usage: 0.07, cuda graph: True, gen throughput (token/s): 249.32, #queue-req: 0\n",
      "[2025-08-13 21:38:27] Prefill batch. #new-seq: 1, #new-token: 1738, #cached-token: 554, token usage: 0.07, #running-req: 4, #queue-req: 0\n",
      "[2025-08-13 21:38:27] Decode batch. #running-req: 5, #token: 18827, token usage: 0.08, cuda graph: True, gen throughput (token/s): 196.26, #queue-req: 0\n",
      "[2025-08-13 21:38:28] Decode batch. #running-req: 5, #token: 19027, token usage: 0.08, cuda graph: True, gen throughput (token/s): 274.40, #queue-req: 0\n",
      "[2025-08-13 21:38:28] Decode batch. #running-req: 5, #token: 19227, token usage: 0.08, cuda graph: True, gen throughput (token/s): 273.92, #queue-req: 0\n",
      "[2025-08-13 21:38:29] Decode batch. #running-req: 5, #token: 19427, token usage: 0.08, cuda graph: True, gen throughput (token/s): 273.49, #queue-req: 0\n",
      "[2025-08-13 21:38:30] Decode batch. #running-req: 5, #token: 19627, token usage: 0.08, cuda graph: True, gen throughput (token/s): 272.56, #queue-req: 0\n",
      "[2025-08-13 21:38:31] Decode batch. #running-req: 5, #token: 19827, token usage: 0.08, cuda graph: True, gen throughput (token/s): 272.22, #queue-req: 0\n",
      "[2025-08-13 21:38:31] Decode batch. #running-req: 5, #token: 20027, token usage: 0.08, cuda graph: True, gen throughput (token/s): 271.04, #queue-req: 0\n",
      "[2025-08-13 21:38:32] Decode batch. #running-req: 5, #token: 20227, token usage: 0.08, cuda graph: True, gen throughput (token/s): 269.69, #queue-req: 0\n",
      "[2025-08-13 21:38:33] Decode batch. #running-req: 5, #token: 20427, token usage: 0.08, cuda graph: True, gen throughput (token/s): 269.26, #queue-req: 0\n",
      "[2025-08-13 21:38:33] INFO:     127.0.0.1:54734 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:34] Decode batch. #running-req: 4, #token: 11939, token usage: 0.05, cuda graph: True, gen throughput (token/s): 263.29, #queue-req: 0\n",
      "[2025-08-13 21:38:34] Decode batch. #running-req: 4, #token: 12099, token usage: 0.05, cuda graph: True, gen throughput (token/s): 240.64, #queue-req: 0\n",
      "[2025-08-13 21:38:34] Prefill batch. #new-seq: 1, #new-token: 592, #cached-token: 1892, token usage: 0.06, #running-req: 4, #queue-req: 0\n",
      "[2025-08-13 21:38:35] Decode batch. #running-req: 5, #token: 14321, token usage: 0.06, cuda graph: True, gen throughput (token/s): 242.79, #queue-req: 0\n",
      "[2025-08-13 21:38:36] Decode batch. #running-req: 5, #token: 14521, token usage: 0.06, cuda graph: True, gen throughput (token/s): 288.02, #queue-req: 0\n",
      "[2025-08-13 21:38:36] Decode batch. #running-req: 5, #token: 14721, token usage: 0.06, cuda graph: True, gen throughput (token/s): 287.18, #queue-req: 0\n",
      "[2025-08-13 21:38:37] Decode batch. #running-req: 5, #token: 14921, token usage: 0.06, cuda graph: True, gen throughput (token/s): 286.80, #queue-req: 0\n",
      "[2025-08-13 21:38:38] Decode batch. #running-req: 5, #token: 15121, token usage: 0.06, cuda graph: True, gen throughput (token/s): 285.79, #queue-req: 0\n",
      "[2025-08-13 21:38:38] Decode batch. #running-req: 5, #token: 15321, token usage: 0.06, cuda graph: True, gen throughput (token/s): 283.39, #queue-req: 0\n",
      "[2025-08-13 21:38:39] Decode batch. #running-req: 5, #token: 15521, token usage: 0.06, cuda graph: True, gen throughput (token/s): 283.33, #queue-req: 0\n",
      "[2025-08-13 21:38:40] Decode batch. #running-req: 5, #token: 15721, token usage: 0.06, cuda graph: True, gen throughput (token/s): 285.97, #queue-req: 0\n",
      "[2025-08-13 21:38:41] Decode batch. #running-req: 5, #token: 15921, token usage: 0.06, cuda graph: True, gen throughput (token/s): 284.39, #queue-req: 0\n",
      "[2025-08-13 21:38:41] Decode batch. #running-req: 5, #token: 16121, token usage: 0.07, cuda graph: True, gen throughput (token/s): 283.82, #queue-req: 0\n",
      "[2025-08-13 21:38:42] Decode batch. #running-req: 5, #token: 16321, token usage: 0.07, cuda graph: True, gen throughput (token/s): 283.36, #queue-req: 0\n",
      "[2025-08-13 21:38:43] Decode batch. #running-req: 5, #token: 16521, token usage: 0.07, cuda graph: True, gen throughput (token/s): 283.52, #queue-req: 0\n",
      "[2025-08-13 21:38:43] Decode batch. #running-req: 5, #token: 16721, token usage: 0.07, cuda graph: True, gen throughput (token/s): 279.90, #queue-req: 0\n",
      "[2025-08-13 21:38:44] Decode batch. #running-req: 5, #token: 16921, token usage: 0.07, cuda graph: True, gen throughput (token/s): 277.95, #queue-req: 0\n",
      "[2025-08-13 21:38:45] Decode batch. #running-req: 5, #token: 17121, token usage: 0.07, cuda graph: True, gen throughput (token/s): 280.99, #queue-req: 0\n",
      "[2025-08-13 21:38:46] Decode batch. #running-req: 5, #token: 17321, token usage: 0.07, cuda graph: True, gen throughput (token/s): 281.43, #queue-req: 0\n",
      "[2025-08-13 21:38:46] Decode batch. #running-req: 5, #token: 17521, token usage: 0.07, cuda graph: True, gen throughput (token/s): 280.34, #queue-req: 0\n",
      "[2025-08-13 21:38:47] Decode batch. #running-req: 5, #token: 17721, token usage: 0.07, cuda graph: True, gen throughput (token/s): 279.25, #queue-req: 0\n",
      "[2025-08-13 21:38:48] Decode batch. #running-req: 5, #token: 17921, token usage: 0.07, cuda graph: True, gen throughput (token/s): 278.26, #queue-req: 0\n",
      "[2025-08-13 21:38:48] Decode batch. #running-req: 5, #token: 18121, token usage: 0.07, cuda graph: True, gen throughput (token/s): 276.46, #queue-req: 0\n",
      "[2025-08-13 21:38:49] Decode batch. #running-req: 5, #token: 18321, token usage: 0.07, cuda graph: True, gen throughput (token/s): 277.21, #queue-req: 0\n",
      "[2025-08-13 21:38:50] Decode batch. #running-req: 5, #token: 18521, token usage: 0.08, cuda graph: True, gen throughput (token/s): 277.24, #queue-req: 0\n",
      "[2025-08-13 21:38:51] Decode batch. #running-req: 5, #token: 18721, token usage: 0.08, cuda graph: True, gen throughput (token/s): 275.34, #queue-req: 0\n",
      "[2025-08-13 21:38:51] Decode batch. #running-req: 5, #token: 18921, token usage: 0.08, cuda graph: True, gen throughput (token/s): 273.94, #queue-req: 0\n",
      "[2025-08-13 21:38:52] INFO:     127.0.0.1:54750 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:52] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 2582, token usage: 0.08, #running-req: 4, #queue-req: 0\n",
      "[2025-08-13 21:38:52] Decode batch. #running-req: 5, #token: 19140, token usage: 0.08, cuda graph: True, gen throughput (token/s): 264.32, #queue-req: 0\n",
      "[2025-08-13 21:38:53] Decode batch. #running-req: 5, #token: 19340, token usage: 0.08, cuda graph: True, gen throughput (token/s): 274.07, #queue-req: 0\n",
      "[2025-08-13 21:38:54] Decode batch. #running-req: 5, #token: 19540, token usage: 0.08, cuda graph: True, gen throughput (token/s): 271.97, #queue-req: 0\n",
      "[2025-08-13 21:38:54] INFO:     127.0.0.1:54750 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:54] INFO:     127.0.0.1:49502 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:38:54] Decode batch. #running-req: 3, #token: 13031, token usage: 0.05, cuda graph: True, gen throughput (token/s): 254.50, #queue-req: 0\n",
      "[2025-08-13 21:38:55] Decode batch. #running-req: 3, #token: 13151, token usage: 0.05, cuda graph: True, gen throughput (token/s): 177.90, #queue-req: 0\n",
      "[2025-08-13 21:38:55] Prefill batch. #new-seq: 2, #new-token: 2361, #cached-token: 5237, token usage: 0.07, #running-req: 3, #queue-req: 0\n",
      "[2025-08-13 21:38:56] Decode batch. #running-req: 5, #token: 20045, token usage: 0.08, cuda graph: True, gen throughput (token/s): 185.66, #queue-req: 0\n",
      "[2025-08-13 21:38:57] Decode batch. #running-req: 5, #token: 20245, token usage: 0.08, cuda graph: True, gen throughput (token/s): 270.02, #queue-req: 0\n",
      "[2025-08-13 21:38:57] Decode batch. #running-req: 5, #token: 20445, token usage: 0.08, cuda graph: True, gen throughput (token/s): 268.51, #queue-req: 0\n",
      "[2025-08-13 21:38:58] INFO:     127.0.0.1:49502 - \"POST /generate HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:38:58] Decode batch. #running-req: 4, #token: 16123, token usage: 0.07, cuda graph: True, gen throughput (token/s): 250.73, #queue-req: 0\n",
      "[2025-08-13 21:38:59] Decode batch. #running-req: 4, #token: 16283, token usage: 0.07, cuda graph: True, gen throughput (token/s): 227.51, #queue-req: 0\n",
      "[2025-08-13 21:38:59] Decode batch. #running-req: 4, #token: 16443, token usage: 0.07, cuda graph: True, gen throughput (token/s): 227.16, #queue-req: 0\n",
      "[2025-08-13 21:39:00] Decode batch. #running-req: 4, #token: 16603, token usage: 0.07, cuda graph: True, gen throughput (token/s): 226.89, #queue-req: 0\n",
      "[2025-08-13 21:39:01] Decode batch. #running-req: 4, #token: 16763, token usage: 0.07, cuda graph: True, gen throughput (token/s): 226.80, #queue-req: 0\n",
      "[2025-08-13 21:39:01] INFO:     127.0.0.1:49504 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:39:02] Decode batch. #running-req: 3, #token: 10518, token usage: 0.04, cuda graph: True, gen throughput (token/s): 208.23, #queue-req: 0\n",
      "[2025-08-13 21:39:02] Prefill batch. #new-seq: 1, #new-token: 2018, #cached-token: 468, token usage: 0.04, #running-req: 3, #queue-req: 0\n",
      "[2025-08-13 21:39:02] Decode batch. #running-req: 3, #token: 12728, token usage: 0.05, cuda graph: True, gen throughput (token/s): 177.91, #queue-req: 0\n",
      "[2025-08-13 21:39:03] INFO:     127.0.0.1:49518 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:39:03] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 4291, token usage: 0.05, #running-req: 3, #queue-req: 0\n",
      "[2025-08-13 21:39:03] Decode batch. #running-req: 4, #token: 12911, token usage: 0.05, cuda graph: True, gen throughput (token/s): 187.23, #queue-req: 0\n",
      "[2025-08-13 21:39:04] Decode batch. #running-req: 4, #token: 13071, token usage: 0.05, cuda graph: True, gen throughput (token/s): 237.09, #queue-req: 0\n",
      "[2025-08-13 21:39:04] INFO:     127.0.0.1:49532 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:39:04] Decode batch. #running-req: 3, #token: 9519, token usage: 0.04, cuda graph: True, gen throughput (token/s): 190.21, #queue-req: 0\n",
      "[2025-08-13 21:39:05] INFO:     127.0.0.1:49518 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:39:05] Decode batch. #running-req: 2, #token: 5588, token usage: 0.02, cuda graph: True, gen throughput (token/s): 151.99, #queue-req: 0\n",
      "[2025-08-13 21:39:06] Prefill batch. #new-seq: 1, #new-token: 427, #cached-token: 437, token usage: 0.02, #running-req: 2, #queue-req: 0\n",
      "[2025-08-13 21:39:06] Decode batch. #running-req: 2, #token: 6095, token usage: 0.02, cuda graph: True, gen throughput (token/s): 126.58, #queue-req: 0\n",
      "[2025-08-13 21:39:06] Decode batch. #running-req: 3, #token: 6218, token usage: 0.03, cuda graph: True, gen throughput (token/s): 188.04, #queue-req: 0\n",
      "[2025-08-13 21:39:07] Decode batch. #running-req: 3, #token: 6338, token usage: 0.03, cuda graph: True, gen throughput (token/s): 194.51, #queue-req: 0\n",
      "[2025-08-13 21:39:08] Decode batch. #running-req: 3, #token: 6458, token usage: 0.03, cuda graph: True, gen throughput (token/s): 194.28, #queue-req: 0\n",
      "[2025-08-13 21:39:08] Decode batch. #running-req: 3, #token: 6578, token usage: 0.03, cuda graph: True, gen throughput (token/s): 194.16, #queue-req: 0\n",
      "[2025-08-13 21:39:09] Decode batch. #running-req: 3, #token: 6698, token usage: 0.03, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0\n",
      "[2025-08-13 21:39:09] Decode batch. #running-req: 3, #token: 6818, token usage: 0.03, cuda graph: True, gen throughput (token/s): 193.34, #queue-req: 0\n",
      "[2025-08-13 21:39:10] Decode batch. #running-req: 3, #token: 6938, token usage: 0.03, cuda graph: True, gen throughput (token/s): 192.37, #queue-req: 0\n",
      "[2025-08-13 21:39:11] Decode batch. #running-req: 3, #token: 7058, token usage: 0.03, cuda graph: True, gen throughput (token/s): 192.59, #queue-req: 0\n",
      "[2025-08-13 21:39:11] Decode batch. #running-req: 3, #token: 7178, token usage: 0.03, cuda graph: True, gen throughput (token/s): 191.71, #queue-req: 0\n",
      "[2025-08-13 21:39:12] INFO:     127.0.0.1:54132 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:39:12] Decode batch. #running-req: 2, #token: 3967, token usage: 0.02, cuda graph: True, gen throughput (token/s): 171.79, #queue-req: 0\n",
      "[2025-08-13 21:39:12] Decode batch. #running-req: 2, #token: 4047, token usage: 0.02, cuda graph: True, gen throughput (token/s): 135.14, #queue-req: 0\n",
      "[2025-08-13 21:39:13] Decode batch. #running-req: 2, #token: 4127, token usage: 0.02, cuda graph: True, gen throughput (token/s): 135.00, #queue-req: 0\n",
      "[2025-08-13 21:39:14] Decode batch. #running-req: 2, #token: 4207, token usage: 0.02, cuda graph: True, gen throughput (token/s): 134.87, #queue-req: 0\n",
      "[2025-08-13 21:39:14] Decode batch. #running-req: 2, #token: 4287, token usage: 0.02, cuda graph: True, gen throughput (token/s): 134.73, #queue-req: 0\n",
      "[2025-08-13 21:39:15] Decode batch. #running-req: 2, #token: 4367, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.94, #queue-req: 0\n",
      "[2025-08-13 21:39:15] Decode batch. #running-req: 2, #token: 4447, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.72, #queue-req: 0\n",
      "[2025-08-13 21:39:16] Decode batch. #running-req: 2, #token: 4527, token usage: 0.02, cuda graph: True, gen throughput (token/s): 134.07, #queue-req: 0\n",
      "[2025-08-13 21:39:17] Decode batch. #running-req: 2, #token: 4607, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.56, #queue-req: 0\n",
      "[2025-08-13 21:39:17] Decode batch. #running-req: 2, #token: 4687, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.73, #queue-req: 0\n",
      "[2025-08-13 21:39:18] Decode batch. #running-req: 2, #token: 4767, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0\n",
      "[2025-08-13 21:39:18] Decode batch. #running-req: 2, #token: 4847, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0\n",
      "[2025-08-13 21:39:19] Decode batch. #running-req: 2, #token: 4927, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.27, #queue-req: 0\n",
      "[2025-08-13 21:39:20] Decode batch. #running-req: 2, #token: 5007, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.71, #queue-req: 0\n",
      "[2025-08-13 21:39:20] Decode batch. #running-req: 2, #token: 5087, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.48, #queue-req: 0\n",
      "[2025-08-13 21:39:21] Decode batch. #running-req: 2, #token: 5167, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.70, #queue-req: 0\n",
      "[2025-08-13 21:39:21] Decode batch. #running-req: 2, #token: 5247, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.41, #queue-req: 0\n",
      "[2025-08-13 21:39:22] Decode batch. #running-req: 2, #token: 5327, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.48, #queue-req: 0\n",
      "[2025-08-13 21:39:23] Decode batch. #running-req: 2, #token: 5407, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.67, #queue-req: 0\n",
      "[2025-08-13 21:39:23] Decode batch. #running-req: 2, #token: 5487, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.43, #queue-req: 0\n",
      "[2025-08-13 21:39:24] Decode batch. #running-req: 2, #token: 5567, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.40, #queue-req: 0\n",
      "[2025-08-13 21:39:24] Decode batch. #running-req: 2, #token: 5647, token usage: 0.02, cuda graph: True, gen throughput (token/s): 131.66, #queue-req: 0\n",
      "[2025-08-13 21:39:25] INFO:     127.0.0.1:55458 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:39:25] Decode batch. #running-req: 1, #token: 2145, token usage: 0.01, cuda graph: True, gen throughput (token/s): 79.03, #queue-req: 0\n",
      "[2025-08-13 21:39:26] Decode batch. #running-req: 1, #token: 2185, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.58, #queue-req: 0\n",
      "[2025-08-13 21:39:26] Prefill batch. #new-seq: 1, #new-token: 2213, #cached-token: 441, token usage: 0.01, #running-req: 1, #queue-req: 0\n",
      "[2025-08-13 21:39:26] Decode batch. #running-req: 2, #token: 4482, token usage: 0.02, cuda graph: True, gen throughput (token/s): 94.60, #queue-req: 0\n",
      "[2025-08-13 21:39:27] Decode batch. #running-req: 2, #token: 4562, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.55, #queue-req: 0\n",
      "[2025-08-13 21:39:28] Decode batch. #running-req: 2, #token: 4642, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.53, #queue-req: 0\n",
      "[2025-08-13 21:39:28] Decode batch. #running-req: 2, #token: 4722, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.86, #queue-req: 0\n",
      "[2025-08-13 21:39:29] Decode batch. #running-req: 2, #token: 4802, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.49, #queue-req: 0\n",
      "[2025-08-13 21:39:29] Decode batch. #running-req: 2, #token: 4882, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.35, #queue-req: 0\n",
      "[2025-08-13 21:39:30] Decode batch. #running-req: 2, #token: 4962, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.85, #queue-req: 0\n",
      "[2025-08-13 21:39:31] Decode batch. #running-req: 2, #token: 5042, token usage: 0.02, cuda graph: True, gen throughput (token/s): 133.02, #queue-req: 0\n",
      "[2025-08-13 21:39:31] Decode batch. #running-req: 2, #token: 5122, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.60, #queue-req: 0\n",
      "[2025-08-13 21:39:32] Decode batch. #running-req: 2, #token: 5202, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.28, #queue-req: 0\n",
      "[2025-08-13 21:39:32] Decode batch. #running-req: 2, #token: 5282, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.62, #queue-req: 0\n",
      "[2025-08-13 21:39:33] Decode batch. #running-req: 2, #token: 5362, token usage: 0.02, cuda graph: True, gen throughput (token/s): 132.56, #queue-req: 0\n",
      "[2025-08-13 21:39:34] Decode batch. #running-req: 2, #token: 5442, token usage: 0.02, cuda graph: True, gen throughput (token/s): 131.35, #queue-req: 0\n",
      "[2025-08-13 21:39:34] Decode batch. #running-req: 2, #token: 5522, token usage: 0.02, cuda graph: True, gen throughput (token/s): 131.56, #queue-req: 0\n",
      "[2025-08-13 21:39:35] Decode batch. #running-req: 2, #token: 5602, token usage: 0.02, cuda graph: True, gen throughput (token/s): 131.71, #queue-req: 0\n",
      "[2025-08-13 21:39:36] Decode batch. #running-req: 2, #token: 5682, token usage: 0.02, cuda graph: True, gen throughput (token/s): 131.69, #queue-req: 0\n",
      "[2025-08-13 21:39:36] INFO:     127.0.0.1:55470 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:39:36] Decode batch. #running-req: 2, #token: 3331, token usage: 0.01, cuda graph: True, gen throughput (token/s): 130.98, #queue-req: 0\n",
      "[2025-08-13 21:39:36] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 2863, token usage: 0.02, #running-req: 1, #queue-req: 0\n",
      "[2025-08-13 21:39:37] Decode batch. #running-req: 2, #token: 5860, token usage: 0.02, cuda graph: True, gen throughput (token/s): 123.84, #queue-req: 0\n",
      "[2025-08-13 21:39:37] Decode batch. #running-req: 2, #token: 5940, token usage: 0.02, cuda graph: True, gen throughput (token/s): 131.48, #queue-req: 0\n",
      "[2025-08-13 21:39:38] Decode batch. #running-req: 2, #token: 6020, token usage: 0.02, cuda graph: True, gen throughput (token/s): 131.63, #queue-req: 0\n",
      "[2025-08-13 21:39:38] INFO:     127.0.0.1:55470 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:39:39] Decode batch. #running-req: 1, #token: 3491, token usage: 0.01, cuda graph: True, gen throughput (token/s): 82.08, #queue-req: 0\n",
      "[2025-08-13 21:39:39] Prefill batch. #new-seq: 1, #new-token: 3834, #cached-token: 554, token usage: 0.01, #running-req: 1, #queue-req: 0\n",
      "[2025-08-13 21:39:40] Decode batch. #running-req: 2, #token: 7554, token usage: 0.03, cuda graph: True, gen throughput (token/s): 61.68, #queue-req: 0\n",
      "[2025-08-13 21:39:40] Decode batch. #running-req: 2, #token: 7634, token usage: 0.03, cuda graph: True, gen throughput (token/s): 128.13, #queue-req: 0\n",
      "[2025-08-13 21:39:41] Decode batch. #running-req: 2, #token: 7714, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.72, #queue-req: 0\n",
      "[2025-08-13 21:39:41] Decode batch. #running-req: 2, #token: 7794, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.45, #queue-req: 0\n",
      "[2025-08-13 21:39:42] Decode batch. #running-req: 2, #token: 7874, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.17, #queue-req: 0\n",
      "[2025-08-13 21:39:43] Decode batch. #running-req: 2, #token: 7954, token usage: 0.03, cuda graph: True, gen throughput (token/s): 127.32, #queue-req: 0\n",
      "[2025-08-13 21:39:43] Decode batch. #running-req: 2, #token: 8034, token usage: 0.03, cuda graph: True, gen throughput (token/s): 126.46, #queue-req: 0\n",
      "[2025-08-13 21:39:43] INFO:     127.0.0.1:58176 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      ".[2025-08-13 21:39:44] Decode batch. #running-req: 1, #token: 4688, token usage: 0.02, cuda graph: True, gen throughput (token/s): 69.02, #queue-req: 0\n",
      "[2025-08-13 21:39:45] Decode batch. #running-req: 1, #token: 4728, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.71, #queue-req: 0\n",
      "[2025-08-13 21:39:45] Decode batch. #running-req: 1, #token: 4768, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.84, #queue-req: 0\n",
      "[2025-08-13 21:39:46] Decode batch. #running-req: 1, #token: 4808, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.92, #queue-req: 0\n",
      "[2025-08-13 21:39:46] Decode batch. #running-req: 1, #token: 4848, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.47, #queue-req: 0\n",
      "[2025-08-13 21:39:47] Decode batch. #running-req: 1, #token: 4888, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.42, #queue-req: 0\n",
      "[2025-08-13 21:39:48] Decode batch. #running-req: 1, #token: 4928, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.55, #queue-req: 0\n",
      "[2025-08-13 21:39:48] Decode batch. #running-req: 1, #token: 4968, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.61, #queue-req: 0\n",
      "[2025-08-13 21:39:49] Decode batch. #running-req: 1, #token: 5008, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.76, #queue-req: 0\n",
      "[2025-08-13 21:39:49] Decode batch. #running-req: 1, #token: 5048, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.83, #queue-req: 0\n",
      "[2025-08-13 21:39:50] Decode batch. #running-req: 1, #token: 5088, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.70, #queue-req: 0\n",
      "[2025-08-13 21:39:51] Decode batch. #running-req: 1, #token: 5128, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.57, #queue-req: 0\n",
      "[2025-08-13 21:39:51] Decode batch. #running-req: 1, #token: 5168, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.24, #queue-req: 0\n",
      "[2025-08-13 21:39:52] Decode batch. #running-req: 1, #token: 5208, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.43, #queue-req: 0\n",
      "[2025-08-13 21:39:52] Decode batch. #running-req: 1, #token: 5248, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.22, #queue-req: 0\n",
      "[2025-08-13 21:39:53] Decode batch. #running-req: 1, #token: 5288, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.14, #queue-req: 0\n",
      "[2025-08-13 21:39:54] Decode batch. #running-req: 1, #token: 5328, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.10, #queue-req: 0\n",
      "[2025-08-13 21:39:54] Decode batch. #running-req: 1, #token: 5368, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.09, #queue-req: 0\n",
      "[2025-08-13 21:39:55] Decode batch. #running-req: 1, #token: 5408, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.28, #queue-req: 0\n",
      "[2025-08-13 21:39:56] Decode batch. #running-req: 1, #token: 5448, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.25, #queue-req: 0\n",
      "[2025-08-13 21:39:56] Decode batch. #running-req: 1, #token: 5488, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.15, #queue-req: 0\n",
      "[2025-08-13 21:39:57] Decode batch. #running-req: 1, #token: 5528, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.17, #queue-req: 0\n",
      "[2025-08-13 21:39:57] Decode batch. #running-req: 1, #token: 5568, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.98, #queue-req: 0\n",
      "[2025-08-13 21:39:58] Decode batch. #running-req: 1, #token: 5608, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.05, #queue-req: 0\n",
      "[2025-08-13 21:39:59] Decode batch. #running-req: 1, #token: 5648, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.97, #queue-req: 0\n",
      "[2025-08-13 21:39:59] Decode batch. #running-req: 1, #token: 5688, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.49, #queue-req: 0\n",
      "[2025-08-13 21:40:00] Decode batch. #running-req: 1, #token: 5728, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.80, #queue-req: 0\n",
      "[2025-08-13 21:40:00] Decode batch. #running-req: 1, #token: 5768, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.46, #queue-req: 0\n",
      "[2025-08-13 21:40:01] Decode batch. #running-req: 1, #token: 5808, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.49, #queue-req: 0\n",
      "[2025-08-13 21:40:02] Decode batch. #running-req: 1, #token: 5848, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.90, #queue-req: 0\n",
      "[2025-08-13 21:40:02] Decode batch. #running-req: 1, #token: 5888, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.69, #queue-req: 0\n",
      "[2025-08-13 21:40:03] Decode batch. #running-req: 1, #token: 5928, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.78, #queue-req: 0\n",
      "[2025-08-13 21:40:04] Decode batch. #running-req: 1, #token: 5968, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.27, #queue-req: 0\n",
      "[2025-08-13 21:40:04] Decode batch. #running-req: 1, #token: 6008, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.69, #queue-req: 0\n",
      "[2025-08-13 21:40:05] Decode batch. #running-req: 1, #token: 6048, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.29, #queue-req: 0\n",
      "[2025-08-13 21:40:05] Decode batch. #running-req: 1, #token: 6088, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.40, #queue-req: 0\n",
      "[2025-08-13 21:40:06] Decode batch. #running-req: 1, #token: 6128, token usage: 0.02, cuda graph: True, gen throughput (token/s): 64.55, #queue-req: 0\n",
      "[2025-08-13 21:40:07] Decode batch. #running-req: 1, #token: 6168, token usage: 0.03, cuda graph: True, gen throughput (token/s): 64.40, #queue-req: 0\n",
      "[2025-08-13 21:40:07] Decode batch. #running-req: 1, #token: 6208, token usage: 0.03, cuda graph: True, gen throughput (token/s): 64.54, #queue-req: 0\n",
      "[2025-08-13 21:40:08] Decode batch. #running-req: 1, #token: 6248, token usage: 0.03, cuda graph: True, gen throughput (token/s): 64.38, #queue-req: 0\n",
      "[2025-08-13 21:40:09] Decode batch. #running-req: 1, #token: 6288, token usage: 0.03, cuda graph: True, gen throughput (token/s): 64.34, #queue-req: 0\n",
      "[2025-08-13 21:40:09] Decode batch. #running-req: 1, #token: 6328, token usage: 0.03, cuda graph: True, gen throughput (token/s): 64.30, #queue-req: 0\n",
      "[2025-08-13 21:40:10] Decode batch. #running-req: 1, #token: 6368, token usage: 0.03, cuda graph: True, gen throughput (token/s): 63.83, #queue-req: 0\n",
      "[2025-08-13 21:40:10] INFO:     127.0.0.1:42434 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:40:10] Prefill batch. #new-seq: 1, #new-token: 21, #cached-token: 6387, token usage: 0.03, #running-req: 0, #queue-req: 0\n",
      "[2025-08-13 21:40:10] INFO:     127.0.0.1:42434 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:40:11] Prefill batch. #new-seq: 1, #new-token: 2353, #cached-token: 448, token usage: 0.00, #running-req: 0, #queue-req: 0\n",
      "[2025-08-13 21:40:11] Decode batch. #running-req: 1, #token: 2805, token usage: 0.01, cuda graph: True, gen throughput (token/s): 24.92, #queue-req: 0\n",
      "[2025-08-13 21:40:12] Decode batch. #running-req: 1, #token: 2845, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.72, #queue-req: 0\n",
      "[2025-08-13 21:40:13] Decode batch. #running-req: 1, #token: 2885, token usage: 0.01, cuda graph: True, gen throughput (token/s): 67.02, #queue-req: 0\n",
      "[2025-08-13 21:40:13] Decode batch. #running-req: 1, #token: 2925, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.41, #queue-req: 0\n",
      "[2025-08-13 21:40:14] Decode batch. #running-req: 1, #token: 2965, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.17, #queue-req: 0\n",
      "[2025-08-13 21:40:14] Decode batch. #running-req: 1, #token: 3005, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.89, #queue-req: 0\n",
      "[2025-08-13 21:40:15] Decode batch. #running-req: 1, #token: 3045, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.13, #queue-req: 0\n",
      "[2025-08-13 21:40:16] Decode batch. #running-req: 1, #token: 3085, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.06, #queue-req: 0\n",
      "[2025-08-13 21:40:16] Decode batch. #running-req: 1, #token: 3125, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.25, #queue-req: 0\n",
      "[2025-08-13 21:40:17] Decode batch. #running-req: 1, #token: 3165, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.48, #queue-req: 0\n",
      "[2025-08-13 21:40:17] Decode batch. #running-req: 1, #token: 3205, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.85, #queue-req: 0\n",
      "[2025-08-13 21:40:18] Decode batch. #running-req: 1, #token: 3245, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.90, #queue-req: 0\n",
      "[2025-08-13 21:40:19] Decode batch. #running-req: 1, #token: 3285, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.62, #queue-req: 0\n",
      "[2025-08-13 21:40:19] Decode batch. #running-req: 1, #token: 3325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.74, #queue-req: 0\n",
      "[2025-08-13 21:40:20] Decode batch. #running-req: 1, #token: 3365, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.75, #queue-req: 0\n",
      "[2025-08-13 21:40:20] Decode batch. #running-req: 1, #token: 3405, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.74, #queue-req: 0\n",
      "[2025-08-13 21:40:21] Decode batch. #running-req: 1, #token: 3445, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.25, #queue-req: 0\n",
      "[2025-08-13 21:40:22] Decode batch. #running-req: 1, #token: 3485, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.51, #queue-req: 0\n",
      "[2025-08-13 21:40:22] Decode batch. #running-req: 1, #token: 3525, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.53, #queue-req: 0\n",
      "[2025-08-13 21:40:23] Decode batch. #running-req: 1, #token: 3565, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.88, #queue-req: 0\n",
      "[2025-08-13 21:40:23] Decode batch. #running-req: 1, #token: 3605, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.62, #queue-req: 0\n",
      "[2025-08-13 21:40:24] Decode batch. #running-req: 1, #token: 3645, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.47, #queue-req: 0\n",
      "[2025-08-13 21:40:25] Decode batch. #running-req: 1, #token: 3685, token usage: 0.01, cuda graph: True, gen throughput (token/s): 66.49, #queue-req: 0\n",
      "[2025-08-13 21:40:25] Decode batch. #running-req: 1, #token: 3725, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.54, #queue-req: 0\n",
      "[2025-08-13 21:40:26] Decode batch. #running-req: 1, #token: 3765, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.07, #queue-req: 0\n",
      "[2025-08-13 21:40:26] Decode batch. #running-req: 1, #token: 3805, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.33, #queue-req: 0\n",
      "[2025-08-13 21:40:27] Decode batch. #running-req: 1, #token: 3845, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.29, #queue-req: 0\n",
      "[2025-08-13 21:40:28] Decode batch. #running-req: 1, #token: 3885, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.31, #queue-req: 0\n",
      "[2025-08-13 21:40:28] Decode batch. #running-req: 1, #token: 3925, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.60, #queue-req: 0\n",
      "[2025-08-13 21:40:29] Decode batch. #running-req: 1, #token: 3965, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.00, #queue-req: 0\n",
      "[2025-08-13 21:40:29] Decode batch. #running-req: 1, #token: 4005, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.48, #queue-req: 0\n",
      "[2025-08-13 21:40:30] Decode batch. #running-req: 1, #token: 4045, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.11, #queue-req: 0\n",
      "[2025-08-13 21:40:31] Decode batch. #running-req: 1, #token: 4085, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.13, #queue-req: 0\n",
      "[2025-08-13 21:40:31] Decode batch. #running-req: 1, #token: 4125, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.12, #queue-req: 0\n",
      "[2025-08-13 21:40:32] Decode batch. #running-req: 1, #token: 4165, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.85, #queue-req: 0\n",
      "[2025-08-13 21:40:32] Decode batch. #running-req: 1, #token: 4205, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.02, #queue-req: 0\n",
      "[2025-08-13 21:40:33] Decode batch. #running-req: 1, #token: 4245, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.18, #queue-req: 0\n",
      "[2025-08-13 21:40:34] Decode batch. #running-req: 1, #token: 4285, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.97, #queue-req: 0\n",
      "[2025-08-13 21:40:34] Decode batch. #running-req: 1, #token: 4325, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.98, #queue-req: 0\n",
      "[2025-08-13 21:40:35] Decode batch. #running-req: 1, #token: 4365, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.20, #queue-req: 0\n",
      "[2025-08-13 21:40:35] Decode batch. #running-req: 1, #token: 4405, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.69, #queue-req: 0\n",
      "[2025-08-13 21:40:36] Decode batch. #running-req: 1, #token: 4445, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.21, #queue-req: 0\n",
      "[2025-08-13 21:40:37] Decode batch. #running-req: 1, #token: 4485, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.66, #queue-req: 0\n",
      "[2025-08-13 21:40:37] Decode batch. #running-req: 1, #token: 4525, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.69, #queue-req: 0\n",
      "[2025-08-13 21:40:38] Decode batch. #running-req: 1, #token: 4565, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.08, #queue-req: 0\n",
      "[2025-08-13 21:40:39] Decode batch. #running-req: 1, #token: 4605, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.10, #queue-req: 0\n",
      "[2025-08-13 21:40:39] Decode batch. #running-req: 1, #token: 4645, token usage: 0.02, cuda graph: True, gen throughput (token/s): 66.08, #queue-req: 0\n",
      "[2025-08-13 21:40:40] Decode batch. #running-req: 1, #token: 4685, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.80, #queue-req: 0\n",
      "[2025-08-13 21:40:40] Decode batch. #running-req: 1, #token: 4725, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.59, #queue-req: 0\n",
      "[2025-08-13 21:40:41] Decode batch. #running-req: 1, #token: 4765, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.42, #queue-req: 0\n",
      "[2025-08-13 21:40:41] INFO:     127.0.0.1:49100 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "[2025-08-13 21:40:42] Prefill batch. #new-seq: 1, #new-token: 20, #cached-token: 4800, token usage: 0.02, #running-req: 0, #queue-req: 0\n",
      "[2025-08-13 21:40:42] Decode batch. #running-req: 1, #token: 4824, token usage: 0.02, cuda graph: True, gen throughput (token/s): 62.42, #queue-req: 0\n",
      "[2025-08-13 21:40:42] Decode batch. #running-req: 1, #token: 4864, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.55, #queue-req: 0\n",
      "[2025-08-13 21:40:43] Decode batch. #running-req: 1, #token: 4904, token usage: 0.02, cuda graph: True, gen throughput (token/s): 65.54, #queue-req: 0\n",
      "[2025-08-13 21:40:43] INFO:     127.0.0.1:49100 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "."
     ]
    }
   ],
   "source": [
    "from run_baselines_paprika_frontier import run_multiple_iterations_multiple_games\n",
    "\n",
    "await run_multiple_iterations_multiple_games(\n",
    "    num_games=40,\n",
    "    list_envs=['wordle','mastermind'],\n",
    "    models=[local_model_name],\n",
    "    word_limits=[None],\n",
    "    logs_file='./logs/paprika_qwen3_4B.jsonl',\n",
    "    infos=['belief','history','both'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d2df2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to terminate the server when you're done!\n",
    "terminate_process(server_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0200e8",
   "metadata": {},
   "source": [
    "# 1. Load the Paprika Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac1d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import JerichoInferenceEngine, so cannot use it!\n",
      "Could not import VLLMInferenceEngine, so cannot use it!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sys.path.append('../../paprika/') # Remove this when verl and paprika are installed in the same env\n",
    "from llm_exploration.paprika_config_helper import PaprikaConfigHelper\n",
    "from verl.interactions.paprika_interaction import PaprikaInteraction\n",
    "from pprint import pprint as pp\n",
    "paprika_games = ['twenty_questions', 'guess_my_city', 'murder_mystery', 'customer_service', 'wordle', 'cellular_automata', \\\n",
    "    'mastermind'] # 'battleship', 'minesweeper', 'bandit_bai_fixed_budget' \n",
    "import dotenv\n",
    "dotenv.load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ade1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twenty_questions => 367\n",
      "guess_my_city => 185\n",
      "murder_mystery => 50\n",
      "customer_service => 200\n",
      "wordle => 800\n",
      "cellular_automata => 500\n",
      "mastermind => 500\n"
     ]
    }
   ],
   "source": [
    "for env_name in paprika_games:\n",
    "    config = PaprikaConfigHelper.create_config(env_name)\n",
    "    config['belief_config']['style'] = 'none'\n",
    "\n",
    "    interaction = PaprikaInteraction(config={})\n",
    "\n",
    "    import builtins\n",
    "    _original_print = builtins.print\n",
    "    builtins.print = lambda *a, **k: None\n",
    "    try:\n",
    "        instance_id = await interaction.start_interaction(\n",
    "            instance_id=None,\n",
    "            scenario_id=None, # start a random scenario\n",
    "            **config,\n",
    "        )\n",
    "    finally:\n",
    "        builtins.print = _original_print\n",
    "    num_scenarios = interaction.game_scenarios.__len__()\n",
    "    print(f'{env_name} => {num_scenarios}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54995906",
   "metadata": {},
   "source": [
    "# 3. Belief Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f117ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def update_belief(\n",
    "        curr_belief: str,\n",
    "        action: str,\n",
    "        response: str,\n",
    "        model_name: str,\n",
    "    ):\n",
    "\n",
    "\n",
    "    user_content = f'''\\\n",
    "Look at the current belief and the agent's action and environment response on that belief.\\\n",
    "Compress the context, remove redundant information, and maintain important information about the game state \\\n",
    "needed to take optimal future actions.\\\n",
    "Current belief: {curr_belief}\n",
    "Agent's action: {action}\n",
    "Environment's response: {response}\n",
    "Output the updated belief state inside <BELIEF> and </BELIEF> tags.\\\n",
    "Understand that only the generated belief is fed to the agent, so be sure to include all necessary information about game mechanics.'''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'You are a helpful assistant.'},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]\n",
    "\n",
    "    if 'qwen' in model_name.lower():\n",
    "        url = f\"http://localhost:{port}/v1/chat/completions\"\n",
    "    else:\n",
    "        url = None\n",
    "\n",
    "    out = await llm_call(\n",
    "        model=model_name,\n",
    "        get_everything=True,\n",
    "        reasoning_effort='high',\n",
    "        messages=messages,\n",
    "        url=url\n",
    "    )\n",
    "\n",
    "    import re\n",
    "    content = out['choices'][0]['message']['content']\n",
    "    match = re.search(r\"<BELIEF>(.*?)</BELIEF>\", content, re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        belief = match.group(1).strip()\n",
    "    else:\n",
    "        # fallback: return the whole content if tags not found\n",
    "        belief = content.strip()\n",
    "    \n",
    "    if 'reasoning_details' in out['choices'][0]['message']:\n",
    "        reasoning = out['choices'][0]['message']['reasoning_details'][0]['text']\n",
    "    else:\n",
    "        reasoning = None\n",
    "\n",
    "    return belief, reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "763a4fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def take_action(\n",
    "        belief: str,\n",
    "        model_name: str,\n",
    "    ):\n",
    "\n",
    "\n",
    "    user_content = f'''\\\n",
    "Look at the current belief take the next action based on the belief.\\\n",
    "Take an action that leads to optimal exploration.\\\n",
    "Belief: {belief}\n",
    "Output the action inside <ACTION> and </ACTION> tags.'''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'You are a helpful assistant.'},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]\n",
    "\n",
    "    if 'qwen' in model_name.lower():\n",
    "        url = f\"http://localhost:{port}/v1/chat/completions\"\n",
    "    else:\n",
    "        url = None\n",
    "\n",
    "    out = await llm_call(\n",
    "        model=model_name,\n",
    "        url=url,\n",
    "        get_everything=True,\n",
    "        reasoning_effort='high',\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    import re\n",
    "    content = out['choices'][0]['message']['content']\n",
    "    match = re.search(r\"<\\s*action\\s*>(.*?)<\\s*/\\s*action\\s*>\", content, re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        action = match.group(1).strip()\n",
    "    else:\n",
    "        # fallback: return the whole content if tags not found\n",
    "        action = content.strip()\n",
    "    \n",
    "    if 'reasoning_details' in out['choices'][0]['message']:\n",
    "        reasoning = out['choices'][0]['message']['reasoning_details'][0]['text']\n",
    "    else:\n",
    "        reasoning = None\n",
    "\n",
    "    return action, reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2402b6",
   "metadata": {},
   "source": [
    "# 4. Paprika Rollout with Belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3c8fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def run_one_iteration_with_belief_llm(\n",
    "        env_name: str,\n",
    "        model_name: str,\n",
    "        game_id: int,\n",
    "    ):\n",
    "    config = PaprikaConfigHelper.create_config(env_name)\n",
    "    config['belief_config']['style'] = 'none'\n",
    "    interaction = PaprikaInteraction(config={})\n",
    "\n",
    "    import builtins\n",
    "    _original_print = builtins.print\n",
    "    builtins.print = lambda *a, **k: None\n",
    "    try:\n",
    "        instance_id = await interaction.start_interaction(instance_id=None, scenario_id=None, **config)\n",
    "    finally:\n",
    "        builtins.print = _original_print\n",
    "\n",
    "    first_user_message = interaction.agent_conv.messages[0][1]\n",
    "    attempts = 0\n",
    "    game_history = []\n",
    "    belief = f'This is the start of the game. The only available information right now are the game rules:\\n{first_user_message}'\n",
    "    max_attempts = interaction._instance_dict[instance_id]['max_turns']\n",
    "\n",
    "    while attempts < max_attempts:\n",
    "        \n",
    "        attempts += 1\n",
    "\n",
    "        action, action_reasoning = await take_action(belief, model_name)\n",
    "\n",
    "        message = [\n",
    "            {\"role\": \"user\", \"content\": f\"Output the next action.\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"<action>{action}</action>\"}\n",
    "        ]\n",
    "        done, response, score, additional_data = await interaction.generate_response(instance_id=instance_id, messages=message)\n",
    "        \n",
    "        belief, belief_reasoning = await update_belief(belief, action, response, model_name)\n",
    "\n",
    "        game_history.append({\n",
    "            \"model\": model_name,\n",
    "            \"game_id\": str(game_id),\n",
    "            \"env\": env_name,\n",
    "            \"attempt\": attempts,\n",
    "            \"guess\": action,\n",
    "            \"response\": response,\n",
    "            \"score\": score,\n",
    "            \"done\": done,\n",
    "            \"data\": additional_data,\n",
    "            \"belief\": belief,\n",
    "            \"action_reasoning\": action_reasoning,\n",
    "            \"belief_reasoning\": belief_reasoning,\n",
    "        })\n",
    "\n",
    "        if \"Goal reached\" in response:\n",
    "            break\n",
    "    \n",
    "    print(f'.', end='', flush=True)\n",
    "    \n",
    "    return game_history\n",
    "\n",
    "async def run_multiple_iterations_multiple_games(\n",
    "        num_games: int,\n",
    "        list_envs,\n",
    "        models,\n",
    "        logs_file='./logs/paprika_local.jsonl',\n",
    "    ):\n",
    "    import json\n",
    "\n",
    "    tasks = []\n",
    "    for model in models:\n",
    "        for env_name in list_envs:\n",
    "            for game_id in range(num_games):\n",
    "                tasks.append(run_one_iteration_with_belief_llm(env_name, model, game_id))\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # Flatten results and write to file\n",
    "    with open(logs_file, \"a\") as f:\n",
    "        for game_history in results:\n",
    "            for entry in game_history:\n",
    "                f.write(json.dumps(entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096e2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8616ece5",
   "metadata": {},
   "source": [
    "# 4. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e13dc08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint as pp\n",
    "import json\n",
    "\n",
    "logs_file = './logs/paprika_qwen3_4B.jsonl'\n",
    "with open(logs_file, 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "logs_file = './logs/paprika_frontier_v6.jsonl'\n",
    "with open(logs_file, 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "df2 = pd.DataFrame(data)\n",
    "df = pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3f3ec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model', 'game_id', 'env', 'attempt', 'info', 'raw_guess', 'guess',\n",
      "       'response', 'word_limit', 'score', 'done', 'data', 'belief',\n",
      "       'action_reasoning', 'belief_reasoning'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8fe61ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>game_id</th>\n",
       "      <th>env</th>\n",
       "      <th>attempt</th>\n",
       "      <th>info</th>\n",
       "      <th>raw_guess</th>\n",
       "      <th>guess</th>\n",
       "      <th>response</th>\n",
       "      <th>word_limit</th>\n",
       "      <th>score</th>\n",
       "      <th>done</th>\n",
       "      <th>data</th>\n",
       "      <th>belief</th>\n",
       "      <th>action_reasoning</th>\n",
       "      <th>belief_reasoning</th>\n",
       "      <th>model_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen/Qwen3-4B (belief)</td>\n",
       "      <td>5</td>\n",
       "      <td>wordle</td>\n",
       "      <td>1</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;think&gt;\\nOkay, the user is playing Wordle and ...</td>\n",
       "      <td>stare</td>\n",
       "      <td>First letter, s, is not in the target word \\nS...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'word', 'env_game_scen...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's see. The user is playing ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Qwen/Qwen3-4B (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen/Qwen3-4B (belief)</td>\n",
       "      <td>5</td>\n",
       "      <td>wordle</td>\n",
       "      <td>2</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;think&gt;\\nOkay, the user is playing Wordle and ...</td>\n",
       "      <td>trend</td>\n",
       "      <td>First letter, t, is correct and in the correct...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'word', 'env_game_scen...</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's see. The user is playing ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Qwen/Qwen3-4B (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen/Qwen3-4B (belief)</td>\n",
       "      <td>5</td>\n",
       "      <td>wordle</td>\n",
       "      <td>3</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;think&gt;\\nOkay, the user is playing Wordle and ...</td>\n",
       "      <td>tried</td>\n",
       "      <td>Goal reached</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'word', 'env_game_scen...</td>\n",
       "      <td>The secret word is confirmed as \"tried\". The l...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Qwen/Qwen3-4B (belief)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model game_id     env  attempt    info  \\\n",
       "0  Qwen/Qwen3-4B (belief)       5  wordle        1  belief   \n",
       "1  Qwen/Qwen3-4B (belief)       5  wordle        2  belief   \n",
       "2  Qwen/Qwen3-4B (belief)       5  wordle        3  belief   \n",
       "\n",
       "                                           raw_guess  guess  \\\n",
       "0  <think>\\nOkay, the user is playing Wordle and ...  stare   \n",
       "1  <think>\\nOkay, the user is playing Wordle and ...  trend   \n",
       "2  <think>\\nOkay, the user is playing Wordle and ...  tried   \n",
       "\n",
       "                                            response word_limit  score  done  \\\n",
       "0  First letter, s, is not in the target word \\nS...       None      1  True   \n",
       "1  First letter, t, is correct and in the correct...       None      2  True   \n",
       "2                                       Goal reached       None      3  True   \n",
       "\n",
       "                                                data  \\\n",
       "0  {'agent_game_scenario': 'word', 'env_game_scen...   \n",
       "1  {'agent_game_scenario': 'word', 'env_game_scen...   \n",
       "2  {'agent_game_scenario': 'word', 'env_game_scen...   \n",
       "\n",
       "                                              belief action_reasoning  \\\n",
       "0  <think>\\nOkay, let's see. The user is playing ...                    \n",
       "1  <think>\\nOkay, let's see. The user is playing ...                    \n",
       "2  The secret word is confirmed as \"tried\". The l...                    \n",
       "\n",
       "  belief_reasoning              model_info  \n",
       "0                   Qwen/Qwen3-4B (belief)  \n",
       "1                   Qwen/Qwen3-4B (belief)  \n",
       "2                   Qwen/Qwen3-4B (belief)  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "084e5622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attempt</th>\n",
       "      <th>guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>crane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>STRAW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>stone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;think&gt;\\nOkay, let's try to figure out the sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>BAKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>stare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>STAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>crane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attempt                                              guess\n",
       "0        1                                              crane\n",
       "1        2                                              STRAW\n",
       "2        1                                              stone\n",
       "3        2                                              beach\n",
       "4        3  <think>\\nOkay, let's try to figure out the sec...\n",
       "5        4                                              BAKER\n",
       "6        1                                                ...\n",
       "7        2                                              stare\n",
       "8        3                                              STAIR\n",
       "9        1                                              crane"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['model'].str.contains('qwen', case=False)].head(10)[['attempt', 'guess']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6daaa35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<think>\\nOkay, the user is playing Wordle and needs help with their first guess. Let me think. Since it\\'s the start of the game, there are no previous beliefs. I need to choose a word that\\'s common and has a good chance of being the secret word. Wordle words are usually five letters, so I should pick a common one. Words like \"crane\", \"apple\", or \"stone\" are often used. But maybe \"crane\" is too specific. \"Apple\" is a good choice because it\\'s common and has a lot of vowels. Alternatively, \"stare\" is another option. Wait, the user is on their second attempt, but the belief says it\\'s the start. Maybe the user is confused. Wait, the initial message says \"You are currently taking your attempt 2, and you have a total of 6 attempts.\" But the belief is that it\\'s the start. That seems conflicting. Maybe the user is in a situation where they have already made one guess and are on the second attempt. But the belief says \"This is the start of the game. No beliefs right now.\" So perhaps the user is just starting, and the first guess is their first attempt. Wait, the instructions say \"You are currently taking your attempt 2\", but the belief is the start. That might be a mistake. But according to the given information, the user is on attempt 2. However, the belief says no beliefs, so maybe the initial state is the start, and the user is on their second attempt. Maybe the user is in a scenario where they have already made one guess, but the system is indicating that it\\'s the start. Hmm, perhaps the user is in a situation where they have to make their first guess, but the system is saying attempt 2. Maybe that\\'s a typo. But regardless, the user is asking for the first guess. So I should pick a common five-letter word that\\'s likely. Words like \"crane\", \"apple\", \"stare\", \"tears\", \"green\". Maybe \"green\" is a good choice because it\\'s common and has a lot of vowels. Alternatively, \"crane\" is also a good one. But maybe \"stare\" is better. Wait, but the user is on attempt 2. Wait, maybe the user is in a situation where they have already made one guess, and the second attempt is now. But the belief says it\\'s the start. I think the key here is to pick a word that maximizes information. So, pick a word with a mix of vowels and consonants. \"Stare\" has S, T, A, R, E. That\\'s a good mix. Alternatively, \"crane\" has C, R, A, N, E. Both are good. Maybe \"stare\" is better because it\\'s more common. So I\\'ll go with \"stare\" as the first guess. But wait, the user is on attempt 2. Maybe the first guess was \"stare\", and now they\\'re on attempt 2. But the belief says it\\'s the start. Maybe the user is confused. But according to the given information, the answer should be the first guess. So I need to pick the first guess. Therefore, the answer is \"stare\".\\n</think>\\n\\n<Answer>stare</Answer>',\n",
       "       '<think>\\nOkay, the user is playing Wordle and has provided some feedback after their first guess, \"stare\". The assistant needs to determine the next best guess based on the current belief state. Let me break down the information given.\\n\\nFirst, the feedback from the first guess \"stare\" indicates:\\n- \\'s\\' is not in the word.\\n- \\'t\\' is in the word but not in position 2.\\n- \\'a\\' is not in the word at all.\\n- \\'r\\' is in the word but not in position 4.\\n- \\'e\\' is in the word but not in position 5.\\n\\nSo the target word must include the letters \\'t\\', \\'r\\', and \\'e\\', but not \\'a\\' or \\'s\\'. The letters \\'t\\', \\'r\\', and \\'e\\' are present but in different positions than in \"stare\". \\n\\nPossible words that fit these criteria:\\n- \"trend\" (t, r, e, n, d)\\n- \"treed\" (t, r, e, e, d)\\n- \"terne\" (t, e, r, n, e)\\n- \"treen\" (t, r, e, e, n)\\n\\nHowever, \"stare\" was the first guess, and the user is now on their third attempt. The assistant needs to choose a word that maximizes information gain. Words like \"trend\" or \"treed\" are good candidates because they include the necessary letters and avoid the eliminated ones. \\n\\nBut since the user is on their third attempt, it\\'s important to choose a word that might narrow down the possibilities quickly. \"Trend\" is a common word and fits the criteria. However, the assistant should consider other possibilities as well. \\n\\nWait, the user\\'s initial instruction says to make the first guess. But the current belief state shows that the first guess was already made. The user is now asking for the next guess, which is the third attempt. The assistant needs to provide the next guess based on the feedback from the first attempt. \\n\\nLooking back, the assistant\\'s initial answer was \"stare\", which was the first guess. Now, the user is asking for the next guess. The correct approach is to select a word that includes \\'t\\', \\'r\\', \\'e\\' and avoids \\'a\\' and \\'s\\'. \"Trend\" fits all these criteria. Therefore, the next guess should be \"trend\".\\n</think>\\n\\n<Answer>trend</Answer>',\n",
       "       '<think>\\nOkay, the user is playing Wordle and has already made some guesses. The current belief state is based on the feedback from the previous attempts. The user is on their fourth attempt, so they have two more tries left. The task is to determine the correct five-letter word based on the given belief.\\n\\nFirst, I need to analyze the feedback from the guess \"trend\". The environment\\'s response indicates that the first letter \\'t\\' is correct and in the right position, the second letter \\'r\\' is also correct, the third letter \\'e\\' is present but not in position 3, the fourth letter \\'n\\' is not in the word, and the fifth letter \\'d\\' is correct. \\n\\nSo, from this, the secret word must start with \\'t\\', followed by \\'r\\', end with \\'d\\', and have an \\'e\\' somewhere else. The \\'n\\' is eliminated. The third letter in the guess is \\'e\\', which is in the word but not in position 3, so the \\'e\\' must be in position 4. That leaves the third position to be another letter. \\n\\nPossible words that fit this pattern are \"tried\" (t-r-i-e-d) or \"tread\" (t-r-e-a-d), but \"tread\" includes an \\'a\\' which wasn\\'t confirmed. However, the first guess was \"stare\", and the feedback indicated that \\'a\\' is not in the word. Therefore, \"tread\" is out. \"Tried\" fits all the constraints: \\'t\\', \\'r\\', \\'i\\', \\'e\\', \\'d\\'. The \\'e\\' is in position 4, which matches the feedback that \\'e\\' is present but not in position 3. \\n\\nSince the user has two attempts left, it\\'s important to maximize information. However, since \"tried\" fits all the clues, it\\'s the most logical choice. There\\'s no need for further guesses if \"tried\" is correct.\\n</think>\\n\\n<Answer>tried</Answer>',\n",
       "       '<think>\\nOkay, so I need to figure out the secret Wordle word. The user mentioned that it\\'s the start of the game, so there are no previous beliefs. Since it\\'s the first guess, I should choose a word that\\'s common and has a good chance of being correct. But wait, the user says they\\'re on their second attempt. Wait, no, the initial message says \"You are currently taking your attempt 2, and you have a total of 6 attempts.\" Hmm, that\\'s confusing. Wait, maybe there was a previous attempt? But the belief state says it\\'s the start of the game, so maybe the user is just starting, and the second attempt is the first guess? Or maybe there was a mistake in the count.\\n\\nBut according to the belief state, it\\'s the start, so no prior information. So the first guess is attempt 1. But the user says they\\'re on attempt 2. Maybe there\\'s a misunderstanding. But regardless, the user wants the first guess. Since there\\'s no prior information, I should pick a common Wordle word. Wordle words are five letters, and common ones might be \"crane\", \"steer\", \"stone\", \"apple\", \"black\", \"spice\", \"audio\", etc. But since the user is on attempt 2, maybe the first guess was wrong? But the belief state says it\\'s the start, so perhaps the user is just starting, and the second attempt is the first guess. Maybe the user made a mistake in counting. Either way, the first guess should be a word that\\'s likely. Maybe \"crane\" is a good choice because it\\'s a common word and has a good mix of letters. Alternatively, \"stone\" is also common. Alternatively, \"apple\" is a common word. But I need to pick one. Since the user is on attempt 2, maybe the first guess was \"crane\" and it was wrong. But since the belief state is the start, maybe the first guess is the first attempt. So I should just pick a common word. Let\\'s go with \"crane\" as the first guess.\\n</think>\\n\\n<Answer>crane</Answer>',\n",
       "       '<think>\\nOkay, let me try to figure this out. The user mentioned that the game is Wordle, and they want me to make a guess. The initial instruction says to make the first guess, but then there\\'s a mention of the current belief state being \"tags\" and the user is asking for the next guess. Wait, maybe the user is providing a scenario where the agent has already made some guesses, and now they need the next one.\\n\\nBut the user\\'s message is a bit confusing. Let me parse it again. The user says: \"You are playing a game of Wordle. Format your response in the following way: <Answer> your guess of what the word should be </Answer> The game begins now, please make your first guess about the secret five-letter word! You are currently taking your attempt 3, and you have a total of 6 attempts. Look at the current belief state and give an answer based on it. Give an answer that leads to optimal exploration and do not be greedy unless it is the last attempt. Try to maximize the amount of information you have so that you can solve the task correctly. Belief: tags. Then, the next action (guess) is to be determined. But the user is asking for the answer (the guess) in the format <Answer> ... </Answer>. Wait, the initial instruction says: \"Please make your first guess about the secret five-letter word!\" So the user is asking for the first guess, which is \\'crane\\', but the environment\\'s response is given. Then, the assistant is to update the belief based on that response and then make the next guess.\"\\n\\nHmm, this is a bit tangled. Let me try to break it down. The user is simulating a game where the player has already made some guesses. The current belief state is \"tags\", which probably refers to the possible words that are consistent with the previous guesses and the feedback received. The user is asking for the next guess, which is the third attempt out of six. The assistant needs to give a guess that maximizes information gain, not being greedy unless it\\'s the last attempt.\\n\\nSo, the first guess was \\'crane\\', and the environment\\'s response (which the user hasn\\'t provided) would have given some feedback. But since the user hasn\\'t given that feedback, maybe the belief state \"tags\" is the result of the first guess. Wait, maybe the user is showing that after the first guess \\'crane\\', the belief state is now \"tags\", which could be the set of possible words that match the feedback. But without knowing the actual feedback, it\\'s hard to say. However, the user is asking for the next guess, which is the third attempt. The assistant needs to choose a word that would split the possible remaining words into as many groups as possible, based on the current belief state of \"tags\".\\n\\nBut \"tags\" as a belief state is unclear. Maybe \"tags\" refers to the letters that are in the correct position, or some other clue. Alternatively, maybe \"tags\" is a placeholder for the possible words that the agent thinks are candidates. However, without knowing the exact feedback from the first guess, it\\'s challenging to proceed. But the user might have intended that after the first guess \\'crane\\', the agent received some feedback, leading to the belief state being \"tags\", and now the assistant needs to make the next guess.\\n\\nSince the user is asking for the next guess (third attempt), and the belief is \"tags\", perhaps the assistant should choose a word that would maximize the information gain. For example, if the secret word is in the \"tags\" category, maybe words that have common letters or patterns. But since I don\\'t have the exact feedback, I need to make an educated guess. Alternatively, maybe \"tags\" is a hint that the correct word has the letters T, A, G, S, but that\\'s only four letters. Wait, the secret word is five letters. So maybe \"tags\" is part of the feedback, like letters that are correct but in the wrong position, or something else.\\n\\nAlternatively, maybe the belief state \"tags\" is the set of possible words that the agent thinks are possible. For example, if the first guess was \\'crane\\' and the feedback was that none of the letters were correct, then the possible words would be different. But without knowing the feedback, it\\'s hard to say. However, the user is asking for the next guess, so the assistant must choose a word that would best narrow down the possibilities.\\n\\nIn Wordle, each guess gives feedback on which letters are correct and in the right position (green), which are correct but in the wrong position (yellow), and which are incorrect (gray). The belief state \"tags\" might indicate that the correct word has some letters that are in the word but not in the right position, or something else. But without more context, it\\'s challenging.\\n\\nGiven that the user is asking for the third guess, and the total attempts are 6, the assistant should choose a word that is likely to reveal more information. For example, if the secret word is a common five-letter word, maybe something like \"stone\" or \"check\" could be good. Alternatively, if the belief is that the word contains the letters T, A, G, S, then a word like \"stags\" might be a good guess, but that\\'s a 5-letter word. However, if the belief is that the word is \"tags\", but that\\'s only four letters, maybe the correct word is \"stags\".\\n\\nBut given that the user hasn\\'t provided the actual feedback from the first guess, I have to make an assumption. If the belief state is \"tags\", perhaps the correct word is \"stags\", which is a 5-letter word. So the next guess would be \"stags\". Alternatively, if the belief is that the correct word has the letters T, A, G, S, but not necessarily in that order, then \"stags\" could be the right guess.\\n\\nAlternatively, maybe \"tags\" is a hint that the correct word is \"stags\", and the assistant should guess that. So the answer would be <Answer>stags</Answer>.\\n</think>\\n\\n<Answer>stags</Answer>',\n",
       "       \"<think>\\nOkay, the user is playing Wordle and has made a guess called 'crane', but the environment says it doesn't have five letters, which is impossible. The user is asking for the first guess, and the assistant needs to provide a five-letter word. The initial belief is 'tags', so maybe the secret word is 'tags'. But the guess 'crane' is invalid. However, 'crane' is a valid five-letter word. The environment's response must be incorrect. The assistant should proceed with the correct guess. Since the user is asking for the first guess, the answer should be 'crane' as it's a valid word. The environment's error is likely a mistake, so the assistant should ignore it and proceed.\\n</think>\\n\\n<Answer>crane</Answer>\",\n",
       "       \"<think>\\nOkay, the user is playing Wordle and has made a guess called 'crane'. The environment responded that 'crane' doesn't have five letters but has 37, which is impossible. So there's a mistake here. The correct response should be that 'crane' is a valid guess, but the environment's response is wrong. The user is asking for the first guess, so maybe the initial guess was 'crane', but the environment's response is incorrect. The assistant needs to update the belief based on the environment's response, even if it's wrong. Since 'crane' is a valid five-letter word, the environment's response is wrong, so the assistant should adjust the belief to reflect that 'crane' is incorrect. Therefore, the next guess should be a different word. However, the user is asking for the first guess, which is 'crane', but the environment says it's invalid. The assistant must output the next guess after updating the belief. The correct answer should be a different word, but since the user's initial message is confusing, the assistant should proceed with the next logical guess based on the invalid response. Maybe the next guess is 'apple' or 'crane' again. But given the environment's error, the assistant should choose a valid word. The final answer should be the next guess after the invalid response.\\n</think>\\n\\n<Answer>apple</Answer>\",\n",
       "       '<think>\\nOkay, let me try to figure this out. The user is playing Wordle and has made a mistake in their first guess with \"crane\", but the environment says it\\'s not a five-letter word. Wait, that doesn\\'t make sense because \"crane\" is definitely five letters. Maybe the environment made an error in validating the word. The user then tried \"apple\", and the environment said none of its letters are in the target word. So the secret word doesn\\'t have a, p, l, or e. \\n\\nNow, the user is on their sixth attempt. Since the environment\\'s response to \"apple\" indicates that the secret word doesn\\'t contain any of those letters, the next guess should avoid those letters. The word \"crane\" has a \\'c\\', \\'r\\', \\'a\\', \\'n\\', \\'e\\'. But since \"apple\" was invalid, the secret word can\\'t have a, p, l, or e. Wait, but \"crane\" has \\'a\\' and \\'e\\', which would make it invalid. So maybe the environment\\'s initial response to \"crane\" was incorrect, but the user is supposed to proceed despite that. Alternatively, maybe the secret word is \"crane\" and the environment\\'s validation was wrong. \\n\\nGiven that the user is on their sixth attempt, they need to make an educated guess. Since \"apple\" was invalid, the secret word must not have a, p, l, e. So possible letters are b, c, d, f, g, h, i, j, k, m, n, o, q, r, s, t, u, v, w, x, y, z. The word \"crane\" has \\'c\\', \\'r\\', \\'a\\', \\'n\\', \\'e\\'—but \\'a\\' and \\'e\\' are excluded. So \"crane\" can\\'t be the answer. Maybe the correct word is \"crane\" but the environment\\'s initial validation was wrong. Alternatively, maybe the correct word is \"crane\" and the user should guess it again. But since the user is on the sixth attempt, maybe they need to try a different word. However, given the previous invalid response, the user might have to guess \"crane\" again despite the error. Alternatively, maybe the correct answer is \"crane\" and the environment\\'s first response was a mistake. So the best guess here is \"crane\".\\n</think>\\n\\n<Answer>crane</Answer>',\n",
       "       '<think>\\nOkay, the user is playing Wordle and has already made two guesses: \"crane\" and \"apple\". The environment\\'s responses indicate that \"crane\" has \\'r\\' in the word but in a different position, and \"apple\" has none of its letters in the target word. So, the secret word doesn\\'t include \\'c\\', \\'a\\', \\'n\\', \\'e\\', \\'p\\', \\'l\\', or \\'e\\'. The remaining letters allowed are \\'r\\' and others not in those excluded sets. The next guess should be a 5-letter word containing \\'r\\' and avoiding the excluded letters. \"Routs\" fits this: r, o, u, t, s. None of these letters are in \"apple\", and \\'r\\' is present. So, \"routs\" is a logical next guess.\\n</think>\\n\\n<Answer>routs</Answer>',\n",
       "       '<think>\\nOkay, the user is playing Wordle and needs help with their first guess. The instructions say to format the response as <Answer> followed by the guessed word. Since it\\'s the start of the game, there are no prior beliefs or clues. The assistant should choose a word that\\'s common and likely to provide useful feedback. Words like \"crane\" or \"steal\" are often good first guesses because they have a mix of vowels and consonants. But maybe \"crane\" is a better choice because it\\'s a common word and has the vowels A and E, which are frequent in Wordle answers. Alternatively, \"apple\" is another common word. Wait, but the user mentioned that the assistant should maximize information, so a word with varied letters that can cover different possibilities. \"crane\" has C, R, A, N, E – that\\'s a good mix. Let me check if there are any other considerations. Since it\\'s the first guess, the assistant should pick a word that\\'s likely to be in the list of possible answers. Maybe \"adobe\" or \"crane\" are better. I think \"crane\" is a solid choice here. So the answer should be <Answer>crane</Answer>.\\n</think>\\n\\n<Answer>crane</Answer>'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['model'].str.contains('qwen', case=False)].head(10)['raw_guess'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b46ad10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151, 145, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print([len(x) for x in df[df['model'].str.contains('qwen', case=False)].head(10)['belief'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bde9367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.iloc[0]['word_limit']:\n",
    "    df['word_limit'] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc168b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "info\n",
       "belief     9462\n",
       "both       9194\n",
       "history    8863\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['info'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b25cbae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model_info'] = df['model'].astype(str) + ' (' + df['info'].astype(str) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eae9f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model'] = df['model_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68295a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.585833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std</td>\n",
       "      <td>0.492680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count</td>\n",
       "      <td>2400.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     response\n",
       "0   mean     0.585833\n",
       "1    std     0.492680\n",
       "2  count  2400.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "won = df.groupby(['model', 'game_id', 'env', 'word_limit'])['response'].apply(\n",
    "        lambda responses: any('goal reached' in resp.lower() for resp in responses))\n",
    "won.agg(['mean', 'std', 'count']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2956b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "def summarize_game_outcomes(df):\n",
    "    df['response'] = df['response'].str.lower()\n",
    "    grouped = df.groupby(['model', 'game_id', 'env', 'word_limit'])['response'].apply(\n",
    "        lambda responses: any('goal reached' in resp for resp in responses)\n",
    "    ).reset_index(name='won')\n",
    "    return grouped\n",
    "\n",
    "def plot_win_rates(summary_df):\n",
    "    # Compute mean and std of win rates for each group\n",
    "    stats = summary_df.groupby(['env', 'model', 'word_limit'])['won'].agg(['mean', 'std', 'count']).reset_index()\n",
    "    stats['success_rate'] = stats['mean'] * 100\n",
    "    # Standard error of the mean (SEM)\n",
    "    stats['sem'] = stats['std'] / np.sqrt(stats['count'])\n",
    "    stats['sem'] = stats['sem'].fillna(0)\n",
    "    stats['success_rate_sem'] = stats['sem'] * 100\n",
    "\n",
    "    envs = stats['env'].unique()\n",
    "    models = stats['model'].unique()[[0, 2, 1, 3, 5, 4, 6, 8, 7, 9, 11, 10]]\n",
    "    word_limits = sorted(stats['word_limit'].unique())\n",
    "\n",
    "    colors = [\n",
    "        \"#ADD8E6\",  # light blue\n",
    "        \"#4682B4\",  # medium blue\n",
    "        \"#003366\",  # dark blue\n",
    "        \"#FFB6C1\",  # light red\n",
    "        \"#FF6347\",  # medium red\n",
    "        \"#8B0000\",  # dark red\n",
    "        \"#90EE90\",  # light green\n",
    "        \"#32CD32\",  # medium green\n",
    "        \"#006400\",  # dark green\n",
    "        \"#E6E6FA\",  # light purple\n",
    "        \"#9370DB\",  # medium purple\n",
    "        \"#800080\",  # dark purple\n",
    "    ]\n",
    "    color_map = {model: colors[i % len(colors)] for i, model in enumerate(models)}\n",
    "\n",
    "    # Create subplots: rows = word_limit values, cols = envs\n",
    "    fig = make_subplots(\n",
    "        rows=len(word_limits), cols=len(envs),\n",
    "        subplot_titles=[f\"{env}\" for env in envs],\n",
    "        shared_yaxes=True,\n",
    "        vertical_spacing=0.2 / len(word_limits),\n",
    "        horizontal_spacing=0.03\n",
    "    )\n",
    "\n",
    "    for r, wl in enumerate(word_limits, start=1):\n",
    "        for c, env in enumerate(envs, start=1):\n",
    "            for model in models:\n",
    "                subset = stats[\n",
    "                    (stats['env'] == env) &\n",
    "                    (stats['model'] == model) &\n",
    "                    (stats['word_limit'] == wl)\n",
    "                ]\n",
    "                if not subset.empty:\n",
    "                    # Plot bar with error bar (standard error of mean)\n",
    "                    fig.add_trace(\n",
    "                        go.Bar(\n",
    "                            x=[model],\n",
    "                            y=subset['success_rate'],\n",
    "                            name=model,\n",
    "                            marker_color=color_map[model],\n",
    "                            width=0.8,\n",
    "                            showlegend=(r == 1 and c == 1),\n",
    "                            error_y=dict(\n",
    "                                type='data',\n",
    "                                array=subset['success_rate_sem'],\n",
    "                                visible=True,\n",
    "                                color='black',\n",
    "                                thickness=1,\n",
    "                                width=4,\n",
    "                            ),\n",
    "                            hovertemplate=(\n",
    "                                f\"Env: {env}<br>\"\n",
    "                                f\"Word Limit: {wl}<br>\"\n",
    "                                f\"Model: {model}<br>\"\n",
    "                                f\"Success Rate: {{y:.2f}}%<br>\"\n",
    "                                f\"SEM: {subset['success_rate_sem'].values[0]:.2f}%<br>\"\n",
    "                                f\"N: {subset['count'].values[0]}\"\n",
    "                            ),\n",
    "                        ),\n",
    "                        row=r, col=c\n",
    "                    )\n",
    "            # # Add row label for word_limit\n",
    "            # if c == 1:\n",
    "            #     fig.add_annotation(\n",
    "            #         text=f\"Word Limit: {wl}\",\n",
    "            #         xref=\"paper\",\n",
    "            #         yref=\"paper\",\n",
    "            #         x=0.1,\n",
    "            #         y=0.95 - ((r - 1) / len(word_limits)),\n",
    "            #         showarrow=False,\n",
    "            #         font=dict(size=14)\n",
    "            #     )\n",
    "\n",
    "    # Update y-axis\n",
    "    for r in range(1, len(word_limits) + 1):\n",
    "        for c in range(1, len(envs) + 1):\n",
    "            fig.update_yaxes(\n",
    "                range=[0, 100],\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgray',\n",
    "                row=r, col=c\n",
    "            )\n",
    "\n",
    "    # Update x-axis to remove tick labels\n",
    "    for r in range(1, len(word_limits) + 1):\n",
    "        for c in range(1, len(envs) + 1):\n",
    "            fig.update_xaxes(\n",
    "                showticklabels=False,\n",
    "                row=r, col=c\n",
    "            )\n",
    "\n",
    "    # Fixed subplot size\n",
    "    fig_width = 180 * len(envs)\n",
    "    fig_height = 200 * len(word_limits)\n",
    "\n",
    "    # Layout with horizontal legend\n",
    "    fig.update_layout(\n",
    "        height=fig_height + 150,\n",
    "        width=fig_width,\n",
    "        template='simple_white',\n",
    "        font=dict(family='Computer Modern, serif', size=16),\n",
    "        barmode='group',\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            title='Models',\n",
    "            orientation='h',\n",
    "            yanchor='bottom',\n",
    "            y=1.18,\n",
    "            xanchor='center',\n",
    "            x=0.5,\n",
    "            bgcolor='rgba(255,255,255,0.9)',\n",
    "            bordercolor='black',\n",
    "            borderwidth=1\n",
    "        ),\n",
    "        margin=dict(t=100, b=50, l=80, r=20),\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Avg. Success Rate\", row=1, col=1)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "63b18c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_belief = df.loc[df['info'] == 'belief'].copy()\n",
    "df_history = df.loc[df['info'] == 'history'].copy()\n",
    "summary_df = summarize_game_outcomes(df)\n",
    "summary_df_belief = summarize_game_outcomes(df_belief)\n",
    "summary_df_history = summarize_game_outcomes(df_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2bb59921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "error_y": {
          "array": {
           "bdata": "Oq5djk78H0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: customer_service<br>Word Limit: None<br>Model: deepseek/deepseek-chat (belief)<br>Success Rate: {y:.2f}%<br>SEM: 8.00%<br>N: 40",
         "marker": {
          "color": "#ADD8E6"
         },
         "name": "deepseek/deepseek-chat (belief)",
         "showlegend": true,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (belief)"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAADAR0A=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "error_y": {
          "array": {
           "bdata": "SrExFSa/GkA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: customer_service<br>Word Limit: None<br>Model: deepseek/deepseek-chat (history)<br>Success Rate: {y:.2f}%<br>SEM: 6.69%<br>N: 40",
         "marker": {
          "color": "#4682B4"
         },
         "name": "deepseek/deepseek-chat (history)",
         "showlegend": true,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (history)"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAABgU0A=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "error_y": {
          "array": {
           "bdata": "aCzJDxtaHUA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: customer_service<br>Word Limit: None<br>Model: deepseek/deepseek-chat (both)<br>Success Rate: {y:.2f}%<br>SEM: 7.34%<br>N: 40",
         "marker": {
          "color": "#003366"
         },
         "name": "deepseek/deepseek-chat (both)",
         "showlegend": true,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (both)"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAACAUUA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "error_y": {
          "array": {
           "bdata": "Ahd5rIyZHEA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: customer_service<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (belief)<br>Success Rate: {y:.2f}%<br>SEM: 7.15%<br>N: 40",
         "marker": {
          "color": "#FFB6C1"
         },
         "name": "deepseek/deepseek-r1 (belief)",
         "showlegend": true,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (belief)"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAgUkA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "error_y": {
          "array": {
           "bdata": "tSto3kcDIEA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: customer_service<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (history)<br>Success Rate: {y:.2f}%<br>SEM: 8.01%<br>N: 40",
         "marker": {
          "color": "#FF6347"
         },
         "name": "deepseek/deepseek-r1 (history)",
         "showlegend": true,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (history)"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAASUA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "error_y": {
          "array": {
           "bdata": "3jIj3+2MHkA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: customer_service<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (both)<br>Success Rate: {y:.2f}%<br>SEM: 7.64%<br>N: 40",
         "marker": {
          "color": "#8B0000"
         },
         "name": "deepseek/deepseek-r1 (both)",
         "showlegend": true,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (both)"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAABAUEA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "error_y": {
          "array": {
           "bdata": "pmfjCiM3E0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: customer_service<br>Word Limit: None<br>Model: google/gemini-2.5-pro (belief)<br>Success Rate: {y:.2f}%<br>SEM: 4.80%<br>N: 40",
         "marker": {
          "color": "#90EE90"
         },
         "name": "google/gemini-2.5-pro (belief)",
         "showlegend": true,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (belief)"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAACAVkA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "error_y": {
          "array": {
           "bdata": "AAAAAAAAAAA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: customer_service<br>Word Limit: None<br>Model: google/gemini-2.5-pro (history)<br>Success Rate: {y:.2f}%<br>SEM: 0.00%<br>N: 40",
         "marker": {
          "color": "#32CD32"
         },
         "name": "google/gemini-2.5-pro (history)",
         "showlegend": true,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (history)"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAAWUA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "error_y": {
          "array": {
           "bdata": "sfa0FlfrC0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: customer_service<br>Word Limit: None<br>Model: google/gemini-2.5-pro (both)<br>Success Rate: {y:.2f}%<br>SEM: 3.49%<br>N: 40",
         "marker": {
          "color": "#006400"
         },
         "name": "google/gemini-2.5-pro (both)",
         "showlegend": true,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (both)"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAADAV0A=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "error_y": {
          "array": {
           "bdata": "Z5tdmim8G0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: guess_my_city<br>Word Limit: None<br>Model: deepseek/deepseek-chat (belief)<br>Success Rate: {y:.2f}%<br>SEM: 6.93%<br>N: 40",
         "marker": {
          "color": "#ADD8E6"
         },
         "name": "deepseek/deepseek-chat (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (belief)"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AAAAAADAUkA=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "error_y": {
          "array": {
           "bdata": "TLIiNnfdH0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: guess_my_city<br>Word Limit: None<br>Model: deepseek/deepseek-chat (history)<br>Success Rate: {y:.2f}%<br>SEM: 7.97%<br>N: 40",
         "marker": {
          "color": "#4682B4"
         },
         "name": "deepseek/deepseek-chat (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (history)"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AQAAAACAS0A=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "error_y": {
          "array": {
           "bdata": "o9OluepgH0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: guess_my_city<br>Word Limit: None<br>Model: deepseek/deepseek-chat (both)<br>Success Rate: {y:.2f}%<br>SEM: 7.84%<br>N: 40",
         "marker": {
          "color": "#003366"
         },
         "name": "deepseek/deepseek-chat (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (both)"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AAAAAAAATkA=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "error_y": {
          "array": {
           "bdata": "TLIiNnfdH0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: guess_my_city<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (belief)<br>Success Rate: {y:.2f}%<br>SEM: 7.97%<br>N: 40",
         "marker": {
          "color": "#FFB6C1"
         },
         "name": "deepseek/deepseek-r1 (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (belief)"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AQAAAACAS0A=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "error_y": {
          "array": {
           "bdata": "3DIj3+2MHkA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: guess_my_city<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (history)<br>Success Rate: {y:.2f}%<br>SEM: 7.64%<br>N: 40",
         "marker": {
          "color": "#FF6347"
         },
         "name": "deepseek/deepseek-r1 (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (history)"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AAAAAABAUEA=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "error_y": {
          "array": {
           "bdata": "N65djk78H0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: guess_my_city<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (both)<br>Success Rate: {y:.2f}%<br>SEM: 8.00%<br>N: 40",
         "marker": {
          "color": "#8B0000"
         },
         "name": "deepseek/deepseek-r1 (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (both)"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AAAAAABASkA=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "error_y": {
          "array": {
           "bdata": "h9/ZY9meGUA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: guess_my_city<br>Word Limit: None<br>Model: google/gemini-2.5-pro (belief)<br>Success Rate: {y:.2f}%<br>SEM: 6.41%<br>N: 40",
         "marker": {
          "color": "#90EE90"
         },
         "name": "google/gemini-2.5-pro (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (belief)"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AAAAAAAAVEA=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "error_y": {
          "array": {
           "bdata": "BlaVCF5WGEA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: guess_my_city<br>Word Limit: None<br>Model: google/gemini-2.5-pro (history)<br>Success Rate: {y:.2f}%<br>SEM: 6.08%<br>N: 40",
         "marker": {
          "color": "#32CD32"
         },
         "name": "google/gemini-2.5-pro (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (history)"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AAAAAACgVEA=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "error_y": {
          "array": {
           "bdata": "Bhd5rIyZHEA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: guess_my_city<br>Word Limit: None<br>Model: google/gemini-2.5-pro (both)<br>Success Rate: {y:.2f}%<br>SEM: 7.15%<br>N: 40",
         "marker": {
          "color": "#006400"
         },
         "name": "google/gemini-2.5-pro (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (both)"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AAAAAAAgUkA=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "error_y": {
          "array": {
           "bdata": "s/a0FlfrC0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: deepseek/deepseek-chat (belief)<br>Success Rate: {y:.2f}%<br>SEM: 3.49%<br>N: 40",
         "marker": {
          "color": "#ADD8E6"
         },
         "name": "deepseek/deepseek-chat (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (belief)"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAAAAFEA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "error_y": {
          "array": {
           "bdata": "s/a0FlfrC0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: deepseek/deepseek-chat (history)<br>Success Rate: {y:.2f}%<br>SEM: 3.49%<br>N: 40",
         "marker": {
          "color": "#4682B4"
         },
         "name": "deepseek/deepseek-chat (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (history)"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAAAAFEA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "error_y": {
          "array": {
           "bdata": "s/a0FlfrC0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: deepseek/deepseek-chat (both)<br>Success Rate: {y:.2f}%<br>SEM: 3.49%<br>N: 40",
         "marker": {
          "color": "#003366"
         },
         "name": "deepseek/deepseek-chat (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (both)"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAAAAFEA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "error_y": {
          "array": {
           "bdata": "3zIj3+2MHkA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (belief)<br>Success Rate: {y:.2f}%<br>SEM: 7.64%<br>N: 40",
         "marker": {
          "color": "#FFB6C1"
         },
         "name": "deepseek/deepseek-r1 (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (belief)"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAACAQUA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "error_y": {
          "array": {
           "bdata": "aCzJDxtaHUA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (history)<br>Success Rate: {y:.2f}%<br>SEM: 7.34%<br>N: 40",
         "marker": {
          "color": "#FF6347"
         },
         "name": "deepseek/deepseek-r1 (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (history)"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAACAUUA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "error_y": {
          "array": {
           "bdata": "N65djk78H0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (both)<br>Success Rate: {y:.2f}%<br>SEM: 8.00%<br>N: 40",
         "marker": {
          "color": "#8B0000"
         },
         "name": "deepseek/deepseek-r1 (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (both)"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAABASkA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "error_y": {
          "array": {
           "bdata": "AAAAAAAABEA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: google/gemini-2.5-pro (belief)<br>Success Rate: {y:.2f}%<br>SEM: 2.50%<br>N: 40",
         "marker": {
          "color": "#90EE90"
         },
         "name": "google/gemini-2.5-pro (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (belief)"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAABgWEA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "error_y": {
          "array": {
           "bdata": "AAAAAAAAAAA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: google/gemini-2.5-pro (history)<br>Success Rate: {y:.2f}%<br>SEM: 0.00%<br>N: 40",
         "marker": {
          "color": "#32CD32"
         },
         "name": "google/gemini-2.5-pro (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (history)"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAAAAWUA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "error_y": {
          "array": {
           "bdata": "AAAAAAAABEA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: google/gemini-2.5-pro (both)<br>Success Rate: {y:.2f}%<br>SEM: 2.50%<br>N: 40",
         "marker": {
          "color": "#006400"
         },
         "name": "google/gemini-2.5-pro (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (both)"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAABgWEA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "error_y": {
          "array": {
           "bdata": "c8uQtNYuFUA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: Qwen/Qwen3-4B (belief)<br>Success Rate: {y:.2f}%<br>SEM: 5.30%<br>N: 40",
         "marker": {
          "color": "#E6E6FA"
         },
         "name": "Qwen/Qwen3-4B (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "Qwen/Qwen3-4B (belief)"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAAAAKUA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "error_y": {
          "array": {
           "bdata": "AAAAAAAABEA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: Qwen/Qwen3-4B (history)<br>Success Rate: {y:.2f}%<br>SEM: 2.50%<br>N: 40",
         "marker": {
          "color": "#9370DB"
         },
         "name": "Qwen/Qwen3-4B (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "Qwen/Qwen3-4B (history)"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAAAABEA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "error_y": {
          "array": {
           "bdata": "5A0/OdzeEEA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: Qwen/Qwen3-4B (both)<br>Success Rate: {y:.2f}%<br>SEM: 4.22%<br>N: 40",
         "marker": {
          "color": "#800080"
         },
         "name": "Qwen/Qwen3-4B (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "Qwen/Qwen3-4B (both)"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAAAAHkA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "error_y": {
          "array": {
           "bdata": "2zIj3+2MHkA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: murder_mystery<br>Word Limit: None<br>Model: deepseek/deepseek-chat (belief)<br>Success Rate: {y:.2f}%<br>SEM: 7.64%<br>N: 40",
         "marker": {
          "color": "#ADD8E6"
         },
         "name": "deepseek/deepseek-chat (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (belief)"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "AAAAAACAQUA=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "error_y": {
          "array": {
           "bdata": "SrExFSa/GkA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: murder_mystery<br>Word Limit: None<br>Model: deepseek/deepseek-chat (history)<br>Success Rate: {y:.2f}%<br>SEM: 6.69%<br>N: 40",
         "marker": {
          "color": "#4682B4"
         },
         "name": "deepseek/deepseek-chat (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (history)"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "AAAAAABgU0A=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "error_y": {
          "array": {
           "bdata": "BBd5rIyZHEA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: murder_mystery<br>Word Limit: None<br>Model: deepseek/deepseek-chat (both)<br>Success Rate: {y:.2f}%<br>SEM: 7.15%<br>N: 40",
         "marker": {
          "color": "#003366"
         },
         "name": "deepseek/deepseek-chat (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (both)"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "AAAAAAAgUkA=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "error_y": {
          "array": {
           "bdata": "dMuQtNYuFUA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: murder_mystery<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (belief)<br>Success Rate: {y:.2f}%<br>SEM: 5.30%<br>N: 40",
         "marker": {
          "color": "#FFB6C1"
         },
         "name": "deepseek/deepseek-r1 (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (belief)"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "AAAAAAAAKUA=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "error_y": {
          "array": {
           "bdata": "pmfjCiM3E0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: murder_mystery<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (history)<br>Success Rate: {y:.2f}%<br>SEM: 4.80%<br>N: 40",
         "marker": {
          "color": "#FF6347"
         },
         "name": "deepseek/deepseek-r1 (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (history)"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "AAAAAACAVkA=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "error_y": {
          "array": {
           "bdata": "kbJbjM2pH0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: murder_mystery<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (both)<br>Success Rate: {y:.2f}%<br>SEM: 7.92%<br>N: 40",
         "marker": {
          "color": "#8B0000"
         },
         "name": "deepseek/deepseek-r1 (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (both)"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "AAAAAABARUA=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "error_y": {
          "array": {
           "bdata": "pmfjCiM3E0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: murder_mystery<br>Word Limit: None<br>Model: google/gemini-2.5-pro (belief)<br>Success Rate: {y:.2f}%<br>SEM: 4.80%<br>N: 40",
         "marker": {
          "color": "#90EE90"
         },
         "name": "google/gemini-2.5-pro (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (belief)"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "AAAAAACAVkA=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "error_y": {
          "array": {
           "bdata": "h9/ZY9meGUA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: murder_mystery<br>Word Limit: None<br>Model: google/gemini-2.5-pro (history)<br>Success Rate: {y:.2f}%<br>SEM: 6.41%<br>N: 40",
         "marker": {
          "color": "#32CD32"
         },
         "name": "google/gemini-2.5-pro (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (history)"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "AAAAAAAAVEA=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "error_y": {
          "array": {
           "bdata": "hN/ZY9meGUA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: murder_mystery<br>Word Limit: None<br>Model: google/gemini-2.5-pro (both)<br>Success Rate: {y:.2f}%<br>SEM: 6.41%<br>N: 40",
         "marker": {
          "color": "#006400"
         },
         "name": "google/gemini-2.5-pro (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (both)"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "AAAAAAAAVEA=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        },
        {
         "error_y": {
          "array": {
           "bdata": "3jIj3+2MHkA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: twenty_questions<br>Word Limit: None<br>Model: deepseek/deepseek-chat (belief)<br>Success Rate: {y:.2f}%<br>SEM: 7.64%<br>N: 40",
         "marker": {
          "color": "#ADD8E6"
         },
         "name": "deepseek/deepseek-chat (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (belief)"
         ],
         "xaxis": "x5",
         "y": {
          "bdata": "AAAAAACAQUA=",
          "dtype": "f8"
         },
         "yaxis": "y5"
        },
        {
         "error_y": {
          "array": {
           "bdata": "Oq5djk78H0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: twenty_questions<br>Word Limit: None<br>Model: deepseek/deepseek-chat (history)<br>Success Rate: {y:.2f}%<br>SEM: 8.00%<br>N: 40",
         "marker": {
          "color": "#4682B4"
         },
         "name": "deepseek/deepseek-chat (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (history)"
         ],
         "xaxis": "x5",
         "y": {
          "bdata": "AAAAAADAR0A=",
          "dtype": "f8"
         },
         "yaxis": "y5"
        },
        {
         "error_y": {
          "array": {
           "bdata": "N65djk78H0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: twenty_questions<br>Word Limit: None<br>Model: deepseek/deepseek-chat (both)<br>Success Rate: {y:.2f}%<br>SEM: 8.00%<br>N: 40",
         "marker": {
          "color": "#003366"
         },
         "name": "deepseek/deepseek-chat (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (both)"
         ],
         "xaxis": "x5",
         "y": {
          "bdata": "AAAAAADAR0A=",
          "dtype": "f8"
         },
         "yaxis": "y5"
        },
        {
         "error_y": {
          "array": {
           "bdata": "o9OluepgH0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: twenty_questions<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (belief)<br>Success Rate: {y:.2f}%<br>SEM: 7.84%<br>N: 40",
         "marker": {
          "color": "#FFB6C1"
         },
         "name": "deepseek/deepseek-r1 (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (belief)"
         ],
         "xaxis": "x5",
         "y": {
          "bdata": "AAAAAAAAREA=",
          "dtype": "f8"
         },
         "yaxis": "y5"
        },
        {
         "error_y": {
          "array": {
           "bdata": "odOluepgH0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: twenty_questions<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (history)<br>Success Rate: {y:.2f}%<br>SEM: 7.84%<br>N: 40",
         "marker": {
          "color": "#FF6347"
         },
         "name": "deepseek/deepseek-r1 (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (history)"
         ],
         "xaxis": "x5",
         "y": {
          "bdata": "AAAAAAAATkA=",
          "dtype": "f8"
         },
         "yaxis": "y5"
        },
        {
         "error_y": {
          "array": {
           "bdata": "TLIiNnfdH0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: twenty_questions<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (both)<br>Success Rate: {y:.2f}%<br>SEM: 7.97%<br>N: 40",
         "marker": {
          "color": "#8B0000"
         },
         "name": "deepseek/deepseek-r1 (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (both)"
         ],
         "xaxis": "x5",
         "y": {
          "bdata": "AAAAAACARkA=",
          "dtype": "f8"
         },
         "yaxis": "y5"
        },
        {
         "error_y": {
          "array": {
           "bdata": "Oq5djk78H0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: twenty_questions<br>Word Limit: None<br>Model: google/gemini-2.5-pro (belief)<br>Success Rate: {y:.2f}%<br>SEM: 8.00%<br>N: 40",
         "marker": {
          "color": "#90EE90"
         },
         "name": "google/gemini-2.5-pro (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (belief)"
         ],
         "xaxis": "x5",
         "y": {
          "bdata": "AAAAAABASkA=",
          "dtype": "f8"
         },
         "yaxis": "y5"
        },
        {
         "error_y": {
          "array": {
           "bdata": "LixtFzkCH0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: twenty_questions<br>Word Limit: None<br>Model: google/gemini-2.5-pro (history)<br>Success Rate: {y:.2f}%<br>SEM: 7.75%<br>N: 40",
         "marker": {
          "color": "#32CD32"
         },
         "name": "google/gemini-2.5-pro (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (history)"
         ],
         "xaxis": "x5",
         "y": {
          "bdata": "AAAAAABAT0A=",
          "dtype": "f8"
         },
         "yaxis": "y5"
        },
        {
         "error_y": {
          "array": {
           "bdata": "aZtdmim8G0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: twenty_questions<br>Word Limit: None<br>Model: google/gemini-2.5-pro (both)<br>Success Rate: {y:.2f}%<br>SEM: 6.93%<br>N: 40",
         "marker": {
          "color": "#006400"
         },
         "name": "google/gemini-2.5-pro (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (both)"
         ],
         "xaxis": "x5",
         "y": {
          "bdata": "AAAAAADAUkA=",
          "dtype": "f8"
         },
         "yaxis": "y5"
        },
        {
         "error_y": {
          "array": {
           "bdata": "AAAAAAAAHkA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: deepseek/deepseek-chat (belief)<br>Success Rate: {y:.2f}%<br>SEM: 7.50%<br>N: 40",
         "marker": {
          "color": "#ADD8E6"
         },
         "name": "deepseek/deepseek-chat (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (belief)"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "AAAAAABAQEA=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        },
        {
         "error_y": {
          "array": {
           "bdata": "N65djk78H0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: deepseek/deepseek-chat (history)<br>Success Rate: {y:.2f}%<br>SEM: 8.00%<br>N: 40",
         "marker": {
          "color": "#4682B4"
         },
         "name": "deepseek/deepseek-chat (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (history)"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "AAAAAABASkA=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        },
        {
         "error_y": {
          "array": {
           "bdata": "kbJbjM2pH0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: deepseek/deepseek-chat (both)<br>Success Rate: {y:.2f}%<br>SEM: 7.92%<br>N: 40",
         "marker": {
          "color": "#003366"
         },
         "name": "deepseek/deepseek-chat (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-chat (both)"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "AAAAAABARUA=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        },
        {
         "error_y": {
          "array": {
           "bdata": "hi/qqfHeFkA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (belief)<br>Success Rate: {y:.2f}%<br>SEM: 5.72%<br>N: 40",
         "marker": {
          "color": "#FFB6C1"
         },
         "name": "deepseek/deepseek-r1 (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (belief)"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "AAAAAABAVUA=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        },
        {
         "error_y": {
          "array": {
           "bdata": "pmfjCiM3E0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (history)<br>Success Rate: {y:.2f}%<br>SEM: 4.80%<br>N: 40",
         "marker": {
          "color": "#FF6347"
         },
         "name": "deepseek/deepseek-r1 (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (history)"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "AAAAAACAVkA=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        },
        {
         "error_y": {
          "array": {
           "bdata": "B1aVCF5WGEA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: deepseek/deepseek-r1 (both)<br>Success Rate: {y:.2f}%<br>SEM: 6.08%<br>N: 40",
         "marker": {
          "color": "#8B0000"
         },
         "name": "deepseek/deepseek-r1 (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1 (both)"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "AAAAAACgVEA=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        },
        {
         "error_y": {
          "array": {
           "bdata": "h9/ZY9meGUA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: google/gemini-2.5-pro (belief)<br>Success Rate: {y:.2f}%<br>SEM: 6.41%<br>N: 40",
         "marker": {
          "color": "#90EE90"
         },
         "name": "google/gemini-2.5-pro (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (belief)"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "AAAAAAAAVEA=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        },
        {
         "error_y": {
          "array": {
           "bdata": "AAAAAAAABEA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: google/gemini-2.5-pro (history)<br>Success Rate: {y:.2f}%<br>SEM: 2.50%<br>N: 40",
         "marker": {
          "color": "#32CD32"
         },
         "name": "google/gemini-2.5-pro (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (history)"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "AAAAAABgWEA=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        },
        {
         "error_y": {
          "array": {
           "bdata": "s/a0FlfrC0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: google/gemini-2.5-pro (both)<br>Success Rate: {y:.2f}%<br>SEM: 3.49%<br>N: 40",
         "marker": {
          "color": "#006400"
         },
         "name": "google/gemini-2.5-pro (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "google/gemini-2.5-pro (both)"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "AAAAAADAV0A=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        },
        {
         "error_y": {
          "array": {
           "bdata": "pGfjCiM3E0A=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: Qwen/Qwen3-4B (belief)<br>Success Rate: {y:.2f}%<br>SEM: 4.80%<br>N: 40",
         "marker": {
          "color": "#E6E6FA"
         },
         "name": "Qwen/Qwen3-4B (belief)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "Qwen/Qwen3-4B (belief)"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "AAAAAAAAJEA=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        },
        {
         "error_y": {
          "array": {
           "bdata": "BBd5rIyZHEA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: Qwen/Qwen3-4B (history)<br>Success Rate: {y:.2f}%<br>SEM: 7.15%<br>N: 40",
         "marker": {
          "color": "#9370DB"
         },
         "name": "Qwen/Qwen3-4B (history)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "Qwen/Qwen3-4B (history)"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "AQAAAACAO0A=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        },
        {
         "error_y": {
          "array": {
           "bdata": "h9/ZY9meGUA=",
           "dtype": "f8"
          },
          "color": "black",
          "thickness": 1,
          "type": "data",
          "visible": true,
          "width": 4
         },
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: Qwen/Qwen3-4B (both)<br>Success Rate: {y:.2f}%<br>SEM: 6.41%<br>N: 40",
         "marker": {
          "color": "#800080"
         },
         "name": "Qwen/Qwen3-4B (both)",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "Qwen/Qwen3-4B (both)"
         ],
         "xaxis": "x6",
         "y": {
          "bdata": "AAAAAAAANEA=",
          "dtype": "f8"
         },
         "yaxis": "y6"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "customer_service",
          "x": 0.07083333333333333,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "guess_my_city",
          "x": 0.2425,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "mastermind",
          "x": 0.4141666666666667,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "murder_mystery",
          "x": 0.5858333333333334,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "twenty_questions",
          "x": 0.7575000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "wordle",
          "x": 0.9291666666666667,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "barmode": "group",
        "font": {
         "family": "Computer Modern, serif",
         "size": 16
        },
        "height": 350,
        "legend": {
         "bgcolor": "rgba(255,255,255,0.9)",
         "bordercolor": "black",
         "borderwidth": 1,
         "orientation": "h",
         "title": {
          "text": "Models"
         },
         "x": 0.5,
         "xanchor": "center",
         "y": 1.18,
         "yanchor": "bottom"
        },
        "margin": {
         "b": 50,
         "l": 80,
         "r": 20,
         "t": 100
        },
        "plot_bgcolor": "white",
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "width": 1080,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.14166666666666666
         ],
         "showticklabels": false
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.17166666666666666,
          0.31333333333333335
         ],
         "showticklabels": false
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.3433333333333333,
          0.485
         ],
         "showticklabels": false
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.515,
          0.6566666666666667
         ],
         "showticklabels": false
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0.6866666666666666,
          0.8283333333333334
         ],
         "showticklabels": false
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.8583333333333333,
          1
         ],
         "showticklabels": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "range": [
          0,
          100
         ],
         "showgrid": true,
         "title": {
          "text": "Avg. Success Rate"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "matches": "y",
         "range": [
          0,
          100
         ],
         "showgrid": true,
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "matches": "y",
         "range": [
          0,
          100
         ],
         "showgrid": true,
         "showticklabels": false
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "matches": "y",
         "range": [
          0,
          100
         ],
         "showgrid": true,
         "showticklabels": false
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "matches": "y",
         "range": [
          0,
          100
         ],
         "showgrid": true,
         "showticklabels": false
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "matches": "y",
         "range": [
          0,
          100
         ],
         "showgrid": true,
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plot_win_rates(summary_df)\n",
    "fig.update_layout(\n",
    "        \n",
    "        legend=dict(\n",
    "            title='Models',\n",
    "            orientation='h',\n",
    "            yanchor='bottom',\n",
    "            y=1.18,\n",
    "            xanchor='center',\n",
    "            x=0.5,\n",
    "            bgcolor='rgba(255,255,255,0.9)',\n",
    "            bordercolor='black',\n",
    "            borderwidth=1\n",
    "        ),\n",
    "        margin=dict(t=100, b=50, l=80, r=20),\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "35d969d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env</th>\n",
       "      <th>model</th>\n",
       "      <th>word_limit</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customer_service</td>\n",
       "      <td>deepseek/deepseek-chat (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.505736</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>customer_service</td>\n",
       "      <td>deepseek/deepseek-chat (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.464095</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>customer_service</td>\n",
       "      <td>deepseek/deepseek-chat (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.422902</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>customer_service</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.452203</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>customer_service</td>\n",
       "      <td>deepseek/deepseek-r1 (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>customer_service</td>\n",
       "      <td>deepseek/deepseek-r1 (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.506370</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>customer_service</td>\n",
       "      <td>google/gemini-2.5-pro (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.303822</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>customer_service</td>\n",
       "      <td>google/gemini-2.5-pro (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.220721</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>customer_service</td>\n",
       "      <td>google/gemini-2.5-pro (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>guess_my_city</td>\n",
       "      <td>deepseek/deepseek-chat (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.438529</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>guess_my_city</td>\n",
       "      <td>deepseek/deepseek-chat (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.496139</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>guess_my_city</td>\n",
       "      <td>deepseek/deepseek-chat (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.503831</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>guess_my_city</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.503831</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>guess_my_city</td>\n",
       "      <td>deepseek/deepseek-r1 (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.505736</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>guess_my_city</td>\n",
       "      <td>deepseek/deepseek-r1 (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>guess_my_city</td>\n",
       "      <td>google/gemini-2.5-pro (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.405096</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>guess_my_city</td>\n",
       "      <td>google/gemini-2.5-pro (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.452203</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>guess_my_city</td>\n",
       "      <td>google/gemini-2.5-pro (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.384808</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mastermind</td>\n",
       "      <td>deepseek/deepseek-chat (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.220721</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mastermind</td>\n",
       "      <td>deepseek/deepseek-chat (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.220721</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mastermind</td>\n",
       "      <td>deepseek/deepseek-chat (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.220721</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mastermind</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mastermind</td>\n",
       "      <td>deepseek/deepseek-r1 (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.505736</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mastermind</td>\n",
       "      <td>deepseek/deepseek-r1 (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.464095</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mastermind</td>\n",
       "      <td>google/gemini-2.5-pro (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mastermind</td>\n",
       "      <td>google/gemini-2.5-pro (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mastermind</td>\n",
       "      <td>google/gemini-2.5-pro (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>murder_mystery</td>\n",
       "      <td>deepseek/deepseek-chat (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>murder_mystery</td>\n",
       "      <td>deepseek/deepseek-chat (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.452203</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>murder_mystery</td>\n",
       "      <td>deepseek/deepseek-chat (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.422902</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>murder_mystery</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.334932</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>murder_mystery</td>\n",
       "      <td>deepseek/deepseek-r1 (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.500641</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>murder_mystery</td>\n",
       "      <td>deepseek/deepseek-r1 (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.303822</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>murder_mystery</td>\n",
       "      <td>google/gemini-2.5-pro (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.303822</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>murder_mystery</td>\n",
       "      <td>google/gemini-2.5-pro (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.405096</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>murder_mystery</td>\n",
       "      <td>google/gemini-2.5-pro (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.405096</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>deepseek/deepseek-chat (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>deepseek/deepseek-chat (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.505736</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>deepseek/deepseek-chat (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.505736</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.496139</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>deepseek/deepseek-r1 (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.503831</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>deepseek/deepseek-r1 (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.496139</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>google/gemini-2.5-pro (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.505736</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>google/gemini-2.5-pro (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.438529</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>google/gemini-2.5-pro (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.490290</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>wordle</td>\n",
       "      <td>Qwen/Qwen2.5-14B-instruct (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>wordle</td>\n",
       "      <td>Qwen/Qwen2.5-14B-instruct (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>wordle</td>\n",
       "      <td>Qwen/Qwen2.5-14B-instruct (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>wordle</td>\n",
       "      <td>deepseek/deepseek-chat (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.474342</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>wordle</td>\n",
       "      <td>deepseek/deepseek-chat (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.500641</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>wordle</td>\n",
       "      <td>deepseek/deepseek-chat (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.505736</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>wordle</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.361620</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>wordle</td>\n",
       "      <td>deepseek/deepseek-r1 (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.384808</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>wordle</td>\n",
       "      <td>deepseek/deepseek-r1 (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.303822</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>wordle</td>\n",
       "      <td>google/gemini-2.5-pro (belief)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.405096</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>wordle</td>\n",
       "      <td>google/gemini-2.5-pro (both)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.220721</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>wordle</td>\n",
       "      <td>google/gemini-2.5-pro (history)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 env                                model word_limit   mean  \\\n",
       "0   customer_service      deepseek/deepseek-chat (belief)       None  0.475   \n",
       "1   customer_service        deepseek/deepseek-chat (both)       None  0.700   \n",
       "2   customer_service     deepseek/deepseek-chat (history)       None  0.775   \n",
       "3   customer_service        deepseek/deepseek-r1 (belief)       None  0.725   \n",
       "4   customer_service          deepseek/deepseek-r1 (both)       None  0.650   \n",
       "5   customer_service       deepseek/deepseek-r1 (history)       None  0.500   \n",
       "6   customer_service       google/gemini-2.5-pro (belief)       None  0.900   \n",
       "7   customer_service         google/gemini-2.5-pro (both)       None  0.950   \n",
       "8   customer_service      google/gemini-2.5-pro (history)       None  1.000   \n",
       "9      guess_my_city      deepseek/deepseek-chat (belief)       None  0.750   \n",
       "10     guess_my_city        deepseek/deepseek-chat (both)       None  0.600   \n",
       "11     guess_my_city     deepseek/deepseek-chat (history)       None  0.550   \n",
       "12     guess_my_city        deepseek/deepseek-r1 (belief)       None  0.550   \n",
       "13     guess_my_city          deepseek/deepseek-r1 (both)       None  0.525   \n",
       "14     guess_my_city       deepseek/deepseek-r1 (history)       None  0.650   \n",
       "15     guess_my_city       google/gemini-2.5-pro (belief)       None  0.800   \n",
       "16     guess_my_city         google/gemini-2.5-pro (both)       None  0.725   \n",
       "17     guess_my_city      google/gemini-2.5-pro (history)       None  0.825   \n",
       "18        mastermind      deepseek/deepseek-chat (belief)       None  0.050   \n",
       "19        mastermind        deepseek/deepseek-chat (both)       None  0.050   \n",
       "20        mastermind     deepseek/deepseek-chat (history)       None  0.050   \n",
       "21        mastermind        deepseek/deepseek-r1 (belief)       None  0.350   \n",
       "22        mastermind          deepseek/deepseek-r1 (both)       None  0.525   \n",
       "23        mastermind       deepseek/deepseek-r1 (history)       None  0.700   \n",
       "24        mastermind       google/gemini-2.5-pro (belief)       None  0.975   \n",
       "25        mastermind         google/gemini-2.5-pro (both)       None  0.975   \n",
       "26        mastermind      google/gemini-2.5-pro (history)       None  1.000   \n",
       "27    murder_mystery      deepseek/deepseek-chat (belief)       None  0.350   \n",
       "28    murder_mystery        deepseek/deepseek-chat (both)       None  0.725   \n",
       "29    murder_mystery     deepseek/deepseek-chat (history)       None  0.775   \n",
       "30    murder_mystery        deepseek/deepseek-r1 (belief)       None  0.125   \n",
       "31    murder_mystery          deepseek/deepseek-r1 (both)       None  0.425   \n",
       "32    murder_mystery       deepseek/deepseek-r1 (history)       None  0.900   \n",
       "33    murder_mystery       google/gemini-2.5-pro (belief)       None  0.900   \n",
       "34    murder_mystery         google/gemini-2.5-pro (both)       None  0.800   \n",
       "35    murder_mystery      google/gemini-2.5-pro (history)       None  0.800   \n",
       "36  twenty_questions      deepseek/deepseek-chat (belief)       None  0.350   \n",
       "37  twenty_questions        deepseek/deepseek-chat (both)       None  0.475   \n",
       "38  twenty_questions     deepseek/deepseek-chat (history)       None  0.475   \n",
       "39  twenty_questions        deepseek/deepseek-r1 (belief)       None  0.400   \n",
       "40  twenty_questions          deepseek/deepseek-r1 (both)       None  0.450   \n",
       "41  twenty_questions       deepseek/deepseek-r1 (history)       None  0.600   \n",
       "42  twenty_questions       google/gemini-2.5-pro (belief)       None  0.525   \n",
       "43  twenty_questions         google/gemini-2.5-pro (both)       None  0.750   \n",
       "44  twenty_questions      google/gemini-2.5-pro (history)       None  0.625   \n",
       "45            wordle   Qwen/Qwen2.5-14B-instruct (belief)       None  0.000   \n",
       "46            wordle     Qwen/Qwen2.5-14B-instruct (both)       None  0.000   \n",
       "47            wordle  Qwen/Qwen2.5-14B-instruct (history)       None  0.000   \n",
       "48            wordle      deepseek/deepseek-chat (belief)       None  0.325   \n",
       "49            wordle        deepseek/deepseek-chat (both)       None  0.425   \n",
       "50            wordle     deepseek/deepseek-chat (history)       None  0.525   \n",
       "51            wordle        deepseek/deepseek-r1 (belief)       None  0.850   \n",
       "52            wordle          deepseek/deepseek-r1 (both)       None  0.825   \n",
       "53            wordle       deepseek/deepseek-r1 (history)       None  0.900   \n",
       "54            wordle       google/gemini-2.5-pro (belief)       None  0.800   \n",
       "55            wordle         google/gemini-2.5-pro (both)       None  0.950   \n",
       "56            wordle      google/gemini-2.5-pro (history)       None  0.975   \n",
       "\n",
       "         std  count  \n",
       "0   0.505736     40  \n",
       "1   0.464095     40  \n",
       "2   0.422902     40  \n",
       "3   0.452203     40  \n",
       "4   0.483046     40  \n",
       "5   0.506370     40  \n",
       "6   0.303822     40  \n",
       "7   0.220721     40  \n",
       "8   0.000000     40  \n",
       "9   0.438529     40  \n",
       "10  0.496139     40  \n",
       "11  0.503831     40  \n",
       "12  0.503831     40  \n",
       "13  0.505736     40  \n",
       "14  0.483046     40  \n",
       "15  0.405096     40  \n",
       "16  0.452203     40  \n",
       "17  0.384808     40  \n",
       "18  0.220721     40  \n",
       "19  0.220721     40  \n",
       "20  0.220721     40  \n",
       "21  0.483046     40  \n",
       "22  0.505736     40  \n",
       "23  0.464095     40  \n",
       "24  0.158114     40  \n",
       "25  0.158114     40  \n",
       "26  0.000000     40  \n",
       "27  0.483046     40  \n",
       "28  0.452203     40  \n",
       "29  0.422902     40  \n",
       "30  0.334932     40  \n",
       "31  0.500641     40  \n",
       "32  0.303822     40  \n",
       "33  0.303822     40  \n",
       "34  0.405096     40  \n",
       "35  0.405096     40  \n",
       "36  0.483046     40  \n",
       "37  0.505736     40  \n",
       "38  0.505736     40  \n",
       "39  0.496139     40  \n",
       "40  0.503831     40  \n",
       "41  0.496139     40  \n",
       "42  0.505736     40  \n",
       "43  0.438529     40  \n",
       "44  0.490290     40  \n",
       "45  0.000000     10  \n",
       "46  0.000000     10  \n",
       "47  0.000000     10  \n",
       "48  0.474342     40  \n",
       "49  0.500641     40  \n",
       "50  0.505736     40  \n",
       "51  0.361620     40  \n",
       "52  0.384808     40  \n",
       "53  0.303822     40  \n",
       "54  0.405096     40  \n",
       "55  0.220721     40  \n",
       "56  0.158114     40  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = summary_df.groupby(['env', 'model', 'word_limit'])['won'].agg(['mean', 'std', 'count']).reset_index()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "28fa974c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Env: mastermind<br>Word Limit: None<br>Model: deepseek/deepseek-r1<br>Success Rate: {y:.2f}%",
         "marker": {
          "color": "#2E91E5"
         },
         "name": "deepseek/deepseek-r1",
         "showlegend": true,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAAWUA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "Env: murder_mystery<br>Word Limit: None<br>Model: deepseek/deepseek-r1<br>Success Rate: {y:.2f}%",
         "marker": {
          "color": "#2E91E5"
         },
         "name": "deepseek/deepseek-r1",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "AAAAAAAAWUA=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "hovertemplate": "Env: twenty_questions<br>Word Limit: None<br>Model: deepseek/deepseek-r1<br>Success Rate: {y:.2f}%",
         "marker": {
          "color": "#2E91E5"
         },
         "name": "deepseek/deepseek-r1",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "AAAAAAAAAAA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "hovertemplate": "Env: wordle<br>Word Limit: None<br>Model: deepseek/deepseek-r1<br>Success Rate: {y:.2f}%",
         "marker": {
          "color": "#2E91E5"
         },
         "name": "deepseek/deepseek-r1",
         "showlegend": false,
         "type": "bar",
         "width": 0.8,
         "x": [
          "deepseek/deepseek-r1"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "AAAAAAAAWUA=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "mastermind",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "murder_mystery",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "twenty_questions",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "wordle",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 14
          },
          "showarrow": false,
          "text": "Word Limit: None",
          "x": 0.1,
          "xref": "paper",
          "y": 0.95,
          "yref": "paper"
         }
        ],
        "barmode": "group",
        "font": {
         "family": "Computer Modern, serif",
         "size": 16
        },
        "height": 350,
        "legend": {
         "bgcolor": "rgba(255,255,255,0.9)",
         "bordercolor": "black",
         "borderwidth": 1,
         "orientation": "h",
         "title": {
          "text": "Models"
         },
         "x": 0.5,
         "xanchor": "center",
         "y": 1.18,
         "yanchor": "bottom"
        },
        "margin": {
         "b": 50,
         "l": 80,
         "r": 20,
         "t": 100
        },
        "plot_bgcolor": "white",
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "width": 720,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.175
         ],
         "showticklabels": false
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.275,
          0.45
         ],
         "showticklabels": false
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showticklabels": false
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.825,
          1
         ],
         "showticklabels": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "range": [
          0,
          100
         ],
         "showgrid": true
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "matches": "y",
         "range": [
          0,
          100
         ],
         "showgrid": true,
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "matches": "y",
         "range": [
          0,
          100
         ],
         "showgrid": true,
         "showticklabels": false
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgray",
         "matches": "y",
         "range": [
          0,
          100
         ],
         "showgrid": true,
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plot_win_rates(summary_df_history)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e251b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'game_id', 'env', 'attempt', 'raw_guess', 'guess', 'response',\n",
       "       'word_limit', 'score', 'done', 'data', 'belief', 'action_reasoning',\n",
       "       'belief_reasoning'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "faa2c74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "wordle_sample = df[\n",
    "    (df['model'] == 'deepseek/deepseek-r1 (belief)') & \\\n",
    "        (df['env'] == 'twenty_questions') & \\\n",
    "            (df['game_id'] == str(0)) & \\\n",
    "            (df['info'] == 'belief')\n",
    "            ]\n",
    "print(len(wordle_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f9676af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>game_id</th>\n",
       "      <th>env</th>\n",
       "      <th>attempt</th>\n",
       "      <th>info</th>\n",
       "      <th>raw_guess</th>\n",
       "      <th>guess</th>\n",
       "      <th>response</th>\n",
       "      <th>word_limit</th>\n",
       "      <th>score</th>\n",
       "      <th>done</th>\n",
       "      <th>data</th>\n",
       "      <th>belief</th>\n",
       "      <th>action_reasoning</th>\n",
       "      <th>belief_reasoning</th>\n",
       "      <th>model_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>1</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; Start by distinguishing between common...</td>\n",
       "      <td>Is the vegetable typically grown underground?</td>\n",
       "      <td>yes.</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is a root vegetable typically gr...</td>\n",
       "      <td>Okay, so I'm trying to guess a vegetable in 20...</td>\n",
       "      <td>Okay, so I need to update the belief state aft...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>2</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; Asking whether the vegetable is a bulb...</td>\n",
       "      <td>Is the vegetable a bulb, such as onion or garlic?</td>\n",
       "      <td>no.</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is a root vegetable typically gr...</td>\n",
       "      <td>Okay, so the user is playing 20 Questions and ...</td>\n",
       "      <td>Okay, let's see. The user is playing 20 Questi...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>3</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; Asking whether the vegetable is a tube...</td>\n",
       "      <td>Is the vegetable classified as a tuber (e.g., ...</td>\n",
       "      <td>yes.</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is confirmed to be a tuber (e.g....</td>\n",
       "      <td>Okay, let's see. The belief state says it's a ...</td>\n",
       "      <td>Okay, let's break this down. The user provided...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>4</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt;Since the belief state confirms the veg...</td>\n",
       "      <td>Is the vegetable a potato?</td>\n",
       "      <td>no.</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is confirmed to be a tuber, but ...</td>\n",
       "      <td>Okay, so the belief state says the vegetable i...</td>\n",
       "      <td>Okay, let's break down how to update the belie...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>5</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt;\\nTo differentiate between the remainin...</td>\n",
       "      <td>Is the vegetable typically smaller than a pota...</td>\n",
       "      <td>yes.</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is a tuber, confirmed not to be ...</td>\n",
       "      <td>Okay, let's see. The user is trying to figure ...</td>\n",
       "      <td>Okay, let me process this step by step. The cu...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>6</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; The belief strongly points to Jerusale...</td>\n",
       "      <td>Does the vegetable have thin, pale brown skin?</td>\n",
       "      <td>yes.</td>\n",
       "      <td>None</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is a tuber smaller than a potato...</td>\n",
       "      <td>Okay, let's see. The belief state says the veg...</td>\n",
       "      <td>Okay, let me see. The user is playing 20 Quest...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>7</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; The vegetable is likely a sunchoke bas...</td>\n",
       "      <td>Is the vegetable known for having a slightly n...</td>\n",
       "      <td>yes.</td>\n",
       "      <td>None</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is confirmed to have a slightly ...</td>\n",
       "      <td>Okay, so based on the belief state, the curren...</td>\n",
       "      <td>Okay, the user is playing 20 Questions trying ...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>8</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt;The belief state strongly indicates Jer...</td>\n",
       "      <td>Is the vegetable a Jerusalem artichoke (suncho...</td>\n",
       "      <td>no.</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is a small, knobby tuber with th...</td>\n",
       "      <td>Okay, so based on the belief state, the assist...</td>\n",
       "      <td>Okay, so the user was pretty confident that th...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>9</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt;To distinguish between Yacon (eaten raw...</td>\n",
       "      <td>Is the vegetable commonly eaten raw?</td>\n",
       "      <td>no.</td>\n",
       "      <td>None</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is a small, knobby tuber with th...</td>\n",
       "      <td>Okay, so I'm trying to figure out which vegeta...</td>\n",
       "      <td>Okay, let me try to update the belief state ba...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>10</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; To distinguish between Crosne and Chin...</td>\n",
       "      <td>Is the vegetable typically known for having a ...</td>\n",
       "      <td>yes.</td>\n",
       "      <td>None</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is identified as **Crosne (Chine...</td>\n",
       "      <td>Okay, let's see. The belief state says the veg...</td>\n",
       "      <td>Okay, let me process this. The user is playing...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>11</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; Given the belief that the vegetable is...</td>\n",
       "      <td>Is the vegetable characterized by small, spira...</td>\n",
       "      <td>no.</td>\n",
       "      <td>None</td>\n",
       "      <td>11.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is **not Crosne** (spiral-shaped...</td>\n",
       "      <td>Okay, let me try to figure out the next step h...</td>\n",
       "      <td>Okay, let's process this. The current belief w...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>12</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; Since the key candidates (water chestn...</td>\n",
       "      <td>Is it round and smooth?</td>\n",
       "      <td>no.</td>\n",
       "      <td>None</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is **not Crosne**, potato, carro...</td>\n",
       "      <td>Okay, let's see. The user is trying to guess a...</td>\n",
       "      <td>Okay, so the user is playing 20 Questions, try...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>13</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; Both candidates are knobby, so confirm...</td>\n",
       "      <td>Is the vegetable commonly used in Asian cuisine?</td>\n",
       "      <td>yes.</td>\n",
       "      <td>None</td>\n",
       "      <td>13.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>Current belief: The vegetable is **not** Crosn...</td>\n",
       "      <td>Okay, let's see. The user is trying to guess a...</td>\n",
       "      <td>Okay, let me go through this step by step. The...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>14</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; The belief state indicates burdock roo...</td>\n",
       "      <td>Guess: Burdock root (gobo)</td>\n",
       "      <td>no.</td>\n",
       "      <td>None</td>\n",
       "      <td>14.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>&lt;BELIEW&gt;\\nCurrent belief: The vegetable is **n...</td>\n",
       "      <td>Okay, let's break this down. The belief state ...</td>\n",
       "      <td>Okay, let's see. The user was trying to guess ...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>15</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; The belief state strongly points to lo...</td>\n",
       "      <td>Is the vegetable lotus root?</td>\n",
       "      <td>no.</td>\n",
       "      <td>None</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is **not** Burdock root (gobo), ...</td>\n",
       "      <td>Okay, so the belief state says they've narrowe...</td>\n",
       "      <td>Okay, so the user is playing 20 Questions tryi...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>16</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; To differentiate between water caltrop...</td>\n",
       "      <td>Is the vegetable characterized by horn-shaped ...</td>\n",
       "      <td>no.</td>\n",
       "      <td>None</td>\n",
       "      <td>16.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is **not** Burdock root, Crosne,...</td>\n",
       "      <td>Okay, let's see. The user is trying to guess a...</td>\n",
       "      <td>Okay, let's see. The current belief says the v...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>17</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; The key distinction is whether the veg...</td>\n",
       "      <td>Is the vegetable primarily used as a spice or ...</td>\n",
       "      <td>no.</td>\n",
       "      <td>None</td>\n",
       "      <td>17.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is **not** Burdock root, Crosne,...</td>\n",
       "      <td>Okay, let's see. The user has narrowed down th...</td>\n",
       "      <td>Okay, let me update the belief based on the la...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>18</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt;Since crunchiness when cooked is confir...</td>\n",
       "      <td>Is the vegetable commonly stir-fried in Asian ...</td>\n",
       "      <td>yes.</td>\n",
       "      <td>None</td>\n",
       "      <td>18.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is **not** Burdock root, Crosne,...</td>\n",
       "      <td>Okay, let's break this down. The user is tryin...</td>\n",
       "      <td>Okay, let's see. The user is playing 20 Questi...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>19</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt; Considering the narrowed possibilities...</td>\n",
       "      <td>Is the vegetable a gourd (e.g., ivy gourd)?</td>\n",
       "      <td>no.</td>\n",
       "      <td>None</td>\n",
       "      <td>19.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is **not** Burdock root, Crosne,...</td>\n",
       "      <td>Okay, let me process the information given. Th...</td>\n",
       "      <td>Okay, let's break this down. The user is playi...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "      <td>0</td>\n",
       "      <td>twenty_questions</td>\n",
       "      <td>20</td>\n",
       "      <td>belief</td>\n",
       "      <td>&lt;Think&gt;  \\nTo narrow down between the remainin...</td>\n",
       "      <td>Is the vegetable commonly recognized by a wing...</td>\n",
       "      <td>no.</td>\n",
       "      <td>None</td>\n",
       "      <td>20.0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'agent_game_scenario': 'vegetable', 'env_game...</td>\n",
       "      <td>The vegetable is **not** Burdock root, Crosne,...</td>\n",
       "      <td>Okay, let's break this down. The user is tryin...</td>\n",
       "      <td>Okay, so the user is playing 20 Questions tryi...</td>\n",
       "      <td>deepseek/deepseek-r1 (belief)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model game_id               env  attempt    info  \\\n",
       "554  deepseek/deepseek-r1 (belief)       0  twenty_questions        1  belief   \n",
       "555  deepseek/deepseek-r1 (belief)       0  twenty_questions        2  belief   \n",
       "556  deepseek/deepseek-r1 (belief)       0  twenty_questions        3  belief   \n",
       "557  deepseek/deepseek-r1 (belief)       0  twenty_questions        4  belief   \n",
       "558  deepseek/deepseek-r1 (belief)       0  twenty_questions        5  belief   \n",
       "559  deepseek/deepseek-r1 (belief)       0  twenty_questions        6  belief   \n",
       "560  deepseek/deepseek-r1 (belief)       0  twenty_questions        7  belief   \n",
       "561  deepseek/deepseek-r1 (belief)       0  twenty_questions        8  belief   \n",
       "562  deepseek/deepseek-r1 (belief)       0  twenty_questions        9  belief   \n",
       "563  deepseek/deepseek-r1 (belief)       0  twenty_questions       10  belief   \n",
       "564  deepseek/deepseek-r1 (belief)       0  twenty_questions       11  belief   \n",
       "565  deepseek/deepseek-r1 (belief)       0  twenty_questions       12  belief   \n",
       "566  deepseek/deepseek-r1 (belief)       0  twenty_questions       13  belief   \n",
       "567  deepseek/deepseek-r1 (belief)       0  twenty_questions       14  belief   \n",
       "568  deepseek/deepseek-r1 (belief)       0  twenty_questions       15  belief   \n",
       "569  deepseek/deepseek-r1 (belief)       0  twenty_questions       16  belief   \n",
       "570  deepseek/deepseek-r1 (belief)       0  twenty_questions       17  belief   \n",
       "571  deepseek/deepseek-r1 (belief)       0  twenty_questions       18  belief   \n",
       "572  deepseek/deepseek-r1 (belief)       0  twenty_questions       19  belief   \n",
       "573  deepseek/deepseek-r1 (belief)       0  twenty_questions       20  belief   \n",
       "\n",
       "                                             raw_guess  \\\n",
       "554  <Think> Start by distinguishing between common...   \n",
       "555  <Think> Asking whether the vegetable is a bulb...   \n",
       "556  <Think> Asking whether the vegetable is a tube...   \n",
       "557  <Think>Since the belief state confirms the veg...   \n",
       "558  <Think>\\nTo differentiate between the remainin...   \n",
       "559  <Think> The belief strongly points to Jerusale...   \n",
       "560  <Think> The vegetable is likely a sunchoke bas...   \n",
       "561  <Think>The belief state strongly indicates Jer...   \n",
       "562  <Think>To distinguish between Yacon (eaten raw...   \n",
       "563  <Think> To distinguish between Crosne and Chin...   \n",
       "564  <Think> Given the belief that the vegetable is...   \n",
       "565  <Think> Since the key candidates (water chestn...   \n",
       "566  <Think> Both candidates are knobby, so confirm...   \n",
       "567  <Think> The belief state indicates burdock roo...   \n",
       "568  <Think> The belief state strongly points to lo...   \n",
       "569  <Think> To differentiate between water caltrop...   \n",
       "570  <Think> The key distinction is whether the veg...   \n",
       "571  <Think>Since crunchiness when cooked is confir...   \n",
       "572  <Think> Considering the narrowed possibilities...   \n",
       "573  <Think>  \\nTo narrow down between the remainin...   \n",
       "\n",
       "                                                 guess response word_limit  \\\n",
       "554      Is the vegetable typically grown underground?     yes.       None   \n",
       "555  Is the vegetable a bulb, such as onion or garlic?      no.       None   \n",
       "556  Is the vegetable classified as a tuber (e.g., ...     yes.       None   \n",
       "557                         Is the vegetable a potato?      no.       None   \n",
       "558  Is the vegetable typically smaller than a pota...     yes.       None   \n",
       "559     Does the vegetable have thin, pale brown skin?     yes.       None   \n",
       "560  Is the vegetable known for having a slightly n...     yes.       None   \n",
       "561  Is the vegetable a Jerusalem artichoke (suncho...      no.       None   \n",
       "562               Is the vegetable commonly eaten raw?      no.       None   \n",
       "563  Is the vegetable typically known for having a ...     yes.       None   \n",
       "564  Is the vegetable characterized by small, spira...      no.       None   \n",
       "565                            Is it round and smooth?      no.       None   \n",
       "566   Is the vegetable commonly used in Asian cuisine?     yes.       None   \n",
       "567                         Guess: Burdock root (gobo)      no.       None   \n",
       "568                       Is the vegetable lotus root?      no.       None   \n",
       "569  Is the vegetable characterized by horn-shaped ...      no.       None   \n",
       "570  Is the vegetable primarily used as a spice or ...      no.       None   \n",
       "571  Is the vegetable commonly stir-fried in Asian ...     yes.       None   \n",
       "572        Is the vegetable a gourd (e.g., ivy gourd)?      no.       None   \n",
       "573  Is the vegetable commonly recognized by a wing...      no.       None   \n",
       "\n",
       "     score  done                                               data  \\\n",
       "554    1.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "555    2.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "556    3.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "557    4.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "558    5.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "559    6.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "560    7.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "561    8.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "562    9.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "563   10.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "564   11.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "565   12.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "566   13.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "567   14.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "568   15.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "569   16.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "570   17.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "571   18.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "572   19.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "573   20.0  True  {'agent_game_scenario': 'vegetable', 'env_game...   \n",
       "\n",
       "                                                belief  \\\n",
       "554  The vegetable is a root vegetable typically gr...   \n",
       "555  The vegetable is a root vegetable typically gr...   \n",
       "556  The vegetable is confirmed to be a tuber (e.g....   \n",
       "557  The vegetable is confirmed to be a tuber, but ...   \n",
       "558  The vegetable is a tuber, confirmed not to be ...   \n",
       "559  The vegetable is a tuber smaller than a potato...   \n",
       "560  The vegetable is confirmed to have a slightly ...   \n",
       "561  The vegetable is a small, knobby tuber with th...   \n",
       "562  The vegetable is a small, knobby tuber with th...   \n",
       "563  The vegetable is identified as **Crosne (Chine...   \n",
       "564  The vegetable is **not Crosne** (spiral-shaped...   \n",
       "565  The vegetable is **not Crosne**, potato, carro...   \n",
       "566  Current belief: The vegetable is **not** Crosn...   \n",
       "567  <BELIEW>\\nCurrent belief: The vegetable is **n...   \n",
       "568  The vegetable is **not** Burdock root (gobo), ...   \n",
       "569  The vegetable is **not** Burdock root, Crosne,...   \n",
       "570  The vegetable is **not** Burdock root, Crosne,...   \n",
       "571  The vegetable is **not** Burdock root, Crosne,...   \n",
       "572  The vegetable is **not** Burdock root, Crosne,...   \n",
       "573  The vegetable is **not** Burdock root, Crosne,...   \n",
       "\n",
       "                                      action_reasoning  \\\n",
       "554  Okay, so I'm trying to guess a vegetable in 20...   \n",
       "555  Okay, so the user is playing 20 Questions and ...   \n",
       "556  Okay, let's see. The belief state says it's a ...   \n",
       "557  Okay, so the belief state says the vegetable i...   \n",
       "558  Okay, let's see. The user is trying to figure ...   \n",
       "559  Okay, let's see. The belief state says the veg...   \n",
       "560  Okay, so based on the belief state, the curren...   \n",
       "561  Okay, so based on the belief state, the assist...   \n",
       "562  Okay, so I'm trying to figure out which vegeta...   \n",
       "563  Okay, let's see. The belief state says the veg...   \n",
       "564  Okay, let me try to figure out the next step h...   \n",
       "565  Okay, let's see. The user is trying to guess a...   \n",
       "566  Okay, let's see. The user is trying to guess a...   \n",
       "567  Okay, let's break this down. The belief state ...   \n",
       "568  Okay, so the belief state says they've narrowe...   \n",
       "569  Okay, let's see. The user is trying to guess a...   \n",
       "570  Okay, let's see. The user has narrowed down th...   \n",
       "571  Okay, let's break this down. The user is tryin...   \n",
       "572  Okay, let me process the information given. Th...   \n",
       "573  Okay, let's break this down. The user is tryin...   \n",
       "\n",
       "                                      belief_reasoning  \\\n",
       "554  Okay, so I need to update the belief state aft...   \n",
       "555  Okay, let's see. The user is playing 20 Questi...   \n",
       "556  Okay, let's break this down. The user provided...   \n",
       "557  Okay, let's break down how to update the belie...   \n",
       "558  Okay, let me process this step by step. The cu...   \n",
       "559  Okay, let me see. The user is playing 20 Quest...   \n",
       "560  Okay, the user is playing 20 Questions trying ...   \n",
       "561  Okay, so the user was pretty confident that th...   \n",
       "562  Okay, let me try to update the belief state ba...   \n",
       "563  Okay, let me process this. The user is playing...   \n",
       "564  Okay, let's process this. The current belief w...   \n",
       "565  Okay, so the user is playing 20 Questions, try...   \n",
       "566  Okay, let me go through this step by step. The...   \n",
       "567  Okay, let's see. The user was trying to guess ...   \n",
       "568  Okay, so the user is playing 20 Questions tryi...   \n",
       "569  Okay, let's see. The current belief says the v...   \n",
       "570  Okay, let me update the belief based on the la...   \n",
       "571  Okay, let's see. The user is playing 20 Questi...   \n",
       "572  Okay, let's break this down. The user is playi...   \n",
       "573  Okay, so the user is playing 20 Questions tryi...   \n",
       "\n",
       "                        model_info  \n",
       "554  deepseek/deepseek-r1 (belief)  \n",
       "555  deepseek/deepseek-r1 (belief)  \n",
       "556  deepseek/deepseek-r1 (belief)  \n",
       "557  deepseek/deepseek-r1 (belief)  \n",
       "558  deepseek/deepseek-r1 (belief)  \n",
       "559  deepseek/deepseek-r1 (belief)  \n",
       "560  deepseek/deepseek-r1 (belief)  \n",
       "561  deepseek/deepseek-r1 (belief)  \n",
       "562  deepseek/deepseek-r1 (belief)  \n",
       "563  deepseek/deepseek-r1 (belief)  \n",
       "564  deepseek/deepseek-r1 (belief)  \n",
       "565  deepseek/deepseek-r1 (belief)  \n",
       "566  deepseek/deepseek-r1 (belief)  \n",
       "567  deepseek/deepseek-r1 (belief)  \n",
       "568  deepseek/deepseek-r1 (belief)  \n",
       "569  deepseek/deepseek-r1 (belief)  \n",
       "570  deepseek/deepseek-r1 (belief)  \n",
       "571  deepseek/deepseek-r1 (belief)  \n",
       "572  deepseek/deepseek-r1 (belief)  \n",
       "573  deepseek/deepseek-r1 (belief)  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordle_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2af8aebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The vegetable is **not** Burdock root, Crosne, potato, carrot, beet, Chinese '\n",
      " 'yam, water chestnut, jicama, Jerusalem artichoke, lotus root, water caltrop, '\n",
      " 'galangal, **gourd (including ivy gourd)**, Hosui pear-shaped yam, **or '\n",
      " 'winged yam (Dioscorea alata)**.  \\n'\n",
      " '**Confirmed traits**:  \\n'\n",
      " '- Crunchy when cooked.  \\n'\n",
      " '- Small, knobby, non-round/non-smooth appearance.  \\n'\n",
      " '- Pale brown skin with nutty/sweet flavor.  \\n'\n",
      " '- Asian origin (common in Asian cuisine).  \\n'\n",
      " '- Primarily used as a culinary vegetable (**not** a spice/herb).  \\n'\n",
      " '- Commonly stir-fried in Asian dishes.  \\n'\n",
      " '**Narrowed possibilities**:  \\n'\n",
      " '- Excludes winged/lobed shapes. Focus on knobby, irregularly shaped '\n",
      " 'tubers/roots.  \\n'\n",
      " '- Candidates: Lesser-known Southeast Asian tubers (e.g., *greater yam '\n",
      " 'variants*, *Taro cultivars* with knobby texture) or fibrous-textured roots '\n",
      " 'used in Thai/Malay/Indonesian stir-fries.  \\n'\n",
      " '- Key questions remaining: Distinguish between starchy vs. fibrous texture, '\n",
      " 'regional specificity (e.g., Thai vs. Filipino cuisine), or cooking methods '\n",
      " 'beyond stir-fry (e.g., soups, pickling).')\n"
     ]
    }
   ],
   "source": [
    "pp(wordle_sample.iloc[19]['belief'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb344f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8799a5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495517be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c57f8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df4c224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90539d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
